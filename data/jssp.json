{
    "current_population": [
        {
            "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
            },
            "fitness": 23.42775824076793,
            "solver_reports": [
                {
                    "total_time": 12.38,
                    "explored_nodes": 1,
                    "simplex_iterations": 27620,
                    "explored_time": 12.33,
                    "work_units": 10.0
                },
                {
                    "total_time": 10.55,
                    "explored_nodes": 1,
                    "simplex_iterations": 37042,
                    "explored_time": 10.5,
                    "work_units": 10.0
                },
                {
                    "total_time": 11.4,
                    "explored_nodes": 1,
                    "simplex_iterations": 28803,
                    "explored_time": 11.34,
                    "work_units": 10.01
                },
                {
                    "gap": 18.4011,
                    "total_time": 13.75,
                    "explored_nodes": 1,
                    "simplex_iterations": 43262,
                    "explored_time": 13.74,
                    "work_units": 10.06
                },
                {
                    "total_time": 12.31,
                    "explored_nodes": 1,
                    "simplex_iterations": 30048,
                    "explored_time": 12.21,
                    "work_units": 10.0
                },
                {
                    "gap": 0.0,
                    "total_time": 13.01,
                    "explored_nodes": 564,
                    "simplex_iterations": 81963,
                    "explored_time": 13.01,
                    "work_units": 11.03
                },
                {
                    "gap": 22.6865,
                    "total_time": 12.8,
                    "explored_nodes": 1,
                    "simplex_iterations": 42173,
                    "explored_time": 12.78,
                    "work_units": 10.0
                },
                {
                    "total_time": 11.01,
                    "explored_nodes": 1,
                    "simplex_iterations": 37354,
                    "explored_time": 10.96,
                    "work_units": 10.0
                }
            ],
            "generator": "Intersection",
            "parents_id": [
                "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                "101328eb-f36a-4ac9-9863-144887bd3271"
            ]
        },
        {
            "id": "14507db3-6ddd-4e3e-9a9b-4f8750cbb683",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_block_edge_finding_cuts(m):\n        # 1. Preprocessing: Heads (Earliest Start) Calculation\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # Tails Calculation for heuristic block selection\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        # Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            if n_ops < 2: continue\n    \n            # Identify tightest subset (block) on this machine\n            # Maximizing: r_min + sum_p + q_min_approx\n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # Sort candidates by tightness (Lower Bound) to prioritize constraints\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Limit to top critical blocks to manage model size\n        top_blocks = [c['ops'] for c in candidates[:5]]\n    \n        m.edge_finding_cuts = pyo.ConstraintList()\n    \n        # Helper: Expression for \"u precedes v\"\n        def get_prec_expr(u, v):\n            # u, v are (j, k) tuples. Returns pyomo expression (0 or 1)\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # if v < u in tuple order, y is indexed [v,u]. \n                # y[v,u]=1 means v precedes u. u precedes v is 1 - y[v,u].\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Apply Block-Level Edge-Finding Cuts\n        for block in top_blocks:\n            if len(block) < 2: continue\n            \n            # For each operation k in the critical block:\n            # If k is the LAST operation processed in this block, \n            # it must start after all other operations in the block have finished.\n            for k in block:\n                others = [o for o in block if o != k]\n                \n                # Earliest completion of the set (others)\n                min_r_others = min(heads[o] for o in others)\n                sum_p_others = sum(m.p[o] for o in others)\n                bound_val = min_r_others + sum_p_others\n                \n                # Construct Slack: Sum of (1 - (j precedes k)) for all j in others.\n                # If k is indeed last, all j precede k, so (j precedes k) == 1, Slack == 0.\n                # If k is not last, at least one j follows k, Slack >= 1.\n                slack_expr = sum((1 - get_prec_expr(j, k)) for j in others)\n                \n                # Add cut: S_k >= Bound - BigM * Slack\n                m.edge_finding_cuts.add(\n                    m.S[k] >= bound_val - m.bigM * slack_expr\n                )\n    \n    add_critical_block_edge_finding_cuts(model)\n\n    return model\n",
                "added_cut": "def add_critical_block_edge_finding_cuts(m):\n    # 1. Preprocessing: Heads (Earliest Start) Calculation\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # Tails Calculation for heuristic block selection\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    # Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        if n_ops < 2: continue\n\n        # Identify tightest subset (block) on this machine\n        # Maximizing: r_min + sum_p + q_min_approx\n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # Sort candidates by tightness (Lower Bound) to prioritize constraints\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Limit to top critical blocks to manage model size\n    top_blocks = [c['ops'] for c in candidates[:5]]\n\n    m.edge_finding_cuts = pyo.ConstraintList()\n\n    # Helper: Expression for \"u precedes v\"\n    def get_prec_expr(u, v):\n        # u, v are (j, k) tuples. Returns pyomo expression (0 or 1)\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            # if v < u in tuple order, y is indexed [v,u]. \n            # y[v,u]=1 means v precedes u. u precedes v is 1 - y[v,u].\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Apply Block-Level Edge-Finding Cuts\n    for block in top_blocks:\n        if len(block) < 2: continue\n        \n        # For each operation k in the critical block:\n        # If k is the LAST operation processed in this block, \n        # it must start after all other operations in the block have finished.\n        for k in block:\n            others = [o for o in block if o != k]\n            \n            # Earliest completion of the set (others)\n            min_r_others = min(heads[o] for o in others)\n            sum_p_others = sum(m.p[o] for o in others)\n            bound_val = min_r_others + sum_p_others\n            \n            # Construct Slack: Sum of (1 - (j precedes k)) for all j in others.\n            # If k is indeed last, all j precede k, so (j precedes k) == 1, Slack == 0.\n            # If k is not last, at least one j follows k, Slack >= 1.\n            slack_expr = sum((1 - get_prec_expr(j, k)) for j in others)\n            \n            # Add cut: S_k >= Bound - BigM * Slack\n            m.edge_finding_cuts.add(\n                m.S[k] >= bound_val - m.bigM * slack_expr\n            )\n\nadd_critical_block_edge_finding_cuts(model)",
                "idea": "We implement **Generalized Critical Block Edge-Finding**, which strengthens the provided Scored Carlier logic by upgrading from triplet-based cuts to **block-level valid inequalities**. We identify critical subsets of operations (blocks) on bottleneck machines that have high lower bounds (tight release times and tails). For each operation $k$ in such a block $\\Omega$, we impose a **conditional start-time lower bound**: if binary variables imply $k$ is processed last in $\\Omega$, its start time is lifted to at least $\\min_{j \\in \\Omega \\setminus k} r_j + \\sum_{j \\in \\Omega \\setminus k} p_j$. This acts as a linearized Edge-Finding cut, significantly tightening the relaxation on critical paths."
            },
            "fitness": 10.451159809466207,
            "solver_reports": [
                {
                    "gap": 58.9046,
                    "total_time": 15.14,
                    "explored_nodes": 1,
                    "simplex_iterations": 69918,
                    "explored_time": 15.09,
                    "work_units": 10.38
                },
                {
                    "gap": 96.7323,
                    "total_time": 14.4,
                    "explored_nodes": 1,
                    "simplex_iterations": 27946,
                    "explored_time": 14.37,
                    "work_units": 10.0
                },
                {
                    "gap": 96.8266,
                    "total_time": 14.9,
                    "explored_nodes": 1,
                    "simplex_iterations": 29491,
                    "explored_time": 14.85,
                    "work_units": 10.02
                },
                {
                    "gap": 91.2408,
                    "total_time": 17.53,
                    "explored_nodes": 59,
                    "simplex_iterations": 93856,
                    "explored_time": 17.52,
                    "work_units": 13.12
                },
                {
                    "gap": 96.9489,
                    "total_time": 13.55,
                    "explored_nodes": 1,
                    "simplex_iterations": 30067,
                    "explored_time": 13.49,
                    "work_units": 10.01
                },
                {
                    "gap": 35.7358,
                    "total_time": 11.73,
                    "explored_nodes": 4915,
                    "simplex_iterations": 307169,
                    "explored_time": 11.71,
                    "work_units": 10.0
                },
                {
                    "total_time": 11.46,
                    "explored_nodes": 2131,
                    "simplex_iterations": 169297,
                    "explored_time": 11.44,
                    "work_units": 10.01
                },
                {
                    "gap": 96.7052,
                    "total_time": 15.3,
                    "explored_nodes": 1,
                    "simplex_iterations": 28807,
                    "explored_time": 15.26,
                    "work_units": 10.01
                }
            ],
            "generator": "General",
            "parents_id": [
                "23f863a1-a5e8-4533-81dc-bb9c7b47fd7d"
            ]
        },
        {
            "id": "e44f289e-51a1-4dc9-9e6a-d88efdcdc924",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_scored_block_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Heads and Tails\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Helper for disjunctive variables (handles y_uv vs y_vu)\n        def get_y(u, v):\n            if u[0] == v[0] and u[1] == v[1]: return 0\n            if (u[0], u[1]) < (v[0], v[1]):\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        candidates = []\n        WINDOW_SIZE = 8  # Limit block size to keep cuts local and dense\n    \n        # 4. Identify Critical Blocks via Impact Density (Parent 2 Strategy)\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            s_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(s_ops)\n    \n            for i in range(n):\n                # Look ahead within a window to find tight [u...v] blocks\n                for j in range(i + 1, min(i + WINDOW_SIZE, n)):\n                    u = s_ops[i]\n                    v = s_ops[j]\n                    intermediates = s_ops[i+1 : j]\n                    \n                    if not intermediates: continue\n    \n                    # Impact Density Score: Mass / Spread\n                    # Mass includes intermediates; Spread is head difference\n                    mass = m.p[u] + m.p[v] + sum(m.p[k] for k in intermediates)\n                    spread = heads[v] - heads[u]\n                    if spread < 1e-4: spread = 1e-4\n                    \n                    # LB estimation for sorting\n                    lb = heads[u] + mass + tails[v]\n                    score = mass / spread\n    \n                    # Store candidate block\n                    candidates.append({\n                        'u': u, 'v': v,\n                        'inters': intermediates,\n                        'score': score,\n                        'lb': lb\n                    })\n    \n        # 5. Add Aggregated Cuts to Top Candidates\n        # Sort by score to prioritize high density (ambiguous) regions\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        \n        added_count = 0\n        MAX_CUTS = 20\n    \n        for cand in candidates:\n            if added_count >= MAX_CUTS: break\n            u, v = cand['u'], cand['v']\n            inters = cand['inters']\n            y_uv = get_y(u, v)\n    \n            # (A) Sum-based Precedence Cut (Parent 1 Structure)\n            # S_v >= S_u + p_u + sum(p_k * (is_between_u_v)) - M*(1-y_uv)\n            # This aggregates processing times of ALL intermediates found in sequence\n            sum_term = 0\n            for k in inters:\n                # term is 1 iff u -> k -> v\n                term = get_y(u, k) + get_y(k, v) - 1\n                sum_term += m.p[k] * term\n    \n            m.hybrid_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + sum_term - m.bigM * (1 - y_uv)\n            )\n    \n            # (B) Transitivity Anchor (Logic Strengthening)\n            # Enforce transitivity for the largest intermediate to help LP relaxation\n            best_k = max(inters, key=lambda x: m.p[x])\n            m.hybrid_cuts.add(\n                get_y(u, best_k) + get_y(best_k, v) - y_uv <= 1\n            )\n            \n            # (C) Global Propagation (Parent 2 Influence)\n            # Link the tightened local finish of v directly to Cmax\n            m.hybrid_cuts.add(\n                m.Cmax >= m.S[v] + m.p[v] + tails[v]\n            )\n    \n            added_count += 1\n    \n    add_hybrid_scored_block_cuts(model)\n\n    return model\n",
                "added_cut": "def add_hybrid_scored_block_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Heads and Tails\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Helper for disjunctive variables (handles y_uv vs y_vu)\n    def get_y(u, v):\n        if u[0] == v[0] and u[1] == v[1]: return 0\n        if (u[0], u[1]) < (v[0], v[1]):\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    candidates = []\n    WINDOW_SIZE = 8  # Limit block size to keep cuts local and dense\n\n    # 4. Identify Critical Blocks via Impact Density (Parent 2 Strategy)\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        s_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(s_ops)\n\n        for i in range(n):\n            # Look ahead within a window to find tight [u...v] blocks\n            for j in range(i + 1, min(i + WINDOW_SIZE, n)):\n                u = s_ops[i]\n                v = s_ops[j]\n                intermediates = s_ops[i+1 : j]\n                \n                if not intermediates: continue\n\n                # Impact Density Score: Mass / Spread\n                # Mass includes intermediates; Spread is head difference\n                mass = m.p[u] + m.p[v] + sum(m.p[k] for k in intermediates)\n                spread = heads[v] - heads[u]\n                if spread < 1e-4: spread = 1e-4\n                \n                # LB estimation for sorting\n                lb = heads[u] + mass + tails[v]\n                score = mass / spread\n\n                # Store candidate block\n                candidates.append({\n                    'u': u, 'v': v,\n                    'inters': intermediates,\n                    'score': score,\n                    'lb': lb\n                })\n\n    # 5. Add Aggregated Cuts to Top Candidates\n    # Sort by score to prioritize high density (ambiguous) regions\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    added_count = 0\n    MAX_CUTS = 20\n\n    for cand in candidates:\n        if added_count >= MAX_CUTS: break\n        u, v = cand['u'], cand['v']\n        inters = cand['inters']\n        y_uv = get_y(u, v)\n\n        # (A) Sum-based Precedence Cut (Parent 1 Structure)\n        # S_v >= S_u + p_u + sum(p_k * (is_between_u_v)) - M*(1-y_uv)\n        # This aggregates processing times of ALL intermediates found in sequence\n        sum_term = 0\n        for k in inters:\n            # term is 1 iff u -> k -> v\n            term = get_y(u, k) + get_y(k, v) - 1\n            sum_term += m.p[k] * term\n\n        m.hybrid_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + sum_term - m.bigM * (1 - y_uv)\n        )\n\n        # (B) Transitivity Anchor (Logic Strengthening)\n        # Enforce transitivity for the largest intermediate to help LP relaxation\n        best_k = max(inters, key=lambda x: m.p[x])\n        m.hybrid_cuts.add(\n            get_y(u, best_k) + get_y(best_k, v) - y_uv <= 1\n        )\n        \n        # (C) Global Propagation (Parent 2 Influence)\n        # Link the tightened local finish of v directly to Cmax\n        m.hybrid_cuts.add(\n            m.Cmax >= m.S[v] + m.p[v] + tails[v]\n        )\n\n        added_count += 1\n\nadd_hybrid_scored_block_cuts(model)",
                "idea": "We implement **Scored Block-Sum Lifting**, combining the structural aggregation of Parent 1 with the density-based selection of Parent 2. By identifying high-density blocks $[u, v]$ (where processing mass is high relative to the time window), we apply a **Sum-based Precedence Cut**: $S_v \\ge S_u + p_u + \\sum p_k(y_{uk} + y_{kv} - 1) - M(1 - y_{uv})$. This aggregates the delay of *all* topologically intermediate operations into a single strong inequality, strictly tightening the start time of $v$. Combined with tail bound propagation ($C_{max} \\ge S_v + p_v + q_v$), this ensures that sequencing decisions in the most critical regions immediately lift the global lower bound."
            },
            "fitness": 10.800454278736236,
            "solver_reports": [
                {
                    "gap": 95.8767,
                    "total_time": 13.47,
                    "explored_nodes": 1,
                    "simplex_iterations": 33494,
                    "explored_time": 13.44,
                    "work_units": 10.08
                },
                {
                    "gap": 96.6074,
                    "total_time": 16.43,
                    "explored_nodes": 1,
                    "simplex_iterations": 27008,
                    "explored_time": 16.38,
                    "work_units": 10.03
                },
                {
                    "gap": 96.8266,
                    "total_time": 13.63,
                    "explored_nodes": 1,
                    "simplex_iterations": 29339,
                    "explored_time": 13.58,
                    "work_units": 10.01
                },
                {
                    "gap": 47.1999,
                    "total_time": 13.17,
                    "explored_nodes": 1217,
                    "simplex_iterations": 149606,
                    "explored_time": 13.15,
                    "work_units": 10.36
                },
                {
                    "gap": 96.9489,
                    "total_time": 13.67,
                    "explored_nodes": 1,
                    "simplex_iterations": 30025,
                    "explored_time": 13.61,
                    "work_units": 10.01
                },
                {
                    "gap": 32.3713,
                    "total_time": 10.25,
                    "explored_nodes": 7874,
                    "simplex_iterations": 395899,
                    "explored_time": 10.22,
                    "work_units": 10.0
                },
                {
                    "total_time": 10.38,
                    "explored_nodes": 2759,
                    "simplex_iterations": 210343,
                    "explored_time": 10.37,
                    "work_units": 10.2
                },
                {
                    "gap": 93.3737,
                    "total_time": 13.52,
                    "explored_nodes": 1,
                    "simplex_iterations": 35782,
                    "explored_time": 13.48,
                    "work_units": 10.0
                }
            ],
            "generator": "Hybrid",
            "parents_id": [
                "a9d5fa37-53e0-43d3-b897-4595398fc360",
                "23f863a1-a5e8-4533-81dc-bb9c7b47fd7d"
            ]
        },
        {
            "id": "22a9dcb1-7105-41a3-8c4f-94e732806c2e",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_valid_block_cuts(m):\n        # 1. Precompute Heads (Est. Start) and Tails (Est. Remaining Work)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access disjunctive variables y_{uv} safely\n        def get_y(u, v):\n            if u == v: return 0\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.enhanced_block_cuts = pyo.ConstraintList()\n        candidates = []\n    \n        # 3. Identify Critical Blocks via Static Carlier Bounds\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue \n            # Sort operations by earliest start time (Head)\n            s_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(s_ops)\n            best_lb = -1\n            best_pair = None\n            \n            # Find sub-block [u...v] with max static lower bound\n            for i in range(n):\n                u = s_ops[i]\n                p_accum = 0\n                # Iterate possible end ops v\n                for k_idx in range(i + 1, n):\n                    v = s_ops[k_idx]\n                    # LB = Head(u) + p(u) + Sum(p_intermediates) + p(v) + Tail(v)\n                    current_lb = heads[u] + m.p[u] + p_accum + m.p[v] + tails[v]\n                    \n                    if current_lb > best_lb:\n                        best_lb = current_lb\n                        best_pair = (u, v)\n                    \n                    # Add current v to accumulator for subsequent iterations\n                    p_accum += m.p[v]\n            \n            if best_pair:\n                candidates.append({'pair': best_pair, 'lb': best_lb, 'ops': ops})\n    \n        # Sort blocks by tightness (LB)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n        # 4. Apply Cuts to Top Critical Blocks\n        seen = set()\n        for cand in candidates[:8]:\n            u, v = cand['pair']\n            if (u, v) in seen: continue\n            seen.add((u, v))\n    \n            ops = cand['ops']\n            y_uv = get_y(u, v)\n    \n            intermediate_sum_expr = 0\n            \n            # Iterate over all other ops on the machine\n            for k in ops:\n                if k == u or k == v: continue\n                \n                # (A) Triangle Inequality Support\n                # Enforce transitivity: u->k and k->v implies u->v\n                # y_uk + y_kv - y_uv <= 1\n                # This strengthens the relaxation for the sum term below.\n                m.enhanced_block_cuts.add(get_y(u, k) + get_y(k, v) - y_uv <= 1)\n    \n                # (B) Intermediate Sum Term\n                # Term is 1 iff u -> k -> v. \n                # Sums processing times of all jobs strictly between u and v.\n                term = get_y(u, k) + get_y(k, v) - 1\n                intermediate_sum_expr += m.p[k] * term\n    \n            # (C) Lifted Precedence Cut with Global Big-M\n            # S_v >= S_u + p_u + Sum(p_k * term) - BigM * (1 - y_uv)\n            # If y_uv=1, S_v >= S_u + p_u + actual_intermediate_work.\n            # If y_uv=0, S_v >= S_u + ... - BigM (valid/redundant).\n            m.enhanced_block_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + intermediate_sum_expr - m.bigM * (1 - y_uv)\n            )\n    \n            # (D) Tail Bound Propagation\n            m.enhanced_block_cuts.add(m.Cmax >= m.S[v] + m.p[v] + tails[v])\n    \n    add_valid_block_cuts(model)\n\n    return model\n",
                "added_cut": "def add_valid_block_cuts(m):\n    # 1. Precompute Heads (Est. Start) and Tails (Est. Remaining Work)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access disjunctive variables y_{uv} safely\n    def get_y(u, v):\n        if u == v: return 0\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.enhanced_block_cuts = pyo.ConstraintList()\n    candidates = []\n\n    # 3. Identify Critical Blocks via Static Carlier Bounds\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue \n        # Sort operations by earliest start time (Head)\n        s_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(s_ops)\n        best_lb = -1\n        best_pair = None\n        \n        # Find sub-block [u...v] with max static lower bound\n        for i in range(n):\n            u = s_ops[i]\n            p_accum = 0\n            # Iterate possible end ops v\n            for k_idx in range(i + 1, n):\n                v = s_ops[k_idx]\n                # LB = Head(u) + p(u) + Sum(p_intermediates) + p(v) + Tail(v)\n                current_lb = heads[u] + m.p[u] + p_accum + m.p[v] + tails[v]\n                \n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    best_pair = (u, v)\n                \n                # Add current v to accumulator for subsequent iterations\n                p_accum += m.p[v]\n        \n        if best_pair:\n            candidates.append({'pair': best_pair, 'lb': best_lb, 'ops': ops})\n\n    # Sort blocks by tightness (LB)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n\n    # 4. Apply Cuts to Top Critical Blocks\n    seen = set()\n    for cand in candidates[:8]:\n        u, v = cand['pair']\n        if (u, v) in seen: continue\n        seen.add((u, v))\n\n        ops = cand['ops']\n        y_uv = get_y(u, v)\n\n        intermediate_sum_expr = 0\n        \n        # Iterate over all other ops on the machine\n        for k in ops:\n            if k == u or k == v: continue\n            \n            # (A) Triangle Inequality Support\n            # Enforce transitivity: u->k and k->v implies u->v\n            # y_uk + y_kv - y_uv <= 1\n            # This strengthens the relaxation for the sum term below.\n            m.enhanced_block_cuts.add(get_y(u, k) + get_y(k, v) - y_uv <= 1)\n\n            # (B) Intermediate Sum Term\n            # Term is 1 iff u -> k -> v. \n            # Sums processing times of all jobs strictly between u and v.\n            term = get_y(u, k) + get_y(k, v) - 1\n            intermediate_sum_expr += m.p[k] * term\n\n        # (C) Lifted Precedence Cut with Global Big-M\n        # S_v >= S_u + p_u + Sum(p_k * term) - BigM * (1 - y_uv)\n        # If y_uv=1, S_v >= S_u + p_u + actual_intermediate_work.\n        # If y_uv=0, S_v >= S_u + ... - BigM (valid/redundant).\n        m.enhanced_block_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + intermediate_sum_expr - m.bigM * (1 - y_uv)\n        )\n\n        # (D) Tail Bound Propagation\n        m.enhanced_block_cuts.add(m.Cmax >= m.S[v] + m.p[v] + tails[v])\n\nadd_valid_block_cuts(model)",
                "idea": "We apply a corrected **Block Sequence Lifting** strategy. To ensure validity across all problem instances, we use the global `bigM` (sum of all processing times) instead of a local machine load, which prevents invalid cuts when operations are delayed by other machines. The core innovation is the **Intermediate Sum Cut**: for a critical pair $(u, v)$, we enforce $S_v \\ge S_u + p_u + \\sum p_k(y_{uk} + y_{kv} - 1) - M(1-y_{uv})$. This dynamically adds the processing times of all operations scheduled between $u$ and $v$. We simultaneously enforce **Triangle Inequality** cuts ($y_{uk} + y_{kv} - y_{uv} \\le 1$) for all involved operations; this couples the variables, preventing the LP relaxation from setting $y_{uk}$ and $y_{kv}$ high while keeping $y_{uv}$ low, thereby tightening the lower bound."
            },
            "fitness": 9.963877167958726,
            "solver_reports": [
                {
                    "total_time": 13.78,
                    "explored_nodes": 1,
                    "simplex_iterations": 66407,
                    "explored_time": 13.74,
                    "work_units": 10.0
                },
                {
                    "total_time": 14.54,
                    "explored_nodes": 1,
                    "simplex_iterations": 70505,
                    "explored_time": 14.5,
                    "work_units": 10.0
                },
                {
                    "total_time": 13.95,
                    "explored_nodes": 1,
                    "simplex_iterations": 75862,
                    "explored_time": 13.87,
                    "work_units": 10.0
                },
                {
                    "total_time": 9.3,
                    "explored_nodes": 1907,
                    "simplex_iterations": 268710,
                    "explored_time": 9.29,
                    "work_units": 10.02
                },
                {
                    "total_time": 14.13,
                    "explored_nodes": 1,
                    "simplex_iterations": 66781,
                    "explored_time": 14.07,
                    "work_units": 10.0
                },
                {
                    "gap": 33.648,
                    "total_time": 12.06,
                    "explored_nodes": 6531,
                    "simplex_iterations": 412023,
                    "explored_time": 12.04,
                    "work_units": 10.0
                },
                {
                    "total_time": 10.35,
                    "explored_nodes": 1100,
                    "simplex_iterations": 202043,
                    "explored_time": 10.34,
                    "work_units": 10.02
                },
                {
                    "gap": 95.2053,
                    "total_time": 13.75,
                    "explored_nodes": 1,
                    "simplex_iterations": 68009,
                    "explored_time": 13.71,
                    "work_units": 10.03
                }
            ],
            "generator": "General",
            "parents_id": [
                "a9d5fa37-53e0-43d3-b897-4595398fc360"
            ]
        },
        {
            "id": "b4cfbf8e-a63b-48bf-9370-04530d260575",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_sequence_dependent_machine_lifting(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Static Heads and Tails for Critical Block Analysis\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.seq_dep_lifting = pyo.ConstraintList()\n    \n        # Helper: retrieve binary variable for \"u precedes v\"\n        # Accounts for the fact that model.y is indexed by sorted pairs\n        def get_y_prec(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Generate One Strengthened Cut Per Machine\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            \n            # Sort ops by static head (earliest release) for block detection\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Detect the most critical block (Carlier Lower Bound logic)\n            # We select the boundary pair (u, v) that defines the tightest window.\n            best_lb = -1\n            u, v = None, None\n            \n            for i in range(n):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]]\n                min_tail = float('inf')\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_tail: min_tail = tails[op]\n                    \n                    lb = r_val + p_sum + min_tail\n                    if lb > best_lb:\n                        best_lb = lb\n                        u = sorted_ops[i]\n                        v = sorted_ops[j]\n            \n            if u is None or v is None or u == v: continue\n    \n            # Machine-Specific Tight Big-M: Sum of P on this machine\n            # This provides a valid upper bound for the gap between any two ops on the same machine,\n            # significantly tighter than the global problem-wide BigM.\n            M_local = sum(m.p[k] for k in ops)\n    \n            # Lifting Term: Expand scope to ALL operations on the machine.\n            # Instead of just the block members, we check every operation k on the machine.\n            # If the solver sequences k strictly between u and v, we force the gap to increase by p[k].\n            lift_term = 0\n            for k in ops:\n                if k == u or k == v: continue\n                # (y_uk + y_kv - 1) equals 1 iff u -> k -> v, otherwise <= 0\n                lift_term += m.p[k] * (get_y_prec(u, k) + get_y_prec(k, v) - 1)\n            \n            y_uv = get_y_prec(u, v)\n    \n            # Add the lifted constraint:\n            # S_v >= S_u + p_u + Sum(p_k if k between u and v) - M_local * (1 - y_uv)\n            m.seq_dep_lifting.add(\n                m.S[v] >= m.S[u] + m.p[u] + lift_term - M_local * (1 - y_uv)\n            )\n\n    return model\n",
                "added_cut": "def add_sequence_dependent_machine_lifting(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Static Heads and Tails for Critical Block Analysis\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.seq_dep_lifting = pyo.ConstraintList()\n\n    # Helper: retrieve binary variable for \"u precedes v\"\n    # Accounts for the fact that model.y is indexed by sorted pairs\n    def get_y_prec(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Generate One Strengthened Cut Per Machine\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        \n        # Sort ops by static head (earliest release) for block detection\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Detect the most critical block (Carlier Lower Bound logic)\n        # We select the boundary pair (u, v) that defines the tightest window.\n        best_lb = -1\n        u, v = None, None\n        \n        for i in range(n):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]]\n            min_tail = float('inf')\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_tail: min_tail = tails[op]\n                \n                lb = r_val + p_sum + min_tail\n                if lb > best_lb:\n                    best_lb = lb\n                    u = sorted_ops[i]\n                    v = sorted_ops[j]\n        \n        if u is None or v is None or u == v: continue\n\n        # Machine-Specific Tight Big-M: Sum of P on this machine\n        # This provides a valid upper bound for the gap between any two ops on the same machine,\n        # significantly tighter than the global problem-wide BigM.\n        M_local = sum(m.p[k] for k in ops)\n\n        # Lifting Term: Expand scope to ALL operations on the machine.\n        # Instead of just the block members, we check every operation k on the machine.\n        # If the solver sequences k strictly between u and v, we force the gap to increase by p[k].\n        lift_term = 0\n        for k in ops:\n            if k == u or k == v: continue\n            # (y_uk + y_kv - 1) equals 1 iff u -> k -> v, otherwise <= 0\n            lift_term += m.p[k] * (get_y_prec(u, k) + get_y_prec(k, v) - 1)\n        \n        y_uv = get_y_prec(u, v)\n\n        # Add the lifted constraint:\n        # S_v >= S_u + p_u + Sum(p_k if k between u and v) - M_local * (1 - y_uv)\n        m.seq_dep_lifting.add(\n            m.S[v] >= m.S[u] + m.p[u] + lift_term - M_local * (1 - y_uv)\n        )",
                "idea": "We apply **Global Sequence-Dependent Lifting** derived from critical blocks. We first identify the most contended 'critical block' on each machine to select a bottleneck boundary pair $(u, v)$. We then generate a lifted precedence constraint that applies to **all** operations on that machine, not just the block members. The term $\\sum p_k(y_{uk} + y_{kv} - 1)$ dynamically adds the processing time of any operation $k$ sequenced between $u$ and $v$ to the required time gap. Furthermore, we replace the global Big-M with a **machine-specific tight M** (sum of machine processing times), which significantly strengthens the relaxation when the precedence $u \\to v$ is not active."
            },
            "fitness": 10.0,
            "solver_reports": [
                {
                    "gap": 95.8767,
                    "total_time": 12.86,
                    "explored_nodes": 1,
                    "simplex_iterations": 34683,
                    "explored_time": 12.82,
                    "work_units": 10.05
                },
                {
                    "gap": 96.7323,
                    "total_time": 15.88,
                    "explored_nodes": 1,
                    "simplex_iterations": 27131,
                    "explored_time": 15.83,
                    "work_units": 10.06
                },
                {
                    "gap": 96.7595,
                    "total_time": 15.95,
                    "explored_nodes": 1,
                    "simplex_iterations": 28980,
                    "explored_time": 15.9,
                    "work_units": 10.03
                },
                {
                    "gap": 92.175,
                    "total_time": 19.1,
                    "explored_nodes": 15,
                    "simplex_iterations": 30620,
                    "explored_time": 19.09,
                    "work_units": 10.02
                },
                {
                    "gap": 96.9489,
                    "total_time": 14.32,
                    "explored_nodes": 1,
                    "simplex_iterations": 29713,
                    "explored_time": 14.27,
                    "work_units": 10.02
                },
                {
                    "gap": 32.9271,
                    "total_time": 12.94,
                    "explored_nodes": 3239,
                    "simplex_iterations": 227059,
                    "explored_time": 12.94,
                    "work_units": 10.0
                },
                {
                    "gap": 92.0874,
                    "total_time": 19.31,
                    "explored_nodes": 1,
                    "simplex_iterations": 14843,
                    "explored_time": 19.29,
                    "work_units": 10.11
                },
                {
                    "gap": 96.6214,
                    "total_time": 15.15,
                    "explored_nodes": 1,
                    "simplex_iterations": 29064,
                    "explored_time": 15.11,
                    "work_units": 10.03
                }
            ],
            "generator": "Lifted",
            "parents_id": [
                "768d55be-56bc-4138-bb99-be3a57c52c52"
            ]
        },
        {
            "id": "62131001-99ab-49ba-9690-08fef5efa9eb",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_transitive_path_lifting(m):\n        import pyomo.environ as pyo\n    \n        # 1. Calculate Heads (r_j) and Tails (q_j)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in reversed(list(m.K)):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Machine Blocks\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        WINDOW = 8  # Look-ahead window for dense sub-sequences\n    \n        # 3. Generate Candidates based on Impact Density\n        for mid, ops in mach_ops.items():\n            # Sort operations by earliest start time (Heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            for i in range(n_ops):\n                u = sorted_ops[i]\n                # Form pairs (u, v) within the window\n                for j_idx in range(i + 1, min(i + WINDOW, n_ops)):\n                    v = sorted_ops[j_idx]\n                    \n                    # Identify intermediates strictly between u and v in the sorted order\n                    intermediates = sorted_ops[i+1 : j_idx]\n                    if not intermediates: continue\n    \n                    # Calculate Impact Density (Parent 1 Strategy)\n                    # Density = Total Processing Mass / Time Spread\n                    load = m.p[u] + m.p[v] + sum(m.p[k] for k in intermediates)\n                    spread = heads[v] - heads[u]\n                    if spread < 1e-4: spread = 1e-4\n                    \n                    density = load / spread\n                    \n                    candidates.append({\n                        'u': u, 'v': v,\n                        'K': intermediates,\n                        'density': density\n                    })\n    \n        # 4. Filter and Apply Hybrid Cuts\n        # Prioritize regions with highest contention density\n        candidates.sort(key=lambda x: x['density'], reverse=True)\n    \n        m.transitive_path_cuts = pyo.ConstraintList()\n        \n        def get_y(a, b):\n            # Returns expression for \"a precedes b\"\n            if a < b: return m.y[a[0], a[1], b[0], b[1]]\n            else:     return 1 - m.y[b[0], b[1], a[0], a[1]]\n    \n        added_ops = 0\n        BUDGET = 200\n        \n        for cand in candidates:\n            if added_ops >= BUDGET: break\n            \n            u, v = cand['u'], cand['v']\n            K = cand['K']\n            y_uv = get_y(u, v)\n    \n            # (A) Multi-Node Metric Lifting (Parent 2 Hybrid)\n            # Tightens S_v based on path u -> ... -> v. Sums p_k for all active intermediates.\n            # Term (y_uk + y_kv - 1) is 1 if u->k->v, else <= 0.\n            lift_term = 0\n            for k in K:\n                lift_term += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n            \n            m.transitive_path_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + lift_term - m.bigM * (1 - y_uv)\n            )\n            \n            # (B) Triangle Transitivity (Parent 1 Logic)\n            # Enforces consistency: if u->k and k->v, then u->v must hold.\n            # This prevents invalid cycle configurations that might weaken the lifting.\n            for k in K:\n                m.transitive_path_cuts.add(\n                    get_y(u, k) + get_y(k, v) - y_uv <= 1\n                )\n                \n            # (C) Conditional Carlier Bound (Parent 1 Objective Tightening)\n            # Apply specifically to the strongest intermediate k* to lift Cmax\n            k_star = max(K, key=lambda x: m.p[x])\n            seq_active = get_y(u, k_star) + get_y(k_star, v) # == 2 if u->k*->v active\n            \n            lb_val = heads[u] + m.p[u] + m.p[k_star] + m.p[v] + tails[v]\n            m.transitive_path_cuts.add(\n                m.Cmax >= lb_val - m.bigM * (2 - seq_active)\n            )\n            \n            added_ops += 2 + len(K)\n\n    return model\n",
                "added_cut": "def add_transitive_path_lifting(m):\n    import pyomo.environ as pyo\n\n    # 1. Calculate Heads (r_j) and Tails (q_j)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in reversed(list(m.K)):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Machine Blocks\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    WINDOW = 8  # Look-ahead window for dense sub-sequences\n\n    # 3. Generate Candidates based on Impact Density\n    for mid, ops in mach_ops.items():\n        # Sort operations by earliest start time (Heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        for i in range(n_ops):\n            u = sorted_ops[i]\n            # Form pairs (u, v) within the window\n            for j_idx in range(i + 1, min(i + WINDOW, n_ops)):\n                v = sorted_ops[j_idx]\n                \n                # Identify intermediates strictly between u and v in the sorted order\n                intermediates = sorted_ops[i+1 : j_idx]\n                if not intermediates: continue\n\n                # Calculate Impact Density (Parent 1 Strategy)\n                # Density = Total Processing Mass / Time Spread\n                load = m.p[u] + m.p[v] + sum(m.p[k] for k in intermediates)\n                spread = heads[v] - heads[u]\n                if spread < 1e-4: spread = 1e-4\n                \n                density = load / spread\n                \n                candidates.append({\n                    'u': u, 'v': v,\n                    'K': intermediates,\n                    'density': density\n                })\n\n    # 4. Filter and Apply Hybrid Cuts\n    # Prioritize regions with highest contention density\n    candidates.sort(key=lambda x: x['density'], reverse=True)\n\n    m.transitive_path_cuts = pyo.ConstraintList()\n    \n    def get_y(a, b):\n        # Returns expression for \"a precedes b\"\n        if a < b: return m.y[a[0], a[1], b[0], b[1]]\n        else:     return 1 - m.y[b[0], b[1], a[0], a[1]]\n\n    added_ops = 0\n    BUDGET = 200\n    \n    for cand in candidates:\n        if added_ops >= BUDGET: break\n        \n        u, v = cand['u'], cand['v']\n        K = cand['K']\n        y_uv = get_y(u, v)\n\n        # (A) Multi-Node Metric Lifting (Parent 2 Hybrid)\n        # Tightens S_v based on path u -> ... -> v. Sums p_k for all active intermediates.\n        # Term (y_uk + y_kv - 1) is 1 if u->k->v, else <= 0.\n        lift_term = 0\n        for k in K:\n            lift_term += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n        \n        m.transitive_path_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + lift_term - m.bigM * (1 - y_uv)\n        )\n        \n        # (B) Triangle Transitivity (Parent 1 Logic)\n        # Enforces consistency: if u->k and k->v, then u->v must hold.\n        # This prevents invalid cycle configurations that might weaken the lifting.\n        for k in K:\n            m.transitive_path_cuts.add(\n                get_y(u, k) + get_y(k, v) - y_uv <= 1\n            )\n            \n        # (C) Conditional Carlier Bound (Parent 1 Objective Tightening)\n        # Apply specifically to the strongest intermediate k* to lift Cmax\n        k_star = max(K, key=lambda x: m.p[x])\n        seq_active = get_y(u, k_star) + get_y(k_star, v) # == 2 if u->k*->v active\n        \n        lb_val = heads[u] + m.p[u] + m.p[k_star] + m.p[v] + tails[v]\n        m.transitive_path_cuts.add(\n            m.Cmax >= lb_val - m.bigM * (2 - seq_active)\n        )\n        \n        added_ops += 2 + len(K)",
                "idea": "We implement **Transitive Path Lifting**, a hybrid cut strategy that strengthens the relaxation in high-contention zones. By filtering operation pairs using Parent 1's **Impact Density**, we identify critical scheduling windows. For these pairs $(i, j)$ and their intermediate operations $K$, we enforce a valid path: (1) **Triangle Transitivity** constraints ensuring sequence logic for all triplets $(i, k, j)$, (2) **Multi-Node Metric Lifting** which dynamically sums processing times of all active intermediates to tighten $S_j - S_i$, and (3) a **Conditional Carlier Bound** on $C_{max}$ for the dominant triplet. This combines the precision of Parent 1's scoring with the aggregate tightening power of Parent 2's block approach."
            },
            "fitness": 10.0,
            "solver_reports": [
                {
                    "gap": 95.8767,
                    "total_time": 13.04,
                    "explored_nodes": 1,
                    "simplex_iterations": 34683,
                    "explored_time": 12.98,
                    "work_units": 10.05
                },
                {
                    "gap": 96.7323,
                    "total_time": 15.08,
                    "explored_nodes": 1,
                    "simplex_iterations": 27131,
                    "explored_time": 15.04,
                    "work_units": 10.06
                },
                {
                    "gap": 96.7595,
                    "total_time": 15.82,
                    "explored_nodes": 1,
                    "simplex_iterations": 28980,
                    "explored_time": 15.76,
                    "work_units": 10.03
                },
                {
                    "gap": 92.175,
                    "total_time": 18.82,
                    "explored_nodes": 15,
                    "simplex_iterations": 30620,
                    "explored_time": 18.81,
                    "work_units": 10.02
                },
                {
                    "gap": 96.9489,
                    "total_time": 14.22,
                    "explored_nodes": 1,
                    "simplex_iterations": 29713,
                    "explored_time": 14.18,
                    "work_units": 10.02
                },
                {
                    "gap": 32.9271,
                    "total_time": 12.84,
                    "explored_nodes": 3239,
                    "simplex_iterations": 227059,
                    "explored_time": 12.83,
                    "work_units": 10.0
                },
                {
                    "gap": 92.0874,
                    "total_time": 19.68,
                    "explored_nodes": 1,
                    "simplex_iterations": 14843,
                    "explored_time": 19.66,
                    "work_units": 10.11
                },
                {
                    "gap": 96.6214,
                    "total_time": 15.16,
                    "explored_nodes": 1,
                    "simplex_iterations": 29064,
                    "explored_time": 15.12,
                    "work_units": 10.03
                }
            ],
            "generator": "Min_Violation",
            "parents_id": [
                "23f863a1-a5e8-4533-81dc-bb9c7b47fd7d",
                "768d55be-56bc-4138-bb99-be3a57c52c52"
            ]
        },
        {
            "id": "b7138234-6457-4642-9629-c02c6646ad53",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_boundary_position_cuts(m):\n        # 1. Precompute Static Heads and Tails\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Helper: Get expression for \"u precedes v\"\n        # y[u,v] exists if u < v (lexicographically) and same machine\n        # Returns 1 if u->v, 0 if v->u\n        def get_precedes_expr(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Generate Cuts\n        m.boundary_cuts = pyo.ConstraintList()\n        \n        # Heuristic: Estimate a baseline Global LB to filter weak cuts\n        # This prevents adding too many inactive constraints\n        global_lb_est = 0\n        for j in m.J:\n            last_op = (j, max(m.K))\n            val = heads[last_op] + m.p[last_op]\n            if val > global_lb_est: global_lb_est = val\n    \n        cut_count = 0\n        CUT_LIMIT = 200\n    \n        # Iterate over machines to find dense triplets\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            if cut_count >= CUT_LIMIT: break\n    \n            # Sort by Earliest Release Date (Heads) to find local clusters\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            \n            # Sliding window of size 3 (Triplets)\n            for i in range(len(sorted_ops) - 2):\n                subset = sorted_ops[i : i+3]\n                \n                # --- Cut Type A: \"First in Subset\" Penalties ---\n                # If u is the FIRST of {u, v1, v2}, Cmax must cover the sequence u -> {v1, v2}\n                # LB = head(u) + p(u) + p(v1) + p(v2) + min(tail(v1), tail(v2))\n                # Logic: Cmax >= LB - M * ( (v1->u) + (v2->u) )\n                # Explanation: If u is truly first, v1->u and v2->u are 0, forcing Cmax >= LB.\n                \n                for u in subset:\n                    others = [o for o in subset if o != u]\n                    v1, v2 = others[0], others[1]\n                    \n                    p_subset = m.p[u] + m.p[v1] + m.p[v2]\n                    lb_first = heads[u] + p_subset + min(tails[v1], tails[v2])\n                    \n                    # Only add if this local sequence bound is significant\n                    if lb_first > global_lb_est * 0.85:\n                        term_v1_u = get_precedes_expr(v1, u)\n                        term_v2_u = get_precedes_expr(v2, u)\n                        \n                        # Tight M: if cut is relaxed (sum >= 1), RHS should be <= global_lb_est safely\n                        # Using a safe local M based on the calculated LB\n                        M_local = lb_first \n                        \n                        m.boundary_cuts.add(\n                            m.Cmax >= lb_first - M_local * (term_v1_u + term_v2_u)\n                        )\n                        cut_count += 1\n    \n                # --- Cut Type B: \"Last in Subset\" Penalties ---\n                # If u is the LAST of {v1, v2, u}, Cmax must cover {v1, v2} -> u\n                # LB = min(head(v1), head(v2)) + p(v1) + p(v2) + p(u) + tail(u)\n                # Logic: Cmax >= LB - M * ( (u->v1) + (u->v2) )\n                # Explanation: If u is last, u->v1 and u->v2 are 0.\n                \n                for u in subset:\n                    others = [o for o in subset if o != u]\n                    v1, v2 = others[0], others[1]\n                    \n                    p_subset = m.p[v1] + m.p[v2] + m.p[u]\n                    lb_last = min(heads[v1], heads[v2]) + p_subset + tails[u]\n                    \n                    if lb_last > global_lb_est * 0.85:\n                        term_u_v1 = get_precedes_expr(u, v1)\n                        term_u_v2 = get_precedes_expr(u, v2)\n                        \n                        M_local = lb_last\n                        \n                        m.boundary_cuts.add(\n                            m.Cmax >= lb_last - M_local * (term_u_v1 + term_u_v2)\n                        )\n                        cut_count += 1\n\n    return model\n",
                "added_cut": "def add_boundary_position_cuts(m):\n    # 1. Precompute Static Heads and Tails\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Helper: Get expression for \"u precedes v\"\n    # y[u,v] exists if u < v (lexicographically) and same machine\n    # Returns 1 if u->v, 0 if v->u\n    def get_precedes_expr(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Generate Cuts\n    m.boundary_cuts = pyo.ConstraintList()\n    \n    # Heuristic: Estimate a baseline Global LB to filter weak cuts\n    # This prevents adding too many inactive constraints\n    global_lb_est = 0\n    for j in m.J:\n        last_op = (j, max(m.K))\n        val = heads[last_op] + m.p[last_op]\n        if val > global_lb_est: global_lb_est = val\n\n    cut_count = 0\n    CUT_LIMIT = 200\n\n    # Iterate over machines to find dense triplets\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        if cut_count >= CUT_LIMIT: break\n\n        # Sort by Earliest Release Date (Heads) to find local clusters\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        \n        # Sliding window of size 3 (Triplets)\n        for i in range(len(sorted_ops) - 2):\n            subset = sorted_ops[i : i+3]\n            \n            # --- Cut Type A: \"First in Subset\" Penalties ---\n            # If u is the FIRST of {u, v1, v2}, Cmax must cover the sequence u -> {v1, v2}\n            # LB = head(u) + p(u) + p(v1) + p(v2) + min(tail(v1), tail(v2))\n            # Logic: Cmax >= LB - M * ( (v1->u) + (v2->u) )\n            # Explanation: If u is truly first, v1->u and v2->u are 0, forcing Cmax >= LB.\n            \n            for u in subset:\n                others = [o for o in subset if o != u]\n                v1, v2 = others[0], others[1]\n                \n                p_subset = m.p[u] + m.p[v1] + m.p[v2]\n                lb_first = heads[u] + p_subset + min(tails[v1], tails[v2])\n                \n                # Only add if this local sequence bound is significant\n                if lb_first > global_lb_est * 0.85:\n                    term_v1_u = get_precedes_expr(v1, u)\n                    term_v2_u = get_precedes_expr(v2, u)\n                    \n                    # Tight M: if cut is relaxed (sum >= 1), RHS should be <= global_lb_est safely\n                    # Using a safe local M based on the calculated LB\n                    M_local = lb_first \n                    \n                    m.boundary_cuts.add(\n                        m.Cmax >= lb_first - M_local * (term_v1_u + term_v2_u)\n                    )\n                    cut_count += 1\n\n            # --- Cut Type B: \"Last in Subset\" Penalties ---\n            # If u is the LAST of {v1, v2, u}, Cmax must cover {v1, v2} -> u\n            # LB = min(head(v1), head(v2)) + p(v1) + p(v2) + p(u) + tail(u)\n            # Logic: Cmax >= LB - M * ( (u->v1) + (u->v2) )\n            # Explanation: If u is last, u->v1 and u->v2 are 0.\n            \n            for u in subset:\n                others = [o for o in subset if o != u]\n                v1, v2 = others[0], others[1]\n                \n                p_subset = m.p[v1] + m.p[v2] + m.p[u]\n                lb_last = min(heads[v1], heads[v2]) + p_subset + tails[u]\n                \n                if lb_last > global_lb_est * 0.85:\n                    term_u_v1 = get_precedes_expr(u, v1)\n                    term_u_v2 = get_precedes_expr(u, v2)\n                    \n                    M_local = lb_last\n                    \n                    m.boundary_cuts.add(\n                        m.Cmax >= lb_last - M_local * (term_u_v1 + term_u_v2)\n                    )\n                    cut_count += 1",
                "idea": "We introduce **Boundary Position Cuts**, an exploratory lifting of Constraint Programming 'Edge-Finding' logic into MILP. Unlike the input's specific sequence cuts, this method targets **subset boundaries** on bottleneck machines. For dense triplets {u, v, w}, it derives conditional lower bounds on Cmax that activate specifically when an operation u is forced to be **first** (preceded by none) or **last** (preceding none) in the subset. This robustly penalizes suboptimal boundary assignments without requiring the solver to explore the full permutations of the subset, thus tightening the relaxation around critical block heads and tails."
            },
            "fitness": 10.0,
            "solver_reports": [
                {
                    "gap": 95.8767,
                    "total_time": 13.47,
                    "explored_nodes": 1,
                    "simplex_iterations": 34683,
                    "explored_time": 13.42,
                    "work_units": 10.05
                },
                {
                    "gap": 96.7323,
                    "total_time": 15.88,
                    "explored_nodes": 1,
                    "simplex_iterations": 27131,
                    "explored_time": 15.84,
                    "work_units": 10.06
                },
                {
                    "gap": 96.7595,
                    "total_time": 15.82,
                    "explored_nodes": 1,
                    "simplex_iterations": 28980,
                    "explored_time": 15.76,
                    "work_units": 10.03
                },
                {
                    "gap": 92.175,
                    "total_time": 19.01,
                    "explored_nodes": 15,
                    "simplex_iterations": 30620,
                    "explored_time": 19.0,
                    "work_units": 10.02
                },
                {
                    "gap": 96.9489,
                    "total_time": 13.89,
                    "explored_nodes": 1,
                    "simplex_iterations": 29713,
                    "explored_time": 13.83,
                    "work_units": 10.02
                },
                {
                    "gap": 32.9271,
                    "total_time": 12.8,
                    "explored_nodes": 3239,
                    "simplex_iterations": 227059,
                    "explored_time": 12.79,
                    "work_units": 10.0
                },
                {
                    "gap": 92.0874,
                    "total_time": 19.83,
                    "explored_nodes": 1,
                    "simplex_iterations": 14843,
                    "explored_time": 19.8,
                    "work_units": 10.11
                },
                {
                    "gap": 96.6214,
                    "total_time": 15.63,
                    "explored_nodes": 1,
                    "simplex_iterations": 29064,
                    "explored_time": 15.59,
                    "work_units": 10.03
                }
            ],
            "generator": "Exploratory",
            "parents_id": [
                "a1be8606-43cc-42b7-b23c-40098d05d110"
            ]
        },
        {
            "id": "d77ca1d9-1624-45b2-b179-b6fd7c73aa50",
            "chromosome": {
                "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_pivot_conditional_carlier_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Heads/Tails Calculation\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (approx sequence)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Identify subset with max Carlier Bound\n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            # Only keep blocks large enough to matter\n            if best_lb > 0 and len(best_sub) >= 3:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n    \n        # 3. Cut Generation\n        # Prioritize blocks with high lower bounds\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        m.pivot_carlier_cuts = pyo.ConstraintList()\n        \n        def get_y_val(u, v):\n            # Returns expression 1 if u->v, 0 if v->u\n            # m.y is defined for pairs (a,b) where a < b\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        BUDGET = 200\n        \n        for cand in candidates:\n            if cuts_added >= BUDGET: break\n            block = cand['ops']\n            p_block = sum(m.p[op] for op in block)\n            \n            # Iterate every op in block as a potential pivot\n            for u in block:\n                if cuts_added >= BUDGET: break\n                \n                others = [v for v in block if v != u]\n                if not others: continue\n                n_others = len(others)\n                \n                # --- Hypothesis: u is First in the block ---\n                # If u precedes all others, Cmax >= r_u + p_u + sum(p_others) + min(q_others)\n                # Activation condition: sum(y_uv for v in others) == n_others\n                min_q = min(tails[v] for v in others)\n                bound_first = heads[u] + m.p[u] + (p_block - m.p[u]) + min_q\n                \n                sum_y_uv = sum(get_y_val(u, v) for v in others)\n                \n                # Constraint: Cmax >= Bound - BigM * (Violations)\n                # Violations = n_others - sum_y_uv (which is 0 if u is truly first)\n                m.pivot_carlier_cuts.add(\n                    m.Cmax >= bound_first - m.bigM * (n_others - sum_y_uv)\n                )\n                cuts_added += 1\n                if cuts_added >= BUDGET: break\n    \n                # --- Hypothesis: u is Last in the block ---\n                # If u succeeds all others, Cmax >= min(r_others) + sum(p_others) + p_u + q_u\n                # Activation condition: sum(y_vu for v in others) == n_others\n                min_r = min(heads[v] for v in others)\n                bound_last = min_r + (p_block - m.p[u]) + m.p[u] + tails[u]\n                \n                sum_y_vu = sum(get_y_val(v, u) for v in others)\n                \n                m.pivot_carlier_cuts.add(\n                    m.Cmax >= bound_last - m.bigM * (n_others - sum_y_vu)\n                )\n                cuts_added += 1\n\n    return model\n",
                "added_cut": "def add_pivot_conditional_carlier_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Heads/Tails Calculation\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (approx sequence)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Identify subset with max Carlier Bound\n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        # Only keep blocks large enough to matter\n        if best_lb > 0 and len(best_sub) >= 3:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n\n    # 3. Cut Generation\n    # Prioritize blocks with high lower bounds\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    m.pivot_carlier_cuts = pyo.ConstraintList()\n    \n    def get_y_val(u, v):\n        # Returns expression 1 if u->v, 0 if v->u\n        # m.y is defined for pairs (a,b) where a < b\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    BUDGET = 200\n    \n    for cand in candidates:\n        if cuts_added >= BUDGET: break\n        block = cand['ops']\n        p_block = sum(m.p[op] for op in block)\n        \n        # Iterate every op in block as a potential pivot\n        for u in block:\n            if cuts_added >= BUDGET: break\n            \n            others = [v for v in block if v != u]\n            if not others: continue\n            n_others = len(others)\n            \n            # --- Hypothesis: u is First in the block ---\n            # If u precedes all others, Cmax >= r_u + p_u + sum(p_others) + min(q_others)\n            # Activation condition: sum(y_uv for v in others) == n_others\n            min_q = min(tails[v] for v in others)\n            bound_first = heads[u] + m.p[u] + (p_block - m.p[u]) + min_q\n            \n            sum_y_uv = sum(get_y_val(u, v) for v in others)\n            \n            # Constraint: Cmax >= Bound - BigM * (Violations)\n            # Violations = n_others - sum_y_uv (which is 0 if u is truly first)\n            m.pivot_carlier_cuts.add(\n                m.Cmax >= bound_first - m.bigM * (n_others - sum_y_uv)\n            )\n            cuts_added += 1\n            if cuts_added >= BUDGET: break\n\n            # --- Hypothesis: u is Last in the block ---\n            # If u succeeds all others, Cmax >= min(r_others) + sum(p_others) + p_u + q_u\n            # Activation condition: sum(y_vu for v in others) == n_others\n            min_r = min(heads[v] for v in others)\n            bound_last = min_r + (p_block - m.p[u]) + m.p[u] + tails[u]\n            \n            sum_y_vu = sum(get_y_val(v, u) for v in others)\n            \n            m.pivot_carlier_cuts.add(\n                m.Cmax >= bound_last - m.bigM * (n_others - sum_y_vu)\n            )\n            cuts_added += 1",
                "idea": "We introduce **Pivot-Conditional Carlier Cuts**, a technique that decomposes critical machine blocks into mutually exclusive 'pivot' scenarios. Instead of local triplet lifting, we identify bottleneck blocks and enforce a global makespan lower bound conditioned on every possible 'start' or 'end' operation ($u$) for that block. If $u$ is first, $C_{max}$ must exceed the block's Carlier bound calculated with $u$ fixed at the head; if not, a Big-M term relaxes it. This creates a 'convex hull' of disjunctive bounds, forcing the solver to account for the necessary makespan cost of whatever sequence it chooses on critical machines."
            },
            "fitness": 10.0,
            "solver_reports": [
                {
                    "gap": 95.8767,
                    "total_time": 12.91,
                    "explored_nodes": 1,
                    "simplex_iterations": 34683,
                    "explored_time": 12.85,
                    "work_units": 10.05
                },
                {
                    "gap": 96.7323,
                    "total_time": 15.36,
                    "explored_nodes": 1,
                    "simplex_iterations": 27131,
                    "explored_time": 15.32,
                    "work_units": 10.06
                },
                {
                    "gap": 96.7595,
                    "total_time": 15.79,
                    "explored_nodes": 1,
                    "simplex_iterations": 28980,
                    "explored_time": 15.74,
                    "work_units": 10.03
                },
                {
                    "gap": 92.175,
                    "total_time": 19.47,
                    "explored_nodes": 15,
                    "simplex_iterations": 30620,
                    "explored_time": 19.46,
                    "work_units": 10.02
                },
                {
                    "gap": 96.9489,
                    "total_time": 13.9,
                    "explored_nodes": 1,
                    "simplex_iterations": 29713,
                    "explored_time": 13.84,
                    "work_units": 10.02
                },
                {
                    "gap": 32.9271,
                    "total_time": 12.85,
                    "explored_nodes": 3239,
                    "simplex_iterations": 227059,
                    "explored_time": 12.85,
                    "work_units": 10.0
                },
                {
                    "gap": 92.0874,
                    "total_time": 20.25,
                    "explored_nodes": 1,
                    "simplex_iterations": 14843,
                    "explored_time": 20.23,
                    "work_units": 10.11
                },
                {
                    "gap": 96.6214,
                    "total_time": 15.16,
                    "explored_nodes": 1,
                    "simplex_iterations": 29064,
                    "explored_time": 15.12,
                    "work_units": 10.03
                }
            ],
            "generator": "Complement",
            "parents_id": [
                "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                "23f863a1-a5e8-4533-81dc-bb9c7b47fd7d"
            ]
        }
    ],
    "prev_populations": [
        [
            [
                {
                    "id": "3eafbe86-c941-41bd-9bd6-06895845419c",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    import itertools\n    \n    # Group operations by machine to identify cliques of conflicting operations\n    machine_ops = {}\n    for (j, k) in model.O:\n        m_id = machines[j][k]\n        if m_id not in machine_ops:\n            machine_ops[m_id] = []\n        machine_ops[m_id].append((j, k))\n    \n    model.transitivity_cuts = pyo.ConstraintList()\n    \n    # Generate 3-cycle cuts for every triplet on the same machine\n    for m_id, ops in machine_ops.items():\n        # Sort operations to match the index ordering of model.y (j1,k1) < (j2,k2)\n        ops.sort()\n        for o1, o2, o3 in itertools.combinations(ops, 3):\n            # Access binary precedence variables for the three pairs\n            # o1, o2, o3 are sorted, so the keys exist in model.y\n            y12 = model.y[o1 + o2]\n            y23 = model.y[o2 + o3]\n            y13 = model.y[o1 + o3]\n    \n            # 1. Forward Transitivity: If o1 -> o2 and o2 -> o3, then o1 -> o3\n            # y12 + y23 - y13 <= 1  => (1 + 1 - 0 <= 1) is False, cutting the cycle\n            model.transitivity_cuts.add(y12 + y23 - y13 <= 1)\n    \n            # 2. Reverse Transitivity: If o3 -> o2 and o2 -> o1, then o3 -> o1\n            # This corresponds to y23=0 (o3->o2) and y12=0 (o2->o1) => y13=0 (o3->o1)\n            # y13 - y12 - y23 <= 0  => (1 - 0 - 0 <= 0) is False, cutting the cycle\n            model.transitivity_cuts.add(y13 - y12 - y23 <= 0)\n\n    return model\n",
                        "added_cut": "import itertools\n\n# Group operations by machine to identify cliques of conflicting operations\nmachine_ops = {}\nfor (j, k) in model.O:\n    m_id = machines[j][k]\n    if m_id not in machine_ops:\n        machine_ops[m_id] = []\n    machine_ops[m_id].append((j, k))\n\nmodel.transitivity_cuts = pyo.ConstraintList()\n\n# Generate 3-cycle cuts for every triplet on the same machine\nfor m_id, ops in machine_ops.items():\n    # Sort operations to match the index ordering of model.y (j1,k1) < (j2,k2)\n    ops.sort()\n    for o1, o2, o3 in itertools.combinations(ops, 3):\n        # Access binary precedence variables for the three pairs\n        # o1, o2, o3 are sorted, so the keys exist in model.y\n        y12 = model.y[o1 + o2]\n        y23 = model.y[o2 + o3]\n        y13 = model.y[o1 + o3]\n\n        # 1. Forward Transitivity: If o1 -> o2 and o2 -> o3, then o1 -> o3\n        # y12 + y23 - y13 <= 1  => (1 + 1 - 0 <= 1) is False, cutting the cycle\n        model.transitivity_cuts.add(y12 + y23 - y13 <= 1)\n\n        # 2. Reverse Transitivity: If o3 -> o2 and o2 -> o1, then o3 -> o1\n        # This corresponds to y23=0 (o3->o2) and y12=0 (o2->o1) => y13=0 (o3->o1)\n        # y13 - y12 - y23 <= 0  => (1 - 0 - 0 <= 0) is False, cutting the cycle\n        model.transitivity_cuts.add(y13 - y12 - y23 <= 0)",
                        "idea": "We apply triangle (transitivity) inequalities to the binary precedence variables $y_{ijk'k'}$. For any triplet of operations $i, j, k$ competing for the same machine, logical consistency dictates that the precedence ordering must be transitive (no cycles like $i \\to j \\to k \\to i$). The standard Big-M formulation links $y$ to start times but permits fractional cycles (e.g., $y=0.5$) in the LP relaxation. These cuts strictly enforce the linear ordering polytope constraints: $y_{ij} + y_{jk} - y_{ik} \\le 1$ and $y_{ik} - y_{ij} - y_{jk} \\le 0$ (assuming ordered indices), significantly tightening the relaxation."
                    },
                    "fitness": 9.580743099237264,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 11.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 22328,
                            "explored_time": 11.58,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 12.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 27884,
                            "explored_time": 11.92,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 10.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.46,
                            "work_units": 10.13
                        },
                        {
                            "gap": 94.8761,
                            "total_time": 7.67,
                            "explored_nodes": 1,
                            "simplex_iterations": 28230,
                            "explored_time": 7.6,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.49,
                            "work_units": 10.19
                        },
                        {
                            "gap": 42.1573,
                            "total_time": 13.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 23840,
                            "explored_time": 13.8,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.713,
                            "total_time": 8.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 28404,
                            "explored_time": 7.93,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9893,
                            "total_time": 11.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 22544,
                            "explored_time": 11.61,
                            "work_units": 10.0
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-compute Heads (earliest release) and Tails (remaining work) for all operations\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        # Forward pass: Heads\n        h_accum = 0\n        for k in range(n_machines):\n            op_heads[j, k] = h_accum\n            h_accum += times[j][k]\n        # Backward pass: Tails\n        t_accum = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = t_accum\n            t_accum += times[j][k]\n    \n    # Group operations by machine ID\n    machine_to_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in machine_to_ops:\n                machine_to_ops[m_id] = []\n            machine_to_ops[m_id].append((j, k))\n    \n    def machine_workload_rule(m, m_id):\n        # 1-Machine Relaxation Bound:\n        # The makespan must accommodate the total processing time of all ops on the machine,\n        # plus the earliest possible arrival (min Head) and latest mandatory work-off (min Tail).\n        ops = machine_to_ops[m_id]\n        if not ops:\n            return pyo.Constraint.Skip\n        \n        min_head = min(op_heads[op] for op in ops)\n        total_p = sum(times[op[0]][op[1]] for op in ops)\n        min_tail = min(op_tails[op] for op in ops)\n        \n        return m.Cmax >= min_head + total_p + min_tail\n    \n    # Apply the cut for every machine used in the instance\n    model.machine_workload_cuts = pyo.Constraint(list(machine_to_ops.keys()), rule=machine_workload_rule)\n\n    return model\n",
                        "added_cut": "# Pre-compute Heads (earliest release) and Tails (remaining work) for all operations\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    # Forward pass: Heads\n    h_accum = 0\n    for k in range(n_machines):\n        op_heads[j, k] = h_accum\n        h_accum += times[j][k]\n    # Backward pass: Tails\n    t_accum = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = t_accum\n        t_accum += times[j][k]\n\n# Group operations by machine ID\nmachine_to_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in machine_to_ops:\n            machine_to_ops[m_id] = []\n        machine_to_ops[m_id].append((j, k))\n\ndef machine_workload_rule(m, m_id):\n    # 1-Machine Relaxation Bound:\n    # The makespan must accommodate the total processing time of all ops on the machine,\n    # plus the earliest possible arrival (min Head) and latest mandatory work-off (min Tail).\n    ops = machine_to_ops[m_id]\n    if not ops:\n        return pyo.Constraint.Skip\n    \n    min_head = min(op_heads[op] for op in ops)\n    total_p = sum(times[op[0]][op[1]] for op in ops)\n    min_tail = min(op_tails[op] for op in ops)\n    \n    return m.Cmax >= min_head + total_p + min_tail\n\n# Apply the cut for every machine used in the instance\nmodel.machine_workload_cuts = pyo.Constraint(list(machine_to_ops.keys()), rule=machine_workload_rule)",
                        "idea": "We apply static **Machine Workload Cuts** (derived from the 1-machine relaxation). For any machine $m$, the makespan $C_{max}$ is strictly bounded by the sum of processing times of all operations assigned to $m$, shifted by the earliest release time (Head) and the minimum post-processing time (Tail) among those operations. Formally, $C_{max} \\ge \\min_{i \\in \\Omega_m}(Head_i) + \\sum_{i \\in \\Omega_m} p_i + \\min_{i \\in \\Omega_m}(Tail_i)$. This cut aggregates capacity constraints, strengthening the LP relaxation where disjunctive constraints are often loose."
                    },
                    "fitness": 12.107175463655313,
                    "solver_reports": [
                        {
                            "gap": 89.8612,
                            "total_time": 15.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 27070,
                            "explored_time": 15.27,
                            "work_units": 10.06
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.34,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 9.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.64,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 13.86,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 13.85,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.4069,
                            "total_time": 9.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 36528,
                            "explored_time": 9.7,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.4,
                            "total_time": 13.29,
                            "explored_nodes": 9932,
                            "simplex_iterations": 303128,
                            "explored_time": 13.27,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.0633,
                            "total_time": 19.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 33623,
                            "explored_time": 19.35,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.44,
                            "work_units": 10.0
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "9395d90c-2832-44a7-96f0-c9ff646e2922",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Inter-Machine Crossing Cuts\n    # These cuts tighten the relaxation by linking precedence variables on different machines.\n    # For a pair of jobs (j1, j2) that both visit machine A then machine B,\n    # if the sequence swaps (j1->j2 on A, j2->j1 on B), a specific path delay is enforced.\n    model.crossing_cuts = pyo.ConstraintList()\n    \n    for j1 in range(n_jobs):\n        for j2 in range(j1 + 1, n_jobs):\n            # Map machine ID -> step index for O(1) lookup for these jobs\n            mj1 = {machines[j1][k]: k for k in range(n_machines)}\n            mj2 = {machines[j2][k]: k for k in range(n_machines)}\n            \n            # Identify common machines\n            common_machines = set(mj1.keys()) & set(mj2.keys())\n            \n            for mA in common_machines:\n                for mB in common_machines:\n                    if mA == mB:\n                        continue\n                    \n                    # Get step indices on machine A (u) and machine B (v)\n                    u1, v1 = mj1[mA], mj1[mB]\n                    u2, v2 = mj2[mA], mj2[mB]\n                    \n                    # Apply cut only if both jobs visit A before B\n                    if u1 < v1 and u2 < v2:\n                        # Retrieve precedence variables (j1 < j2 guaranteed by loop order)\n                        # yA = 1 implies j1 -> j2 on machine A\n                        # yB = 1 implies j1 -> j2 on machine B\n                        yA = model.y[j1, u1, j2, u2]\n                        yB = model.y[j1, v1, j2, v2]\n                        \n                        # If a swap occurs (yA=1, yB=0), the sequence is j1@A -> j2@A -> j2@B -> j1@B\n                        # The extra delay imposed on j1@B is p(j2@A) + p(j2@B)\n                        penalty = model.p[j2, u2] + model.p[j2, v2]\n                        \n                        model.crossing_cuts.add(\n                            model.S[j1, v1] >= model.S[j1, u1] + model.p[j1, u1] + \n                            penalty * (yA - yB)\n                        )\n\n    return model\n",
                        "added_cut": "# Inter-Machine Crossing Cuts\n# These cuts tighten the relaxation by linking precedence variables on different machines.\n# For a pair of jobs (j1, j2) that both visit machine A then machine B,\n# if the sequence swaps (j1->j2 on A, j2->j1 on B), a specific path delay is enforced.\nmodel.crossing_cuts = pyo.ConstraintList()\n\nfor j1 in range(n_jobs):\n    for j2 in range(j1 + 1, n_jobs):\n        # Map machine ID -> step index for O(1) lookup for these jobs\n        mj1 = {machines[j1][k]: k for k in range(n_machines)}\n        mj2 = {machines[j2][k]: k for k in range(n_machines)}\n        \n        # Identify common machines\n        common_machines = set(mj1.keys()) & set(mj2.keys())\n        \n        for mA in common_machines:\n            for mB in common_machines:\n                if mA == mB:\n                    continue\n                \n                # Get step indices on machine A (u) and machine B (v)\n                u1, v1 = mj1[mA], mj1[mB]\n                u2, v2 = mj2[mA], mj2[mB]\n                \n                # Apply cut only if both jobs visit A before B\n                if u1 < v1 and u2 < v2:\n                    # Retrieve precedence variables (j1 < j2 guaranteed by loop order)\n                    # yA = 1 implies j1 -> j2 on machine A\n                    # yB = 1 implies j1 -> j2 on machine B\n                    yA = model.y[j1, u1, j2, u2]\n                    yB = model.y[j1, v1, j2, v2]\n                    \n                    # If a swap occurs (yA=1, yB=0), the sequence is j1@A -> j2@A -> j2@B -> j1@B\n                    # The extra delay imposed on j1@B is p(j2@A) + p(j2@B)\n                    penalty = model.p[j2, u2] + model.p[j2, v2]\n                    \n                    model.crossing_cuts.add(\n                        model.S[j1, v1] >= model.S[j1, u1] + model.p[j1, u1] + \n                        penalty * (yA - yB)\n                    )",
                        "idea": "We implement **Inter-Machine Crossing Cuts** to strengthen the MILP formulation by explicitly linking precedence decisions across different machines. In the Job-Shop problem, if two jobs $j_1$ and $j_2$ both visit machine $A$ and then machine $B$, they should ideally maintain the same relative order to minimize makespan. However, if they 'cross' (i.e., $j_1 \to j_2$ on $A$ but $j_2 \to j_1$ on $B$), a physical path $O_{j1,A} \to O_{j2,A} \to O_{j2,B} \to O_{j1,B}$ is created. This path is strictly longer than the intra-job precedence $O_{j1,A} \to O_{j1,B}$. The proposed cut lifts the lower bound of the start time $S_{j1,B}$ by adding the processing times of the interfering job $j_2$ ($p_{j2,A} + p_{j2,B}$) whenever such a crossing ($y_A - y_B = 1$) occurs, thereby removing fractional solutions that violate this temporal necessity."
                    },
                    "fitness": 9.20942484903599,
                    "solver_reports": [
                        {
                            "total_time": 7.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 27959,
                            "explored_time": 6.93,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 28864,
                            "explored_time": 8.57,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 25455,
                            "explored_time": 8.14,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 5.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 11458,
                            "explored_time": 5.8,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 27045,
                            "explored_time": 8.61,
                            "work_units": 10.0
                        },
                        {
                            "gap": 35.6389,
                            "total_time": 11.5,
                            "explored_nodes": 31,
                            "simplex_iterations": 38611,
                            "explored_time": 11.49,
                            "work_units": 10.1
                        },
                        {
                            "total_time": 6.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 12299,
                            "explored_time": 6.54,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 7.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 32335,
                            "explored_time": 7.26,
                            "work_units": 10.0
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "366493b1-62c2-4cdd-b383-18a9e183ff4d",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Added Constraint: Precedence-Based Start Time Lifting\n    # ----------------------------------------------------------------\n    \n    # 1. Precompute Heads (earliest possible start time) for each operation\n    #    based solely on job-internal predecessors.\n    op_heads = {}\n    for j_idx in range(n_jobs):\n        acc_time = 0\n        for k_idx in range(n_machines):\n            op_heads[(j_idx, k_idx)] = acc_time\n            acc_time += times[j_idx][k_idx]\n    \n    # 2. Group operations by machine to iterate efficiently\n    ops_by_machine = {m_id: [] for m_id in range(n_machines)}\n    for j_idx in range(n_jobs):\n        for k_idx in range(n_machines):\n            m_id = machines[j_idx][k_idx]\n            ops_by_machine[m_id].append((j_idx, k_idx))\n    \n    # 3. Define the cut rule\n    def start_time_lifting_rule(m, j, k):\n        mach_id = machines[j][k]\n        machine_ops = ops_by_machine[mach_id]\n        \n        # The earliest any operation on this machine can possibly start\n        # is the minimum Head of all operations assigned to it.\n        r_min = min(op_heads[op] for op in machine_ops)\n        \n        # Build expression for the total processing time of all operations \n        # that are decided to precede the current operation (j,k).\n        predecessor_work = 0\n        current_op = (j, k)\n        \n        for (j2, k2) in machine_ops:\n            if (j2, k2) == current_op:\n                continue\n            \n            # Identify the binary variable for the pair and add p * y if j2 -> j\n            if (j2, k2) < current_op:\n                # Pair is stored as ((j2,k2), (j,k)). y=1 implies j2 precedes j\n                predecessor_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n            else:\n                # Pair is stored as ((j,k), (j2,k2)). y=0 implies j2 precedes j\n                predecessor_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n        \n        # The start time must be at least the earliest machine availability \n        # plus the work of all predecessors.\n        return m.S[j, k] >= r_min + predecessor_work\n    \n    model.StartTimeLifting = pyo.Constraint(model.J, model.K, rule=start_time_lifting_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Added Constraint: Precedence-Based Start Time Lifting\n# ----------------------------------------------------------------\n\n# 1. Precompute Heads (earliest possible start time) for each operation\n#    based solely on job-internal predecessors.\nop_heads = {}\nfor j_idx in range(n_jobs):\n    acc_time = 0\n    for k_idx in range(n_machines):\n        op_heads[(j_idx, k_idx)] = acc_time\n        acc_time += times[j_idx][k_idx]\n\n# 2. Group operations by machine to iterate efficiently\nops_by_machine = {m_id: [] for m_id in range(n_machines)}\nfor j_idx in range(n_jobs):\n    for k_idx in range(n_machines):\n        m_id = machines[j_idx][k_idx]\n        ops_by_machine[m_id].append((j_idx, k_idx))\n\n# 3. Define the cut rule\ndef start_time_lifting_rule(m, j, k):\n    mach_id = machines[j][k]\n    machine_ops = ops_by_machine[mach_id]\n    \n    # The earliest any operation on this machine can possibly start\n    # is the minimum Head of all operations assigned to it.\n    r_min = min(op_heads[op] for op in machine_ops)\n    \n    # Build expression for the total processing time of all operations \n    # that are decided to precede the current operation (j,k).\n    predecessor_work = 0\n    current_op = (j, k)\n    \n    for (j2, k2) in machine_ops:\n        if (j2, k2) == current_op:\n            continue\n        \n        # Identify the binary variable for the pair and add p * y if j2 -> j\n        if (j2, k2) < current_op:\n            # Pair is stored as ((j2,k2), (j,k)). y=1 implies j2 precedes j\n            predecessor_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n        else:\n            # Pair is stored as ((j,k), (j2,k2)). y=0 implies j2 precedes j\n            predecessor_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n    \n    # The start time must be at least the earliest machine availability \n    # plus the work of all predecessors.\n    return m.S[j, k] >= r_min + predecessor_work\n\nmodel.StartTimeLifting = pyo.Constraint(model.J, model.K, rule=start_time_lifting_rule)",
                        "idea": "We introduce **Precedence-Based Start Time Lifting Cuts** (operation-specific capacity constraints). For every operation $i$ on machine $m$, its start time $S_i$ is strictly bounded from below by the machine's earliest possible availability ($r_{min} = \\min_{k \\in \\Omega_m} \\text{Head}_k$) plus the sum of processing times of all operations $j$ sequenced before $i$. This cut rigorously links the binary precedence variables $y$ to the continuous start times $S$, eliminating weak fractional solutions where operations 'overlap' or start earlier than the cumulative volume of their predecessors allows. Unlike the previously suggested global workload cuts (which bound $C_{max}$), this cut tightens the feasible region for individual intermediate start times."
                    },
                    "fitness": 9.1865186928481,
                    "solver_reports": [
                        {
                            "total_time": 11.32,
                            "explored_nodes": 1,
                            "simplex_iterations": 41321,
                            "explored_time": 11.27,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.11,
                            "explored_nodes": 1,
                            "simplex_iterations": 49978,
                            "explored_time": 8.06,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.13,
                            "explored_nodes": 1,
                            "simplex_iterations": 24360,
                            "explored_time": 8.07,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.25,
                            "explored_nodes": 52,
                            "simplex_iterations": 71623,
                            "explored_time": 10.24,
                            "work_units": 10.25
                        },
                        {
                            "total_time": 8.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 41839,
                            "explored_time": 8.69,
                            "work_units": 10.01
                        },
                        {
                            "gap": 35.7209,
                            "total_time": 12.06,
                            "explored_nodes": 316,
                            "simplex_iterations": 116508,
                            "explored_time": 12.06,
                            "work_units": 10.02
                        },
                        {
                            "total_time": 10.82,
                            "explored_nodes": 15,
                            "simplex_iterations": 47884,
                            "explored_time": 10.81,
                            "work_units": 10.05
                        },
                        {
                            "total_time": 9.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 40262,
                            "explored_time": 8.96,
                            "work_units": 10.04
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "8a37cb28-d2ae-43b3-a05c-4e7d0160b668",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def successor_workload_rule(m, j, k):\n        # This constraint ensures the makespan accounts for operation u=(j,k) \n        # and the processing times of all operations v that are sequenced AFTER u \n        # on the same machine.\n        u_mach = m.mach[j, k]\n        p_u = m.p[j, k]\n        \n        # Calculate the sum of processing times for all v on the same machine that follow u.\n        following_load = 0\n        for (j2, k2) in m.O:\n            if (j, k) == (j2, k2):\n                continue\n            if m.mach[j2, k2] == u_mach:\n                # Determine the pair index in model.Pairs based on lexicographical order\n                if (j, k) < (j2, k2):\n                    # Pair is (j, k, j2, k2). y=1 means u precedes v (v follows u).\n                    following_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n                else:\n                    # Pair is (j2, k2, j, k). y=1 means v precedes u.\n                    # y=0 means u precedes v (v follows u).\n                    following_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                    \n        return m.Cmax >= m.S[j, k] + p_u + following_load\n    \n    model.successor_workload = pyo.Constraint(model.J, model.K, rule=successor_workload_rule)\n\n    return model\n",
                        "added_cut": "def successor_workload_rule(m, j, k):\n    # This constraint ensures the makespan accounts for operation u=(j,k) \n    # and the processing times of all operations v that are sequenced AFTER u \n    # on the same machine.\n    u_mach = m.mach[j, k]\n    p_u = m.p[j, k]\n    \n    # Calculate the sum of processing times for all v on the same machine that follow u.\n    following_load = 0\n    for (j2, k2) in m.O:\n        if (j, k) == (j2, k2):\n            continue\n        if m.mach[j2, k2] == u_mach:\n            # Determine the pair index in model.Pairs based on lexicographical order\n            if (j, k) < (j2, k2):\n                # Pair is (j, k, j2, k2). y=1 means u precedes v (v follows u).\n                following_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n            else:\n                # Pair is (j2, k2, j, k). y=1 means v precedes u.\n                # y=0 means u precedes v (v follows u).\n                following_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                \n    return m.Cmax >= m.S[j, k] + p_u + following_load\n\nmodel.successor_workload = pyo.Constraint(model.J, model.K, rule=successor_workload_rule)",
                        "idea": "We introduce 'Successor-Based Cumulative Makespan Cuts'. For every operation $u$ on machine $m$, the global makespan $C_{max}$ is strictly bounded from below by the completion time of $u$ ($S_u + p_u$) plus the sum of processing times of all other operations $v$ on $m$ that are dynamically sequenced after $u$. Formally, $C_{max} \\ge S_u + p_u + \\sum_{v \\in \\Omega_m, v \\neq u} p_v \\cdot \\mathbb{I}(u \\prec v)$. Unlike static workload cuts (which use pre-calculated heads/tails) or simple disjunctive constraints (which act locally between pairs), this cut links the continuous variable $C_{max}$ directly to the specific schedule determined by the binary variables $y$. It forces the makespan to expand if the start time $S_u$ is delayed or if more jobs are sequenced after $u$, thereby tightening the relaxation significantly by removing solutions where the 'tail' capacity is underestimated."
                    },
                    "fitness": 10.76936579615406,
                    "solver_reports": [
                        {
                            "gap": 89.5937,
                            "total_time": 15.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 42354,
                            "explored_time": 15.82,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.9157,
                            "total_time": 10.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 43773,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.0959,
                            "total_time": 10.61,
                            "explored_nodes": 1,
                            "simplex_iterations": 48634,
                            "explored_time": 10.57,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.2437,
                            "total_time": 17.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 16454,
                            "explored_time": 17.65,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.4893,
                            "total_time": 10.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 53848,
                            "explored_time": 10.77,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.1489,
                            "total_time": 13.47,
                            "explored_nodes": 170,
                            "simplex_iterations": 63882,
                            "explored_time": 13.47,
                            "work_units": 11.08
                        },
                        {
                            "gap": 91.982,
                            "total_time": 18.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 16328,
                            "explored_time": 18.46,
                            "work_units": 10.01
                        },
                        {
                            "gap": 94.1553,
                            "total_time": 11.32,
                            "explored_nodes": 1,
                            "simplex_iterations": 38831,
                            "explored_time": 11.28,
                            "work_units": 10.0
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "47d4dcd5-92c0-4da1-b133-5eefbe8078a9",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-compute operations on each machine to facilitate the cut generation\n    ops_per_machine = {}\n    for (j, k) in model.O:\n        m_id = machines[j][k]\n        if m_id not in ops_per_machine:\n            ops_per_machine[m_id] = []\n        ops_per_machine[m_id].append((j, k))\n    \n    def get_y_val_lift(m, op_a, op_b):\n        # Helper to retrieve y_ab regardless of index order in model.Pairs\n        if op_a < op_b:\n            return m.y[op_a[0], op_a[1], op_b[0], op_b[1]]\n        else:\n            return 1 - m.y[op_b[0], op_b[1], op_a[0], op_a[1]]\n    \n    def intermediate_lifting_rule(m, j1, k1, j2, k2):\n        # For a pair u -> v, lift the start time of v based on intermediate ops w\n        u, v = (j1, k1), (j2, k2)\n        mach_id = machines[j1][k1]\n        \n        # Calculate the sum of processing times for all w strictly between u and v\n        # The term (y_uw + y_wv - 1) is 1 iff u -> w -> v, else <= 0\n        intermediate_term = 0\n        for w in ops_per_machine[mach_id]:\n            if w != u and w != v:\n                y_uw = get_y_val_lift(m, u, w)\n                y_wv = get_y_val_lift(m, w, v)\n                intermediate_term += m.p[w] * (y_uw + y_wv - 1)\n                \n        y_uv = m.y[j1, k1, j2, k2]\n        # Strengthened disjunctive constraint: \n        # S_v >= S_u + p_u + sum(p_w * is_between) - M*(1 - y_uv)\n        return m.S[v] >= m.S[u] + m.p[u] + intermediate_term - m.bigM * (1 - y_uv)\n    \n    model.intermediate_lifting_cuts = pyo.Constraint(model.Pairs, rule=intermediate_lifting_rule)\n\n    return model\n",
                        "added_cut": "# Pre-compute operations on each machine to facilitate the cut generation\nops_per_machine = {}\nfor (j, k) in model.O:\n    m_id = machines[j][k]\n    if m_id not in ops_per_machine:\n        ops_per_machine[m_id] = []\n    ops_per_machine[m_id].append((j, k))\n\ndef get_y_val_lift(m, op_a, op_b):\n    # Helper to retrieve y_ab regardless of index order in model.Pairs\n    if op_a < op_b:\n        return m.y[op_a[0], op_a[1], op_b[0], op_b[1]]\n    else:\n        return 1 - m.y[op_b[0], op_b[1], op_a[0], op_a[1]]\n\ndef intermediate_lifting_rule(m, j1, k1, j2, k2):\n    # For a pair u -> v, lift the start time of v based on intermediate ops w\n    u, v = (j1, k1), (j2, k2)\n    mach_id = machines[j1][k1]\n    \n    # Calculate the sum of processing times for all w strictly between u and v\n    # The term (y_uw + y_wv - 1) is 1 iff u -> w -> v, else <= 0\n    intermediate_term = 0\n    for w in ops_per_machine[mach_id]:\n        if w != u and w != v:\n            y_uw = get_y_val_lift(m, u, w)\n            y_wv = get_y_val_lift(m, w, v)\n            intermediate_term += m.p[w] * (y_uw + y_wv - 1)\n            \n    y_uv = m.y[j1, k1, j2, k2]\n    # Strengthened disjunctive constraint: \n    # S_v >= S_u + p_u + sum(p_w * is_between) - M*(1 - y_uv)\n    return m.S[v] >= m.S[u] + m.p[u] + intermediate_term - m.bigM * (1 - y_uv)\n\nmodel.intermediate_lifting_cuts = pyo.Constraint(model.Pairs, rule=intermediate_lifting_rule)",
                        "idea": "We introduce **Intermediate Operation Lifting Cuts** (also known as Sequential Lifting). For any pair of operations $u, v$ on the same machine where $u$ precedes $v$ ($y_{uv}=1$), the time lag $S_v - S_u$ must accommodate not just $p_u$, but also the processing times of all other operations $w$ sequenced *between* $u$ and $v$. The condition 'Sequence: $u \\to w \\to v$' is linearized as $(y_{uw} + y_{wv} - 1)$. This constraint tightens the formulation by explicitly linking the continuous start times to the cumulative processing volume of intermediate operations, preventing fractional solutions where the gap between $u$ and $v$ is artificially compressed."
                    },
                    "fitness": 8.368165045102419,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 4836,
                            "explored_time": 13.04,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 13.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 4938,
                            "explored_time": 12.99,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 11.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 11.05,
                            "work_units": 10.02
                        },
                        {
                            "gap": 94.8761,
                            "total_time": 9.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 10336,
                            "explored_time": 8.98,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 10.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.35,
                            "work_units": 10.01
                        },
                        {
                            "gap": 77.803,
                            "total_time": 13.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 16092,
                            "explored_time": 13.14,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.713,
                            "total_time": 7.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 13050,
                            "explored_time": 7.1,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9893,
                            "total_time": 13.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 4904,
                            "explored_time": 13.07,
                            "work_units": 10.0
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "d0c3bb89-c4a6-4d12-aa07-60b386ce308a",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-calculate earliest release times (Heads) for each operation based on job predecessors.\n    # These serve as valid static lower bounds for start times.\n    op_heads_static = {}\n    for j in range(n_jobs):\n        accumulated_time = 0\n        for k in range(n_machines):\n            op_heads_static[j, k] = accumulated_time\n            accumulated_time += times[j][k]\n    \n    def machine_sum_starts_rule(m, mach_id):\n        # Identify all operations processed on this specific machine\n        mach_ops = [(j, k) for j in range(n_jobs) for k in range(n_machines) \n                    if machines[j][k] == mach_id]\n        \n        if not mach_ops:\n            return pyo.Constraint.Skip\n        \n        # Derivation of the Cut:\n        # We want a lower bound on the Sum of Start Times (Sum S_ijk) for this machine.\n        # Relaxation: Assume all operations on this machine are released at the \n        # earliest release time (r_min) among them.\n        # The scheduling policy that minimizes the sum of start times (or flow time) \n        # on a single machine is Shortest Processing Time (SPT).\n        \n        # 1. Determine r_min (relaxed release date)\n        r_min = min(op_heads_static[op] for op in mach_ops)\n        \n        # 2. Get processing times and sort them (SPT ordering)\n        p_sorted = sorted([times[j][k] for (j, k) in mach_ops])\n        n_ops = len(p_sorted)\n        \n        # 3. Calculate the minimal sum of waiting times.\n        # In an SPT sequence starting at r_min:\n        # - Op 0 starts at r_min\n        # - Op 1 starts at r_min + p_0\n        # - Op i starts at r_min + sum(p_0 ... p_{i-1})\n        # Contribution of p_k to the total sum is (n_ops - 1 - k) * p_k\n        \n        spt_waiting_contribution = sum((n_ops - 1 - i) * p_sorted[i] for i in range(n_ops))\n        \n        # Lower Bound = Sum(Starts) >= n * r_min + Sum(Waiting Times)\n        lb_sum_starts = n_ops * r_min + spt_waiting_contribution\n        \n        return sum(m.S[j, k] for (j, k) in mach_ops) >= lb_sum_starts\n    \n    model.sum_start_times_cuts = pyo.Constraint(pyo.RangeSet(0, n_machines - 1), \n                                                rule=machine_sum_starts_rule)\n\n    return model\n",
                        "added_cut": "# Pre-calculate earliest release times (Heads) for each operation based on job predecessors.\n# These serve as valid static lower bounds for start times.\nop_heads_static = {}\nfor j in range(n_jobs):\n    accumulated_time = 0\n    for k in range(n_machines):\n        op_heads_static[j, k] = accumulated_time\n        accumulated_time += times[j][k]\n\ndef machine_sum_starts_rule(m, mach_id):\n    # Identify all operations processed on this specific machine\n    mach_ops = [(j, k) for j in range(n_jobs) for k in range(n_machines) \n                if machines[j][k] == mach_id]\n    \n    if not mach_ops:\n        return pyo.Constraint.Skip\n    \n    # Derivation of the Cut:\n    # We want a lower bound on the Sum of Start Times (Sum S_ijk) for this machine.\n    # Relaxation: Assume all operations on this machine are released at the \n    # earliest release time (r_min) among them.\n    # The scheduling policy that minimizes the sum of start times (or flow time) \n    # on a single machine is Shortest Processing Time (SPT).\n    \n    # 1. Determine r_min (relaxed release date)\n    r_min = min(op_heads_static[op] for op in mach_ops)\n    \n    # 2. Get processing times and sort them (SPT ordering)\n    p_sorted = sorted([times[j][k] for (j, k) in mach_ops])\n    n_ops = len(p_sorted)\n    \n    # 3. Calculate the minimal sum of waiting times.\n    # In an SPT sequence starting at r_min:\n    # - Op 0 starts at r_min\n    # - Op 1 starts at r_min + p_0\n    # - Op i starts at r_min + sum(p_0 ... p_{i-1})\n    # Contribution of p_k to the total sum is (n_ops - 1 - k) * p_k\n    \n    spt_waiting_contribution = sum((n_ops - 1 - i) * p_sorted[i] for i in range(n_ops))\n    \n    # Lower Bound = Sum(Starts) >= n * r_min + Sum(Waiting Times)\n    lb_sum_starts = n_ops * r_min + spt_waiting_contribution\n    \n    return sum(m.S[j, k] for (j, k) in mach_ops) >= lb_sum_starts\n\nmodel.sum_start_times_cuts = pyo.Constraint(pyo.RangeSet(0, n_machines - 1), \n                                            rule=machine_sum_starts_rule)",
                        "idea": "We introduce **Sum-of-Start-Times Cuts** (Aggregate Machine Schedule Cuts). Unlike cuts that bound the global makespan or pairwise gaps, this constraint enforces a lower bound on the **sum** of start times for all operations on a specific machine. By relaxing the single-machine subproblem to one where all operations are available at the earliest group release time ($r_{min}$), we utilize the property that the Shortest Processing Time (SPT) rule minimizes the sum of start times. The resulting inequality, $\\sum S_{i} \\ge n \\cdot r_{min} + \\sum (n-1-k) p_{(k)}$, creates a valid 'center of mass' constraint. This tightens the LP relaxation by penalizing solutions where multiple operations are fractionally scheduled earlier than the machine's cumulative capacity allows, forcing the aggregate schedule to spread out over time."
                    },
                    "fitness": 10.066617394147068,
                    "solver_reports": [
                        {
                            "gap": 95.1428,
                            "total_time": 16.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 27723,
                            "explored_time": 16.02,
                            "work_units": 10.03
                        },
                        {
                            "gap": 95.4402,
                            "total_time": 14.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 27686,
                            "explored_time": 14.88,
                            "work_units": 10.01
                        },
                        {
                            "gap": 95.5672,
                            "total_time": 13.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 44852,
                            "explored_time": 12.94,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.2273,
                            "total_time": 18.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 25051,
                            "explored_time": 18.29,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.1899,
                            "total_time": 15.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 35943,
                            "explored_time": 15.45,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.6593,
                            "total_time": 12.76,
                            "explored_nodes": 555,
                            "simplex_iterations": 79519,
                            "explored_time": 12.75,
                            "work_units": 10.79
                        },
                        {
                            "gap": 92.6867,
                            "total_time": 19.71,
                            "explored_nodes": 1,
                            "simplex_iterations": 19090,
                            "explored_time": 19.67,
                            "work_units": 10.01
                        },
                        {
                            "gap": 95.5686,
                            "total_time": 17.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 24265,
                            "explored_time": 17.21,
                            "work_units": 10.01
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "ce74d044-76f0-491a-a9ba-2998fd928265",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # (4) Opposed Routing Flow Cuts\n    # This constraint strengthens the formulation for pairs of jobs with \"opposed\" routing.\n    # If Job j1 goes Machine A -> Machine B, and Job j2 goes Machine B -> Machine A,\n    # and j1 precedes j2 on BOTH machines, a strict physical path is formed:\n    # Start(j1, A) -> End(j1, A) -> ... -> Start(j1, B) -> End(j1, B) -> Start(j2, B) -> End(j2, B) -> ... -> Start(j2, A).\n    # This cut lifts the start time of j2 on A based on the precedence decision on B.\n    \n    model.OpposedRoutingCuts = pyo.ConstraintList()\n    \n    for j1 in model.J:\n        for j2 in model.J:\n            if j1 >= j2:\n                continue\n            \n            # Iterate over all pairs of operations for j1 that define a flow A -> B\n            for k1_A in model.K:\n                for k1_B in model.K:\n                    if k1_A >= k1_B:\n                        continue\n                    \n                    mA = model.mach[j1, k1_A]\n                    mB = model.mach[j1, k1_B]\n                    \n                    if mA == mB:\n                        continue\n                    \n                    # Check if j2 has the opposed flow B -> A\n                    # Find operations of j2 on mA and mB\n                    k2_A_opts = [k for k in model.K if model.mach[j2, k] == mA]\n                    k2_B_opts = [k for k in model.K if model.mach[j2, k] == mB]\n                    \n                    for k2_A in k2_A_opts:\n                        for k2_B in k2_B_opts:\n                            # For opposed routing, j2 must visit B before A (k2_B < k2_A)\n                            if k2_B < k2_A:\n                                # Variables for precedence (j1 precedes j2)\n                                # Since j1 < j2, the keys are (j1, k1, j2, k2)\n                                y_A = model.y[j1, k1_A, j2, k2_A]\n                                y_B = model.y[j1, k1_B, j2, k2_B]\n                                \n                                # Processing times involved in the loop\n                                p1_A = model.p[j1, k1_A]\n                                p1_B = model.p[j1, k1_B]\n                                p2_B = model.p[j2, k2_B]\n                                \n                                # Intermediate processing times within jobs\n                                gap1 = sum(model.p[j1, k] for k in range(k1_A + 1, k1_B))\n                                gap2 = sum(model.p[j2, k] for k in range(k2_B + 1, k2_A))\n                                \n                                # The lift value represents the minimum time elapsed between End(j1,A) and Start(j2,A)\n                                # if j1 precedes j2 on B. Path: j1(A->B) + p1_B + p2_B + j2(B->A)\n                                lift_val = gap1 + p1_B + p2_B + gap2\n                                \n                                # Constraint: S(j2, A) >= S(j1, A) + p1_A + lift * y_B - M(1 - y_A)\n                                model.OpposedRoutingCuts.add(\n                                    model.S[j2, k2_A] >= model.S[j1, k1_A] + p1_A + lift_val * y_B - model.bigM * (1 - y_A)\n                                )\n\n    return model\n",
                        "added_cut": "    # (4) Opposed Routing Flow Cuts\n    # This constraint strengthens the formulation for pairs of jobs with \"opposed\" routing.\n    # If Job j1 goes Machine A -> Machine B, and Job j2 goes Machine B -> Machine A,\n    # and j1 precedes j2 on BOTH machines, a strict physical path is formed:\n    # Start(j1, A) -> End(j1, A) -> ... -> Start(j1, B) -> End(j1, B) -> Start(j2, B) -> End(j2, B) -> ... -> Start(j2, A).\n    # This cut lifts the start time of j2 on A based on the precedence decision on B.\n    \n    model.OpposedRoutingCuts = pyo.ConstraintList()\n    \n    for j1 in model.J:\n        for j2 in model.J:\n            if j1 >= j2:\n                continue\n            \n            # Iterate over all pairs of operations for j1 that define a flow A -> B\n            for k1_A in model.K:\n                for k1_B in model.K:\n                    if k1_A >= k1_B:\n                        continue\n                    \n                    mA = model.mach[j1, k1_A]\n                    mB = model.mach[j1, k1_B]\n                    \n                    if mA == mB:\n                        continue\n                    \n                    # Check if j2 has the opposed flow B -> A\n                    # Find operations of j2 on mA and mB\n                    k2_A_opts = [k for k in model.K if model.mach[j2, k] == mA]\n                    k2_B_opts = [k for k in model.K if model.mach[j2, k] == mB]\n                    \n                    for k2_A in k2_A_opts:\n                        for k2_B in k2_B_opts:\n                            # For opposed routing, j2 must visit B before A (k2_B < k2_A)\n                            if k2_B < k2_A:\n                                # Variables for precedence (j1 precedes j2)\n                                # Since j1 < j2, the keys are (j1, k1, j2, k2)\n                                y_A = model.y[j1, k1_A, j2, k2_A]\n                                y_B = model.y[j1, k1_B, j2, k2_B]\n                                \n                                # Processing times involved in the loop\n                                p1_A = model.p[j1, k1_A]\n                                p1_B = model.p[j1, k1_B]\n                                p2_B = model.p[j2, k2_B]\n                                \n                                # Intermediate processing times within jobs\n                                gap1 = sum(model.p[j1, k] for k in range(k1_A + 1, k1_B))\n                                gap2 = sum(model.p[j2, k] for k in range(k2_B + 1, k2_A))\n                                \n                                # The lift value represents the minimum time elapsed between End(j1,A) and Start(j2,A)\n                                # if j1 precedes j2 on B. Path: j1(A->B) + p1_B + p2_B + j2(B->A)\n                                lift_val = gap1 + p1_B + p2_B + gap2\n                                \n                                # Constraint: S(j2, A) >= S(j1, A) + p1_A + lift * y_B - M(1 - y_A)\n                                model.OpposedRoutingCuts.add(\n                                    model.S[j2, k2_A] >= model.S[j1, k1_A] + p1_A + lift_val * y_B - model.bigM * (1 - y_A)\n                                )",
                        "idea": "We introduce **Opposed Routing Flow Cuts** to tighten the relaxation for pairs of jobs with swapped machine sequences (e.g., Job 1 visits $A \\to B$, Job 2 visits $B \\to A$). If Job 1 precedes Job 2 on both machines ($y^A=1$ and $y^B=1$), a mandatory 'loop' delay is created: the schedule must satisfy the path $S_{1,A} \\xrightarrow{Job1} S_{1,B} \\xrightarrow{MachB} S_{2,B} \\xrightarrow{Job2} S_{2,A}$. This implies $S_{2,A} \\ge S_{1,A} + p_{1,A} + (p_{1,B} + p_{2,B} + \\text{JobGap}_1 + \\text{JobGap}_2)$. Standard disjunctive constraints only enforce $S_{2,A} \\ge S_{1,A} + p_{1,A}$ locally on machine A. This cut lifts the start time lower bound by conditionally adding the cumulative latency from machine B and the intermediate job flows, strictly penalizing fractional solutions where precedence variables are active on both machines."
                    },
                    "fitness": 9.60501594666032,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 7.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 19075,
                            "explored_time": 7.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 7.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 17222,
                            "explored_time": 7.32,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 8.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 17106,
                            "explored_time": 8.29,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.2173,
                            "total_time": 15.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 10795,
                            "explored_time": 15.32,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 7.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 17757,
                            "explored_time": 7.76,
                            "work_units": 10.0
                        },
                        {
                            "gap": 41.7736,
                            "total_time": 13.2,
                            "explored_nodes": 115,
                            "simplex_iterations": 48451,
                            "explored_time": 13.19,
                            "work_units": 11.23
                        },
                        {
                            "gap": 94.5802,
                            "total_time": 13.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 10794,
                            "explored_time": 13.9,
                            "work_units": 10.04
                        },
                        {
                            "gap": 96.9893,
                            "total_time": 8.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 16773,
                            "explored_time": 7.97,
                            "work_units": 10.01
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                }
            ],
            12.107175463655313
        ],
        [
            [
                {
                    "id": "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-compute Heads (earliest release) and Tails (remaining work) for all operations\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        # Forward pass: Heads\n        h_accum = 0\n        for k in range(n_machines):\n            op_heads[j, k] = h_accum\n            h_accum += times[j][k]\n        # Backward pass: Tails\n        t_accum = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = t_accum\n            t_accum += times[j][k]\n    \n    # Group operations by machine ID\n    machine_to_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in machine_to_ops:\n                machine_to_ops[m_id] = []\n            machine_to_ops[m_id].append((j, k))\n    \n    def machine_workload_rule(m, m_id):\n        # 1-Machine Relaxation Bound:\n        # The makespan must accommodate the total processing time of all ops on the machine,\n        # plus the earliest possible arrival (min Head) and latest mandatory work-off (min Tail).\n        ops = machine_to_ops[m_id]\n        if not ops:\n            return pyo.Constraint.Skip\n        \n        min_head = min(op_heads[op] for op in ops)\n        total_p = sum(times[op[0]][op[1]] for op in ops)\n        min_tail = min(op_tails[op] for op in ops)\n        \n        return m.Cmax >= min_head + total_p + min_tail\n    \n    # Apply the cut for every machine used in the instance\n    model.machine_workload_cuts = pyo.Constraint(list(machine_to_ops.keys()), rule=machine_workload_rule)\n\n    return model\n",
                        "added_cut": "# Pre-compute Heads (earliest release) and Tails (remaining work) for all operations\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    # Forward pass: Heads\n    h_accum = 0\n    for k in range(n_machines):\n        op_heads[j, k] = h_accum\n        h_accum += times[j][k]\n    # Backward pass: Tails\n    t_accum = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = t_accum\n        t_accum += times[j][k]\n\n# Group operations by machine ID\nmachine_to_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in machine_to_ops:\n            machine_to_ops[m_id] = []\n        machine_to_ops[m_id].append((j, k))\n\ndef machine_workload_rule(m, m_id):\n    # 1-Machine Relaxation Bound:\n    # The makespan must accommodate the total processing time of all ops on the machine,\n    # plus the earliest possible arrival (min Head) and latest mandatory work-off (min Tail).\n    ops = machine_to_ops[m_id]\n    if not ops:\n        return pyo.Constraint.Skip\n    \n    min_head = min(op_heads[op] for op in ops)\n    total_p = sum(times[op[0]][op[1]] for op in ops)\n    min_tail = min(op_tails[op] for op in ops)\n    \n    return m.Cmax >= min_head + total_p + min_tail\n\n# Apply the cut for every machine used in the instance\nmodel.machine_workload_cuts = pyo.Constraint(list(machine_to_ops.keys()), rule=machine_workload_rule)",
                        "idea": "We apply static **Machine Workload Cuts** (derived from the 1-machine relaxation). For any machine $m$, the makespan $C_{max}$ is strictly bounded by the sum of processing times of all operations assigned to $m$, shifted by the earliest release time (Head) and the minimum post-processing time (Tail) among those operations. Formally, $C_{max} \\ge \\min_{i \\in \\Omega_m}(Head_i) + \\sum_{i \\in \\Omega_m} p_i + \\min_{i \\in \\Omega_m}(Tail_i)$. This cut aggregates capacity constraints, strengthening the LP relaxation where disjunctive constraints are often loose."
                    },
                    "fitness": 12.107175463655313,
                    "solver_reports": [
                        {
                            "gap": 89.8612,
                            "total_time": 15.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 27070,
                            "explored_time": 15.27,
                            "work_units": 10.06
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.34,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 9.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.64,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 13.86,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 13.85,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.4069,
                            "total_time": 9.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 36528,
                            "explored_time": 9.7,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.4,
                            "total_time": 13.29,
                            "explored_nodes": 9932,
                            "simplex_iterations": 303128,
                            "explored_time": 13.27,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.0633,
                            "total_time": 19.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 33623,
                            "explored_time": 19.35,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.44,
                            "work_units": 10.0
                        }
                    ],
                    "generator": null,
                    "parents_id": null
                },
                {
                    "id": "bc838ac0-4d80-447a-8bdb-738d4bdaf0ce",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Precompute job tails (remaining processing time after each operation)\n    # tails[j][k] = sum(p[j][x] for x > k)\n    tails = [[sum(times[j][x] for x in range(k + 1, n_machines)) \n              for k in range(n_machines)] for j in range(n_jobs)]\n    \n    # Precompute minimum tail for each machine to strengthen bounds\n    # min_mach_tails[m] = min(tail[j][k] for all ops (j,k) on machine m)\n    min_mach_tails = {}\n    for m_id in range(n_machines):\n        ops_on_m = [(j, k) for j in range(n_jobs) for k in range(n_machines) \n                    if machines[j][k] == m_id]\n        min_mach_tails[m_id] = min(tails[j][k] for j, k in ops_on_m) if ops_on_m else 0\n    \n    model.integrated_cuts = pyo.ConstraintList()\n    \n    # 1. Enhanced Successor Workload Cuts (Parent 1 + Static Tail Look-ahead)\n    # We lift Parent 1's cut by adding the minimum job-tail of the machine.\n    # This accounts for the fact that the last operation on machine m has a specific downstream path.\n    for (j, k) in model.O:\n        m_id = machines[j][k]\n        \n        # Calculate dynamic workload of successors on the same machine\n        load_after = 0\n        # Identify all other operations on the same machine\n        others = [(j2, k2) for j2 in range(n_jobs) for k2 in range(n_machines) \n                  if machines[j2][k2] == m_id and (j2, k2) != (j, k)]\n                  \n        for (j2, k2) in others:\n            # Add p[j2,k2] if (j2,k2) is sequenced after (j,k)\n            if (j, k) < (j2, k2):\n                load_after += model.p[j2, k2] * model.y[j, k, j2, k2]\n            else:\n                load_after += model.p[j2, k2] * (1 - model.y[j2, k2, j, k])\n                \n        # Constraint: Cmax >= Start(u) + Proc(u) + SuccessorLoad + MinMachineTail\n        model.integrated_cuts.add(\n            model.Cmax >= model.S[j, k] + model.p[j, k] + load_after + min_mach_tails[m_id]\n        )\n    \n    # 2. Inter-Machine Crossing Cuts (Parent 2)\n    # These tighten the start times (S) that feed into the Cmax cuts above.\n    for j1 in range(n_jobs):\n        for j2 in range(j1 + 1, n_jobs):\n            # Map machine -> stage index\n            m_map1 = {machines[j1][k]: k for k in range(n_machines)}\n            m_map2 = {machines[j2][k]: k for k in range(n_machines)}\n            common = set(m_map1) & set(m_map2)\n            \n            for mA in common:\n                for mB in common:\n                    if mA == mB: continue\n                    u1, v1 = m_map1[mA], m_map1[mB]\n                    u2, v2 = m_map2[mA], m_map2[mB]\n                    \n                    # If both jobs have flow A -> B\n                    if u1 < v1 and u2 < v2:\n                        yA = model.y[j1, u1, j2, u2] # j1->j2 on A\n                        yB = model.y[j1, v1, j2, v2] # j1->j2 on B\n                        \n                        # If sequence crosses (j1->j2 on A, j2->j1 on B), force path delay\n                        penalty = times[j2][u2] + times[j2][v2]\n                        model.integrated_cuts.add(\n                            model.S[j1, v1] >= model.S[j1, u1] + times[j1][u1] + penalty * (yA - yB)\n                        )\n\n    return model\n",
                        "added_cut": "# Precompute job tails (remaining processing time after each operation)\n# tails[j][k] = sum(p[j][x] for x > k)\ntails = [[sum(times[j][x] for x in range(k + 1, n_machines)) \n          for k in range(n_machines)] for j in range(n_jobs)]\n\n# Precompute minimum tail for each machine to strengthen bounds\n# min_mach_tails[m] = min(tail[j][k] for all ops (j,k) on machine m)\nmin_mach_tails = {}\nfor m_id in range(n_machines):\n    ops_on_m = [(j, k) for j in range(n_jobs) for k in range(n_machines) \n                if machines[j][k] == m_id]\n    min_mach_tails[m_id] = min(tails[j][k] for j, k in ops_on_m) if ops_on_m else 0\n\nmodel.integrated_cuts = pyo.ConstraintList()\n\n# 1. Enhanced Successor Workload Cuts (Parent 1 + Static Tail Look-ahead)\n# We lift Parent 1's cut by adding the minimum job-tail of the machine.\n# This accounts for the fact that the last operation on machine m has a specific downstream path.\nfor (j, k) in model.O:\n    m_id = machines[j][k]\n    \n    # Calculate dynamic workload of successors on the same machine\n    load_after = 0\n    # Identify all other operations on the same machine\n    others = [(j2, k2) for j2 in range(n_jobs) for k2 in range(n_machines) \n              if machines[j2][k2] == m_id and (j2, k2) != (j, k)]\n              \n    for (j2, k2) in others:\n        # Add p[j2,k2] if (j2,k2) is sequenced after (j,k)\n        if (j, k) < (j2, k2):\n            load_after += model.p[j2, k2] * model.y[j, k, j2, k2]\n        else:\n            load_after += model.p[j2, k2] * (1 - model.y[j2, k2, j, k])\n            \n    # Constraint: Cmax >= Start(u) + Proc(u) + SuccessorLoad + MinMachineTail\n    model.integrated_cuts.add(\n        model.Cmax >= model.S[j, k] + model.p[j, k] + load_after + min_mach_tails[m_id]\n    )\n\n# 2. Inter-Machine Crossing Cuts (Parent 2)\n# These tighten the start times (S) that feed into the Cmax cuts above.\nfor j1 in range(n_jobs):\n    for j2 in range(j1 + 1, n_jobs):\n        # Map machine -> stage index\n        m_map1 = {machines[j1][k]: k for k in range(n_machines)}\n        m_map2 = {machines[j2][k]: k for k in range(n_machines)}\n        common = set(m_map1) & set(m_map2)\n        \n        for mA in common:\n            for mB in common:\n                if mA == mB: continue\n                u1, v1 = m_map1[mA], m_map1[mB]\n                u2, v2 = m_map2[mA], m_map2[mB]\n                \n                # If both jobs have flow A -> B\n                if u1 < v1 and u2 < v2:\n                    yA = model.y[j1, u1, j2, u2] # j1->j2 on A\n                    yB = model.y[j1, v1, j2, v2] # j1->j2 on B\n                    \n                    # If sequence crosses (j1->j2 on A, j2->j1 on B), force path delay\n                    penalty = times[j2][u2] + times[j2][v2]\n                    model.integrated_cuts.add(\n                        model.S[j1, v1] >= model.S[j1, u1] + times[j1][u1] + penalty * (yA - yB)\n                    )",
                        "idea": "We construct an **Integrated Flow-Workload Cut** that fuses the strengths of both parents. We adopt Parent 1's global makespan formulation (which bounds $C_{max}$ via dynamic machine loading) and strengthen it by adding a **static tail term** ($\\\\min\\\\_mach\\\\_tails$). This term represents the unavoidable downstream processing (job tail) of the last operation on the machine, integrating the \"path look-ahead\" concept from Parent 2 directly into the global bound. Simultaneously, we include Parent 2's crossing cuts to strictly bound the intermediate start times ($S$) in cases of sequence violation. This combination tightens the relaxation from two directions: lifting the global $C_{max}$ lower bound and pushing up local $S$ variables involved in flow conflicts."
                    },
                    "fitness": 12.25355215054149,
                    "solver_reports": [
                        {
                            "total_time": 12.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 22419,
                            "explored_time": 12.18,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 24379,
                            "explored_time": 12.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 16.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 16.44,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 17338,
                            "explored_time": 8.22,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 24.43,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 24.23,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.2353,
                            "total_time": 11.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 20288,
                            "explored_time": 11.85,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 19235,
                            "explored_time": 8.4,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 24385,
                            "explored_time": 11.21,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "8a37cb28-d2ae-43b3-a05c-4e7d0160b668",
                        "9395d90c-2832-44a7-96f0-c9ff646e2922"
                    ]
                },
                {
                    "id": "bda49ecf-46fd-4b71-87d9-86d650cbacd5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Combined Constraint: Bi-Directional Machine Displacement Cuts\n    # ----------------------------------------------------------------\n    \n    # 1. Precompute static heads (earliest start times) and group operations by machine\n    op_heads_map = {}\n    mach_ops_map = {m_id: [] for m_id in range(n_machines)}\n    \n    for j_idx in range(n_jobs):\n        curr_time = 0\n        for k_idx in range(n_machines):\n            op_val = (j_idx, k_idx)\n            m_id = machines[j_idx][k_idx]\n            \n            op_heads_map[op_val] = curr_time\n            mach_ops_map[m_id].append(op_val)\n            \n            curr_time += times[j_idx][k_idx]\n    \n    # Calculate the minimum possible head (release time) for each machine\n    min_mach_heads = {}\n    for m_id in range(n_machines):\n        if mach_ops_map[m_id]:\n            min_mach_heads[m_id] = min(op_heads_map[o] for o in mach_ops_map[m_id])\n        else:\n            min_mach_heads[m_id] = 0\n    \n    # 2. Define a set to toggle between the two cut directions\n    # 'fwd': Bounds Start Time using Predecessors (Parent 2)\n    # 'bwd': Bounds Makespan using Successors (Parent 1)\n    model.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def bidir_cut_rule(m, j, k, c_type):\n        u_op = (j, k)\n        u_mach = machines[j][k]\n        relevant_ops = mach_ops_map[u_mach]\n        \n        if c_type == 'bwd':\n            # Parent 1 Logic: Cmax >= S_u + p_u + Sum(Work of Successors)\n            # This links Cmax to the schedule tail.\n            succ_work = 0\n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # If u_op < (j2,k2), pair is (u,v). y=1 implies u->v (v is successor).\n                if u_op < (j2, k2):\n                    succ_work += m.p[j2, k2] * m.y[j, k, j2, k2]\n                # If (j2,k2) < u_op, pair is (v,u). y=0 implies u->v (v is successor).\n                else:\n                    succ_work += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n            \n            return m.Cmax >= m.S[j, k] + m.p[j, k] + succ_work\n    \n        else:\n            # Parent 2 Logic: S_u >= r_min_machine + Sum(Work of Predecessors)\n            # This lifts the Start Time based on the schedule head.\n            pred_work = 0\n            r_min = min_mach_heads[u_mach]\n            \n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # If (j2,k2) < u_op, pair is (v,u). y=1 implies v->u (v is predecessor).\n                if (j2, k2) < u_op:\n                    pred_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n                # If u_op < (j2,k2), pair is (u,v). y=0 implies v->u (v is predecessor).\n                else:\n                    pred_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n            \n            return m.S[j, k] >= r_min + pred_work\n    \n    model.BiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=bidir_cut_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Combined Constraint: Bi-Directional Machine Displacement Cuts\n# ----------------------------------------------------------------\n\n# 1. Precompute static heads (earliest start times) and group operations by machine\nop_heads_map = {}\nmach_ops_map = {m_id: [] for m_id in range(n_machines)}\n\nfor j_idx in range(n_jobs):\n    curr_time = 0\n    for k_idx in range(n_machines):\n        op_val = (j_idx, k_idx)\n        m_id = machines[j_idx][k_idx]\n        \n        op_heads_map[op_val] = curr_time\n        mach_ops_map[m_id].append(op_val)\n        \n        curr_time += times[j_idx][k_idx]\n\n# Calculate the minimum possible head (release time) for each machine\nmin_mach_heads = {}\nfor m_id in range(n_machines):\n    if mach_ops_map[m_id]:\n        min_mach_heads[m_id] = min(op_heads_map[o] for o in mach_ops_map[m_id])\n    else:\n        min_mach_heads[m_id] = 0\n\n# 2. Define a set to toggle between the two cut directions\n# 'fwd': Bounds Start Time using Predecessors (Parent 2)\n# 'bwd': Bounds Makespan using Successors (Parent 1)\nmodel.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef bidir_cut_rule(m, j, k, c_type):\n    u_op = (j, k)\n    u_mach = machines[j][k]\n    relevant_ops = mach_ops_map[u_mach]\n    \n    if c_type == 'bwd':\n        # Parent 1 Logic: Cmax >= S_u + p_u + Sum(Work of Successors)\n        # This links Cmax to the schedule tail.\n        succ_work = 0\n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # If u_op < (j2,k2), pair is (u,v). y=1 implies u->v (v is successor).\n            if u_op < (j2, k2):\n                succ_work += m.p[j2, k2] * m.y[j, k, j2, k2]\n            # If (j2,k2) < u_op, pair is (v,u). y=0 implies u->v (v is successor).\n            else:\n                succ_work += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n        \n        return m.Cmax >= m.S[j, k] + m.p[j, k] + succ_work\n\n    else:\n        # Parent 2 Logic: S_u >= r_min_machine + Sum(Work of Predecessors)\n        # This lifts the Start Time based on the schedule head.\n        pred_work = 0\n        r_min = min_mach_heads[u_mach]\n        \n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # If (j2,k2) < u_op, pair is (v,u). y=1 implies v->u (v is predecessor).\n            if (j2, k2) < u_op:\n                pred_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n            # If u_op < (j2,k2), pair is (u,v). y=0 implies v->u (v is predecessor).\n            else:\n                pred_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n        \n        return m.S[j, k] >= r_min + pred_work\n\nmodel.BiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=bidir_cut_rule)",
                        "idea": "We introduce **Bi-Directional Machine Displacement Cuts**, which integrate the strengths of both parent constraints into a unified bounding scheme. For every operation $u$ on machine $m$, this cut imposes two simultaneous conditions: (1) **Tail-Bound:** The global makespan $C_{max}$ is bounded below by $u$'s completion time plus the dynamically determined workload of all its successors (enhancing Parent 1's high-fitness logic). (2) **Head-Bound:** $u$'s start time $S_u$ is bounded below by the machine's earliest availability ($r_{min}$) plus the dynamically determined workload of all its predecessors (Parent 2's start-time lifting). By rigorously constraining the operation's position from both the 'left' (start time) and 'right' (makespan contribution) based on the binary sequencing variables $y$, this approach tightens the feasible region more effectively than either cut alone, effectively squeezing out schedules with underestimated delays."
                    },
                    "fitness": 14.394429380838801,
                    "solver_reports": [
                        {
                            "total_time": 6.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 21770,
                            "explored_time": 6.56,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 22960,
                            "explored_time": 6.98,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 32835,
                            "explored_time": 7.67,
                            "work_units": 10.02
                        },
                        {
                            "total_time": 6.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 22092,
                            "explored_time": 6.34,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 7.98,
                            "explored_nodes": 1,
                            "simplex_iterations": 33894,
                            "explored_time": 7.92,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.9332,
                            "total_time": 9.32,
                            "explored_nodes": 26,
                            "simplex_iterations": 41169,
                            "explored_time": 9.31,
                            "work_units": 10.15
                        },
                        {
                            "total_time": 5.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 17772,
                            "explored_time": 5.7,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 23197,
                            "explored_time": 6.58,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "8a37cb28-d2ae-43b3-a05c-4e7d0160b668",
                        "366493b1-62c2-4cdd-b383-18a9e183ff4d"
                    ]
                },
                {
                    "id": "8236f856-c803-471f-b687-0678ca2c73f5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Precompute static tails (remaining processing time) for all operations\n    # tail[j, k] is the sum of processing times for operations of job j following k.\n    op_tails = {}\n    for j_idx in range(n_jobs):\n        for k_idx in range(n_machines):\n            # Sum times of operations appearing after current k in the job sequence\n            op_tails[j_idx, k_idx] = sum(times[j_idx][k_next] for k_next in range(k_idx + 1, n_machines))\n    \n    # Precompute the minimum tail for each machine\n    # This serves as a safe lower bound on the remaining work for the last job leaving that machine.\n    mach_min_tail = {}\n    for m_id in range(n_machines):\n        # Collect tails of all operations that run on this specific machine\n        tails_on_m = [op_tails[j, k] for j in range(n_jobs) for k in range(n_machines) if machines[j][k] == m_id]\n        mach_min_tail[m_id] = min(tails_on_m) if tails_on_m else 0\n    \n    def tail_successor_rule(m, j, k):\n        u_mach = machines[j][k]\n        \n        # Start with completion time of u: S_u + p_u\n        current_load = m.S[j, k] + m.p[j, k]\n        \n        # Add processing times of all operations v that are sequenced AFTER u on the same machine.\n        # This dynamically calculates the completion time of the machine's workload starting from u.\n        for (j2, k2) in m.O:\n            if (j, k) == (j2, k2):\n                continue\n            if machines[j2][k2] == u_mach:\n                # Check precedence variables to determine if v follows u\n                if (j, k) < (j2, k2):\n                    # Pair is (j, k, j2, k2). y=1 means u precedes v (v follows u).\n                    current_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n                else:\n                    # Pair is (j2, k2, j, k). y=0 means u precedes v (v follows u).\n                    current_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                    \n        # The global makespan Cmax must be at least the time this machine finishes all its work,\n        # plus the time the last job on this machine needs to finish its subsequent operations (tail).\n        # Since the last job is unknown/dynamic, we add the minimum possible tail for this machine.\n        return m.Cmax >= current_load + mach_min_tail[u_mach]\n    \n    model.tail_successor_cut = pyo.Constraint(model.J, model.K, rule=tail_successor_rule)\n\n    return model\n",
                        "added_cut": "# Precompute static tails (remaining processing time) for all operations\n# tail[j, k] is the sum of processing times for operations of job j following k.\nop_tails = {}\nfor j_idx in range(n_jobs):\n    for k_idx in range(n_machines):\n        # Sum times of operations appearing after current k in the job sequence\n        op_tails[j_idx, k_idx] = sum(times[j_idx][k_next] for k_next in range(k_idx + 1, n_machines))\n\n# Precompute the minimum tail for each machine\n# This serves as a safe lower bound on the remaining work for the last job leaving that machine.\nmach_min_tail = {}\nfor m_id in range(n_machines):\n    # Collect tails of all operations that run on this specific machine\n    tails_on_m = [op_tails[j, k] for j in range(n_jobs) for k in range(n_machines) if machines[j][k] == m_id]\n    mach_min_tail[m_id] = min(tails_on_m) if tails_on_m else 0\n\ndef tail_successor_rule(m, j, k):\n    u_mach = machines[j][k]\n    \n    # Start with completion time of u: S_u + p_u\n    current_load = m.S[j, k] + m.p[j, k]\n    \n    # Add processing times of all operations v that are sequenced AFTER u on the same machine.\n    # This dynamically calculates the completion time of the machine's workload starting from u.\n    for (j2, k2) in m.O:\n        if (j, k) == (j2, k2):\n            continue\n        if machines[j2][k2] == u_mach:\n            # Check precedence variables to determine if v follows u\n            if (j, k) < (j2, k2):\n                # Pair is (j, k, j2, k2). y=1 means u precedes v (v follows u).\n                current_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n            else:\n                # Pair is (j2, k2, j, k). y=0 means u precedes v (v follows u).\n                current_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                \n    # The global makespan Cmax must be at least the time this machine finishes all its work,\n    # plus the time the last job on this machine needs to finish its subsequent operations (tail).\n    # Since the last job is unknown/dynamic, we add the minimum possible tail for this machine.\n    return m.Cmax >= current_load + mach_min_tail[u_mach]\n\nmodel.tail_successor_cut = pyo.Constraint(model.J, model.K, rule=tail_successor_rule)",
                        "idea": "We strengthen the Successor-Based Cumulative Makespan Cut by incorporating Job Tails. The original cut establishes that the makespan must exceed the completion time of a specific machine, calculated as the start of an operation u plus the processing times of all operations v sequenced after u. However, after the machine finishes its last operation, that specific job still has remaining operations to complete on other machines (its tail). Since we do not know a priori which job will be last, we strengthen the lower bound by adding the minimum tail among all operations assigned to that machine. This forces Cmax to account for the unavoidable post-processing time required by the last job exiting the machine."
                    },
                    "fitness": 10.645290898631119,
                    "solver_reports": [
                        {
                            "gap": 93.3946,
                            "total_time": 10.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 50113,
                            "explored_time": 10.3,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.9131,
                            "total_time": 11.76,
                            "explored_nodes": 1,
                            "simplex_iterations": 49736,
                            "explored_time": 11.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.0959,
                            "total_time": 10.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 48053,
                            "explored_time": 10.54,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8229,
                            "total_time": 19.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 16132,
                            "explored_time": 19.82,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.4481,
                            "total_time": 11.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 51756,
                            "explored_time": 11.51,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.7833,
                            "total_time": 12.09,
                            "explored_nodes": 115,
                            "simplex_iterations": 72262,
                            "explored_time": 12.08,
                            "work_units": 12.12
                        },
                        {
                            "gap": 91.7602,
                            "total_time": 15.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 17255,
                            "explored_time": 15.5,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.1553,
                            "total_time": 11.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 38831,
                            "explored_time": 11.49,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "8a37cb28-d2ae-43b3-a05c-4e7d0160b668"
                    ]
                },
                {
                    "id": "237a1c1a-7c67-4b6b-b79e-cfd0077be1d2",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-compute static tails (remaining processing time) for all operations (Parent 2 feature)\n    job_tails = {}\n    for j in range(n_jobs):\n        t_acc = 0\n        # Backward pass: sum times of subsequent operations in the job\n        for k in range(n_machines - 1, -1, -1):\n            job_tails[j, k] = t_acc\n            t_acc += times[j][k]\n    \n    # Group operations by machine to find the minimum global tail for each machine\n    mach_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in mach_ops:\n                mach_ops[m_id] = []\n            mach_ops[m_id].append((j, k))\n    \n    min_tail_per_machine = {}\n    for m_id, ops in mach_ops.items():\n        # The job that finishes last on this machine must have at least this much work left\n        if ops:\n            min_tail_per_machine[m_id] = min(job_tails[op] for op in ops)\n        else:\n            min_tail_per_machine[m_id] = 0\n    \n    def tail_lifted_successor_rule(m, j, k):\n        # Hybrid Logic: \n        # Cmax >= Start_u + Process_u + (Dynamic Workload After u) + (Static Machine Min Tail)\n        u_mach = machines[j][k]\n        p_u = m.p[j, k]\n        lift_term = min_tail_per_machine.get(u_mach, 0)\n        \n        # Calculate the sum of processing times for all v on the same machine that are sequenced AFTER u\n        # This uses Parent 1's dynamic sequencing logic\n        following_load = 0\n        if u_mach in mach_ops:\n            for (j2, k2) in mach_ops[u_mach]:\n                if (j, k) == (j2, k2):\n                    continue\n                \n                # Retrieve the correct binary variable y depending on index order\n                if (j, k) < (j2, k2):\n                    # y=1 implies u precedes v, so v contributes to the following load\n                    following_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n                else:\n                    # y=0 implies u precedes v (since y is defined as v precedes u here)\n                    following_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n    \n        return m.Cmax >= m.S[j, k] + p_u + following_load + lift_term\n    \n    model.tail_lifted_successor_cuts = pyo.Constraint(model.J, model.K, rule=tail_lifted_successor_rule)\n\n    return model\n",
                        "added_cut": "# Pre-compute static tails (remaining processing time) for all operations (Parent 2 feature)\njob_tails = {}\nfor j in range(n_jobs):\n    t_acc = 0\n    # Backward pass: sum times of subsequent operations in the job\n    for k in range(n_machines - 1, -1, -1):\n        job_tails[j, k] = t_acc\n        t_acc += times[j][k]\n\n# Group operations by machine to find the minimum global tail for each machine\nmach_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in mach_ops:\n            mach_ops[m_id] = []\n        mach_ops[m_id].append((j, k))\n\nmin_tail_per_machine = {}\nfor m_id, ops in mach_ops.items():\n    # The job that finishes last on this machine must have at least this much work left\n    if ops:\n        min_tail_per_machine[m_id] = min(job_tails[op] for op in ops)\n    else:\n        min_tail_per_machine[m_id] = 0\n\ndef tail_lifted_successor_rule(m, j, k):\n    # Hybrid Logic: \n    # Cmax >= Start_u + Process_u + (Dynamic Workload After u) + (Static Machine Min Tail)\n    u_mach = machines[j][k]\n    p_u = m.p[j, k]\n    lift_term = min_tail_per_machine.get(u_mach, 0)\n    \n    # Calculate the sum of processing times for all v on the same machine that are sequenced AFTER u\n    # This uses Parent 1's dynamic sequencing logic\n    following_load = 0\n    if u_mach in mach_ops:\n        for (j2, k2) in mach_ops[u_mach]:\n            if (j, k) == (j2, k2):\n                continue\n            \n            # Retrieve the correct binary variable y depending on index order\n            if (j, k) < (j2, k2):\n                # y=1 implies u precedes v, so v contributes to the following load\n                following_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n            else:\n                # y=0 implies u precedes v (since y is defined as v precedes u here)\n                following_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n\n    return m.Cmax >= m.S[j, k] + p_u + following_load + lift_term\n\nmodel.tail_lifted_successor_cuts = pyo.Constraint(model.J, model.K, rule=tail_lifted_successor_rule)",
                        "idea": "We introduce 'Tail-Lifted Successor Cuts', a hybrid constraint that strengthens the makespan lower bound. It combines the dynamic sequencing logic of Parent 1 (summing processing times of operations sequenced *after* a specific operation $u$) with the static capacity bounds of Parent 2 (specifically, the minimum 'Tail' or post-processing time required by any job on that machine). This formulation ensures that $C_{max}$ is bound not just by the completion of machine $m$'s workload starting from $u$, but also by the inevitable downstream processing required by the last job in that sequence, strictly lifting the relaxation."
                    },
                    "fitness": 10.645290898631119,
                    "solver_reports": [
                        {
                            "gap": 93.3946,
                            "total_time": 10.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 50113,
                            "explored_time": 10.36,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.9131,
                            "total_time": 11.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 49736,
                            "explored_time": 11.76,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.0959,
                            "total_time": 10.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 48053,
                            "explored_time": 10.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8229,
                            "total_time": 18.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 16132,
                            "explored_time": 18.25,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.4481,
                            "total_time": 11.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 51756,
                            "explored_time": 11.68,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.7833,
                            "total_time": 11.61,
                            "explored_nodes": 115,
                            "simplex_iterations": 72262,
                            "explored_time": 11.6,
                            "work_units": 12.12
                        },
                        {
                            "gap": 91.7602,
                            "total_time": 15.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 17255,
                            "explored_time": 15.13,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.1553,
                            "total_time": 11.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 38831,
                            "explored_time": 11.51,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "8a37cb28-d2ae-43b3-a05c-4e7d0160b668",
                        "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235"
                    ]
                },
                {
                    "id": "e3a8f45e-0f68-4d3d-a7aa-305bef1d9562",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # (4) Lifted Opposed Routing Flow Cuts\n    # This mutation strengthens the Opposed Routing idea by introducing \"Precedence Implication\" logic \n    # and \"Decoupled Temporal Lifting\".\n    # For swapped routing (j1: A->B, j2: B->A), if j1 precedes j2 on machine B (y_B=1), \n    # the physical path implies j1 MUST precede j2 on machine A (y_A=1) to avoid a cycle.\n    # This allows us to:\n    # 1. Add the strong logic cut: y_B <= y_A.\n    # 2. Reformulate the temporal cut to rely solely on y_B for its activation, removing dependency \n    #    on y_A's relaxation term. This tightens the relaxation when the solver explores y_B=1.\n    \n    model.LiftedOpposedCuts = pyo.ConstraintList()\n    \n    for j1 in model.J:\n        for j2 in model.J:\n            if j1 >= j2:\n                continue\n            \n            # Iterate over all pairs of operations for j1 that define a flow A -> B\n            for k1_A in model.K:\n                for k1_B in model.K:\n                    if k1_A >= k1_B:\n                        continue\n                    \n                    mA = model.mach[j1, k1_A]\n                    mB = model.mach[j1, k1_B]\n                    if mA == mB:\n                        continue\n                    \n                    # Iterate operations for j2 to find opposed flow B -> A\n                    for k2_B in model.K:\n                        if model.mach[j2, k2_B] != mB: continue\n                        for k2_A in model.K:\n                            if model.mach[j2, k2_A] != mA: continue\n                            \n                            # Check if j2 visits B before A\n                            if k2_B < k2_A:\n                                # Ensure precedence variables exist (keys match model.Pairs logic since j1 < j2)\n                                if (j1, k1_A, j2, k2_A) in model.Pairs and (j1, k1_B, j2, k2_B) in model.Pairs:\n                                    y_A = model.y[j1, k1_A, j2, k2_A]\n                                    y_B = model.y[j1, k1_B, j2, k2_B]\n                                    \n                                    # Calculate mandatory path delay (L) between End(j1, A) and Start(j2, A)\n                                    # Path: End(j1,A) -> ... -> Start(j1,B) -> End(j1,B) -> Start(j2,B) -> End(j2,B) -> ... -> Start(j2,A)\n                                    p1_B = model.p[j1, k1_B]\n                                    p2_B = model.p[j2, k2_B]\n                                    gap1 = sum(model.p[j1, k] for k in range(k1_A + 1, k1_B))\n                                    gap2 = sum(model.p[j2, k] for k in range(k2_B + 1, k2_A))\n                                    \n                                    L = gap1 + p1_B + p2_B + gap2\n                                    \n                                    # Cut 1: Precedence Implication (Logic Lifting)\n                                    # If j1 precedes j2 on the later machine B, it implies precedence on the earlier machine A.\n                                    model.LiftedOpposedCuts.add(y_B <= y_A)\n                                    \n                                    # Cut 2: Decoupled Temporal Lifting\n                                    # We enforce the delay L whenever y_B is active. \n                                    # Unlike the original cut, the relaxation M depends on (1 - y_B), \n                                    # making the bound S[j2,A] >= S[j1,A] + ... strictly tighter when y_B=1, regardless of y_A.\n                                    model.LiftedOpposedCuts.add(\n                                        model.S[j2, k2_A] >= model.S[j1, k1_A] + model.p[j1, k1_A] + L * y_B - model.bigM * (1 - y_B)\n                                    )\n\n    return model\n",
                        "added_cut": "# (4) Lifted Opposed Routing Flow Cuts\n# This mutation strengthens the Opposed Routing idea by introducing \"Precedence Implication\" logic \n# and \"Decoupled Temporal Lifting\".\n# For swapped routing (j1: A->B, j2: B->A), if j1 precedes j2 on machine B (y_B=1), \n# the physical path implies j1 MUST precede j2 on machine A (y_A=1) to avoid a cycle.\n# This allows us to:\n# 1. Add the strong logic cut: y_B <= y_A.\n# 2. Reformulate the temporal cut to rely solely on y_B for its activation, removing dependency \n#    on y_A's relaxation term. This tightens the relaxation when the solver explores y_B=1.\n\nmodel.LiftedOpposedCuts = pyo.ConstraintList()\n\nfor j1 in model.J:\n    for j2 in model.J:\n        if j1 >= j2:\n            continue\n        \n        # Iterate over all pairs of operations for j1 that define a flow A -> B\n        for k1_A in model.K:\n            for k1_B in model.K:\n                if k1_A >= k1_B:\n                    continue\n                \n                mA = model.mach[j1, k1_A]\n                mB = model.mach[j1, k1_B]\n                if mA == mB:\n                    continue\n                \n                # Iterate operations for j2 to find opposed flow B -> A\n                for k2_B in model.K:\n                    if model.mach[j2, k2_B] != mB: continue\n                    for k2_A in model.K:\n                        if model.mach[j2, k2_A] != mA: continue\n                        \n                        # Check if j2 visits B before A\n                        if k2_B < k2_A:\n                            # Ensure precedence variables exist (keys match model.Pairs logic since j1 < j2)\n                            if (j1, k1_A, j2, k2_A) in model.Pairs and (j1, k1_B, j2, k2_B) in model.Pairs:\n                                y_A = model.y[j1, k1_A, j2, k2_A]\n                                y_B = model.y[j1, k1_B, j2, k2_B]\n                                \n                                # Calculate mandatory path delay (L) between End(j1, A) and Start(j2, A)\n                                # Path: End(j1,A) -> ... -> Start(j1,B) -> End(j1,B) -> Start(j2,B) -> End(j2,B) -> ... -> Start(j2,A)\n                                p1_B = model.p[j1, k1_B]\n                                p2_B = model.p[j2, k2_B]\n                                gap1 = sum(model.p[j1, k] for k in range(k1_A + 1, k1_B))\n                                gap2 = sum(model.p[j2, k] for k in range(k2_B + 1, k2_A))\n                                \n                                L = gap1 + p1_B + p2_B + gap2\n                                \n                                # Cut 1: Precedence Implication (Logic Lifting)\n                                # If j1 precedes j2 on the later machine B, it implies precedence on the earlier machine A.\n                                model.LiftedOpposedCuts.add(y_B <= y_A)\n                                \n                                # Cut 2: Decoupled Temporal Lifting\n                                # We enforce the delay L whenever y_B is active. \n                                # Unlike the original cut, the relaxation M depends on (1 - y_B), \n                                # making the bound S[j2,A] >= S[j1,A] + ... strictly tighter when y_B=1, regardless of y_A.\n                                model.LiftedOpposedCuts.add(\n                                    model.S[j2, k2_A] >= model.S[j1, k1_A] + model.p[j1, k1_A] + L * y_B - model.bigM * (1 - y_B)\n                                )",
                        "idea": "The original cut relied on mixing variables from machine A ($y_A$) and machine B ($y_B$) in a single big-M constraint, which weakens the relaxation if $y_A$ is not yet fixed. We applied **Logic-Based Lifting** to split this into two stronger components. First, we identified that for opposed routing ($j1: A \\to B, j2: B \\to A$), the precedence $y_B=1$ physically implies $y_A=1$ to avoid cycles; we enforce this explicitly with the implication cut $y_B \\le y_A$. Second, we **decoupled** the temporal constraint: instead of relaxing the start time bound with $(1-y_A)$, we relax it with $(1-y_B)$. This ensures that whenever the solver explores the path $j1 \\to j2$ on machine B, the full path latency is immediately enforced on machine A's start times, independent of the variable $y_A$."
                    },
                    "fitness": 8.987465817373113,
                    "solver_reports": [
                        {
                            "total_time": 9.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 24001,
                            "explored_time": 8.9,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 25816,
                            "explored_time": 8.66,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 9.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 21826,
                            "explored_time": 9.08,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.8761,
                            "total_time": 6.28,
                            "explored_nodes": 1,
                            "simplex_iterations": 14530,
                            "explored_time": 6.23,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 23536,
                            "explored_time": 8.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 41.5687,
                            "total_time": 12.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 26738,
                            "explored_time": 12.6,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.713,
                            "total_time": 7.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 14136,
                            "explored_time": 7.29,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 25047,
                            "explored_time": 8.16,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "ce74d044-76f0-491a-a9ba-2998fd928265"
                    ]
                },
                {
                    "id": "3cf4467d-0917-4631-95fb-9ec8a696c5ac",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # --- Combined Machine Workload and Opposed Routing Cuts ---\n    \n    # 1. Static Machine Workload Cuts (Parent 1)\n    # These provide a strong global lower bound on Cmax based on 1-machine relaxations.\n    \n    # Pre-compute Heads (earliest release) and Tails (remaining work) for all operations\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        # Forward pass: Heads\n        h_accum = 0\n        for k in range(n_machines):\n            op_heads[j, k] = h_accum\n            h_accum += times[j][k]\n        # Backward pass: Tails\n        t_accum = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = t_accum\n            t_accum += times[j][k]\n    \n    # Group operations by machine\n    machine_to_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in machine_to_ops:\n                machine_to_ops[m_id] = []\n            machine_to_ops[m_id].append((j, k))\n    \n    model.WorkloadCuts = pyo.ConstraintList()\n    for m_id, ops in machine_to_ops.items():\n        if not ops:\n            continue\n        min_head = min(op_heads[op] for op in ops)\n        total_p = sum(times[op[0]][op[1]] for op in ops)\n        min_tail = min(op_tails[op] for op in ops)\n        # Cmax >= MinHead + Sum(P) + MinTail\n        model.WorkloadCuts.add(model.Cmax >= min_head + total_p + min_tail)\n    \n    # 2. Opposed Routing Flow Cuts (Parent 2)\n    # These tighten start times for job pairs with swapping machine orders (A->B vs B->A).\n    \n    model.OpposedRoutingCuts = pyo.ConstraintList()\n    \n    for j1 in range(n_jobs):\n        for j2 in range(n_jobs):\n            if j1 >= j2:\n                continue\n            \n            # Iterate over all operations of j1 to find flow A -> B\n            for k1_A in range(n_machines):\n                for k1_B in range(n_machines):\n                    if k1_A >= k1_B: \n                        continue\n                    \n                    mA = machines[j1][k1_A]\n                    mB = machines[j1][k1_B]\n                    if mA == mB:\n                        continue\n                    \n                    # Check if j2 has flow B -> A\n                    # Find j2 ops on these machines\n                    k2_A_opts = [k for k, m in enumerate(machines[j2]) if m == mA]\n                    k2_B_opts = [k for k, m in enumerate(machines[j2]) if m == mB]\n                    \n                    for k2_A in k2_A_opts:\n                        for k2_B in k2_B_opts:\n                            # Opposed: j2 visits B before A\n                            if k2_B < k2_A:\n                                # Identified conflict structure: J1(A->B) vs J2(B->A)\n                                # Variables: we need y[j1, k1, j2, k2].\n                                # Note: model.y indices are sorted by job index.\n                                \n                                # Conflict on Machine A: (j1, k1_A) vs (j2, k2_A)\n                                # Since j1 < j2, key is (j1, k1_A, j2, k2_A)\n                                y_A = model.y[j1, k1_A, j2, k2_A]\n                                \n                                # Conflict on Machine B: (j1, k1_B) vs (j2, k2_B)\n                                # Key is (j1, k1_B, j2, k2_B)\n                                y_B = model.y[j1, k1_B, j2, k2_B]\n                                \n                                # Calculate Lift Value (the mandatory loop time)\n                                # Gap1: processing time between A and B for J1\n                                gap1 = sum(times[j1][k] for k in range(k1_A + 1, k1_B))\n                                # Gap2: processing time between B and A for J2\n                                gap2 = sum(times[j2][k] for k in range(k2_B + 1, k2_A))\n                                \n                                p1_A = times[j1][k1_A]\n                                p1_B = times[j1][k1_B]\n                                p2_B = times[j2][k2_B]\n                                \n                                # If J1 precedes J2 on B (y_B=1), path is:\n                                # S(j1,A) + p1_A + gap1 -> S(j1,B) + p1_B -> S(j2,B) + p2_B + gap2 -> S(j2,A)\n                                lift_val = gap1 + p1_B + p2_B + gap2\n                                \n                                # Constraint: S(j2, A) >= S(j1, A) + p1_A + lift * y_B - M(1 - y_A)\n                                # Note: We activate this bound if y_A=1 (J1 precedes J2 on A) AND y_B=1 (J1 precedes J2 on B)\n                                # However, in the opposed case, typically y_A and y_B can't both be 1 efficiently.\n                                # But if they ARE, this cut enforces the delay.\n                                # Parent 2 formulation assumes we want to lift S(j2,A) if y_B dictates order on B.\n                                # It uses M*(1-y_A) to relax if J2 actually precedes J1 on A.\n                                \n                                model.OpposedRoutingCuts.add(\n                                    model.S[j2, k2_A] >= model.S[j1, k1_A] + p1_A + lift_val * y_B - model.bigM * (1 - y_A)\n                                )\n\n    return model\n",
                        "added_cut": "# --- Combined Machine Workload and Opposed Routing Cuts ---\n\n# 1. Static Machine Workload Cuts (Parent 1)\n# These provide a strong global lower bound on Cmax based on 1-machine relaxations.\n\n# Pre-compute Heads (earliest release) and Tails (remaining work) for all operations\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    # Forward pass: Heads\n    h_accum = 0\n    for k in range(n_machines):\n        op_heads[j, k] = h_accum\n        h_accum += times[j][k]\n    # Backward pass: Tails\n    t_accum = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = t_accum\n        t_accum += times[j][k]\n\n# Group operations by machine\nmachine_to_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in machine_to_ops:\n            machine_to_ops[m_id] = []\n        machine_to_ops[m_id].append((j, k))\n\nmodel.WorkloadCuts = pyo.ConstraintList()\nfor m_id, ops in machine_to_ops.items():\n    if not ops:\n        continue\n    min_head = min(op_heads[op] for op in ops)\n    total_p = sum(times[op[0]][op[1]] for op in ops)\n    min_tail = min(op_tails[op] for op in ops)\n    # Cmax >= MinHead + Sum(P) + MinTail\n    model.WorkloadCuts.add(model.Cmax >= min_head + total_p + min_tail)\n\n# 2. Opposed Routing Flow Cuts (Parent 2)\n# These tighten start times for job pairs with swapping machine orders (A->B vs B->A).\n\nmodel.OpposedRoutingCuts = pyo.ConstraintList()\n\nfor j1 in range(n_jobs):\n    for j2 in range(n_jobs):\n        if j1 >= j2:\n            continue\n        \n        # Iterate over all operations of j1 to find flow A -> B\n        for k1_A in range(n_machines):\n            for k1_B in range(n_machines):\n                if k1_A >= k1_B: \n                    continue\n                \n                mA = machines[j1][k1_A]\n                mB = machines[j1][k1_B]\n                if mA == mB:\n                    continue\n                \n                # Check if j2 has flow B -> A\n                # Find j2 ops on these machines\n                k2_A_opts = [k for k, m in enumerate(machines[j2]) if m == mA]\n                k2_B_opts = [k for k, m in enumerate(machines[j2]) if m == mB]\n                \n                for k2_A in k2_A_opts:\n                    for k2_B in k2_B_opts:\n                        # Opposed: j2 visits B before A\n                        if k2_B < k2_A:\n                            # Identified conflict structure: J1(A->B) vs J2(B->A)\n                            # Variables: we need y[j1, k1, j2, k2].\n                            # Note: model.y indices are sorted by job index.\n                            \n                            # Conflict on Machine A: (j1, k1_A) vs (j2, k2_A)\n                            # Since j1 < j2, key is (j1, k1_A, j2, k2_A)\n                            y_A = model.y[j1, k1_A, j2, k2_A]\n                            \n                            # Conflict on Machine B: (j1, k1_B) vs (j2, k2_B)\n                            # Key is (j1, k1_B, j2, k2_B)\n                            y_B = model.y[j1, k1_B, j2, k2_B]\n                            \n                            # Calculate Lift Value (the mandatory loop time)\n                            # Gap1: processing time between A and B for J1\n                            gap1 = sum(times[j1][k] for k in range(k1_A + 1, k1_B))\n                            # Gap2: processing time between B and A for J2\n                            gap2 = sum(times[j2][k] for k in range(k2_B + 1, k2_A))\n                            \n                            p1_A = times[j1][k1_A]\n                            p1_B = times[j1][k1_B]\n                            p2_B = times[j2][k2_B]\n                            \n                            # If J1 precedes J2 on B (y_B=1), path is:\n                            # S(j1,A) + p1_A + gap1 -> S(j1,B) + p1_B -> S(j2,B) + p2_B + gap2 -> S(j2,A)\n                            lift_val = gap1 + p1_B + p2_B + gap2\n                            \n                            # Constraint: S(j2, A) >= S(j1, A) + p1_A + lift * y_B - M(1 - y_A)\n                            # Note: We activate this bound if y_A=1 (J1 precedes J2 on A) AND y_B=1 (J1 precedes J2 on B)\n                            # However, in the opposed case, typically y_A and y_B can't both be 1 efficiently.\n                            # But if they ARE, this cut enforces the delay.\n                            # Parent 2 formulation assumes we want to lift S(j2,A) if y_B dictates order on B.\n                            # It uses M*(1-y_A) to relax if J2 actually precedes J1 on A.\n                            \n                            model.OpposedRoutingCuts.add(\n                                model.S[j2, k2_A] >= model.S[j1, k1_A] + p1_A + lift_val * y_B - model.bigM * (1 - y_A)\n                            )",
                        "idea": "We combine Parent 1's static Machine Workload Cuts with Parent 2's dynamic Opposed Routing Flow Cuts. The workload cuts provide a foundational global lower bound on $C_{max}$ by treating each machine as a relaxed single-machine problem (Sum of processing + min Head + min Tail). The opposed routing cuts then identify specific job pairs with conflicting flows ($J_1: A \to B$, $J_2: B \to A$) and add conditional constraints. These constraints lift the start time of $J_2$ on machine $A$ significantly if the precedence variables imply a 'loop' path ($J_1(A) \to J_1(B) \to J_2(B) \to J_2(A)$), thereby tightening the relaxation in the presence of specific resource conflicts that the static bounds cannot capture."
                    },
                    "fitness": 11.440277655309856,
                    "solver_reports": [
                        {
                            "gap": 89.8612,
                            "total_time": 8.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 20622,
                            "explored_time": 8.81,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 8.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 19750,
                            "explored_time": 8.54,
                            "work_units": 10.01
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 8.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 16800,
                            "explored_time": 8.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 36.7783,
                            "total_time": 11.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 25502,
                            "explored_time": 11.93,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.4069,
                            "total_time": 8.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 17415,
                            "explored_time": 8.29,
                            "work_units": 10.01
                        },
                        {
                            "gap": 25.8865,
                            "total_time": 12.55,
                            "explored_nodes": 115,
                            "simplex_iterations": 49354,
                            "explored_time": 12.52,
                            "work_units": 11.6
                        },
                        {
                            "gap": 92.0081,
                            "total_time": 9.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 13191,
                            "explored_time": 9.1,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 8.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 20283,
                            "explored_time": 8.41,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235",
                        "ce74d044-76f0-491a-a9ba-2998fd928265"
                    ]
                },
                {
                    "id": "953456bd-bd70-4803-ab54-4778ff8de5b6",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-compute Heads (earliest start) and Tails (post-processing work) for all operations\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        h_accum = 0\n        for k in range(n_machines):\n            op_heads[j, k] = h_accum\n            h_accum += times[j][k]\n        t_accum = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = t_accum\n            t_accum += times[j][k]\n    \n    # Group operations by machine\n    machine_to_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in machine_to_ops:\n                machine_to_ops[m_id] = []\n            machine_to_ops[m_id].append((j, k))\n    \n    def machine_bottleneck_lifting_rule(m, m_id):\n        \"\"\"\n        Lifts the static workload cut by finding the critical subset of operations\n        (Carlier's Bound) rather than just summing all operations.\n        Max_subset( min_r + sum_p + min_q ).\n        \"\"\"\n        ops = machine_to_ops[m_id]\n        if not ops:\n            return pyo.Constraint.Skip\n        \n        # Collect (Head, P, Tail) for operations on this machine\n        data = []\n        for op in ops:\n            r = op_heads[op]\n            p = times[op[0]][op[1]]\n            q = op_tails[op]\n            data.append((r, p, q))\n        \n        # Determine the tightest lower bound by iterating over valid subsets.\n        # A subset is defined effectively by a start threshold (min_r) and end threshold (min_q).\n        unique_rs = sorted(list(set(d[0] for d in data)))\n        unique_qs = sorted(list(set(d[2] for d in data)))\n        \n        max_bound = 0\n        \n        # Check all \"intervals\" [r_thresh, ..., end - q_thresh]\n        for r_thresh in unique_rs:\n            for q_thresh in unique_qs:\n                # Form the subset Omega' = {i | r_i >= r_thresh AND q_i >= q_thresh}\n                subset_p = 0\n                has_ops = False\n                for (r, p, q) in data:\n                    if r >= r_thresh and q >= q_thresh:\n                        subset_p += p\n                        has_ops = True\n                \n                # If the subset is non-empty, the bound is valid\n                if has_ops:\n                    # Bound: earliest possible start (r_thresh) + total work (subset_p) + mandatory tail (q_thresh)\n                    current_bound = r_thresh + subset_p + q_thresh\n                    if current_bound > max_bound:\n                        max_bound = current_bound\n                        \n        return m.Cmax >= max_bound\n    \n    model.machine_bottleneck_cuts = pyo.Constraint(list(machine_to_ops.keys()), rule=machine_bottleneck_lifting_rule)\n\n    return model\n",
                        "added_cut": "# Pre-compute Heads (earliest start) and Tails (post-processing work) for all operations\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    h_accum = 0\n    for k in range(n_machines):\n        op_heads[j, k] = h_accum\n        h_accum += times[j][k]\n    t_accum = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = t_accum\n        t_accum += times[j][k]\n\n# Group operations by machine\nmachine_to_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in machine_to_ops:\n            machine_to_ops[m_id] = []\n        machine_to_ops[m_id].append((j, k))\n\ndef machine_bottleneck_lifting_rule(m, m_id):\n    \"\"\"\n    Lifts the static workload cut by finding the critical subset of operations\n    (Carlier's Bound) rather than just summing all operations.\n    Max_subset( min_r + sum_p + min_q ).\n    \"\"\"\n    ops = machine_to_ops[m_id]\n    if not ops:\n        return pyo.Constraint.Skip\n    \n    # Collect (Head, P, Tail) for operations on this machine\n    data = []\n    for op in ops:\n        r = op_heads[op]\n        p = times[op[0]][op[1]]\n        q = op_tails[op]\n        data.append((r, p, q))\n    \n    # Determine the tightest lower bound by iterating over valid subsets.\n    # A subset is defined effectively by a start threshold (min_r) and end threshold (min_q).\n    unique_rs = sorted(list(set(d[0] for d in data)))\n    unique_qs = sorted(list(set(d[2] for d in data)))\n    \n    max_bound = 0\n    \n    # Check all \"intervals\" [r_thresh, ..., end - q_thresh]\n    for r_thresh in unique_rs:\n        for q_thresh in unique_qs:\n            # Form the subset Omega' = {i | r_i >= r_thresh AND q_i >= q_thresh}\n            subset_p = 0\n            has_ops = False\n            for (r, p, q) in data:\n                if r >= r_thresh and q >= q_thresh:\n                    subset_p += p\n                    has_ops = True\n            \n            # If the subset is non-empty, the bound is valid\n            if has_ops:\n                # Bound: earliest possible start (r_thresh) + total work (subset_p) + mandatory tail (q_thresh)\n                current_bound = r_thresh + subset_p + q_thresh\n                if current_bound > max_bound:\n                    max_bound = current_bound\n                    \n    return m.Cmax >= max_bound\n\nmodel.machine_bottleneck_cuts = pyo.Constraint(list(machine_to_ops.keys()), rule=machine_bottleneck_lifting_rule)",
                        "idea": "We apply **Subset Lifting** to the Machine Workload Cut. The original cut computed a single bound per machine using all assigned operations, which is weak when operations have disparate time windows. We strengthen this by calculating **Carlier's Bound**: for each machine, we dynamically identify the **critical subset** of operations $\\Omega' \\subseteq \\Omega_m$ that maximizes the quantity $\\min_{i \\in \\Omega'} Head_i + \\sum_{i \\in \\Omega'} p_i + \\min_{i \\in \\Omega'} Tail_i$. This lifts the constraint to the tightest valid inequality for the 1-machine relaxation, effectively filtering out non-critical operations that dilute the lower bound."
                    },
                    "fitness": 14.039559674074326,
                    "solver_reports": [
                        {
                            "gap": 19.1398,
                            "total_time": 14.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 29835,
                            "explored_time": 13.97,
                            "work_units": 10.05
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.54,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 9.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 13.83,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 13.82,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.3583,
                            "total_time": 10.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 32144,
                            "explored_time": 10.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.4,
                            "total_time": 13.19,
                            "explored_nodes": 9932,
                            "simplex_iterations": 303128,
                            "explored_time": 13.17,
                            "work_units": 10.0
                        },
                        {
                            "gap": 48.9448,
                            "total_time": 12.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 42032,
                            "explored_time": 12.87,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.13,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235"
                    ]
                }
            ],
            14.394429380838801
        ],
        [
            [
                {
                    "id": "bda49ecf-46fd-4b71-87d9-86d650cbacd5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Combined Constraint: Bi-Directional Machine Displacement Cuts\n    # ----------------------------------------------------------------\n    \n    # 1. Precompute static heads (earliest start times) and group operations by machine\n    op_heads_map = {}\n    mach_ops_map = {m_id: [] for m_id in range(n_machines)}\n    \n    for j_idx in range(n_jobs):\n        curr_time = 0\n        for k_idx in range(n_machines):\n            op_val = (j_idx, k_idx)\n            m_id = machines[j_idx][k_idx]\n            \n            op_heads_map[op_val] = curr_time\n            mach_ops_map[m_id].append(op_val)\n            \n            curr_time += times[j_idx][k_idx]\n    \n    # Calculate the minimum possible head (release time) for each machine\n    min_mach_heads = {}\n    for m_id in range(n_machines):\n        if mach_ops_map[m_id]:\n            min_mach_heads[m_id] = min(op_heads_map[o] for o in mach_ops_map[m_id])\n        else:\n            min_mach_heads[m_id] = 0\n    \n    # 2. Define a set to toggle between the two cut directions\n    # 'fwd': Bounds Start Time using Predecessors (Parent 2)\n    # 'bwd': Bounds Makespan using Successors (Parent 1)\n    model.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def bidir_cut_rule(m, j, k, c_type):\n        u_op = (j, k)\n        u_mach = machines[j][k]\n        relevant_ops = mach_ops_map[u_mach]\n        \n        if c_type == 'bwd':\n            # Parent 1 Logic: Cmax >= S_u + p_u + Sum(Work of Successors)\n            # This links Cmax to the schedule tail.\n            succ_work = 0\n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # If u_op < (j2,k2), pair is (u,v). y=1 implies u->v (v is successor).\n                if u_op < (j2, k2):\n                    succ_work += m.p[j2, k2] * m.y[j, k, j2, k2]\n                # If (j2,k2) < u_op, pair is (v,u). y=0 implies u->v (v is successor).\n                else:\n                    succ_work += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n            \n            return m.Cmax >= m.S[j, k] + m.p[j, k] + succ_work\n    \n        else:\n            # Parent 2 Logic: S_u >= r_min_machine + Sum(Work of Predecessors)\n            # This lifts the Start Time based on the schedule head.\n            pred_work = 0\n            r_min = min_mach_heads[u_mach]\n            \n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # If (j2,k2) < u_op, pair is (v,u). y=1 implies v->u (v is predecessor).\n                if (j2, k2) < u_op:\n                    pred_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n                # If u_op < (j2,k2), pair is (u,v). y=0 implies v->u (v is predecessor).\n                else:\n                    pred_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n            \n            return m.S[j, k] >= r_min + pred_work\n    \n    model.BiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=bidir_cut_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Combined Constraint: Bi-Directional Machine Displacement Cuts\n# ----------------------------------------------------------------\n\n# 1. Precompute static heads (earliest start times) and group operations by machine\nop_heads_map = {}\nmach_ops_map = {m_id: [] for m_id in range(n_machines)}\n\nfor j_idx in range(n_jobs):\n    curr_time = 0\n    for k_idx in range(n_machines):\n        op_val = (j_idx, k_idx)\n        m_id = machines[j_idx][k_idx]\n        \n        op_heads_map[op_val] = curr_time\n        mach_ops_map[m_id].append(op_val)\n        \n        curr_time += times[j_idx][k_idx]\n\n# Calculate the minimum possible head (release time) for each machine\nmin_mach_heads = {}\nfor m_id in range(n_machines):\n    if mach_ops_map[m_id]:\n        min_mach_heads[m_id] = min(op_heads_map[o] for o in mach_ops_map[m_id])\n    else:\n        min_mach_heads[m_id] = 0\n\n# 2. Define a set to toggle between the two cut directions\n# 'fwd': Bounds Start Time using Predecessors (Parent 2)\n# 'bwd': Bounds Makespan using Successors (Parent 1)\nmodel.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef bidir_cut_rule(m, j, k, c_type):\n    u_op = (j, k)\n    u_mach = machines[j][k]\n    relevant_ops = mach_ops_map[u_mach]\n    \n    if c_type == 'bwd':\n        # Parent 1 Logic: Cmax >= S_u + p_u + Sum(Work of Successors)\n        # This links Cmax to the schedule tail.\n        succ_work = 0\n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # If u_op < (j2,k2), pair is (u,v). y=1 implies u->v (v is successor).\n            if u_op < (j2, k2):\n                succ_work += m.p[j2, k2] * m.y[j, k, j2, k2]\n            # If (j2,k2) < u_op, pair is (v,u). y=0 implies u->v (v is successor).\n            else:\n                succ_work += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n        \n        return m.Cmax >= m.S[j, k] + m.p[j, k] + succ_work\n\n    else:\n        # Parent 2 Logic: S_u >= r_min_machine + Sum(Work of Predecessors)\n        # This lifts the Start Time based on the schedule head.\n        pred_work = 0\n        r_min = min_mach_heads[u_mach]\n        \n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # If (j2,k2) < u_op, pair is (v,u). y=1 implies v->u (v is predecessor).\n            if (j2, k2) < u_op:\n                pred_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n            # If u_op < (j2,k2), pair is (u,v). y=0 implies v->u (v is predecessor).\n            else:\n                pred_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n        \n        return m.S[j, k] >= r_min + pred_work\n\nmodel.BiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=bidir_cut_rule)",
                        "idea": "We introduce **Bi-Directional Machine Displacement Cuts**, which integrate the strengths of both parent constraints into a unified bounding scheme. For every operation $u$ on machine $m$, this cut imposes two simultaneous conditions: (1) **Tail-Bound:** The global makespan $C_{max}$ is bounded below by $u$'s completion time plus the dynamically determined workload of all its successors (enhancing Parent 1's high-fitness logic). (2) **Head-Bound:** $u$'s start time $S_u$ is bounded below by the machine's earliest availability ($r_{min}$) plus the dynamically determined workload of all its predecessors (Parent 2's start-time lifting). By rigorously constraining the operation's position from both the 'left' (start time) and 'right' (makespan contribution) based on the binary sequencing variables $y$, this approach tightens the feasible region more effectively than either cut alone, effectively squeezing out schedules with underestimated delays."
                    },
                    "fitness": 14.394429380838801,
                    "solver_reports": [
                        {
                            "total_time": 6.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 21770,
                            "explored_time": 6.56,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 22960,
                            "explored_time": 6.98,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 32835,
                            "explored_time": 7.67,
                            "work_units": 10.02
                        },
                        {
                            "total_time": 6.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 22092,
                            "explored_time": 6.34,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 7.98,
                            "explored_nodes": 1,
                            "simplex_iterations": 33894,
                            "explored_time": 7.92,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.9332,
                            "total_time": 9.32,
                            "explored_nodes": 26,
                            "simplex_iterations": 41169,
                            "explored_time": 9.31,
                            "work_units": 10.15
                        },
                        {
                            "total_time": 5.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 17772,
                            "explored_time": 5.7,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 23197,
                            "explored_time": 6.58,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "8a37cb28-d2ae-43b3-a05c-4e7d0160b668",
                        "366493b1-62c2-4cdd-b383-18a9e183ff4d"
                    ]
                },
                {
                    "id": "af0773df-70ec-449e-8e27-9c31b5484f21",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Hybrid Constraint: Symmetric Head-Tail Displacement Cuts\n    # ----------------------------------------------------------------\n    # This constraint combines the Bi-Directional structure of Parent 2 with \n    # the Job Tail logic of Parent 1 to create tight bounds on both Start Time and Cmax.\n    \n    # 1. Precompute Heads (time before op) and Tails (time after op) for every operation\n    op_heads = {}\n    op_tails = {}\n    mach_ops = {m: [] for m in range(n_machines)}\n    \n    for j in range(n_jobs):\n        # Forward pass for heads\n        current_head = 0\n        for k in range(n_machines):\n            op = (j, k)\n            op_heads[op] = current_head\n            mach_ops[machines[j][k]].append(op)\n            current_head += times[j][k]\n        \n        # Backward pass for tails\n        current_tail = 0\n        for k in range(n_machines - 1, -1, -1):\n            op = (j, k)\n            op_tails[op] = current_tail\n            current_tail += times[j][k]\n    \n    # 2. Compute per-machine minimum Head and Tail\n    # These serve as valid lower bounds for the machine's first start and last completion.\n    min_mach_head = {}\n    min_mach_tail = {}\n    for m in range(n_machines):\n        if mach_ops[m]:\n            min_mach_head[m] = min(op_heads[o] for o in mach_ops[m])\n            min_mach_tail[m] = min(op_tails[o] for o in mach_ops[m])\n        else:\n            min_mach_head[m] = 0\n            min_mach_tail[m] = 0\n    \n    # 3. Define the Bi-Directional Cut with Head/Tail Lifting\n    model.DisplacementDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def head_tail_displacement_rule(m, j, k, direction):\n        u_op = (j, k)\n        m_id = machines[j][k]\n        relevant_ops = mach_ops[m_id]\n        \n        # Calculate the dynamic workload on the machine relative to u\n        work_load = 0\n        \n        if direction == 'fwd':\n            # Forward Cut: Bounds Start Time (S_u)\n            # S_u >= min_head_of_machine + Sum(Processing of Predecessors of u)\n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # If v precedes u, add p_v. \n                # Case 1: (j2, k2) < (j, k) in O-order. Pair is (v, u). y[v,u]=1 => v->u.\n                if (j2, k2) < u_op:\n                    work_load += m.p[j2, k2] * m.y[j2, k2, j, k]\n                # Case 2: (j, k) < (j2, k2) in O-order. Pair is (u, v). y[u,v]=0 => v->u.\n                else:\n                    work_load += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n            \n            return m.S[j, k] >= min_mach_head[m_id] + work_load\n    \n        else:\n            # Backward Cut: Bounds Cmax\n            # Cmax >= S_u + p_u + Sum(Processing of Successors of u) + min_tail_of_machine\n            # The 'min_tail' term is the enhancement from Parent 1, lifting the bound.\n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # If u precedes v, add p_v.\n                # Case 1: (j, k) < (j2, k2). Pair is (u, v). y[u,v]=1 => u->v.\n                if u_op < (j2, k2):\n                    work_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n                # Case 2: (j2, k2) < (j, k). Pair is (v, u). y[v,u]=0 => u->v.\n                else:\n                    work_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n            \n            return m.Cmax >= m.S[j, k] + m.p[j, k] + work_load + min_mach_tail[m_id]\n    \n    model.SymmetricHeadTailDisplacement = pyo.Constraint(model.J, model.K, model.DisplacementDirs, rule=head_tail_displacement_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Hybrid Constraint: Symmetric Head-Tail Displacement Cuts\n# ----------------------------------------------------------------\n# This constraint combines the Bi-Directional structure of Parent 2 with \n# the Job Tail logic of Parent 1 to create tight bounds on both Start Time and Cmax.\n\n# 1. Precompute Heads (time before op) and Tails (time after op) for every operation\nop_heads = {}\nop_tails = {}\nmach_ops = {m: [] for m in range(n_machines)}\n\nfor j in range(n_jobs):\n    # Forward pass for heads\n    current_head = 0\n    for k in range(n_machines):\n        op = (j, k)\n        op_heads[op] = current_head\n        mach_ops[machines[j][k]].append(op)\n        current_head += times[j][k]\n    \n    # Backward pass for tails\n    current_tail = 0\n    for k in range(n_machines - 1, -1, -1):\n        op = (j, k)\n        op_tails[op] = current_tail\n        current_tail += times[j][k]\n\n# 2. Compute per-machine minimum Head and Tail\n# These serve as valid lower bounds for the machine's first start and last completion.\nmin_mach_head = {}\nmin_mach_tail = {}\nfor m in range(n_machines):\n    if mach_ops[m]:\n        min_mach_head[m] = min(op_heads[o] for o in mach_ops[m])\n        min_mach_tail[m] = min(op_tails[o] for o in mach_ops[m])\n    else:\n        min_mach_head[m] = 0\n        min_mach_tail[m] = 0\n\n# 3. Define the Bi-Directional Cut with Head/Tail Lifting\nmodel.DisplacementDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef head_tail_displacement_rule(m, j, k, direction):\n    u_op = (j, k)\n    m_id = machines[j][k]\n    relevant_ops = mach_ops[m_id]\n    \n    # Calculate the dynamic workload on the machine relative to u\n    work_load = 0\n    \n    if direction == 'fwd':\n        # Forward Cut: Bounds Start Time (S_u)\n        # S_u >= min_head_of_machine + Sum(Processing of Predecessors of u)\n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # If v precedes u, add p_v. \n            # Case 1: (j2, k2) < (j, k) in O-order. Pair is (v, u). y[v,u]=1 => v->u.\n            if (j2, k2) < u_op:\n                work_load += m.p[j2, k2] * m.y[j2, k2, j, k]\n            # Case 2: (j, k) < (j2, k2) in O-order. Pair is (u, v). y[u,v]=0 => v->u.\n            else:\n                work_load += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n        \n        return m.S[j, k] >= min_mach_head[m_id] + work_load\n\n    else:\n        # Backward Cut: Bounds Cmax\n        # Cmax >= S_u + p_u + Sum(Processing of Successors of u) + min_tail_of_machine\n        # The 'min_tail' term is the enhancement from Parent 1, lifting the bound.\n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # If u precedes v, add p_v.\n            # Case 1: (j, k) < (j2, k2). Pair is (u, v). y[u,v]=1 => u->v.\n            if u_op < (j2, k2):\n                work_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n            # Case 2: (j2, k2) < (j, k). Pair is (v, u). y[v,u]=0 => u->v.\n            else:\n                work_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n        \n        return m.Cmax >= m.S[j, k] + m.p[j, k] + work_load + min_mach_tail[m_id]\n\nmodel.SymmetricHeadTailDisplacement = pyo.Constraint(model.J, model.K, model.DisplacementDirs, rule=head_tail_displacement_rule)",
                        "idea": "We construct the **Symmetric Head-Tail Displacement Cut**, a hybrid that integrates the bi-directional bounding structure of Parent 2 with the job-tail tightening logic of Parent 1. For every operation $u$, we generate two constraints: (1) A **Forward Cut** that lifts $u$'s start time based on the machine's minimum availability (head) plus the dynamic load of all predecessors; and (2) A **Backward Cut** that bounds the global makespan $C_{max}$ by $u$'s completion time plus the dynamic load of all successors, further tightened by adding the **minimum job tail** of the machine (adopted from Parent 1). This explicitly accounts for the unavoidable post-processing time of the last job exiting the machine, strictly tightening the feasible region compared to the original bi-directional cut while maintaining its comprehensive coverage."
                    },
                    "fitness": 12.567806103438688,
                    "solver_reports": [
                        {
                            "total_time": 6.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 21834,
                            "explored_time": 6.81,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 23099,
                            "explored_time": 7.04,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.56,
                            "explored_nodes": 1,
                            "simplex_iterations": 32781,
                            "explored_time": 7.48,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 21405,
                            "explored_time": 6.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 33955,
                            "explored_time": 7.94,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.4015,
                            "total_time": 8.98,
                            "explored_nodes": 30,
                            "simplex_iterations": 47063,
                            "explored_time": 8.98,
                            "work_units": 10.11
                        },
                        {
                            "total_time": 5.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 18017,
                            "explored_time": 5.66,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 23197,
                            "explored_time": 6.69,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "8236f856-c803-471f-b687-0678ca2c73f5",
                        "bda49ecf-46fd-4b71-87d9-86d650cbacd5"
                    ]
                },
                {
                    "id": "ffbf0f57-72ae-4c0a-b843-c3033fb53f71",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Combined Constraint: Enhanced Bi-Directional Machine Cuts with Tail Lifting\n    # ----------------------------------------------------------------\n    \n    # 1. Precompute static Heads (earliest start) and Tails (remaining job work)\n    heads = {}\n    tails = {}\n    mach_ops = {m: [] for m in range(n_machines)}\n    \n    for j in range(n_jobs):\n        # Calculate Heads (Release Times)\n        h = 0\n        for k in range(n_machines):\n            op = (j, k)\n            m_id = machines[j][k]\n            heads[op] = h\n            mach_ops[m_id].append(op)\n            h += times[j][k]\n        \n        # Calculate Tails (Delivery Times)\n        t = 0\n        for k in range(n_machines - 1, -1, -1):\n            op = (j, k)\n            tails[op] = t\n            t += times[j][k]\n    \n    # 2. Determine Machine-level static bounds\n    # min_head: Earliest any op on machine m can start (min release time)\n    # min_tail: Minimum work remaining in any job after leaving machine m (min delivery time)\n    min_mach_heads = {m: min(heads[o] for o in mach_ops[m]) if mach_ops[m] else 0 \n                      for m in range(n_machines)}\n    min_mach_tails = {m: min(tails[o] for o in mach_ops[m]) if mach_ops[m] else 0 \n                      for m in range(n_machines)}\n    \n    model.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def enhanced_bidir_rule(m, j, k, direction):\n        u_op = (j, k)\n        u_mach = machines[j][k]\n        relevant = mach_ops[u_mach]\n        \n        if direction == 'fwd':\n            # Forward Cut (Head Bound):\n            # S_u >= MinMachineHead + DynamicWorkOfPredecessors\n            # This lifts the start time based on the machine's earliest availability and sequence.\n            r_min = min_mach_heads[u_mach]\n            pred_work = 0\n            \n            for v_op in relevant:\n                if v_op == u_op: continue\n                \n                # If v_op < u_op (lexicographically), pair is (v, u). y[v,u]=1 => v->u (predecessor)\n                if v_op < u_op:\n                    pred_work += m.p[v_op] * m.y[v_op + u_op]\n                # If u_op < v_op (lexicographically), pair is (u, v). y[u,v]=0 => v->u (predecessor)\n                else:\n                    pred_work += m.p[v_op] * (1 - m.y[u_op + v_op])\n            \n            return m.S[u_op] >= r_min + pred_work\n    \n        else: # direction == 'bwd'\n            # Backward Cut (Tail Bound):\n            # Cmax >= Completion(u) + DynamicWorkOfSuccessors + MinMachineTail\n            # This lifts Cmax by accounting for the remaining machine load AND the inevitable downstream job tail.\n            q_min = min_mach_tails[u_mach]\n            succ_work = 0\n            \n            for v_op in relevant:\n                if v_op == u_op: continue\n                \n                # If u_op < v_op (lex), pair is (u, v). y[u,v]=1 => u->v (successor)\n                if u_op < v_op:\n                    succ_work += m.p[v_op] * m.y[u_op + v_op]\n                # If v_op < u_op (lex), pair is (v, u). y[v,u]=0 => u->v (successor)\n                else:\n                    succ_work += m.p[v_op] * (1 - m.y[v_op + u_op])\n                    \n            return m.Cmax >= m.S[u_op] + m.p[u_op] + succ_work + q_min\n    \n    model.EnhancedBiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=enhanced_bidir_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Combined Constraint: Enhanced Bi-Directional Machine Cuts with Tail Lifting\n# ----------------------------------------------------------------\n\n# 1. Precompute static Heads (earliest start) and Tails (remaining job work)\nheads = {}\ntails = {}\nmach_ops = {m: [] for m in range(n_machines)}\n\nfor j in range(n_jobs):\n    # Calculate Heads (Release Times)\n    h = 0\n    for k in range(n_machines):\n        op = (j, k)\n        m_id = machines[j][k]\n        heads[op] = h\n        mach_ops[m_id].append(op)\n        h += times[j][k]\n    \n    # Calculate Tails (Delivery Times)\n    t = 0\n    for k in range(n_machines - 1, -1, -1):\n        op = (j, k)\n        tails[op] = t\n        t += times[j][k]\n\n# 2. Determine Machine-level static bounds\n# min_head: Earliest any op on machine m can start (min release time)\n# min_tail: Minimum work remaining in any job after leaving machine m (min delivery time)\nmin_mach_heads = {m: min(heads[o] for o in mach_ops[m]) if mach_ops[m] else 0 \n                  for m in range(n_machines)}\nmin_mach_tails = {m: min(tails[o] for o in mach_ops[m]) if mach_ops[m] else 0 \n                  for m in range(n_machines)}\n\nmodel.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef enhanced_bidir_rule(m, j, k, direction):\n    u_op = (j, k)\n    u_mach = machines[j][k]\n    relevant = mach_ops[u_mach]\n    \n    if direction == 'fwd':\n        # Forward Cut (Head Bound):\n        # S_u >= MinMachineHead + DynamicWorkOfPredecessors\n        # This lifts the start time based on the machine's earliest availability and sequence.\n        r_min = min_mach_heads[u_mach]\n        pred_work = 0\n        \n        for v_op in relevant:\n            if v_op == u_op: continue\n            \n            # If v_op < u_op (lexicographically), pair is (v, u). y[v,u]=1 => v->u (predecessor)\n            if v_op < u_op:\n                pred_work += m.p[v_op] * m.y[v_op + u_op]\n            # If u_op < v_op (lexicographically), pair is (u, v). y[u,v]=0 => v->u (predecessor)\n            else:\n                pred_work += m.p[v_op] * (1 - m.y[u_op + v_op])\n        \n        return m.S[u_op] >= r_min + pred_work\n\n    else: # direction == 'bwd'\n        # Backward Cut (Tail Bound):\n        # Cmax >= Completion(u) + DynamicWorkOfSuccessors + MinMachineTail\n        # This lifts Cmax by accounting for the remaining machine load AND the inevitable downstream job tail.\n        q_min = min_mach_tails[u_mach]\n        succ_work = 0\n        \n        for v_op in relevant:\n            if v_op == u_op: continue\n            \n            # If u_op < v_op (lex), pair is (u, v). y[u,v]=1 => u->v (successor)\n            if u_op < v_op:\n                succ_work += m.p[v_op] * m.y[u_op + v_op]\n            # If v_op < u_op (lex), pair is (v, u). y[v,u]=0 => u->v (successor)\n            else:\n                succ_work += m.p[v_op] * (1 - m.y[v_op + u_op])\n                \n        return m.Cmax >= m.S[u_op] + m.p[u_op] + succ_work + q_min\n\nmodel.EnhancedBiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=enhanced_bidir_rule)",
                        "idea": "We construct **Enhanced Bi-Directional Machine Cuts** that fuse the high-fitness machine bounding logic of Parent 1 with the static tail-lifting improvement of Parent 2. For every operation $u$, we impose two bounds: (1) A **Forward Head-Bound**, forcing $S_u$ to exceed the machine's earliest release time plus the dynamic workload of all predecessors; and (2) A **Backward Tail-Bound**, forcing $C_{max}$ to cover $u$'s completion plus the dynamic workload of successors *plus* the machine's minimum job tail ($\\min_{v \\in M} tail_v$). This formulation effectively approximates dynamic Carlier-style bounds for the single-machine relaxation within the global MILP, simultaneously tightening the start times and the global makespan."
                    },
                    "fitness": 12.567806103438688,
                    "solver_reports": [
                        {
                            "total_time": 6.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 21834,
                            "explored_time": 6.75,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 23099,
                            "explored_time": 6.91,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 32781,
                            "explored_time": 7.53,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 21405,
                            "explored_time": 6.57,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 33955,
                            "explored_time": 8.12,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.4015,
                            "total_time": 8.61,
                            "explored_nodes": 30,
                            "simplex_iterations": 47063,
                            "explored_time": 8.6,
                            "work_units": 10.11
                        },
                        {
                            "total_time": 5.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 18017,
                            "explored_time": 5.69,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 23197,
                            "explored_time": 6.61,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "bda49ecf-46fd-4b71-87d9-86d650cbacd5",
                        "bc838ac0-4d80-447a-8bdb-738d4bdaf0ce"
                    ]
                },
                {
                    "id": "1b92114f-a67f-4da6-b6b6-356270075054",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # --- Combined Workload and Opposed Routing Cuts ---\n    \n    # 1. Static Machine Workload Cuts (Parent 1)\n    # Bounds Cmax using 1-machine relaxation: min(Head) + sum(P) + min(Tail)\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        h = 0\n        for k in range(n_machines):\n            op_heads[j, k] = h\n            h += times[j][k]\n        t = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = t\n            t += times[j][k]\n    \n    mach_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m = machines[j][k]\n            if m not in mach_ops: mach_ops[m] = []\n            mach_ops[m].append((j, k))\n    \n    model.WorkloadCuts = pyo.ConstraintList()\n    for m, ops in mach_ops.items():\n        if not ops: continue\n        min_h = min(op_heads[o] for o in ops)\n        sum_p = sum(times[o[0]][o[1]] for o in ops)\n        min_t = min(op_tails[o] for o in ops)\n        # Cut: Cmax must exceed the 1-machine relaxation critical path\n        model.WorkloadCuts.add(model.Cmax >= min_h + sum_p + min_t)\n    \n    # 2. Opposed Routing Cuts (Parent 2)\n    # Identifies pairs J1(A->B), J2(B->A) and tightens bounds for the loop-inducing ordering.\n    model.OpposedRoutingCuts = pyo.ConstraintList()\n    \n    for j1 in range(n_jobs):\n        for j2 in range(j1 + 1, n_jobs): # j1 < j2 ensures unique pairs\n            \n            # Identify flow J1: A -> ... -> B\n            for k1_A in range(n_machines):\n                for k1_B in range(k1_A + 1, n_machines):\n                    mA = machines[j1][k1_A]\n                    mB = machines[j1][k1_B]\n                    if mA == mB: continue\n    \n                    # Identify flow J2: B -> ... -> A\n                    # Find indices for J2 on these machines\n                    k2_A_list = [k for k, m in enumerate(machines[j2]) if m == mA]\n                    k2_B_list = [k for k, m in enumerate(machines[j2]) if m == mB]\n                    \n                    for k2_A in k2_A_list:\n                        for k2_B in k2_B_list:\n                            if k2_B >= k2_A: continue # Must be J2: B -> ... -> A\n                            \n                            # Found Opposed Pair: J1(A->B) vs J2(B->A)\n                            # Access variables (j1 < j2, so keys are ordered (j1, k, j2, k))\n                            yA = model.y[j1, k1_A, j2, k2_A]\n                            yB = model.y[j1, k1_B, j2, k2_B]\n                            \n                            p1A = times[j1][k1_A]\n                            p1B = times[j1][k1_B]\n                            p2B = times[j2][k2_B]\n                            \n                            # Gaps between operations\n                            gap1 = sum(times[j1][k] for k in range(k1_A + 1, k1_B))\n                            gap2 = sum(times[j2][k] for k in range(k2_B + 1, k2_A))\n                            \n                            # Lift Amount: The mandatory path length J1 and J2 spend between A and B\n                            lift = gap1 + p1B + p2B + gap2\n                            \n                            # If J1 precedes J2 on A (yA=1) AND on B (yB=1), the sequence is J1@A->J1@B->J2@B->J2@A.\n                            # This implies a mandatory delay of 'lift' over the standard p1A.\n                            model.OpposedRoutingCuts.add(\n                                model.S[j2, k2_A] >= model.S[j1, k1_A] + p1A + lift * yB - model.bigM * (1 - yA)\n                            )\n\n    return model\n",
                        "added_cut": "# --- Combined Workload and Opposed Routing Cuts ---\n\n# 1. Static Machine Workload Cuts (Parent 1)\n# Bounds Cmax using 1-machine relaxation: min(Head) + sum(P) + min(Tail)\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    h = 0\n    for k in range(n_machines):\n        op_heads[j, k] = h\n        h += times[j][k]\n    t = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = t\n        t += times[j][k]\n\nmach_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m = machines[j][k]\n        if m not in mach_ops: mach_ops[m] = []\n        mach_ops[m].append((j, k))\n\nmodel.WorkloadCuts = pyo.ConstraintList()\nfor m, ops in mach_ops.items():\n    if not ops: continue\n    min_h = min(op_heads[o] for o in ops)\n    sum_p = sum(times[o[0]][o[1]] for o in ops)\n    min_t = min(op_tails[o] for o in ops)\n    # Cut: Cmax must exceed the 1-machine relaxation critical path\n    model.WorkloadCuts.add(model.Cmax >= min_h + sum_p + min_t)\n\n# 2. Opposed Routing Cuts (Parent 2)\n# Identifies pairs J1(A->B), J2(B->A) and tightens bounds for the loop-inducing ordering.\nmodel.OpposedRoutingCuts = pyo.ConstraintList()\n\nfor j1 in range(n_jobs):\n    for j2 in range(j1 + 1, n_jobs): # j1 < j2 ensures unique pairs\n        \n        # Identify flow J1: A -> ... -> B\n        for k1_A in range(n_machines):\n            for k1_B in range(k1_A + 1, n_machines):\n                mA = machines[j1][k1_A]\n                mB = machines[j1][k1_B]\n                if mA == mB: continue\n\n                # Identify flow J2: B -> ... -> A\n                # Find indices for J2 on these machines\n                k2_A_list = [k for k, m in enumerate(machines[j2]) if m == mA]\n                k2_B_list = [k for k, m in enumerate(machines[j2]) if m == mB]\n                \n                for k2_A in k2_A_list:\n                    for k2_B in k2_B_list:\n                        if k2_B >= k2_A: continue # Must be J2: B -> ... -> A\n                        \n                        # Found Opposed Pair: J1(A->B) vs J2(B->A)\n                        # Access variables (j1 < j2, so keys are ordered (j1, k, j2, k))\n                        yA = model.y[j1, k1_A, j2, k2_A]\n                        yB = model.y[j1, k1_B, j2, k2_B]\n                        \n                        p1A = times[j1][k1_A]\n                        p1B = times[j1][k1_B]\n                        p2B = times[j2][k2_B]\n                        \n                        # Gaps between operations\n                        gap1 = sum(times[j1][k] for k in range(k1_A + 1, k1_B))\n                        gap2 = sum(times[j2][k] for k in range(k2_B + 1, k2_A))\n                        \n                        # Lift Amount: The mandatory path length J1 and J2 spend between A and B\n                        lift = gap1 + p1B + p2B + gap2\n                        \n                        # If J1 precedes J2 on A (yA=1) AND on B (yB=1), the sequence is J1@A->J1@B->J2@B->J2@A.\n                        # This implies a mandatory delay of 'lift' over the standard p1A.\n                        model.OpposedRoutingCuts.add(\n                            model.S[j2, k2_A] >= model.S[j1, k1_A] + p1A + lift * yB - model.bigM * (1 - yA)\n                        )",
                        "idea": "We combine Parent 1's **Workload Cuts** and Parent 2's **Opposed Routing Cuts**. The Workload cuts enforce a global lower bound on $C_{max}$ using the 1-machine relaxation (Earliest Release + Sum of Processing + Minimum Delivery Time), which is tighter than basic disjunctive constraints for high-contention machines. The Opposed Routing cuts target job pairs with conflicting flows ($J_1: A \\to B$, $J_2: B \\to A$). When the sequencing variables imply a specific loop structure ($J_1 \\prec J_2$ on both machines), the cut lifts the start time of $J_2$ on machine $A$ by the full processing duration of the cycle between $A$ and $B$, pruning the search space by eliminating infeasible or overly optimistic start times in the LP relaxation."
                    },
                    "fitness": 11.440277655309856,
                    "solver_reports": [
                        {
                            "gap": 89.8612,
                            "total_time": 9.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 20622,
                            "explored_time": 8.98,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 8.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 19750,
                            "explored_time": 8.18,
                            "work_units": 10.01
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 8.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 16800,
                            "explored_time": 8.73,
                            "work_units": 10.0
                        },
                        {
                            "gap": 36.7783,
                            "total_time": 12.57,
                            "explored_nodes": 1,
                            "simplex_iterations": 25502,
                            "explored_time": 12.54,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.4069,
                            "total_time": 8.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 17415,
                            "explored_time": 8.52,
                            "work_units": 10.01
                        },
                        {
                            "gap": 25.8865,
                            "total_time": 13.36,
                            "explored_nodes": 115,
                            "simplex_iterations": 49354,
                            "explored_time": 13.34,
                            "work_units": 11.6
                        },
                        {
                            "gap": 92.0081,
                            "total_time": 9.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 13191,
                            "explored_time": 9.31,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 8.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 20283,
                            "explored_time": 7.95,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235",
                        "3cf4467d-0917-4631-95fb-9ec8a696c5ac"
                    ]
                },
                {
                    "id": "3c0fcf4e-0084-4f27-9101-ae6780ff5a1f",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Pre-compute Heads (earliest release) and Tails (min time after completion) for all ops\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        # Forward pass for Heads\n        current_h = 0\n        for k in range(n_machines):\n            op_heads[j, k] = current_h\n            current_h += times[j][k]\n        # Backward pass for Tails\n        current_t = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = current_t\n            current_t += times[j][k]\n    \n    # Group operations by machine\n    mach_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in mach_ops:\n                mach_ops[m_id] = []\n            mach_ops[m_id].append((j, k))\n    \n    def critical_subset_bound_rule(m, m_id):\n        # Calculates the \"Critical Subset\" 1-machine bound.\n        # Instead of using all operations on the machine (which dilutes min_head/min_tail),\n        # we search for a subset S that maximizes: min(Head_i) + sum(p_i) + min(Tail_i).\n        # The optimal subset is guaranteed to be defined by a pair of operations (u, v)\n        # acting as the boundaries: S_{uv} = {k | Head_k >= Head_u AND Tail_k >= Tail_v}.\n        \n        ops = mach_ops.get(m_id, [])\n        if not ops:\n            return pyo.Constraint.Skip\n        \n        max_bound = 0\n        \n        # Iterate over all possible start boundary ops (u) and end boundary ops (v)\n        for u in ops:\n            r_u = op_heads[u]\n            for v in ops:\n                q_v = op_tails[v]\n                \n                # Calculate workload of the subset bounded by u and v\n                # Note: The subset includes any op k fitting in the window [r_u, Time - q_v]\n                p_sum = 0\n                for k in ops:\n                    if op_heads[k] >= r_u and op_tails[k] >= q_v:\n                        p_sum += times[k[0]][k[1]]\n                \n                # If the subset is valid (non-empty), update the bound\n                if p_sum > 0:\n                    current_bound = r_u + p_sum + q_v\n                    if current_bound > max_bound:\n                        max_bound = current_bound\n    \n        return m.Cmax >= max_bound\n    \n    model.critical_subset_cuts = pyo.Constraint(list(mach_ops.keys()), rule=critical_subset_bound_rule)\n\n    return model\n",
                        "added_cut": "# Pre-compute Heads (earliest release) and Tails (min time after completion) for all ops\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    # Forward pass for Heads\n    current_h = 0\n    for k in range(n_machines):\n        op_heads[j, k] = current_h\n        current_h += times[j][k]\n    # Backward pass for Tails\n    current_t = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = current_t\n        current_t += times[j][k]\n\n# Group operations by machine\nmach_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in mach_ops:\n            mach_ops[m_id] = []\n        mach_ops[m_id].append((j, k))\n\ndef critical_subset_bound_rule(m, m_id):\n    # Calculates the \"Critical Subset\" 1-machine bound.\n    # Instead of using all operations on the machine (which dilutes min_head/min_tail),\n    # we search for a subset S that maximizes: min(Head_i) + sum(p_i) + min(Tail_i).\n    # The optimal subset is guaranteed to be defined by a pair of operations (u, v)\n    # acting as the boundaries: S_{uv} = {k | Head_k >= Head_u AND Tail_k >= Tail_v}.\n    \n    ops = mach_ops.get(m_id, [])\n    if not ops:\n        return pyo.Constraint.Skip\n    \n    max_bound = 0\n    \n    # Iterate over all possible start boundary ops (u) and end boundary ops (v)\n    for u in ops:\n        r_u = op_heads[u]\n        for v in ops:\n            q_v = op_tails[v]\n            \n            # Calculate workload of the subset bounded by u and v\n            # Note: The subset includes any op k fitting in the window [r_u, Time - q_v]\n            p_sum = 0\n            for k in ops:\n                if op_heads[k] >= r_u and op_tails[k] >= q_v:\n                    p_sum += times[k[0]][k[1]]\n            \n            # If the subset is valid (non-empty), update the bound\n            if p_sum > 0:\n                current_bound = r_u + p_sum + q_v\n                if current_bound > max_bound:\n                    max_bound = current_bound\n\n    return m.Cmax >= max_bound\n\nmodel.critical_subset_cuts = pyo.Constraint(list(mach_ops.keys()), rule=critical_subset_bound_rule)",
                        "idea": "We introduce **Critical Subset Machine Cuts**, an exploratory strengthening of the standard 1-machine relaxation. The makespan is often constrained not by the *total* workload on a machine, but by a specific 'bottleneck' subset of operations that has late release times (Heads) and long remaining paths (Tails). By iterating through operation pairs to define time windows, we identify the specific subset of operations $S$ that maximizes the lower bound $LB(S) = \\min_{i \\in S} \\text{Head}_i + \\sum_{i \\in S} p_i + \\min_{i \\in S} \\text{Tail}_i$. This strictly dominates the standard cut (which sets $S$ to all operations) and prunes the search space by enforcing tighter global bounds derived from local machine bottlenecks."
                    },
                    "fitness": 14.039559674074326,
                    "solver_reports": [
                        {
                            "gap": 19.1398,
                            "total_time": 14.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 29835,
                            "explored_time": 14.02,
                            "work_units": 10.05
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 9.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 14.19,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 14.17,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.3583,
                            "total_time": 10.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 32144,
                            "explored_time": 10.43,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.4,
                            "total_time": 12.89,
                            "explored_nodes": 9932,
                            "simplex_iterations": 303128,
                            "explored_time": 12.87,
                            "work_units": 10.0
                        },
                        {
                            "gap": 48.9448,
                            "total_time": 13.47,
                            "explored_nodes": 1,
                            "simplex_iterations": 42032,
                            "explored_time": 13.45,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.44,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235"
                    ]
                },
                {
                    "id": "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_lifted_bottleneck_cuts(m):\n        # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n        # to ensure self-contained execution.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Container for new constraints\n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        for mid, ops in mach_ops.items():\n            # Data: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Sort unique thresholds\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n            for r in rs:\n                for q in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            # Add cut: Cmax must be >= tightest 1-machine relaxation\n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n        # Only applied to the identified bottleneck machine to keep size manageable.\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to get the expression for \"u precedes v\"\n            # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n            def get_precedence_expr(u, v):\n                if u < v:\n                    # Variable exists as y[u, v]\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n            # We limit n_cuts to avoid memory explosion if the machine has many ops\n            cut_count = 0\n            limit = 100 \n            \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Base precedence var: i -> j\n                    y_ij = get_precedence_expr(i, j)\n                    \n                    # Identify intermediate node k\n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_precedence_expr(i, k)\n                        y_kj = get_precedence_expr(k, j)\n                        \n                        # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                        # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        # Logic: \n                        #   If y_ij=1 (i->j active):\n                        #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                        #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                        #      Else:\n                        #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                        #   If y_ij=0 (i->j inactive):\n                        #      RHS is large negative (Valid due to bigM)\n                        \n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count > limit: break\n                if cut_count > limit: break\n    \n    apply_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_lifted_bottleneck_cuts(m):\n    # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n    # to ensure self-contained execution.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Container for new constraints\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    for mid, ops in mach_ops.items():\n        # Data: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Sort unique thresholds\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n        for r in rs:\n            for q in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        # Add cut: Cmax must be >= tightest 1-machine relaxation\n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n    # Only applied to the identified bottleneck machine to keep size manageable.\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to get the expression for \"u precedes v\"\n        # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n        def get_precedence_expr(u, v):\n            if u < v:\n                # Variable exists as y[u, v]\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n        # We limit n_cuts to avoid memory explosion if the machine has many ops\n        cut_count = 0\n        limit = 100 \n        \n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Base precedence var: i -> j\n                y_ij = get_precedence_expr(i, j)\n                \n                # Identify intermediate node k\n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_precedence_expr(i, k)\n                    y_kj = get_precedence_expr(k, j)\n                    \n                    # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                    # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    # Logic: \n                    #   If y_ij=1 (i->j active):\n                    #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                    #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                    #      Else:\n                    #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                    #   If y_ij=0 (i->j inactive):\n                    #      RHS is large negative (Valid due to bigM)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count > limit: break\n            if cut_count > limit: break\n\napply_lifted_bottleneck_cuts(model)",
                        "idea": "We apply **Bottleneck-Focused Triangle Lifting**. First, we strengthen the global lower bound by computing the **Carlier Bound** for every machine; this effectively lifts the `Cmax` constraint by solving the 1-machine head-tail problem exactly. Second, we identify the bottleneck machine (the one generating the max Carlier bound) and apply **Triangle Precedence Cuts** to it. These cuts lift the pairwise disjunctive constraints $S_j \\ge S_i + p_i$ by incorporating intermediate operations $k$: if $i \\to k \\to j$, the delay must include $p_k$. This creates a tighter polyhedral approximation for the critical machine, pruning fractional solutions where precedence is intransitive."
                    },
                    "fitness": 19.745839703599053,
                    "solver_reports": [
                        {
                            "gap": 22.6009,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 34291,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3984,
                            "total_time": 12.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 35151,
                            "explored_time": 12.71,
                            "work_units": 10.28
                        },
                        {
                            "gap": 34.8922,
                            "total_time": 11.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 30987,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6984,
                            "total_time": 13.28,
                            "explored_nodes": 59,
                            "simplex_iterations": 45527,
                            "explored_time": 13.27,
                            "work_units": 10.17
                        },
                        {
                            "total_time": 11.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34484,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.2529,
                            "total_time": 10.35,
                            "explored_nodes": 1497,
                            "simplex_iterations": 87588,
                            "explored_time": 10.34,
                            "work_units": 10.88
                        },
                        {
                            "gap": 25.8837,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 49577,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 39685,
                            "explored_time": 10.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "953456bd-bd70-4803-ab54-4778ff8de5b6"
                    ]
                },
                {
                    "id": "c7e4e596-2d11-4984-88bc-32c7082f7b3f",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Precompute Heads (earliest start) and Tails (post-processing) for all operations\n    op_heads = {}\n    op_tails = {}\n    for j in range(n_jobs):\n        # Forward pass: Heads\n        h_accum = 0\n        for k in range(n_machines):\n            op_heads[j, k] = h_accum\n            h_accum += times[j][k]\n        # Backward pass: Tails\n        t_accum = 0\n        for k in range(n_machines - 1, -1, -1):\n            op_tails[j, k] = t_accum\n            t_accum += times[j][k]\n    \n    # Group operations by machine for efficient lookup\n    machine_ops = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in machine_ops:\n                machine_ops[m_id] = []\n            machine_ops[m_id].append((j, k))\n    \n    # Precompute static bounds per machine (1-Machine Relaxation stats)\n    # mach_stats[m_id] = (min_head, total_processing, min_tail)\n    mach_stats = {}\n    for m_id, ops in machine_ops.items():\n        min_head = min(op_heads[op] for op in ops)\n        min_tail = min(op_tails[op] for op in ops)\n        total_p = sum(times[op[0]][op[1]] for op in ops)\n        mach_stats[m_id] = (min_head, total_p, min_tail)\n    \n    # 1. Static Machine Workload Cut (from Parent 2)\n    # Enforces that Cmax covers the full workload of any machine, padded by the earliest\n    # possible start (min_head) and latest mandatory finish (min_tail).\n    def static_workload_rule(m, m_id):\n        if m_id not in mach_stats:\n            return pyo.Constraint.Skip\n        min_head, total_p, min_tail = mach_stats[m_id]\n        return m.Cmax >= min_head + total_p + min_tail\n    \n    model.static_workload_cuts = pyo.Constraint(list(machine_ops.keys()), rule=static_workload_rule)\n    \n    # 2. Dynamic Successor Cut (from Parent 1)\n    # Tightens the bound during branching by anchoring the workload to a specific operation 'u'.\n    # Cmax >= Start_u + p_u + Sum(p_v for v after u) + min_tail\n    def dynamic_successor_rule(m, j, k):\n        u_mach = machines[j][k]\n        if u_mach not in mach_stats:\n            return pyo.Constraint.Skip\n        \n        # Start counting load from u's completion\n        current_load = m.S[j, k] + m.p[j, k]\n        \n        # Add processing times of all successors v on the same machine\n        # We rely on the disjunctive variables 'y' which are fixed during the B&B search.\n        for (j2, k2) in machine_ops[u_mach]:\n            if (j, k) == (j2, k2):\n                continue\n            \n            if (j, k) < (j2, k2):\n                # Pair is (u, v). y=1 implies u precedes v.\n                current_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n            else:\n                # Pair is (v, u). y=0 implies u precedes v.\n                current_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                \n        # Add the precomputed minimum tail for this machine to ensure the last job's\n        # post-processing is accounted for.\n        return m.Cmax >= current_load + mach_stats[u_mach][2]\n    \n    model.dynamic_successor_cuts = pyo.Constraint(model.J, model.K, rule=dynamic_successor_rule)\n\n    return model\n",
                        "added_cut": "# Precompute Heads (earliest start) and Tails (post-processing) for all operations\nop_heads = {}\nop_tails = {}\nfor j in range(n_jobs):\n    # Forward pass: Heads\n    h_accum = 0\n    for k in range(n_machines):\n        op_heads[j, k] = h_accum\n        h_accum += times[j][k]\n    # Backward pass: Tails\n    t_accum = 0\n    for k in range(n_machines - 1, -1, -1):\n        op_tails[j, k] = t_accum\n        t_accum += times[j][k]\n\n# Group operations by machine for efficient lookup\nmachine_ops = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in machine_ops:\n            machine_ops[m_id] = []\n        machine_ops[m_id].append((j, k))\n\n# Precompute static bounds per machine (1-Machine Relaxation stats)\n# mach_stats[m_id] = (min_head, total_processing, min_tail)\nmach_stats = {}\nfor m_id, ops in machine_ops.items():\n    min_head = min(op_heads[op] for op in ops)\n    min_tail = min(op_tails[op] for op in ops)\n    total_p = sum(times[op[0]][op[1]] for op in ops)\n    mach_stats[m_id] = (min_head, total_p, min_tail)\n\n# 1. Static Machine Workload Cut (from Parent 2)\n# Enforces that Cmax covers the full workload of any machine, padded by the earliest\n# possible start (min_head) and latest mandatory finish (min_tail).\ndef static_workload_rule(m, m_id):\n    if m_id not in mach_stats:\n        return pyo.Constraint.Skip\n    min_head, total_p, min_tail = mach_stats[m_id]\n    return m.Cmax >= min_head + total_p + min_tail\n\nmodel.static_workload_cuts = pyo.Constraint(list(machine_ops.keys()), rule=static_workload_rule)\n\n# 2. Dynamic Successor Cut (from Parent 1)\n# Tightens the bound during branching by anchoring the workload to a specific operation 'u'.\n# Cmax >= Start_u + p_u + Sum(p_v for v after u) + min_tail\ndef dynamic_successor_rule(m, j, k):\n    u_mach = machines[j][k]\n    if u_mach not in mach_stats:\n        return pyo.Constraint.Skip\n    \n    # Start counting load from u's completion\n    current_load = m.S[j, k] + m.p[j, k]\n    \n    # Add processing times of all successors v on the same machine\n    # We rely on the disjunctive variables 'y' which are fixed during the B&B search.\n    for (j2, k2) in machine_ops[u_mach]:\n        if (j, k) == (j2, k2):\n            continue\n        \n        if (j, k) < (j2, k2):\n            # Pair is (u, v). y=1 implies u precedes v.\n            current_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n        else:\n            # Pair is (v, u). y=0 implies u precedes v.\n            current_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n            \n    # Add the precomputed minimum tail for this machine to ensure the last job's\n    # post-processing is accounted for.\n    return m.Cmax >= current_load + mach_stats[u_mach][2]\n\nmodel.dynamic_successor_cuts = pyo.Constraint(model.J, model.K, rule=dynamic_successor_rule)",
                        "idea": "This hybrid strategy combines global and local bounding. The static component ($C_{max} \\ge \\min H + \\sum P + \\min T$) lifts the relaxation at the root node by treating each machine as a 1-machine scheduling problem. The dynamic component tightens bounds deeper in the tree: for every operation $u$, it calculates the specific completion time of the machine's sequence starting from $u$ (using disjunctive variables $y$) and adds the machine's minimum tail. This ensures that as precedence decisions are made, the makespan lower bound immediately reflects the unavoidable workload and post-processing time."
                    },
                    "fitness": 10.758783469211712,
                    "solver_reports": [
                        {
                            "gap": 89.8612,
                            "total_time": 10.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 36021,
                            "explored_time": 10.35,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 8.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 40111,
                            "explored_time": 8.79,
                            "work_units": 10.04
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 8.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 38929,
                            "explored_time": 8.25,
                            "work_units": 10.02
                        },
                        {
                            "gap": 88.5208,
                            "total_time": 15.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 26935,
                            "explored_time": 15.81,
                            "work_units": 10.02
                        },
                        {
                            "gap": 93.4069,
                            "total_time": 7.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 39504,
                            "explored_time": 7.74,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.6297,
                            "total_time": 10.64,
                            "explored_nodes": 115,
                            "simplex_iterations": 82742,
                            "explored_time": 10.63,
                            "work_units": 11.17
                        },
                        {
                            "gap": 91.8728,
                            "total_time": 14.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 16031,
                            "explored_time": 14.1,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 8.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 35574,
                            "explored_time": 8.08,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "8236f856-c803-471f-b687-0678ca2c73f5",
                        "93e5c6fb-0603-4bcd-bf5c-3739c0fb6235"
                    ]
                },
                {
                    "id": "a93a3c08-4e4c-418d-8471-3baec5871e88",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Hybrid Constraint: Symmetric Head-Tail Displacement Cuts\n    # ----------------------------------------------------------------\n    # This constraint fuses the structural logic of Parent 1 (Bi-Directional Displacement)\n    # with the numerical strengthening of Parent 2 (Static Tail Look-ahead).\n    # It bounds operation start times using machine release dates and predecessor workload,\n    # and bounds global makespan using operation completion, successor workload, and downstream tails.\n    \n    # 1. Precompute static Heads (earliest start) and Tails (remaining work) for all operations\n    op_heads = {}\n    op_tails = {}\n    mach_ops = {m: [] for m in range(n_machines)}\n    \n    # Calculate Heads (Forward pass)\n    for j in range(n_jobs):\n        current_time = 0\n        for k in range(n_machines):\n            op = (j, k)\n            op_heads[op] = current_time\n            m_id = machines[j][k]\n            mach_ops[m_id].append(op)\n            current_time += times[j][k]\n    \n    # Calculate Tails (Backward pass)\n    for j in range(n_jobs):\n        # tail[j][k] is sum of p for steps k+1..end\n        # The last operation (k=n_machines-1) has tail 0\n        for k in range(n_machines):\n            remaining = sum(times[j][x] for x in range(k + 1, n_machines))\n            op_tails[(j, k)] = remaining\n    \n    # 2. Determine Machine-level static bounds\n    # min_mach_head: Earliest any operation on this machine can start\n    # min_mach_tail: Minimum remaining work after any operation on this machine finishes\n    min_mach_heads = {}\n    min_mach_tails = {}\n    for m_id in range(n_machines):\n        if mach_ops[m_id]:\n            min_mach_heads[m_id] = min(op_heads[o] for o in mach_ops[m_id])\n            min_mach_tails[m_id] = min(op_tails[o] for o in mach_ops[m_id])\n        else:\n            min_mach_heads[m_id] = 0\n            min_mach_tails[m_id] = 0\n    \n    model.DisplacementDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def symmetric_displacement_rule(m, j, k, mode):\n        u_op = (j, k)\n        u_mach = machines[j][k]\n        relevant_ops = mach_ops[u_mach]\n        \n        # Forward Cut (Head Bound): Lifts Start Time\n        # S_u >= min_head + Sum(p_v * is_predecessor_v)\n        if mode == 'fwd':\n            pred_work = 0\n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # Logic: We add p[j2,k2] only if (j2,k2) precedes u_op\n                if (j2, k2) < u_op:\n                    # Pair is ((j2,k2), u_op). y=1 => (j2,k2)->u_op\n                    pred_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n                else:\n                    # Pair is (u_op, (j2,k2)). y=0 => (j2,k2)->u_op\n                    pred_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n            \n            return m.S[j, k] >= min_mach_heads[u_mach] + pred_work\n    \n        # Backward Cut (Tail Bound): Lifts Makespan\n        # Cmax >= S_u + p_u + Sum(p_v * is_successor_v) + min_mach_tail\n        else:\n            succ_work = 0\n            for (j2, k2) in relevant_ops:\n                if (j2, k2) == u_op: continue\n                \n                # Logic: We add p[j2,k2] only if (j2,k2) succeeds u_op\n                if u_op < (j2, k2):\n                    # Pair is (u_op, (j2,k2)). y=1 => u_op->(j2,k2)\n                    succ_work += m.p[j2, k2] * m.y[j, k, j2, k2]\n                else:\n                    # Pair is ((j2,k2), u_op). y=0 => u_op->(j2,k2)\n                    succ_work += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n            \n            # Strengthened by adding the minimum unavoidable tail of the machine\n            return m.Cmax >= m.S[j, k] + m.p[j, k] + succ_work + min_mach_tails[u_mach]\n    \n    model.SymmetricDisplacement = pyo.Constraint(model.J, model.K, model.DisplacementDirs, \n                                                 rule=symmetric_displacement_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Hybrid Constraint: Symmetric Head-Tail Displacement Cuts\n# ----------------------------------------------------------------\n# This constraint fuses the structural logic of Parent 1 (Bi-Directional Displacement)\n# with the numerical strengthening of Parent 2 (Static Tail Look-ahead).\n# It bounds operation start times using machine release dates and predecessor workload,\n# and bounds global makespan using operation completion, successor workload, and downstream tails.\n\n# 1. Precompute static Heads (earliest start) and Tails (remaining work) for all operations\nop_heads = {}\nop_tails = {}\nmach_ops = {m: [] for m in range(n_machines)}\n\n# Calculate Heads (Forward pass)\nfor j in range(n_jobs):\n    current_time = 0\n    for k in range(n_machines):\n        op = (j, k)\n        op_heads[op] = current_time\n        m_id = machines[j][k]\n        mach_ops[m_id].append(op)\n        current_time += times[j][k]\n\n# Calculate Tails (Backward pass)\nfor j in range(n_jobs):\n    # tail[j][k] is sum of p for steps k+1..end\n    # The last operation (k=n_machines-1) has tail 0\n    for k in range(n_machines):\n        remaining = sum(times[j][x] for x in range(k + 1, n_machines))\n        op_tails[(j, k)] = remaining\n\n# 2. Determine Machine-level static bounds\n# min_mach_head: Earliest any operation on this machine can start\n# min_mach_tail: Minimum remaining work after any operation on this machine finishes\nmin_mach_heads = {}\nmin_mach_tails = {}\nfor m_id in range(n_machines):\n    if mach_ops[m_id]:\n        min_mach_heads[m_id] = min(op_heads[o] for o in mach_ops[m_id])\n        min_mach_tails[m_id] = min(op_tails[o] for o in mach_ops[m_id])\n    else:\n        min_mach_heads[m_id] = 0\n        min_mach_tails[m_id] = 0\n\nmodel.DisplacementDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef symmetric_displacement_rule(m, j, k, mode):\n    u_op = (j, k)\n    u_mach = machines[j][k]\n    relevant_ops = mach_ops[u_mach]\n    \n    # Forward Cut (Head Bound): Lifts Start Time\n    # S_u >= min_head + Sum(p_v * is_predecessor_v)\n    if mode == 'fwd':\n        pred_work = 0\n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # Logic: We add p[j2,k2] only if (j2,k2) precedes u_op\n            if (j2, k2) < u_op:\n                # Pair is ((j2,k2), u_op). y=1 => (j2,k2)->u_op\n                pred_work += m.p[j2, k2] * m.y[j2, k2, j, k]\n            else:\n                # Pair is (u_op, (j2,k2)). y=0 => (j2,k2)->u_op\n                pred_work += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n        \n        return m.S[j, k] >= min_mach_heads[u_mach] + pred_work\n\n    # Backward Cut (Tail Bound): Lifts Makespan\n    # Cmax >= S_u + p_u + Sum(p_v * is_successor_v) + min_mach_tail\n    else:\n        succ_work = 0\n        for (j2, k2) in relevant_ops:\n            if (j2, k2) == u_op: continue\n            \n            # Logic: We add p[j2,k2] only if (j2,k2) succeeds u_op\n            if u_op < (j2, k2):\n                # Pair is (u_op, (j2,k2)). y=1 => u_op->(j2,k2)\n                succ_work += m.p[j2, k2] * m.y[j, k, j2, k2]\n            else:\n                # Pair is ((j2,k2), u_op). y=0 => u_op->(j2,k2)\n                succ_work += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n        \n        # Strengthened by adding the minimum unavoidable tail of the machine\n        return m.Cmax >= m.S[j, k] + m.p[j, k] + succ_work + min_mach_tails[u_mach]\n\nmodel.SymmetricDisplacement = pyo.Constraint(model.J, model.K, model.DisplacementDirs, \n                                             rule=symmetric_displacement_rule)",
                        "idea": "We construct **Symmetric Head-Tail Displacement Cuts** by hybridizing the bi-directional bounding structure of Parent 1 with the static look-ahead tightening of Parent 2. For every operation $u$, we generate two bounds: (1) A **Forward Head-Bound** that forces the start time $S_u$ to be at least the machine's earliest release time ($r_{min}$) plus the dynamic workload of all predecessors. (2) A **Backward Tail-Bound** that forces the makespan $C_{max}$ to be at least the completion time of the machine block ending at $u$, plus the dynamic workload of all successors, plus the **minimum static tail** of any job on that machine. This creates a symmetric 'vise' effect: the forward cut pushes start times later, while the backward cut (reinforced with the tail term) pushes the required makespan higher, aggressively tightening the relaxation gap."
                    },
                    "fitness": 12.567806103438688,
                    "solver_reports": [
                        {
                            "total_time": 6.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 21834,
                            "explored_time": 6.79,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 23099,
                            "explored_time": 6.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 32781,
                            "explored_time": 7.48,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 21405,
                            "explored_time": 6.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 33955,
                            "explored_time": 8.08,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.4015,
                            "total_time": 8.34,
                            "explored_nodes": 30,
                            "simplex_iterations": 47063,
                            "explored_time": 8.34,
                            "work_units": 10.11
                        },
                        {
                            "total_time": 5.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 18017,
                            "explored_time": 5.6,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 23197,
                            "explored_time": 6.78,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "bda49ecf-46fd-4b71-87d9-86d650cbacd5",
                        "bc838ac0-4d80-447a-8bdb-738d4bdaf0ce"
                    ]
                }
            ],
            19.745839703599053
        ],
        [
            [
                {
                    "id": "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_lifted_bottleneck_cuts(m):\n        # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n        # to ensure self-contained execution.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Container for new constraints\n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        for mid, ops in mach_ops.items():\n            # Data: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Sort unique thresholds\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n            for r in rs:\n                for q in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            # Add cut: Cmax must be >= tightest 1-machine relaxation\n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n        # Only applied to the identified bottleneck machine to keep size manageable.\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to get the expression for \"u precedes v\"\n            # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n            def get_precedence_expr(u, v):\n                if u < v:\n                    # Variable exists as y[u, v]\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n            # We limit n_cuts to avoid memory explosion if the machine has many ops\n            cut_count = 0\n            limit = 100 \n            \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Base precedence var: i -> j\n                    y_ij = get_precedence_expr(i, j)\n                    \n                    # Identify intermediate node k\n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_precedence_expr(i, k)\n                        y_kj = get_precedence_expr(k, j)\n                        \n                        # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                        # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        # Logic: \n                        #   If y_ij=1 (i->j active):\n                        #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                        #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                        #      Else:\n                        #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                        #   If y_ij=0 (i->j inactive):\n                        #      RHS is large negative (Valid due to bigM)\n                        \n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count > limit: break\n                if cut_count > limit: break\n    \n    apply_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_lifted_bottleneck_cuts(m):\n    # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n    # to ensure self-contained execution.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Container for new constraints\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    for mid, ops in mach_ops.items():\n        # Data: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Sort unique thresholds\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n        for r in rs:\n            for q in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        # Add cut: Cmax must be >= tightest 1-machine relaxation\n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n    # Only applied to the identified bottleneck machine to keep size manageable.\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to get the expression for \"u precedes v\"\n        # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n        def get_precedence_expr(u, v):\n            if u < v:\n                # Variable exists as y[u, v]\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n        # We limit n_cuts to avoid memory explosion if the machine has many ops\n        cut_count = 0\n        limit = 100 \n        \n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Base precedence var: i -> j\n                y_ij = get_precedence_expr(i, j)\n                \n                # Identify intermediate node k\n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_precedence_expr(i, k)\n                    y_kj = get_precedence_expr(k, j)\n                    \n                    # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                    # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    # Logic: \n                    #   If y_ij=1 (i->j active):\n                    #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                    #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                    #      Else:\n                    #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                    #   If y_ij=0 (i->j inactive):\n                    #      RHS is large negative (Valid due to bigM)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count > limit: break\n            if cut_count > limit: break\n\napply_lifted_bottleneck_cuts(model)",
                        "idea": "We apply **Bottleneck-Focused Triangle Lifting**. First, we strengthen the global lower bound by computing the **Carlier Bound** for every machine; this effectively lifts the `Cmax` constraint by solving the 1-machine head-tail problem exactly. Second, we identify the bottleneck machine (the one generating the max Carlier bound) and apply **Triangle Precedence Cuts** to it. These cuts lift the pairwise disjunctive constraints $S_j \\ge S_i + p_i$ by incorporating intermediate operations $k$: if $i \\to k \\to j$, the delay must include $p_k$. This creates a tighter polyhedral approximation for the critical machine, pruning fractional solutions where precedence is intransitive."
                    },
                    "fitness": 19.745839703599053,
                    "solver_reports": [
                        {
                            "gap": 22.6009,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 34291,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3984,
                            "total_time": 12.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 35151,
                            "explored_time": 12.71,
                            "work_units": 10.28
                        },
                        {
                            "gap": 34.8922,
                            "total_time": 11.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 30987,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6984,
                            "total_time": 13.28,
                            "explored_nodes": 59,
                            "simplex_iterations": 45527,
                            "explored_time": 13.27,
                            "work_units": 10.17
                        },
                        {
                            "total_time": 11.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34484,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.2529,
                            "total_time": 10.35,
                            "explored_nodes": 1497,
                            "simplex_iterations": 87588,
                            "explored_time": 10.34,
                            "work_units": 10.88
                        },
                        {
                            "gap": 25.8837,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 49577,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 39685,
                            "explored_time": 10.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "953456bd-bd70-4803-ab54-4778ff8de5b6"
                    ]
                },
                {
                    "id": "1118323a-bd1c-481f-914b-b5e3b01b201f",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Hybrid Constraint: Critical Subset Displacement\n    # ----------------------------------------------------------------\n    # This constraint fuses the Carlier Bottleneck Detection (Parent 1)\n    # with the Symmetric Displacement structure (Parent 2).\n    # It isolates the critical subset of operations \\Omega that defines the\n    # tightest 1-machine bound, then applies displacement cuts restricted to \\Omega.\n    \n    # 1. Compute static Heads (r) and Tails (q) for all operations\n    r_map = {}\n    q_map = {}\n    mach_bins = {}\n    \n    # Calculate Heads (Forward)\n    for j in model.J:\n        t = 0\n        for k in model.K:\n            op = (j, k)\n            r_map[op] = t\n            t += model.p[op]\n            mid = model.mach[op]\n            if mid not in mach_bins: \n                mach_bins[mid] = []\n            mach_bins[mid].append(op)\n    \n    # Calculate Tails (Backward)\n    for j in model.J:\n        t = 0\n        # Iterate backwards over operations in job\n        for k in range(n_machines - 1, -1, -1):\n            op = (j, k)\n            q_map[op] = t\n            t += model.p[op]\n    \n    # 2. Identify Critical Subset (Carlier Bound Logic)\n    # We search for the machine window [r_val, end-q_val] that maximizes the lower bound.\n    crit_subset = []\n    crit_r = 0\n    crit_q = 0\n    global_lb = -1\n    \n    for mid, ops in mach_bins.items():\n        # Optimization: Filter unique thresholds restricted to this machine's ops\n        r_distinct = sorted(list(set(r_map[o] for o in ops)))\n        q_distinct = sorted(list(set(q_map[o] for o in ops)))\n        \n        for r_val in r_distinct:\n            for q_val in q_distinct:\n                # Define subset: operations strictly contained in the (r_val, q_val) window\n                subset = [o for o in ops if r_map[o] >= r_val and q_map[o] >= q_val]\n                if not subset: continue\n                \n                p_sum = sum(model.p[o] for o in subset)\n                this_lb = r_val + p_sum + q_val\n                \n                if this_lb > global_lb:\n                    global_lb = this_lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n    \n    model.hybrid_cuts = pyo.ConstraintList()\n    \n    # 3. Apply Hybrid Cuts\n    # A. Global Lower Bound (inherited from Parent 1)\n    if global_lb > 0:\n        model.hybrid_cuts.add(model.Cmax >= global_lb)\n    \n    # B. Critical Subset Displacement Cuts (inherited from Parent 2)\n    # Applied only to the bottleneck subset, using the tight window bounds (crit_r, crit_q)\n    # instead of loose global machine bounds.\n    if crit_subset and len(crit_subset) > 1:\n        \n        # Helper to retrieve binary variable y[u->v]\n        def get_prec_y(u, v):\n            if u < v:\n                return model.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - model.y[v[0], v[1], u[0], u[1]]\n    \n        for u in crit_subset:\n            # Forward Cut: S_u >= WindowStart + Work(Predecessors inside subset)\n            # This pushes S_u later if it has many predecessors in the bottleneck.\n            pred_work = sum(model.p[v] * get_prec_y(v, u) for v in crit_subset if v != u)\n            model.hybrid_cuts.add(model.S[u] >= crit_r + pred_work)\n            \n            # Backward Cut: Cmax >= S_u + p_u + Work(Successors inside subset) + WindowTail\n            # This pushes Cmax higher if u has many successors in the bottleneck.\n            succ_work = sum(model.p[v] * get_prec_y(u, v) for v in crit_subset if v != u)\n            model.hybrid_cuts.add(model.Cmax >= model.S[u] + model.p[u] + succ_work + crit_q)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Hybrid Constraint: Critical Subset Displacement\n# ----------------------------------------------------------------\n# This constraint fuses the Carlier Bottleneck Detection (Parent 1)\n# with the Symmetric Displacement structure (Parent 2).\n# It isolates the critical subset of operations \\Omega that defines the\n# tightest 1-machine bound, then applies displacement cuts restricted to \\Omega.\n\n# 1. Compute static Heads (r) and Tails (q) for all operations\nr_map = {}\nq_map = {}\nmach_bins = {}\n\n# Calculate Heads (Forward)\nfor j in model.J:\n    t = 0\n    for k in model.K:\n        op = (j, k)\n        r_map[op] = t\n        t += model.p[op]\n        mid = model.mach[op]\n        if mid not in mach_bins: \n            mach_bins[mid] = []\n        mach_bins[mid].append(op)\n\n# Calculate Tails (Backward)\nfor j in model.J:\n    t = 0\n    # Iterate backwards over operations in job\n    for k in range(n_machines - 1, -1, -1):\n        op = (j, k)\n        q_map[op] = t\n        t += model.p[op]\n\n# 2. Identify Critical Subset (Carlier Bound Logic)\n# We search for the machine window [r_val, end-q_val] that maximizes the lower bound.\ncrit_subset = []\ncrit_r = 0\ncrit_q = 0\nglobal_lb = -1\n\nfor mid, ops in mach_bins.items():\n    # Optimization: Filter unique thresholds restricted to this machine's ops\n    r_distinct = sorted(list(set(r_map[o] for o in ops)))\n    q_distinct = sorted(list(set(q_map[o] for o in ops)))\n    \n    for r_val in r_distinct:\n        for q_val in q_distinct:\n            # Define subset: operations strictly contained in the (r_val, q_val) window\n            subset = [o for o in ops if r_map[o] >= r_val and q_map[o] >= q_val]\n            if not subset: continue\n            \n            p_sum = sum(model.p[o] for o in subset)\n            this_lb = r_val + p_sum + q_val\n            \n            if this_lb > global_lb:\n                global_lb = this_lb\n                crit_subset = subset\n                crit_r = r_val\n                crit_q = q_val\n\nmodel.hybrid_cuts = pyo.ConstraintList()\n\n# 3. Apply Hybrid Cuts\n# A. Global Lower Bound (inherited from Parent 1)\nif global_lb > 0:\n    model.hybrid_cuts.add(model.Cmax >= global_lb)\n\n# B. Critical Subset Displacement Cuts (inherited from Parent 2)\n# Applied only to the bottleneck subset, using the tight window bounds (crit_r, crit_q)\n# instead of loose global machine bounds.\nif crit_subset and len(crit_subset) > 1:\n    \n    # Helper to retrieve binary variable y[u->v]\n    def get_prec_y(u, v):\n        if u < v:\n            return model.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - model.y[v[0], v[1], u[0], u[1]]\n\n    for u in crit_subset:\n        # Forward Cut: S_u >= WindowStart + Work(Predecessors inside subset)\n        # This pushes S_u later if it has many predecessors in the bottleneck.\n        pred_work = sum(model.p[v] * get_prec_y(v, u) for v in crit_subset if v != u)\n        model.hybrid_cuts.add(model.S[u] >= crit_r + pred_work)\n        \n        # Backward Cut: Cmax >= S_u + p_u + Work(Successors inside subset) + WindowTail\n        # This pushes Cmax higher if u has many successors in the bottleneck.\n        succ_work = sum(model.p[v] * get_prec_y(u, v) for v in crit_subset if v != u)\n        model.hybrid_cuts.add(model.Cmax >= model.S[u] + model.p[u] + succ_work + crit_q)",
                        "idea": "We combine Parent 1's **Carlier Bottleneck Detection** with Parent 2's **Symmetric Displacement**. By dynamically identifying the critical subset $\\Omega$ that maximizes the 1-machine lower bound, we determine a tight time window $[r_{min}, \\dots, q_{min}]$. We then apply displacement cuts restricted specifically to $\\Omega$. This lifts the head ($r$) and tail ($q$) terms from loose machine-wide minimums to the bottleneck's active boundaries, creating a 'vise' that tightly bounds start times and makespan for the most contended operations."
                    },
                    "fitness": 13.68852872713477,
                    "solver_reports": [
                        {
                            "total_time": 8.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 18343,
                            "explored_time": 8.31,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 20098,
                            "explored_time": 8.26,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 38820,
                            "explored_time": 8.59,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.9658,
                            "total_time": 10.71,
                            "explored_nodes": 1,
                            "simplex_iterations": 46078,
                            "explored_time": 10.68,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.3388,
                            "total_time": 10.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 16570,
                            "explored_time": 10.44,
                            "work_units": 10.01
                        },
                        {
                            "gap": 17.0086,
                            "total_time": 12.01,
                            "explored_nodes": 143,
                            "simplex_iterations": 73759,
                            "explored_time": 12.0,
                            "work_units": 11.75
                        },
                        {
                            "gap": 89.5312,
                            "total_time": 15.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 31887,
                            "explored_time": 15.36,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 23359,
                            "explored_time": 9.55,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "a93a3c08-4e4c-418d-8471-3baec5871e88"
                    ]
                },
                {
                    "id": "189614b9-a044-4255-b3be-dbb38183be7c",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Constraint: Critical Subset-Restricted Displacement Cuts\n    # ----------------------------------------------------------------\n    # Concept: Identify the bottleneck subset S* on each machine (from Parent 2)\n    # and apply Parent 1's Displacement logic specifically to S*.\n    # This allows using the tighter MinHead and MinTail of S* rather than\n    # the machine-wide minimums.\n    \n    # 1. Precompute Heads and Tails for all operations\n    op_heads = {}\n    op_tails = {}\n    mach_ops = {} # Map machine_id -> list of ops\n    \n    for j in range(n_jobs):\n        # Forward pass for heads\n        current_head = 0\n        for k in range(n_machines):\n            op = (j, k)\n            op_heads[op] = current_head\n            \n            m_id = machines[j][k]\n            if m_id not in mach_ops:\n                mach_ops[m_id] = []\n            mach_ops[m_id].append(op)\n            \n            current_head += times[j][k]\n        \n        # Backward pass for tails\n        current_tail = 0\n        for k in range(n_machines - 1, -1, -1):\n            op = (j, k)\n            op_tails[op] = current_tail\n            current_tail += times[j][k]\n    \n    # 2. Identify the Critical Subset S* for each machine\n    # S* is the subset of ops maximizing the 1-machine bound: min_r + sum_p + min_q\n    critical_subsets = {} # m_id -> {'ops': set, 'min_h': val, 'min_t': val}\n    \n    for m_id, ops in mach_ops.items():\n        best_bound = -1\n        best_subset = []\n        best_min_h = 0\n        best_min_t = 0\n        \n        # Brute-force all pairs (u, v) to define the tightest window [r_u ... q_v]\n        # This is O(N_ops_on_machine^3), typically small per machine\n        for u in ops:\n            r_u = op_heads[u]\n            for v in ops:\n                q_v = op_tails[v]\n                \n                # Form candidate subset: all k with head >= r_u and tail >= q_v\n                candidate_subset = [k for k in ops if op_heads[k] >= r_u and op_tails[k] >= q_v]\n                \n                if not candidate_subset: continue\n                \n                p_sum = sum(times[k[0]][k[1]] for k in candidate_subset)\n                bound = r_u + p_sum + q_v\n                \n                if bound > best_bound:\n                    best_bound = bound\n                    best_subset = candidate_subset\n                    best_min_h = r_u\n                    best_min_t = q_v\n        \n        # Store the critical subset data\n        critical_subsets[m_id] = {\n            'ops': set(best_subset),\n            'min_h': best_min_h,\n            'min_t': best_min_t\n        }\n    \n    # 3. Define the Subset-Restricted Displacement Cuts\n    model.SubsetDispDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def subset_displacement_rule(m, j, k, direction):\n        u = (j, k)\n        m_id = machines[j][k]\n        c_data = critical_subsets.get(m_id)\n        \n        # Only apply cut if the machine has ops and u is part of the critical subset\n        if not c_data or u not in c_data['ops']:\n            return pyo.Constraint.Skip\n        \n        subset = c_data['ops']\n        min_h = c_data['min_h']\n        min_t = c_data['min_t']\n        \n        work_load = 0\n        \n        if direction == 'fwd':\n            # Forward Cut: S_u >= min_head(S*) + sum_{v in S*, v->u} p_v\n            for (j2, k2) in subset:\n                if (j2, k2) == u: continue\n                \n                # If (j2, k2) precedes u\n                if (j2, k2) < u: \n                    # Pair in set is (j2, k2, j, k) -> y=1 means v->u\n                    work_load += m.p[j2, k2] * m.y[j2, k2, j, k]\n                else:\n                    # Pair in set is (j, k, j2, k2) -> y=0 means v->u\n                    work_load += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n            \n            return m.S[j, k] >= min_h + work_load\n    \n        else:\n            # Backward Cut: Cmax >= S_u + p_u + sum_{v in S*, u->v} p_v + min_tail(S*)\n            for (j2, k2) in subset:\n                if (j2, k2) == u: continue\n                \n                # If u precedes (j2, k2)\n                if u < (j2, k2):\n                    # Pair is (u, v) -> y=1 means u->v\n                    work_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n                else:\n                    # Pair is (v, u) -> y=0 means u->v\n                    work_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                    \n            return m.Cmax >= m.S[j, k] + m.p[j, k] + work_load + min_t\n    \n    model.SubsetRestrictedDisplacement = pyo.Constraint(model.J, model.K, model.SubsetDispDirs, rule=subset_displacement_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Constraint: Critical Subset-Restricted Displacement Cuts\n# ----------------------------------------------------------------\n# Concept: Identify the bottleneck subset S* on each machine (from Parent 2)\n# and apply Parent 1's Displacement logic specifically to S*.\n# This allows using the tighter MinHead and MinTail of S* rather than\n# the machine-wide minimums.\n\n# 1. Precompute Heads and Tails for all operations\nop_heads = {}\nop_tails = {}\nmach_ops = {} # Map machine_id -> list of ops\n\nfor j in range(n_jobs):\n    # Forward pass for heads\n    current_head = 0\n    for k in range(n_machines):\n        op = (j, k)\n        op_heads[op] = current_head\n        \n        m_id = machines[j][k]\n        if m_id not in mach_ops:\n            mach_ops[m_id] = []\n        mach_ops[m_id].append(op)\n        \n        current_head += times[j][k]\n    \n    # Backward pass for tails\n    current_tail = 0\n    for k in range(n_machines - 1, -1, -1):\n        op = (j, k)\n        op_tails[op] = current_tail\n        current_tail += times[j][k]\n\n# 2. Identify the Critical Subset S* for each machine\n# S* is the subset of ops maximizing the 1-machine bound: min_r + sum_p + min_q\ncritical_subsets = {} # m_id -> {'ops': set, 'min_h': val, 'min_t': val}\n\nfor m_id, ops in mach_ops.items():\n    best_bound = -1\n    best_subset = []\n    best_min_h = 0\n    best_min_t = 0\n    \n    # Brute-force all pairs (u, v) to define the tightest window [r_u ... q_v]\n    # This is O(N_ops_on_machine^3), typically small per machine\n    for u in ops:\n        r_u = op_heads[u]\n        for v in ops:\n            q_v = op_tails[v]\n            \n            # Form candidate subset: all k with head >= r_u and tail >= q_v\n            candidate_subset = [k for k in ops if op_heads[k] >= r_u and op_tails[k] >= q_v]\n            \n            if not candidate_subset: continue\n            \n            p_sum = sum(times[k[0]][k[1]] for k in candidate_subset)\n            bound = r_u + p_sum + q_v\n            \n            if bound > best_bound:\n                best_bound = bound\n                best_subset = candidate_subset\n                best_min_h = r_u\n                best_min_t = q_v\n    \n    # Store the critical subset data\n    critical_subsets[m_id] = {\n        'ops': set(best_subset),\n        'min_h': best_min_h,\n        'min_t': best_min_t\n    }\n\n# 3. Define the Subset-Restricted Displacement Cuts\nmodel.SubsetDispDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef subset_displacement_rule(m, j, k, direction):\n    u = (j, k)\n    m_id = machines[j][k]\n    c_data = critical_subsets.get(m_id)\n    \n    # Only apply cut if the machine has ops and u is part of the critical subset\n    if not c_data or u not in c_data['ops']:\n        return pyo.Constraint.Skip\n    \n    subset = c_data['ops']\n    min_h = c_data['min_h']\n    min_t = c_data['min_t']\n    \n    work_load = 0\n    \n    if direction == 'fwd':\n        # Forward Cut: S_u >= min_head(S*) + sum_{v in S*, v->u} p_v\n        for (j2, k2) in subset:\n            if (j2, k2) == u: continue\n            \n            # If (j2, k2) precedes u\n            if (j2, k2) < u: \n                # Pair in set is (j2, k2, j, k) -> y=1 means v->u\n                work_load += m.p[j2, k2] * m.y[j2, k2, j, k]\n            else:\n                # Pair in set is (j, k, j2, k2) -> y=0 means v->u\n                work_load += m.p[j2, k2] * (1 - m.y[j, k, j2, k2])\n        \n        return m.S[j, k] >= min_h + work_load\n\n    else:\n        # Backward Cut: Cmax >= S_u + p_u + sum_{v in S*, u->v} p_v + min_tail(S*)\n        for (j2, k2) in subset:\n            if (j2, k2) == u: continue\n            \n            # If u precedes (j2, k2)\n            if u < (j2, k2):\n                # Pair is (u, v) -> y=1 means u->v\n                work_load += m.p[j2, k2] * m.y[j, k, j2, k2]\n            else:\n                # Pair is (v, u) -> y=0 means u->v\n                work_load += m.p[j2, k2] * (1 - m.y[j2, k2, j, k])\n                \n        return m.Cmax >= m.S[j, k] + m.p[j, k] + work_load + min_t\n\nmodel.SubsetRestrictedDisplacement = pyo.Constraint(model.J, model.K, model.SubsetDispDirs, rule=subset_displacement_rule)",
                        "idea": "We construct **Subset-Restricted Displacement Cuts**, a high-strength hybrid of Parent 1 and Parent 2. By pre-calculating the **Critical Subset** $S^*$ that maximizes the single-machine bound (Parent 2) for each machine, we generate displacement cuts (Parent 1) exclusively for operations within $S^*$. Because $S^*$ represents the machine's tightest bottleneck window, its members share high Release Times (Heads) and Tail Times. This allows us to lift the cuts using $\\min_{v \\in S^*} \\text{Head}_v$ and $\\min_{v \\in S^*} \\text{Tail}_v$ as base offsetsvalues strictly tighter than the global machine minimums used in Parent 1. This creates a focused, sharper relaxation for the most contended operations."
                    },
                    "fitness": 11.816707988374395,
                    "solver_reports": [
                        {
                            "total_time": 7.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 21422,
                            "explored_time": 7.19,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 22641,
                            "explored_time": 7.24,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 8.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 32714,
                            "explored_time": 8.38,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 6.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 21735,
                            "explored_time": 6.47,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 33818,
                            "explored_time": 8.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.4306,
                            "total_time": 8.04,
                            "explored_nodes": 87,
                            "simplex_iterations": 98859,
                            "explored_time": 8.03,
                            "work_units": 10.26
                        },
                        {
                            "total_time": 5.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 22629,
                            "explored_time": 5.37,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 22985,
                            "explored_time": 6.97,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "af0773df-70ec-449e-8e27-9c31b5484f21",
                        "3c0fcf4e-0084-4f27-9101-ae6780ff5a1f"
                    ]
                },
                {
                    "id": "e769c71a-be7c-4d3c-80ea-06118adb74c6",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_bottleneck_displacement_cuts(m):\n        # 1. Dynamic calculation of Heads (r) and Tails (q)\n        # These represent the earliest start and minimum time after completion for each op.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        # 3. Identify Bottleneck via Carlier Bound & Lift Cmax (Parent 1 Strength)\n        best_lb = -1\n        bottleneck_mid = None\n        \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Prepare data for 1-machine bound check: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Brute-force tightest interval [r, ... , q] (Carlier Bound logic)\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            for r_val in rs:\n                for q_val in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r_val and d[2] >= q_val)\n                    if p_sum > 0:\n                        bound = r_val + p_sum + q_val\n                        if bound > local_max:\n                            local_max = bound\n            \n            if local_max > best_lb:\n                best_lb = local_max\n                bottleneck_mid = mid\n    \n        # Enforce the strongest global lower bound found\n        if best_lb > 0:\n            m.hybrid_cuts.add(m.Cmax >= best_lb)\n    \n        # 4. Apply Bi-Directional Displacement Cuts on Bottleneck Machine Only (Hybrid Logic)\n        # Uses Parent 2's summation structure but localized to the bottleneck for tightness.\n        if bottleneck_mid is not None:\n            ops = mach_ops[bottleneck_mid]\n            \n            # Compute valid bounds for the displacement logic\n            # r_min: The earliest any op on this machine can start\n            # q_min: The minimum tail any op on this machine must respect\n            min_r = min(heads[op] for op in ops)\n            min_q = min(tails[op] for op in ops)\n    \n            for u in ops:\n                # Build expressions for workload of Predecessors and Successors\n                pred_work_expr = 0\n                succ_work_expr = 0\n                \n                for v in ops:\n                    if u == v: continue\n                    \n                    # Access binary variable y for pair {u, v}\n                    # m.Pairs is indexed by (j1, k1, j2, k2) where tuple1 < tuple2\n                    if u < v:\n                        # Variable is y[u, v]. \n                        # y=1 => u->v (v is successor). y=0 => v->u (v is predecessor).\n                        y_uv = m.y[u[0], u[1], v[0], v[1]]\n                        succ_work_expr += m.p[v] * y_uv\n                        pred_work_expr += m.p[v] * (1 - y_uv)\n                    else:\n                        # Variable is y[v, u].\n                        # y=1 => v->u (v is predecessor). y=0 => u->v (v is successor).\n                        y_vu = m.y[v[0], v[1], u[0], u[1]]\n                        succ_work_expr += m.p[v] * (1 - y_vu)\n                        pred_work_expr += m.p[v] * y_vu\n                \n                # Forward Cut: Start time pushed by all predecessors\n                # S[u] >= Machine_Earliest_Start + Sum(p[v] * IsPred[v])\n                m.hybrid_cuts.add(m.S[u] >= min_r + pred_work_expr)\n                \n                # Backward Cut: Cmax pushed by completion + all successors + Machine_Min_Tail\n                # Cmax >= S[u] + p[u] + Sum(p[v] * IsSucc[v]) + Min_Tail\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_expr + min_q)\n    \n    apply_bottleneck_displacement_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_bottleneck_displacement_cuts(m):\n    # 1. Dynamic calculation of Heads (r) and Tails (q)\n    # These represent the earliest start and minimum time after completion for each op.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    # 3. Identify Bottleneck via Carlier Bound & Lift Cmax (Parent 1 Strength)\n    best_lb = -1\n    bottleneck_mid = None\n    \n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Prepare data for 1-machine bound check: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Brute-force tightest interval [r, ... , q] (Carlier Bound logic)\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        for r_val in rs:\n            for q_val in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r_val and d[2] >= q_val)\n                if p_sum > 0:\n                    bound = r_val + p_sum + q_val\n                    if bound > local_max:\n                        local_max = bound\n        \n        if local_max > best_lb:\n            best_lb = local_max\n            bottleneck_mid = mid\n\n    # Enforce the strongest global lower bound found\n    if best_lb > 0:\n        m.hybrid_cuts.add(m.Cmax >= best_lb)\n\n    # 4. Apply Bi-Directional Displacement Cuts on Bottleneck Machine Only (Hybrid Logic)\n    # Uses Parent 2's summation structure but localized to the bottleneck for tightness.\n    if bottleneck_mid is not None:\n        ops = mach_ops[bottleneck_mid]\n        \n        # Compute valid bounds for the displacement logic\n        # r_min: The earliest any op on this machine can start\n        # q_min: The minimum tail any op on this machine must respect\n        min_r = min(heads[op] for op in ops)\n        min_q = min(tails[op] for op in ops)\n\n        for u in ops:\n            # Build expressions for workload of Predecessors and Successors\n            pred_work_expr = 0\n            succ_work_expr = 0\n            \n            for v in ops:\n                if u == v: continue\n                \n                # Access binary variable y for pair {u, v}\n                # m.Pairs is indexed by (j1, k1, j2, k2) where tuple1 < tuple2\n                if u < v:\n                    # Variable is y[u, v]. \n                    # y=1 => u->v (v is successor). y=0 => v->u (v is predecessor).\n                    y_uv = m.y[u[0], u[1], v[0], v[1]]\n                    succ_work_expr += m.p[v] * y_uv\n                    pred_work_expr += m.p[v] * (1 - y_uv)\n                else:\n                    # Variable is y[v, u].\n                    # y=1 => v->u (v is predecessor). y=0 => u->v (v is successor).\n                    y_vu = m.y[v[0], v[1], u[0], u[1]]\n                    succ_work_expr += m.p[v] * (1 - y_vu)\n                    pred_work_expr += m.p[v] * y_vu\n            \n            # Forward Cut: Start time pushed by all predecessors\n            # S[u] >= Machine_Earliest_Start + Sum(p[v] * IsPred[v])\n            m.hybrid_cuts.add(m.S[u] >= min_r + pred_work_expr)\n            \n            # Backward Cut: Cmax pushed by completion + all successors + Machine_Min_Tail\n            # Cmax >= S[u] + p[u] + Sum(p[v] * IsSucc[v]) + Min_Tail\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_expr + min_q)\n\napply_bottleneck_displacement_cuts(model)",
                        "idea": "We combine **Carlier Bound Lifting** (Parent 1) with **Bottleneck Displacement Cuts** (an enhanced Parent 2). First, we calculate static heads and tails to impose the tightest possible 1-machine lower bound on `Cmax` (Carlier Bound) and identify the bottleneck machine. Second, restricting our focus to this bottleneck machine, we apply bi-directional displacement cuts. These cuts enforce that an operation's start time must account for the workload of all dynamically determined predecessors (relative to the machine's earliest availability), and the global makespan must account for the operation's completion plus all successors and the machine's minimum tail. This hybrid strengthens the relaxation specifically on the critical resource."
                    },
                    "fitness": 15.699110524472708,
                    "solver_reports": [
                        {
                            "total_time": 7.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 15514,
                            "explored_time": 7.65,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 20098,
                            "explored_time": 8.15,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 38820,
                            "explored_time": 8.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.9658,
                            "total_time": 11.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 46078,
                            "explored_time": 11.26,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.3388,
                            "total_time": 7.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 16097,
                            "explored_time": 7.42,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.0086,
                            "total_time": 12.24,
                            "explored_nodes": 143,
                            "simplex_iterations": 73759,
                            "explored_time": 12.24,
                            "work_units": 11.75
                        },
                        {
                            "gap": 39.0504,
                            "total_time": 10.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 34940,
                            "explored_time": 10.63,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 23359,
                            "explored_time": 9.48,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "bda49ecf-46fd-4b71-87d9-86d650cbacd5"
                    ]
                },
                {
                    "id": "a6fac450-2f9d-46e8-a1c3-a66132bb15e8",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Complementary Constraint: Intra-Machine Triangle Transitivity Cuts\n    # ----------------------------------------------------------------\n    \n    # 1. Group operations by machine and sort them to establish a canonical index order.\n    # This allows us to systematically identify triplets (i, j, k) for transitivity enforcement.\n    mach_ops_sorted = {m_id: [] for m_id in range(n_machines)}\n    for j_idx in range(n_jobs):\n        for k_idx in range(n_machines):\n            m_id = machines[j_idx][k_idx]\n            mach_ops_sorted[m_id].append((j_idx, k_idx))\n    \n    for m_id in range(n_machines):\n        mach_ops_sorted[m_id].sort()  # Sorts tuples lexicographically (job, op_index)\n    \n    # 2. Use a ConstraintList to add valid inequalities for all triplets\n    model.TransitivityCuts = pyo.ConstraintList()\n    \n    for m_id in range(n_machines):\n        ops = mach_ops_sorted[m_id]\n        n_ops_m = len(ops)\n        \n        # Generate cuts for all triplets (i, j, k) on the same machine\n        # This enforces the convex hull of the linear ordering polytope on the binary variables\n        for i in range(n_ops_m):\n            for j in range(i + 1, n_ops_m):\n                for k in range(j + 1, n_ops_m):\n                    op_i = ops[i]\n                    op_j = ops[j]\n                    op_k = ops[k]\n                    \n                    # Access binary sequencing variables y. \n                    # Note: model.Pairs keys are sorted (u, v) with u < v.\n                    # Since ops list is sorted, op_i < op_j < op_k holds.\n                    y_ij = model.y[op_i + op_j]\n                    y_jk = model.y[op_j + op_k]\n                    y_ik = model.y[op_i + op_k]\n                    \n                    # Cut 1: Forward Transitivity (Triangle Inequality)\n                    # If i -> j (y_ij=1) and j -> k (y_jk=1), then i -> k (y_ik=1) must hold.\n                    # Removes fractional cycle: i -> j -> k -> i\n                    model.TransitivityCuts.add(y_ij + y_jk - y_ik <= 1)\n                    \n                    # Cut 2: Backward Transitivity / Cycle Elimination\n                    # Prevents the cycle i <- j <- k <- i (which corresponds to y_ij=0, y_jk=0, y_ik=1).\n                    # Effectively: y_ik <= y_ij + y_jk\n                    model.TransitivityCuts.add(y_ik - y_ij - y_jk <= 0)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Complementary Constraint: Intra-Machine Triangle Transitivity Cuts\n# ----------------------------------------------------------------\n\n# 1. Group operations by machine and sort them to establish a canonical index order.\n# This allows us to systematically identify triplets (i, j, k) for transitivity enforcement.\nmach_ops_sorted = {m_id: [] for m_id in range(n_machines)}\nfor j_idx in range(n_jobs):\n    for k_idx in range(n_machines):\n        m_id = machines[j_idx][k_idx]\n        mach_ops_sorted[m_id].append((j_idx, k_idx))\n\nfor m_id in range(n_machines):\n    mach_ops_sorted[m_id].sort()  # Sorts tuples lexicographically (job, op_index)\n\n# 2. Use a ConstraintList to add valid inequalities for all triplets\nmodel.TransitivityCuts = pyo.ConstraintList()\n\nfor m_id in range(n_machines):\n    ops = mach_ops_sorted[m_id]\n    n_ops_m = len(ops)\n    \n    # Generate cuts for all triplets (i, j, k) on the same machine\n    # This enforces the convex hull of the linear ordering polytope on the binary variables\n    for i in range(n_ops_m):\n        for j in range(i + 1, n_ops_m):\n            for k in range(j + 1, n_ops_m):\n                op_i = ops[i]\n                op_j = ops[j]\n                op_k = ops[k]\n                \n                # Access binary sequencing variables y. \n                # Note: model.Pairs keys are sorted (u, v) with u < v.\n                # Since ops list is sorted, op_i < op_j < op_k holds.\n                y_ij = model.y[op_i + op_j]\n                y_jk = model.y[op_j + op_k]\n                y_ik = model.y[op_i + op_k]\n                \n                # Cut 1: Forward Transitivity (Triangle Inequality)\n                # If i -> j (y_ij=1) and j -> k (y_jk=1), then i -> k (y_ik=1) must hold.\n                # Removes fractional cycle: i -> j -> k -> i\n                model.TransitivityCuts.add(y_ij + y_jk - y_ik <= 1)\n                \n                # Cut 2: Backward Transitivity / Cycle Elimination\n                # Prevents the cycle i <- j <- k <- i (which corresponds to y_ij=0, y_jk=0, y_ik=1).\n                # Effectively: y_ik <= y_ij + y_jk\n                model.TransitivityCuts.add(y_ik - y_ij - y_jk <= 0)",
                        "idea": "We introduce **Intra-Machine Triangle Transitivity Cuts**, a logical sequencing constraint that complements the metric-based bounds of the parents. While Parent 1 and 2 focus on lifting continuous start times (S_u) and makespan (Cmax) based on accumulated workloads, this cut targets the **binary sequencing polytope** (y) directly. By enforcing strict triangle inequalities (y_ij + y_jk - y_ik <= 1 and y_ik <= y_ij + y_jk) for all operation triplets on a machine, we eliminate fractional cycles (e.g., i -> j -> k -> i) that often weaken the linear relaxation. This creates a **synergistic effect**: the Transitivity Cuts ensure the sequencing logic is valid, which in turn forces the Parents' workload-displacement cuts to activate more accurately and aggressively, removing schedules with underestimated delays due to 'impossible' cyclic sequences."
                    },
                    "fitness": 9.743195991950603,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 25305,
                            "explored_time": 11.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 12.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 30218,
                            "explored_time": 11.76,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 10.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.35,
                            "work_units": 10.16
                        },
                        {
                            "gap": 94.8761,
                            "total_time": 7.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 30786,
                            "explored_time": 7.49,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 10.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.51,
                            "work_units": 10.22
                        },
                        {
                            "gap": 37.7282,
                            "total_time": 14.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 25737,
                            "explored_time": 14.6,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.713,
                            "total_time": 7.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 28592,
                            "explored_time": 7.66,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9893,
                            "total_time": 11.68,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 11.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "bda49ecf-46fd-4b71-87d9-86d650cbacd5",
                        "af0773df-70ec-449e-8e27-9c31b5484f21"
                    ]
                },
                {
                    "id": "8edbe369-8d41-4790-92f6-d52724b76349",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Lifted Constraint: Head-Tail Symmetric Displacement Cuts\n    # ----------------------------------------------------------------\n    \n    # 1. Precompute Static Heads (r_u) and Tails (q_u)\n    # r_u: Earliest start time of u based on job precedence\n    # q_u: Minimum time from completion of u to job completion\n    op_heads = {}\n    op_tails = {}\n    mach_ops = {m: [] for m in range(n_machines)}\n    \n    for j in range(n_jobs):\n        # Forward pass for heads\n        current_head = 0\n        for k in range(n_machines):\n            u = (j, k)\n            m_id = machines[j][k]\n            op_heads[u] = current_head\n            mach_ops[m_id].append(u)\n            current_head += times[j][k]\n        \n        # Backward pass for tails\n        current_tail = 0\n        for k in range(n_machines - 1, -1, -1):\n            u = (j, k)\n            op_tails[u] = current_tail\n            current_tail += times[j][k]\n    \n    # 2. Compute Machine-level Bounds\n    # R_m: Global minimum head on machine m\n    # Q_m: Global minimum tail on machine m\n    mach_min_head = {}\n    mach_min_tail = {}\n    for m in range(n_machines):\n        if mach_ops[m]:\n            mach_min_head[m] = min(op_heads[u] for u in mach_ops[m])\n            mach_min_tail[m] = min(op_tails[u] for u in mach_ops[m])\n        else:\n            mach_min_head[m] = 0\n            mach_min_tail[m] = 0\n    \n    model.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n    \n    def lifted_bidir_rule(m, j, k, c_type):\n        u = (j, k)\n        m_id = machines[j][k]\n        relevant = mach_ops[m_id]\n        \n        # 'bwd': Makespan Lower Bound (Tail Lifting)\n        # Cmax >= S_u + p_u + (Work of Successors) + Min_Tail_of_Machine\n        if c_type == 'bwd':\n            succ_work = 0\n            for v in relevant:\n                if v == u: continue\n                # Logic: If u -> v, v is successor. Add p_v.\n                # v is identified by tuple (j2, k2)\n                if u < v:\n                    # pair is (u, v), y[u,v]=1 => u->v\n                    succ_work += m.p[v] * m.y[u + v]\n                else:\n                    # pair is (v, u), y[v,u]=0 => u->v\n                    succ_work += m.p[v] * (1 - m.y[v + u])\n            \n            # Lifting: The schedule on machine m must end. \n            # The last operation w has C_w + q_w <= Cmax.\n            # Since q_w >= Q_m, we add Q_m to the displacement bound.\n            return m.Cmax >= m.S[u] + m.p[u] + succ_work + mach_min_tail[m_id]\n    \n        # 'fwd': Start Time Lower Bound (Head Lifting)\n        # S_u >= Min_Head_of_Machine + (Work of Predecessors)\n        else:\n            pred_work = 0\n            for v in relevant:\n                if v == u: continue\n                # Logic: If v -> u, v is predecessor. Add p_v.\n                if v < u:\n                    # pair is (v, u), y[v,u]=1 => v->u\n                    pred_work += m.p[v] * m.y[v + u]\n                else:\n                    # pair is (u, v), y[u,v]=0 => v->u\n                    pred_work += m.p[v] * (1 - m.y[u + v])\n            \n            # Base: The first operation w on machine m starts >= r_w >= R_m.\n            return m.S[u] >= mach_min_head[m_id] + pred_work\n    \n    model.LiftedBiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=lifted_bidir_rule)\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Lifted Constraint: Head-Tail Symmetric Displacement Cuts\n# ----------------------------------------------------------------\n\n# 1. Precompute Static Heads (r_u) and Tails (q_u)\n# r_u: Earliest start time of u based on job precedence\n# q_u: Minimum time from completion of u to job completion\nop_heads = {}\nop_tails = {}\nmach_ops = {m: [] for m in range(n_machines)}\n\nfor j in range(n_jobs):\n    # Forward pass for heads\n    current_head = 0\n    for k in range(n_machines):\n        u = (j, k)\n        m_id = machines[j][k]\n        op_heads[u] = current_head\n        mach_ops[m_id].append(u)\n        current_head += times[j][k]\n    \n    # Backward pass for tails\n    current_tail = 0\n    for k in range(n_machines - 1, -1, -1):\n        u = (j, k)\n        op_tails[u] = current_tail\n        current_tail += times[j][k]\n\n# 2. Compute Machine-level Bounds\n# R_m: Global minimum head on machine m\n# Q_m: Global minimum tail on machine m\nmach_min_head = {}\nmach_min_tail = {}\nfor m in range(n_machines):\n    if mach_ops[m]:\n        mach_min_head[m] = min(op_heads[u] for u in mach_ops[m])\n        mach_min_tail[m] = min(op_tails[u] for u in mach_ops[m])\n    else:\n        mach_min_head[m] = 0\n        mach_min_tail[m] = 0\n\nmodel.CutDirs = pyo.Set(initialize=['fwd', 'bwd'])\n\ndef lifted_bidir_rule(m, j, k, c_type):\n    u = (j, k)\n    m_id = machines[j][k]\n    relevant = mach_ops[m_id]\n    \n    # 'bwd': Makespan Lower Bound (Tail Lifting)\n    # Cmax >= S_u + p_u + (Work of Successors) + Min_Tail_of_Machine\n    if c_type == 'bwd':\n        succ_work = 0\n        for v in relevant:\n            if v == u: continue\n            # Logic: If u -> v, v is successor. Add p_v.\n            # v is identified by tuple (j2, k2)\n            if u < v:\n                # pair is (u, v), y[u,v]=1 => u->v\n                succ_work += m.p[v] * m.y[u + v]\n            else:\n                # pair is (v, u), y[v,u]=0 => u->v\n                succ_work += m.p[v] * (1 - m.y[v + u])\n        \n        # Lifting: The schedule on machine m must end. \n        # The last operation w has C_w + q_w <= Cmax.\n        # Since q_w >= Q_m, we add Q_m to the displacement bound.\n        return m.Cmax >= m.S[u] + m.p[u] + succ_work + mach_min_tail[m_id]\n\n    # 'fwd': Start Time Lower Bound (Head Lifting)\n    # S_u >= Min_Head_of_Machine + (Work of Predecessors)\n    else:\n        pred_work = 0\n        for v in relevant:\n            if v == u: continue\n            # Logic: If v -> u, v is predecessor. Add p_v.\n            if v < u:\n                # pair is (v, u), y[v,u]=1 => v->u\n                pred_work += m.p[v] * m.y[v + u]\n            else:\n                # pair is (u, v), y[u,v]=0 => v->u\n                pred_work += m.p[v] * (1 - m.y[u + v])\n        \n        # Base: The first operation w on machine m starts >= r_w >= R_m.\n        return m.S[u] >= mach_min_head[m_id] + pred_work\n\nmodel.LiftedBiDirectionalCuts = pyo.Constraint(model.J, model.K, model.CutDirs, rule=lifted_bidir_rule)",
                        "idea": "We strengthen the Bi-Directional Machine Displacement Cuts by incorporating static **job tails** (post-processing times) into the makespan bound. In the original 'backward' cut ($C_{max} \\ge C_u + \\text{successors}$), the bound ignores that the machine sequence must eventually finish a job with a specific tail. By adding $Q_m = \\min_{v \\in M} q_v$ (the minimum tail of any operation on the machine) to the RHS, we derive a tighter valid inequality: $C_{max} \\ge S_u + p_u + \\sum p_{succ} + Q_m$. This holds because the last scheduled operation $w$ satisfies $C_{max} \\ge C_w + q_w \\ge C_w + Q_m$. This creates a symmetric bounding scheme: the 'forward' cut lifts the start time using the machine's minimum static head ($R_m$), and the 'backward' cut lifts the makespan using the machine's minimum static tail ($Q_m$)."
                    },
                    "fitness": 12.567806103438688,
                    "solver_reports": [
                        {
                            "total_time": 6.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 21834,
                            "explored_time": 6.8,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 23099,
                            "explored_time": 6.86,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.47,
                            "explored_nodes": 1,
                            "simplex_iterations": 32781,
                            "explored_time": 7.41,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 21405,
                            "explored_time": 6.51,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.23,
                            "explored_nodes": 1,
                            "simplex_iterations": 33955,
                            "explored_time": 8.17,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.4015,
                            "total_time": 8.89,
                            "explored_nodes": 30,
                            "simplex_iterations": 47063,
                            "explored_time": 8.89,
                            "work_units": 10.11
                        },
                        {
                            "total_time": 5.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 18017,
                            "explored_time": 5.61,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.71,
                            "explored_nodes": 1,
                            "simplex_iterations": 23197,
                            "explored_time": 6.67,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "bda49ecf-46fd-4b71-87d9-86d650cbacd5"
                    ]
                },
                {
                    "id": "82d355c8-3e8f-4246-aaff-fe324cf13f72",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # 1. Compute tails (remaining processing time in job) for the 'Machine Tail' logic\n    #    This logic is self-contained to ensure validity.\n    tail_data = {}\n    for j in range(n_jobs):\n        acc = 0\n        for k in range(n_machines - 1, -1, -1):\n            tail_data[j, k] = acc\n            acc += times[j][k]\n    \n    # 2. Group operations by machine to iterate over potential successors\n    mach_groups = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in mach_groups:\n                mach_groups[m_id] = []\n            mach_groups[m_id].append((j, k))\n    \n    def dynamic_workload_rule(m, j, k):\n        # This cut links Start time (S), Sequence (y), and Makespan (Cmax).\n        # For op i=(j,k), Cmax must be >= S_i + p_i + (Workload of all ops strictly after i) + MinTail.\n        \n        m_id = machines[j][k]\n        siblings = mach_groups[m_id]\n        \n        # Conservative bound on remaining job-time after the machine clears\n        min_machine_tail = min(tail_data[u[0], u[1]] for u in siblings)\n        \n        workload_after_i = 0\n        \n        for (j_other, k_other) in siblings:\n            if (j_other, k_other) == (j, k):\n                continue\n            \n            # Identify the binary variable y for the pair {i, other}.\n            # y is defined for lexicographically sorted pairs (u, v) with u < v.\n            # y[u,v] = 1 implies u -> v.\n            \n            if (j, k) < (j_other, k_other):\n                # Pair is (i, other). Key is (j, k, j_other, k_other).\n                # We want condition: i -> other. This corresponds to y == 1.\n                workload_after_i += m.p[j_other, k_other] * m.y[j, k, j_other, k_other]\n            else:\n                # Pair is (other, i). Key is (j_other, k_other, j, k).\n                # We want condition: i -> other. This implies NOT (other -> i).\n                # y == 1 implies other -> i. So we need (1 - y).\n                workload_after_i += m.p[j_other, k_other] * (1 - m.y[j_other, k_other, j, k])\n                \n        # The Cut: The makespan is pushed by the completion of i plus all its machine successors\n        return m.Cmax >= m.S[j, k] + m.p[j, k] + workload_after_i + min_machine_tail\n    \n    model.dynamic_workload_cuts = pyo.Constraint(model.O, rule=dynamic_workload_rule)\n\n    return model\n",
                        "added_cut": "# 1. Compute tails (remaining processing time in job) for the 'Machine Tail' logic\n#    This logic is self-contained to ensure validity.\ntail_data = {}\nfor j in range(n_jobs):\n    acc = 0\n    for k in range(n_machines - 1, -1, -1):\n        tail_data[j, k] = acc\n        acc += times[j][k]\n\n# 2. Group operations by machine to iterate over potential successors\nmach_groups = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in mach_groups:\n            mach_groups[m_id] = []\n        mach_groups[m_id].append((j, k))\n\ndef dynamic_workload_rule(m, j, k):\n    # This cut links Start time (S), Sequence (y), and Makespan (Cmax).\n    # For op i=(j,k), Cmax must be >= S_i + p_i + (Workload of all ops strictly after i) + MinTail.\n    \n    m_id = machines[j][k]\n    siblings = mach_groups[m_id]\n    \n    # Conservative bound on remaining job-time after the machine clears\n    min_machine_tail = min(tail_data[u[0], u[1]] for u in siblings)\n    \n    workload_after_i = 0\n    \n    for (j_other, k_other) in siblings:\n        if (j_other, k_other) == (j, k):\n            continue\n        \n        # Identify the binary variable y for the pair {i, other}.\n        # y is defined for lexicographically sorted pairs (u, v) with u < v.\n        # y[u,v] = 1 implies u -> v.\n        \n        if (j, k) < (j_other, k_other):\n            # Pair is (i, other). Key is (j, k, j_other, k_other).\n            # We want condition: i -> other. This corresponds to y == 1.\n            workload_after_i += m.p[j_other, k_other] * m.y[j, k, j_other, k_other]\n        else:\n            # Pair is (other, i). Key is (j_other, k_other, j, k).\n            # We want condition: i -> other. This implies NOT (other -> i).\n            # y == 1 implies other -> i. So we need (1 - y).\n            workload_after_i += m.p[j_other, k_other] * (1 - m.y[j_other, k_other, j, k])\n            \n    # The Cut: The makespan is pushed by the completion of i plus all its machine successors\n    return m.Cmax >= m.S[j, k] + m.p[j, k] + workload_after_i + min_machine_tail\n\nmodel.dynamic_workload_cuts = pyo.Constraint(model.O, rule=dynamic_workload_rule)",
                        "idea": "We propose **Dynamic Post-Operation Workload Cuts**, a structural mutation of the static bound. While the original cut applies a static pre-computed lower bound on $C_{max}$ using 1-machine windows, this formulation creates a dynamic 'slope' constraint for every operation $i$. It asserts that $C_{max}$ must be at least the start time of $i$, plus $p_i$, plus the sum of processing times of all operations $j$ decided to follow $i$ on the same machine (enforced via binary variables $y$), plus a conservative estimate of the remaining tail. This effectively couples the scheduling decision ($S_i$) and sequencing decisions ($y_{ij}$) to the objective, penalizing early execution of operations that are bottlenecks for the machine's subsequent workload."
                    },
                    "fitness": 10.656577393090332,
                    "solver_reports": [
                        {
                            "gap": 89.5772,
                            "total_time": 14.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 39467,
                            "explored_time": 14.76,
                            "work_units": 10.0
                        },
                        {
                            "gap": 93.9157,
                            "total_time": 10.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 41512,
                            "explored_time": 10.75,
                            "work_units": 10.0
                        },
                        {
                            "gap": 95.0959,
                            "total_time": 10.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 47946,
                            "explored_time": 10.92,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8229,
                            "total_time": 19.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 16205,
                            "explored_time": 19.5,
                            "work_units": 10.02
                        },
                        {
                            "gap": 95.4481,
                            "total_time": 11.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 48624,
                            "explored_time": 11.8,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.8204,
                            "total_time": 12.96,
                            "explored_nodes": 115,
                            "simplex_iterations": 66556,
                            "explored_time": 12.95,
                            "work_units": 12.37
                        },
                        {
                            "gap": 91.7498,
                            "total_time": 18.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 16114,
                            "explored_time": 18.38,
                            "work_units": 10.02
                        },
                        {
                            "gap": 94.1483,
                            "total_time": 10.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 50309,
                            "explored_time": 10.92,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "3c0fcf4e-0084-4f27-9101-ae6780ff5a1f"
                    ]
                },
                {
                    "id": "3931909d-ca7d-49f7-9927-22439f361136",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Organize operations by machine to identify triplets\n    m_ops_trans = {}\n    for j in range(n_jobs):\n        for k in range(n_machines):\n            m_id = machines[j][k]\n            if m_id not in m_ops_trans:\n                m_ops_trans[m_id] = []\n            m_ops_trans[m_id].append((j, k))\n    \n    def transitivity_cuts_rule(m):\n        # Generator for Disjunctive Transitivity (Triangle) Cuts\n        # Enforces logical consistency on the sequence variables y for all triplets on a machine.\n        # For ops u, v, w sorted by index: ensures u->v and v->w implies u->w, preventing cycles.\n        cuts = []\n        for m_id, ops in m_ops_trans.items():\n            # Sort ops to align with the strictly ordered pairs (j1, k1) < (j2, k2) in model.Pairs\n            s_ops = sorted(ops, key=lambda x: (x[0], x[1]))\n            N = len(s_ops)\n            \n            # Iterate over all unique triplets on the machine\n            for i in range(N):\n                for j in range(i + 1, N):\n                    for k in range(j + 1, N):\n                        u, v, w = s_ops[i], s_ops[j], s_ops[k]\n                        \n                        # Retrieve binary sequence variables\n                        # Keys in model.Pairs follow the sorted order u < v < w\n                        y_uv = m.y[u[0], u[1], v[0], v[1]]\n                        y_vw = m.y[v[0], v[1], w[0], w[1]]\n                        y_uw = m.y[u[0], u[1], w[0], w[1]]\n                        \n                        # Cut 1: Prohibit cycle u -> v -> w -> u\n                        # If u->v (y=1) and v->w (y=1), then u->w must be 1 (cannot be 0)\n                        # 1 + 1 - 0 <= 1 is False. Valid states satisfy <= 1.\n                        cuts.append(y_uv + y_vw - y_uw <= 1)\n                        \n                        # Cut 2: Prohibit cycle u -> w -> v -> u\n                        # If u->w (y=1) and w->v (y=0) and v->u (y=0)\n                        # 1 - 0 - 0 <= 0 is False.\n                        cuts.append(y_uw - y_vw - y_uv <= 0)\n        return cuts\n    \n    model.transitivity_cuts = pyo.ConstraintList()\n    for c in transitivity_cuts_rule(model):\n        model.transitivity_cuts.add(c)\n\n    return model\n",
                        "added_cut": "# Organize operations by machine to identify triplets\nm_ops_trans = {}\nfor j in range(n_jobs):\n    for k in range(n_machines):\n        m_id = machines[j][k]\n        if m_id not in m_ops_trans:\n            m_ops_trans[m_id] = []\n        m_ops_trans[m_id].append((j, k))\n\ndef transitivity_cuts_rule(m):\n    # Generator for Disjunctive Transitivity (Triangle) Cuts\n    # Enforces logical consistency on the sequence variables y for all triplets on a machine.\n    # For ops u, v, w sorted by index: ensures u->v and v->w implies u->w, preventing cycles.\n    cuts = []\n    for m_id, ops in m_ops_trans.items():\n        # Sort ops to align with the strictly ordered pairs (j1, k1) < (j2, k2) in model.Pairs\n        s_ops = sorted(ops, key=lambda x: (x[0], x[1]))\n        N = len(s_ops)\n        \n        # Iterate over all unique triplets on the machine\n        for i in range(N):\n            for j in range(i + 1, N):\n                for k in range(j + 1, N):\n                    u, v, w = s_ops[i], s_ops[j], s_ops[k]\n                    \n                    # Retrieve binary sequence variables\n                    # Keys in model.Pairs follow the sorted order u < v < w\n                    y_uv = m.y[u[0], u[1], v[0], v[1]]\n                    y_vw = m.y[v[0], v[1], w[0], w[1]]\n                    y_uw = m.y[u[0], u[1], w[0], w[1]]\n                    \n                    # Cut 1: Prohibit cycle u -> v -> w -> u\n                    # If u->v (y=1) and v->w (y=1), then u->w must be 1 (cannot be 0)\n                    # 1 + 1 - 0 <= 1 is False. Valid states satisfy <= 1.\n                    cuts.append(y_uv + y_vw - y_uw <= 1)\n                    \n                    # Cut 2: Prohibit cycle u -> w -> v -> u\n                    # If u->w (y=1) and w->v (y=0) and v->u (y=0)\n                    # 1 - 0 - 0 <= 0 is False.\n                    cuts.append(y_uw - y_vw - y_uv <= 0)\n    return cuts\n\nmodel.transitivity_cuts = pyo.ConstraintList()\nfor c in transitivity_cuts_rule(model):\n    model.transitivity_cuts.add(c)",
                        "idea": "We introduce **Disjunctive Transitivity Cuts**, a structural mutation distinct from the input's capacity-based bound. The standard disjunctive formulation links timing to sequencing ($M$-constraints) but loosely constrains the binary variables $y$ themselves, allowing fractional 'cycles' (e.g., $i \\to j \\to k \\to i$) in the LP relaxation. By explicitly enforcing the triangle inequalities ($y_{uv} + y_{vw} - y_{uw} \\le 1$) for all operation triplets on the same machine, we cut off these invalid fractional configurations, significantly tightening the sequencing polytope and improving the solver's branching efficiency."
                    },
                    "fitness": 9.580743099237264,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 11.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 22328,
                            "explored_time": 11.41,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 12.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 27884,
                            "explored_time": 11.85,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 11.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.52,
                            "work_units": 10.13
                        },
                        {
                            "gap": 94.8761,
                            "total_time": 7.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 28230,
                            "explored_time": 7.41,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 10.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.43,
                            "work_units": 10.19
                        },
                        {
                            "gap": 42.1573,
                            "total_time": 13.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 23840,
                            "explored_time": 12.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 94.713,
                            "total_time": 8.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 28404,
                            "explored_time": 7.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.9893,
                            "total_time": 11.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 22544,
                            "explored_time": 11.62,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "3c0fcf4e-0084-4f27-9101-ae6780ff5a1f"
                    ]
                }
            ],
            19.745839703599053
        ],
        [
            [
                {
                    "id": "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_lifted_bottleneck_cuts(m):\n        # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n        # to ensure self-contained execution.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Container for new constraints\n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        for mid, ops in mach_ops.items():\n            # Data: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Sort unique thresholds\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n            for r in rs:\n                for q in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            # Add cut: Cmax must be >= tightest 1-machine relaxation\n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n        # Only applied to the identified bottleneck machine to keep size manageable.\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to get the expression for \"u precedes v\"\n            # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n            def get_precedence_expr(u, v):\n                if u < v:\n                    # Variable exists as y[u, v]\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n            # We limit n_cuts to avoid memory explosion if the machine has many ops\n            cut_count = 0\n            limit = 100 \n            \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Base precedence var: i -> j\n                    y_ij = get_precedence_expr(i, j)\n                    \n                    # Identify intermediate node k\n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_precedence_expr(i, k)\n                        y_kj = get_precedence_expr(k, j)\n                        \n                        # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                        # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        # Logic: \n                        #   If y_ij=1 (i->j active):\n                        #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                        #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                        #      Else:\n                        #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                        #   If y_ij=0 (i->j inactive):\n                        #      RHS is large negative (Valid due to bigM)\n                        \n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count > limit: break\n                if cut_count > limit: break\n    \n    apply_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_lifted_bottleneck_cuts(m):\n    # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n    # to ensure self-contained execution.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Container for new constraints\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    for mid, ops in mach_ops.items():\n        # Data: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Sort unique thresholds\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n        for r in rs:\n            for q in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        # Add cut: Cmax must be >= tightest 1-machine relaxation\n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n    # Only applied to the identified bottleneck machine to keep size manageable.\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to get the expression for \"u precedes v\"\n        # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n        def get_precedence_expr(u, v):\n            if u < v:\n                # Variable exists as y[u, v]\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n        # We limit n_cuts to avoid memory explosion if the machine has many ops\n        cut_count = 0\n        limit = 100 \n        \n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Base precedence var: i -> j\n                y_ij = get_precedence_expr(i, j)\n                \n                # Identify intermediate node k\n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_precedence_expr(i, k)\n                    y_kj = get_precedence_expr(k, j)\n                    \n                    # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                    # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    # Logic: \n                    #   If y_ij=1 (i->j active):\n                    #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                    #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                    #      Else:\n                    #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                    #   If y_ij=0 (i->j inactive):\n                    #      RHS is large negative (Valid due to bigM)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count > limit: break\n            if cut_count > limit: break\n\napply_lifted_bottleneck_cuts(model)",
                        "idea": "We apply **Bottleneck-Focused Triangle Lifting**. First, we strengthen the global lower bound by computing the **Carlier Bound** for every machine; this effectively lifts the `Cmax` constraint by solving the 1-machine head-tail problem exactly. Second, we identify the bottleneck machine (the one generating the max Carlier bound) and apply **Triangle Precedence Cuts** to it. These cuts lift the pairwise disjunctive constraints $S_j \\ge S_i + p_i$ by incorporating intermediate operations $k$: if $i \\to k \\to j$, the delay must include $p_k$. This creates a tighter polyhedral approximation for the critical machine, pruning fractional solutions where precedence is intransitive."
                    },
                    "fitness": 19.745839703599053,
                    "solver_reports": [
                        {
                            "gap": 22.6009,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 34291,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3984,
                            "total_time": 12.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 35151,
                            "explored_time": 12.71,
                            "work_units": 10.28
                        },
                        {
                            "gap": 34.8922,
                            "total_time": 11.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 30987,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6984,
                            "total_time": 13.28,
                            "explored_nodes": 59,
                            "simplex_iterations": 45527,
                            "explored_time": 13.27,
                            "work_units": 10.17
                        },
                        {
                            "total_time": 11.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34484,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.2529,
                            "total_time": 10.35,
                            "explored_nodes": 1497,
                            "simplex_iterations": 87588,
                            "explored_time": 10.34,
                            "work_units": 10.88
                        },
                        {
                            "gap": 25.8837,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 49577,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 39685,
                            "explored_time": 10.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "953456bd-bd70-4803-ab54-4778ff8de5b6"
                    ]
                },
                {
                    "id": "bbb86382-1898-4cb0-a5cd-18a813585ec0",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_bi_directional_machine_cuts(m):\n        # 1. Precompute static Heads (earliest start) and Tails (post-processing)\n        #    based on job precedence structure.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.bi_dir_cuts = pyo.ConstraintList()\n        \n        # 3. Lift Global Cmax Lower Bound using static Carlier logic (Parent 2 Strength)\n        #    We find the tightest 1-machine bottleneck bound across all machines.\n        global_lb = 0\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Prepare data: (release_time, duration, delivery_time)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Brute-force the tightest interval [r, q] for the 1-machine relaxation\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            for r_val in rs:\n                for q_val in qs:\n                    # Sum p for all ops that fit strictly within the [r_val, ..., q_val] window\n                    p_sum = sum(d[1] for d in data if d[0] >= r_val and d[2] >= q_val)\n                    if p_sum > 0:\n                        bound = r_val + p_sum + q_val\n                        if bound > global_lb:\n                            global_lb = bound\n        \n        # Apply the strongest static bound globally\n        if global_lb > 0:\n            m.bi_dir_cuts.add(m.Cmax >= global_lb)\n    \n        # 4. Bi-Directional Displacement Cuts for ALL machines (Integrating Parent 1 & 2)\n        #    Instead of just the bottleneck (Parent 2) or just backward cuts (Parent 1),\n        #    we apply full forward/backward displacement logic to all resources.\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Machine-wide loose bounds\n            min_r = min(heads[op] for op in ops)\n            min_q = min(tails[op] for op in ops)\n            \n            for u in ops:\n                pred_workload = 0\n                succ_workload = 0\n                \n                for v in ops:\n                    if u == v: continue\n                    \n                    # Identify the binary variable y for pair {u, v}\n                    # m.Pairs is indexed by (j1, k1, j2, k2) where tuple1 < tuple2\n                    if u < v:\n                        # Variable is y[u, v]. \n                        # y=1 => u->v (v is successor). y=0 => v->u (v is predecessor).\n                        y_uv = m.y[u[0], u[1], v[0], v[1]]\n                        succ_workload += m.p[v] * y_uv\n                        pred_workload += m.p[v] * (1 - y_uv)\n                    else:\n                        # Variable is y[v, u].\n                        # y=1 => v->u (v is predecessor). y=0 => u->v (v is successor).\n                        y_vu = m.y[v[0], v[1], u[0], u[1]]\n                        pred_workload += m.p[v] * y_vu\n                        succ_workload += m.p[v] * (1 - y_vu)\n                \n                # Forward Displacement: \n                # Start time of u must account for machine's earliest start + all chosen predecessors\n                m.bi_dir_cuts.add(m.S[u] >= min_r + pred_workload)\n                \n                # Backward Displacement:\n                # Makespan must account for u's completion + all chosen successors + machine's min tail\n                m.bi_dir_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_workload + min_q)\n    \n    add_bi_directional_machine_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_bi_directional_machine_cuts(m):\n    # 1. Precompute static Heads (earliest start) and Tails (post-processing)\n    #    based on job precedence structure.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.bi_dir_cuts = pyo.ConstraintList()\n    \n    # 3. Lift Global Cmax Lower Bound using static Carlier logic (Parent 2 Strength)\n    #    We find the tightest 1-machine bottleneck bound across all machines.\n    global_lb = 0\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Prepare data: (release_time, duration, delivery_time)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Brute-force the tightest interval [r, q] for the 1-machine relaxation\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        for r_val in rs:\n            for q_val in qs:\n                # Sum p for all ops that fit strictly within the [r_val, ..., q_val] window\n                p_sum = sum(d[1] for d in data if d[0] >= r_val and d[2] >= q_val)\n                if p_sum > 0:\n                    bound = r_val + p_sum + q_val\n                    if bound > global_lb:\n                        global_lb = bound\n    \n    # Apply the strongest static bound globally\n    if global_lb > 0:\n        m.bi_dir_cuts.add(m.Cmax >= global_lb)\n\n    # 4. Bi-Directional Displacement Cuts for ALL machines (Integrating Parent 1 & 2)\n    #    Instead of just the bottleneck (Parent 2) or just backward cuts (Parent 1),\n    #    we apply full forward/backward displacement logic to all resources.\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Machine-wide loose bounds\n        min_r = min(heads[op] for op in ops)\n        min_q = min(tails[op] for op in ops)\n        \n        for u in ops:\n            pred_workload = 0\n            succ_workload = 0\n            \n            for v in ops:\n                if u == v: continue\n                \n                # Identify the binary variable y for pair {u, v}\n                # m.Pairs is indexed by (j1, k1, j2, k2) where tuple1 < tuple2\n                if u < v:\n                    # Variable is y[u, v]. \n                    # y=1 => u->v (v is successor). y=0 => v->u (v is predecessor).\n                    y_uv = m.y[u[0], u[1], v[0], v[1]]\n                    succ_workload += m.p[v] * y_uv\n                    pred_workload += m.p[v] * (1 - y_uv)\n                else:\n                    # Variable is y[v, u].\n                    # y=1 => v->u (v is predecessor). y=0 => u->v (v is successor).\n                    y_vu = m.y[v[0], v[1], u[0], u[1]]\n                    pred_workload += m.p[v] * y_vu\n                    succ_workload += m.p[v] * (1 - y_vu)\n            \n            # Forward Displacement: \n            # Start time of u must account for machine's earliest start + all chosen predecessors\n            m.bi_dir_cuts.add(m.S[u] >= min_r + pred_workload)\n            \n            # Backward Displacement:\n            # Makespan must account for u's completion + all chosen successors + machine's min tail\n            m.bi_dir_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_workload + min_q)\n\nadd_bi_directional_machine_cuts(model)",
                        "idea": "We implement **Bi-Directional Machine Displacement Cuts with Carlier Lifting**. This hybrid approach first computes the static Carlier 1-machine bound to lift the global `Cmax` lower bound (derived from Parent 2). It then applies bi-directional displacement constraints to *all* machines (generalizing Parent 2's bottleneck-only logic and Parent 1's global backward logic). For every operation, we enforce two dynamic bounds: (1) its start time must exceed the machine's earliest availability plus the workload of all dynamically scheduled predecessors, and (2) the global makespan must exceed the operation's completion plus the workload of all successors and the machine's minimum tail. This tightly couples the binary sequence variables ($y$) with continuous time variables ($S, C_{max}$) across the entire scheduling horizon."
                    },
                    "fitness": 13.92923576368574,
                    "solver_reports": [
                        {
                            "total_time": 6.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 21810,
                            "explored_time": 6.71,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 23138,
                            "explored_time": 6.97,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 32798,
                            "explored_time": 7.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 22004,
                            "explored_time": 6.02,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 34080,
                            "explored_time": 7.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.0149,
                            "total_time": 8.03,
                            "explored_nodes": 31,
                            "simplex_iterations": 53153,
                            "explored_time": 8.02,
                            "work_units": 10.31
                        },
                        {
                            "total_time": 5.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 17781,
                            "explored_time": 5.77,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 23334,
                            "explored_time": 6.58,
                            "work_units": 10.02
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "82d355c8-3e8f-4246-aaff-fe324cf13f72",
                        "e769c71a-be7c-4d3c-80ea-06118adb74c6"
                    ]
                },
                {
                    "id": "c3316d11-af29-49c7-880c-c581a429c71e",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # New Constraint: Cross-Machine Job Interaction Cuts\n    # ----------------------------------------------------------------\n    # This constraint detects \"crossing\" patterns between two jobs (j1, j2)\n    # across two adjacent machines in j1's route. It explicitly links\n    # sequencing decisions on Machine A and Machine B, which are usually\n    # decoupled in standard disjunctive formulations.\n    \n    model.InteractionCuts = pyo.ConstraintList()\n    \n    # 1. Precompute map for (job, machine) -> op_index\n    job_mach_map = {}\n    for j in model.J:\n        for k in model.K:\n            m_id = machines[j][k]\n            job_mach_map[(j, m_id)] = k\n    \n    # 2. Helper: Calculate processing time of j between two steps\n    def get_internal_work(j, k_start, k_end):\n        # Sum processing times strictly between k_start and k_end\n        if k_end <= k_start + 1:\n            return 0\n        return sum(times[j][k] for k in range(k_start + 1, k_end))\n    \n    # 3. Helper: Get expression for \"op_a precedes op_b\" (value 0 or 1)\n    def is_preceding(op_a, op_b):\n        # model.y[(j1,k1), (j2,k2)] is 1 if (j1,k1)->(j2,k2), defined for sorted pairs\n        if op_a < op_b:\n            return model.y[op_a[0], op_a[1], op_b[0], op_b[1]]\n        else:\n            # if op_a > op_b, the pair is (op_b, op_a). \n            # y[b,a]=1 => b->a. We want a->b, which is 1 - y[b,a].\n            return 1 - model.y[op_b[0], op_b[1], op_a[0], op_a[1]]\n    \n    # 4. Generate Cuts\n    # Iterate over every transition in Job j1: u1 (on mA) -> v1 (on mB)\n    for j1 in model.J:\n        for k1 in range(n_machines - 1):\n            u1 = (j1, k1)\n            v1 = (j1, k1 + 1)\n            mA = machines[j1][k1]\n            mB = machines[j1][k1 + 1]\n            \n            # Check against every other job j2\n            for j2 in model.J:\n                if j1 == j2: continue\n                \n                # If j2 also uses mA and mB in that order (mA ... mB)\n                if (j2, mA) in job_mach_map and (j2, mB) in job_mach_map:\n                    k2_A = job_mach_map[(j2, mA)]\n                    k2_B = job_mach_map[(j2, mB)]\n                    \n                    # Ensure j2 visits mA before mB\n                    if k2_A < k2_B:\n                        u2 = (j2, k2_A) # Op of j2 on mA\n                        v2 = (j2, k2_B) # Op of j2 on mB\n                        \n                        # CROSSING CONDITION:\n                        # If j1 precedes j2 on mA (u1 -> u2) \n                        # AND j2 precedes j1 on mB (v2 -> v1)\n                        # Then j1 \"wraps around\" the entirety of j2's activity between mA and mB.\n                        # The span S_v1 - S_u1 must cover p_u1 + p_u2 + j2_internal + p_v2.\n                        \n                        # Calculate the penalty (extra delay imposed by inserting j2)\n                        # Delay = Work of j2 on mA + Work of j2 intermediate + Work of j2 on mB\n                        penalty = times[j2][k2_A] + get_internal_work(j2, k2_A, k2_B) + times[j2][k2_B]\n                        \n                        # Boolean Logic: active if (prec_A=1 AND prec_B=1)\n                        # Expression: prec_A + prec_B - 1\n                        prec_A = is_preceding(u1, u2)\n                        prec_B = is_preceding(v2, v1)\n                        \n                        # Cut: S_v1 >= S_u1 + p_u1 + Penalty * (is_crossing)\n                        # This tightens the precedence S_v1 >= S_u1 + p_u1 dynamically.\n                        model.InteractionCuts.add(\n                            model.S[v1] >= model.S[u1] + model.p[u1] + \n                            penalty * (prec_A + prec_B - 1)\n                        )\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# New Constraint: Cross-Machine Job Interaction Cuts\n# ----------------------------------------------------------------\n# This constraint detects \"crossing\" patterns between two jobs (j1, j2)\n# across two adjacent machines in j1's route. It explicitly links\n# sequencing decisions on Machine A and Machine B, which are usually\n# decoupled in standard disjunctive formulations.\n\nmodel.InteractionCuts = pyo.ConstraintList()\n\n# 1. Precompute map for (job, machine) -> op_index\njob_mach_map = {}\nfor j in model.J:\n    for k in model.K:\n        m_id = machines[j][k]\n        job_mach_map[(j, m_id)] = k\n\n# 2. Helper: Calculate processing time of j between two steps\ndef get_internal_work(j, k_start, k_end):\n    # Sum processing times strictly between k_start and k_end\n    if k_end <= k_start + 1:\n        return 0\n    return sum(times[j][k] for k in range(k_start + 1, k_end))\n\n# 3. Helper: Get expression for \"op_a precedes op_b\" (value 0 or 1)\ndef is_preceding(op_a, op_b):\n    # model.y[(j1,k1), (j2,k2)] is 1 if (j1,k1)->(j2,k2), defined for sorted pairs\n    if op_a < op_b:\n        return model.y[op_a[0], op_a[1], op_b[0], op_b[1]]\n    else:\n        # if op_a > op_b, the pair is (op_b, op_a). \n        # y[b,a]=1 => b->a. We want a->b, which is 1 - y[b,a].\n        return 1 - model.y[op_b[0], op_b[1], op_a[0], op_a[1]]\n\n# 4. Generate Cuts\n# Iterate over every transition in Job j1: u1 (on mA) -> v1 (on mB)\nfor j1 in model.J:\n    for k1 in range(n_machines - 1):\n        u1 = (j1, k1)\n        v1 = (j1, k1 + 1)\n        mA = machines[j1][k1]\n        mB = machines[j1][k1 + 1]\n        \n        # Check against every other job j2\n        for j2 in model.J:\n            if j1 == j2: continue\n            \n            # If j2 also uses mA and mB in that order (mA ... mB)\n            if (j2, mA) in job_mach_map and (j2, mB) in job_mach_map:\n                k2_A = job_mach_map[(j2, mA)]\n                k2_B = job_mach_map[(j2, mB)]\n                \n                # Ensure j2 visits mA before mB\n                if k2_A < k2_B:\n                    u2 = (j2, k2_A) # Op of j2 on mA\n                    v2 = (j2, k2_B) # Op of j2 on mB\n                    \n                    # CROSSING CONDITION:\n                    # If j1 precedes j2 on mA (u1 -> u2) \n                    # AND j2 precedes j1 on mB (v2 -> v1)\n                    # Then j1 \"wraps around\" the entirety of j2's activity between mA and mB.\n                    # The span S_v1 - S_u1 must cover p_u1 + p_u2 + j2_internal + p_v2.\n                    \n                    # Calculate the penalty (extra delay imposed by inserting j2)\n                    # Delay = Work of j2 on mA + Work of j2 intermediate + Work of j2 on mB\n                    penalty = times[j2][k2_A] + get_internal_work(j2, k2_A, k2_B) + times[j2][k2_B]\n                    \n                    # Boolean Logic: active if (prec_A=1 AND prec_B=1)\n                    # Expression: prec_A + prec_B - 1\n                    prec_A = is_preceding(u1, u2)\n                    prec_B = is_preceding(v2, v1)\n                    \n                    # Cut: S_v1 >= S_u1 + p_u1 + Penalty * (is_crossing)\n                    # This tightens the precedence S_v1 >= S_u1 + p_u1 dynamically.\n                    model.InteractionCuts.add(\n                        model.S[v1] >= model.S[u1] + model.p[u1] + \n                        penalty * (prec_A + prec_B - 1)\n                    )",
                        "idea": "We introduce **Cross-Machine Job Interaction Cuts**. While both parents focus on *intra-machine* capacity (ordering operations on a single machine to lift start times), this offspring addresses *inter-machine* flow consistency. It identifies pairs of jobs that compete on adjacent processing stages (Machine A $\\to$ Machine B). If Job 1 precedes Job 2 on A but follows Job 2 on B, Job 1 essentially 'wraps around' Job 2. This cut explicitly lifts the start time of Job 1's second operation by the **entire duration** of Job 2's segment (processing on A + B + travel). This leverages the problem's job-shop routing structure to eliminate infeasible or inefficient 'crossed' schedules that single-machine cuts cannot detect."
                    },
                    "fitness": 8.174169496770423,
                    "solver_reports": [
                        {
                            "total_time": 7.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 27124,
                            "explored_time": 7.46,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 29956,
                            "explored_time": 7.22,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 35478,
                            "explored_time": 8.03,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 5.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 10795,
                            "explored_time": 5.95,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 32779,
                            "explored_time": 8.73,
                            "work_units": 10.0
                        },
                        {
                            "gap": 39.5654,
                            "total_time": 9.57,
                            "explored_nodes": 87,
                            "simplex_iterations": 86190,
                            "explored_time": 9.56,
                            "work_units": 11.17
                        },
                        {
                            "total_time": 6.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 12604,
                            "explored_time": 6.08,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 30905,
                            "explored_time": 7.45,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "1118323a-bd1c-481f-914b-b5e3b01b201f",
                        "8edbe369-8d41-4790-92f6-d52724b76349"
                    ]
                },
                {
                    "id": "00dfdfed-5771-4e8f-b23b-0ce2031a4b38",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_bottleneck_transitivity_cuts(m):\n        # 1. Precompute Heads and Tails for Carlier Bound calculations\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access precedence variables y(u->v) regardless of index order\n        # Returns expression for \"u precedes v\"\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.combined_cuts = pyo.ConstraintList()\n        \n        # 3. Apply Carlier Bounds (Global) & Identify Bottleneck Machine\n        bottleneck_mach = None\n        max_lb = -1\n        \n        for mid, ops in mach_ops.items():\n            # Data: (release r, process p, tail q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            carlier_lb = 0\n            # Exact Carlier Bound check over all subset intervals\n            for r in rs:\n                for q in qs:\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        val = r + p_sum + q\n                        if val > carlier_lb: carlier_lb = val\n            \n            # Add Global Lower Bound Cut\n            if carlier_lb > 0:\n                m.combined_cuts.add(m.Cmax >= carlier_lb)\n            \n            # Track max lower bound to identify the critical bottleneck\n            if carlier_lb > max_lb:\n                max_lb = carlier_lb\n                bottleneck_mach = mid\n    \n        # 4. Apply Synergistic Cuts on Bottleneck Machine Only\n        if bottleneck_mach is not None:\n            ops = sorted(mach_ops[bottleneck_mach])\n            metric_limit = 150 # Heuristic limit to manage model size\n            metric_count = 0\n            \n            # Iterate all ordered triplets (i, j, k) on the bottleneck\n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    y_ij = get_y(i, j)\n                    \n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Logical Transitivity Cut (Parent 2)\n                        # Enforce strict ordering: (i->k and k->j) => i->j\n                        # This eliminates fractional cycles that weaken the relaxation.\n                        m.combined_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Triangle Lifting (Parent 1)\n                        # If i->k->j, the start time S_j is pushed by p_k.\n                        # Formulation: S_j >= S_i + p_i + p_k * (is_path_ikj) - M * (not_is_path_ij)\n                        if metric_count < metric_limit:\n                            m.combined_cuts.add(\n                                m.S[j] >= m.S[i] + m.p[i] + \n                                m.p[k] * (y_ik + y_kj - 1) - \n                                m.bigM * (1 - y_ij)\n                            )\n                            metric_count += 1\n    \n    add_bottleneck_transitivity_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_bottleneck_transitivity_cuts(m):\n    # 1. Precompute Heads and Tails for Carlier Bound calculations\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access precedence variables y(u->v) regardless of index order\n    # Returns expression for \"u precedes v\"\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.combined_cuts = pyo.ConstraintList()\n    \n    # 3. Apply Carlier Bounds (Global) & Identify Bottleneck Machine\n    bottleneck_mach = None\n    max_lb = -1\n    \n    for mid, ops in mach_ops.items():\n        # Data: (release r, process p, tail q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        carlier_lb = 0\n        # Exact Carlier Bound check over all subset intervals\n        for r in rs:\n            for q in qs:\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    val = r + p_sum + q\n                    if val > carlier_lb: carlier_lb = val\n        \n        # Add Global Lower Bound Cut\n        if carlier_lb > 0:\n            m.combined_cuts.add(m.Cmax >= carlier_lb)\n        \n        # Track max lower bound to identify the critical bottleneck\n        if carlier_lb > max_lb:\n            max_lb = carlier_lb\n            bottleneck_mach = mid\n\n    # 4. Apply Synergistic Cuts on Bottleneck Machine Only\n    if bottleneck_mach is not None:\n        ops = sorted(mach_ops[bottleneck_mach])\n        metric_limit = 150 # Heuristic limit to manage model size\n        metric_count = 0\n        \n        # Iterate all ordered triplets (i, j, k) on the bottleneck\n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Logical Transitivity Cut (Parent 2)\n                    # Enforce strict ordering: (i->k and k->j) => i->j\n                    # This eliminates fractional cycles that weaken the relaxation.\n                    m.combined_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Triangle Lifting (Parent 1)\n                    # If i->k->j, the start time S_j is pushed by p_k.\n                    # Formulation: S_j >= S_i + p_i + p_k * (is_path_ikj) - M * (not_is_path_ij)\n                    if metric_count < metric_limit:\n                        m.combined_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        metric_count += 1\n\nadd_bottleneck_transitivity_cuts(model)",
                        "idea": "We combine Parent 1's **Bottleneck Carlier Lifting** with Parent 2's **Triangle Transitivity** to form a synergistic cut strategy. First, we tighten the global `Cmax` lower bound using Carlier's 1-machine relaxation. Second, on the identified bottleneck machine, we simultaneously enforce **binary transitivity** ($y_{ik} + y_{kj} - y_{ij} \\le 1$) and **metric precedence lifting** ($S_j \\ge S_i + p_i + p_k$ if $i \\to k \\to j$). The transitivity cuts actively prune fractional cycles, ensuring that the computationally expensive metric lifting cuts (which depend on valid paths) are applied to a tighter, logically consistent substructure."
                    },
                    "fitness": 16.918823011925145,
                    "solver_reports": [
                        {
                            "gap": 20.1631,
                            "total_time": 13.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 21567,
                            "explored_time": 13.44,
                            "work_units": 10.01
                        },
                        {
                            "gap": 90.596,
                            "total_time": 12.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 25697,
                            "explored_time": 12.49,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 30526,
                            "explored_time": 9.99,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.1247,
                            "total_time": 13.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 47320,
                            "explored_time": 13.65,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 29502,
                            "explored_time": 10.15,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.305,
                            "total_time": 11.58,
                            "explored_nodes": 1094,
                            "simplex_iterations": 73181,
                            "explored_time": 11.56,
                            "work_units": 10.68
                        },
                        {
                            "gap": 36.614,
                            "total_time": 13.98,
                            "explored_nodes": 1,
                            "simplex_iterations": 45725,
                            "explored_time": 13.93,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 31204,
                            "explored_time": 10.74,
                            "work_units": 10.02
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "a6fac450-2f9d-46e8-a1c3-a66132bb15e8"
                    ]
                },
                {
                    "id": "35810229-131e-49d5-85da-470453f26a6b",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_sequence_dependent_lifted_cuts(m):\n        # 1. Dynamic calculation of Heads (r) and Tails (q) based on instance data\n        # These allow us to derive tight bounds for start times.\n        heads = {}\n        tails = {}\n        # Forward pass: earliest start times\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass: minimum time to completion\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # Calculate global horizon (sum of all processing times) as a safe UB for Cmax\n        horizon = sum(pyo.value(m.p[op]) for op in m.O)\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Global Carlier Bound Lifting\n        # Lifts the lower bound of Cmax using 1-machine relaxations\n        for mid, ops in mach_ops.items():\n            data = [(heads[op], pyo.value(m.p[op]), tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            for r in rs:\n                for q in qs:\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Sequence-Dependent Triangle Lifting on Bottleneck Machine\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to handle symmetric precedence variables\n            def get_y(u, v):\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            cut_count = 0\n            MAX_CUTS = 150\n    \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Calculate Sequence-Dependent Big-M (Lifting Coefficient)\n                    # We need M >= S_i + p_i - S_j when y_ij=0 (i.e., j -> i).\n                    # Max(S_i) <= Horizon - tail_i. Min(S_j) >= head_j.\n                    # A tighter M strengthens the cut when precedence is inactive.\n                    M_ij = horizon - tails[i] - heads[j] + pyo.value(m.p[i])\n                    \n                    y_ij = get_y(i, j)\n                    \n                    # Filter Intermediates: Prioritize k with large processing times (Stronger cuts)\n                    candidates = [k for k in ops if k != i and k != j]\n                    candidates.sort(key=lambda k: pyo.value(m.p[k]), reverse=True)\n                    \n                    # Generate cuts for top 3 strongest intermediates\n                    for k in candidates[:3]:\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Cut: If i->k->j, delay is at least p_k.\n                        # Strengthened by M_ij and selective k.\n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            M_ij * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count >= MAX_CUTS: break\n                if cut_count >= MAX_CUTS: break\n\n    return model\n",
                        "added_cut": "def apply_sequence_dependent_lifted_cuts(m):\n    # 1. Dynamic calculation of Heads (r) and Tails (q) based on instance data\n    # These allow us to derive tight bounds for start times.\n    heads = {}\n    tails = {}\n    # Forward pass: earliest start times\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass: minimum time to completion\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # Calculate global horizon (sum of all processing times) as a safe UB for Cmax\n    horizon = sum(pyo.value(m.p[op]) for op in m.O)\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Global Carlier Bound Lifting\n    # Lifts the lower bound of Cmax using 1-machine relaxations\n    for mid, ops in mach_ops.items():\n        data = [(heads[op], pyo.value(m.p[op]), tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        for r in rs:\n            for q in qs:\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Sequence-Dependent Triangle Lifting on Bottleneck Machine\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to handle symmetric precedence variables\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        cut_count = 0\n        MAX_CUTS = 150\n\n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Calculate Sequence-Dependent Big-M (Lifting Coefficient)\n                # We need M >= S_i + p_i - S_j when y_ij=0 (i.e., j -> i).\n                # Max(S_i) <= Horizon - tail_i. Min(S_j) >= head_j.\n                # A tighter M strengthens the cut when precedence is inactive.\n                M_ij = horizon - tails[i] - heads[j] + pyo.value(m.p[i])\n                \n                y_ij = get_y(i, j)\n                \n                # Filter Intermediates: Prioritize k with large processing times (Stronger cuts)\n                candidates = [k for k in ops if k != i and k != j]\n                candidates.sort(key=lambda k: pyo.value(m.p[k]), reverse=True)\n                \n                # Generate cuts for top 3 strongest intermediates\n                for k in candidates[:3]:\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # Cut: If i->k->j, delay is at least p_k.\n                    # Strengthened by M_ij and selective k.\n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        M_ij * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count >= MAX_CUTS: break\n            if cut_count >= MAX_CUTS: break",
                        "idea": "We apply **Sequence-Dependent Triangle Lifting** to the bottleneck machine. Unlike standard triangle cuts which use a static Big-M, we derive a **tightened Big-M coefficient** ($M_{ij}$) for each pair $(i,j)$ based on their operation heads and tails (earliest start/latest finish). This creates a tighter polyhedral relaxation when the precedence binary variables are fractional. Additionally, we employ **Dominance Filtering** to select intermediate operations $k$ with the largest processing times, ensuring the cuts provide the maximum possible lift to the objective lower bound."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.86,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.85,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.15,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.29,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.28,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.25,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.69,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.68,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.04,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.75,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                },
                {
                    "id": "b165c800-214c-4492-bc72-b2ac1e8a9671",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_bottleneck_cuts(m):\n        # 1. Calculate static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Global Bottleneck and Critical Subset\n        # Maximize LB = r_min + sum(p) + q_min across all machine windows\n        best_lb = -1\n        crit_mid = None\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            for r_val in r_vals:\n                for q_val in q_vals:\n                    # Operations strictly contained in window [r_val, ..., q_val]\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    this_lb = r_val + p_sum + q_val\n                    \n                    if this_lb > best_lb:\n                        best_lb = this_lb\n                        crit_mid = mid\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        # 4. Apply Hybrid Cuts\n        if best_lb > 0:\n            # Lift Global Cmax\n            m.hybrid_cuts.add(m.Cmax >= best_lb)\n            \n            if crit_mid is not None:\n                all_ops = mach_ops[crit_mid]\n                mach_min_r = min(heads[op] for op in all_ops)\n                mach_min_q = min(tails[op] for op in all_ops)\n                subset_set = set(crit_subset)\n    \n                # Helper for directional variables: y=1 => u->v\n                def get_y(u, v):\n                    if u < v:\n                        return m.y[u[0], u[1], v[0], v[1]]\n                    else:\n                        return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n                for u in all_ops:\n                    # A. Broad Cuts (Parent 2 style): Apply to ALL ops on bottleneck machine\n                    # Uses loose bounds (machine min) but sums over ALL machine ops\n                    pred_work_broad = sum(m.p[v] * (1 - get_y(u, v)) for v in all_ops if v != u)\n                    succ_work_broad = sum(m.p[v] * get_y(u, v)       for v in all_ops if v != u)\n                    \n                    m.hybrid_cuts.add(m.S[u] >= mach_min_r + pred_work_broad)\n                    m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_broad + mach_min_q)\n    \n                    # B. Tight Cuts (Parent 1 style): Apply only to Critical Subset\n                    # Uses tight bounds (crit_r/q) and sums only over subset ops\n                    if u in subset_set and len(crit_subset) < len(all_ops):\n                        pred_work_tight = sum(m.p[v] * (1 - get_y(u, v)) for v in crit_subset if v != u)\n                        succ_work_tight = sum(m.p[v] * get_y(u, v)       for v in crit_subset if v != u)\n                        \n                        m.hybrid_cuts.add(m.S[u] >= crit_r + pred_work_tight)\n                        m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_tight + crit_q)\n    \n    add_hybrid_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_bottleneck_cuts(m):\n    # 1. Calculate static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Global Bottleneck and Critical Subset\n    # Maximize LB = r_min + sum(p) + q_min across all machine windows\n    best_lb = -1\n    crit_mid = None\n    crit_subset = []\n    crit_r = 0\n    crit_q = 0\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        for r_val in r_vals:\n            for q_val in q_vals:\n                # Operations strictly contained in window [r_val, ..., q_val]\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                this_lb = r_val + p_sum + q_val\n                \n                if this_lb > best_lb:\n                    best_lb = this_lb\n                    crit_mid = mid\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    # 4. Apply Hybrid Cuts\n    if best_lb > 0:\n        # Lift Global Cmax\n        m.hybrid_cuts.add(m.Cmax >= best_lb)\n        \n        if crit_mid is not None:\n            all_ops = mach_ops[crit_mid]\n            mach_min_r = min(heads[op] for op in all_ops)\n            mach_min_q = min(tails[op] for op in all_ops)\n            subset_set = set(crit_subset)\n\n            # Helper for directional variables: y=1 => u->v\n            def get_y(u, v):\n                if u < v:\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n            for u in all_ops:\n                # A. Broad Cuts (Parent 2 style): Apply to ALL ops on bottleneck machine\n                # Uses loose bounds (machine min) but sums over ALL machine ops\n                pred_work_broad = sum(m.p[v] * (1 - get_y(u, v)) for v in all_ops if v != u)\n                succ_work_broad = sum(m.p[v] * get_y(u, v)       for v in all_ops if v != u)\n                \n                m.hybrid_cuts.add(m.S[u] >= mach_min_r + pred_work_broad)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_broad + mach_min_q)\n\n                # B. Tight Cuts (Parent 1 style): Apply only to Critical Subset\n                # Uses tight bounds (crit_r/q) and sums only over subset ops\n                if u in subset_set and len(crit_subset) < len(all_ops):\n                    pred_work_tight = sum(m.p[v] * (1 - get_y(u, v)) for v in crit_subset if v != u)\n                    succ_work_tight = sum(m.p[v] * get_y(u, v)       for v in crit_subset if v != u)\n                    \n                    m.hybrid_cuts.add(m.S[u] >= crit_r + pred_work_tight)\n                    m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_tight + crit_q)\n\nadd_hybrid_bottleneck_cuts(model)",
                        "idea": "We combine Parent 2's broad displacement (covering all ops on the bottleneck machine) with Parent 1's tight displacement (restricted to the Carlier critical subset). This creates a two-tiered bounding structure: broad cuts provide global structural support using machine-wide bounds, while tight cuts impose stronger limits specifically on the most contended window of operations."
                    },
                    "fitness": 17.791336485607687,
                    "solver_reports": [
                        {
                            "total_time": 9.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 27116,
                            "explored_time": 9.53,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 8.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 20098,
                            "explored_time": 8.03,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.76,
                            "explored_nodes": 1,
                            "simplex_iterations": 38820,
                            "explored_time": 8.7,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.9658,
                            "total_time": 10.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 46078,
                            "explored_time": 10.67,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 25103,
                            "explored_time": 7.33,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.0086,
                            "total_time": 12.17,
                            "explored_nodes": 143,
                            "simplex_iterations": 73759,
                            "explored_time": 12.16,
                            "work_units": 11.75
                        },
                        {
                            "gap": 42.592,
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 29564,
                            "explored_time": 10.97,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 23359,
                            "explored_time": 9.46,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "1118323a-bd1c-481f-914b-b5e3b01b201f",
                        "e769c71a-be7c-4d3c-80ea-06118adb74c6"
                    ]
                },
                {
                    "id": "f0b4fd60-3d55-4246-8be1-1b01730e5376",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_multi_level_bottleneck_cuts(m):\n        # 1. Calculate static Heads (r) and Tails (q)\n        # These are pre-calculated bounds based on job sequence structure\n        r = {}\n        q = {}\n        # Heads (Forward)\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                r[j, k] = t\n                t += m.p[j, k]\n        # Tails (Backward)\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                q[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Global Bottleneck Machine and Critical Subset (Omega)\n        # We search for the machine and time window [rv, ... , qv] that maximizes the 1-machine LB.\n        best_lb = -1\n        bn_mid = None\n        bn_subset = []\n        bn_r_crit = 0\n        bn_q_crit = 0\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Filter unique start/tail thresholds relevant to this machine\n            r_vals = sorted(list(set(r[o] for o in ops)))\n            q_vals = sorted(list(set(q[o] for o in ops)))\n            \n            for rv in r_vals:\n                for qv in q_vals:\n                    # Define subset: operations strictly contained in the (rv, qv) window\n                    subset = [o for o in ops if r[o] >= rv and q[o] >= qv]\n                    if not subset: continue\n                    \n                    # Carlier Bound Logic: r + sum(p) + q\n                    lb = rv + sum(m.p[o] for o in subset) + qv\n                    if lb > best_lb:\n                        best_lb = lb\n                        bn_mid = mid\n                        bn_subset = subset\n                        bn_r_crit = rv\n                        bn_q_crit = qv\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n    \n        # 4. Enforce Global Lower Bound\n        if best_lb > 0:\n            m.hybrid_cuts.add(m.Cmax >= best_lb)\n    \n        # 5. Apply Dual-Layer Displacement Cuts (Broad + Targeted)\n        if bn_mid is not None:\n            all_ops = mach_ops[bn_mid]\n            omega_set = set(bn_subset)\n            \n            # Calculate broad bounds for the entire bottleneck machine\n            min_r_broad = min(r[o] for o in all_ops)\n            min_q_broad = min(q[o] for o in all_ops)\n            \n            # Helper: returns expression for y[u->v] (1 if u precedes v)\n            def get_y_uv(u, v):\n                # m.Pairs is ordered; check tuple order to access correct variable\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            for u in all_ops:\n                # Layer A: Broad Cuts (Parent 2 Strength)\n                # Applies to ALL ops on the bottleneck machine using loose global bounds.\n                # Ensures general coherence against machine-wide contention.\n                pred_work_broad = sum(m.p[v] * get_y_uv(v, u) for v in all_ops if v != u)\n                m.hybrid_cuts.add(m.S[u] >= min_r_broad + pred_work_broad)\n                \n                succ_work_broad = sum(m.p[v] * get_y_uv(u, v) for v in all_ops if v != u)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_broad + min_q_broad)\n                \n                # Layer B: Targeted Cuts (Parent 1 Strength)\n                # Applies ONLY to the Critical Subset Omega using tight critical bounds.\n                # Creates a 'vise' effect on the most contented operations.\n                if u in omega_set:\n                    pred_work_tight = sum(m.p[v] * get_y_uv(v, u) for v in bn_subset if v != u)\n                    m.hybrid_cuts.add(m.S[u] >= bn_r_crit + pred_work_tight)\n                    \n                    succ_work_tight = sum(m.p[v] * get_y_uv(u, v) for v in bn_subset if v != u)\n                    m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_tight + bn_q_crit)\n    \n    add_multi_level_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_multi_level_bottleneck_cuts(m):\n    # 1. Calculate static Heads (r) and Tails (q)\n    # These are pre-calculated bounds based on job sequence structure\n    r = {}\n    q = {}\n    # Heads (Forward)\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            r[j, k] = t\n            t += m.p[j, k]\n    # Tails (Backward)\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            q[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Global Bottleneck Machine and Critical Subset (Omega)\n    # We search for the machine and time window [rv, ... , qv] that maximizes the 1-machine LB.\n    best_lb = -1\n    bn_mid = None\n    bn_subset = []\n    bn_r_crit = 0\n    bn_q_crit = 0\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Filter unique start/tail thresholds relevant to this machine\n        r_vals = sorted(list(set(r[o] for o in ops)))\n        q_vals = sorted(list(set(q[o] for o in ops)))\n        \n        for rv in r_vals:\n            for qv in q_vals:\n                # Define subset: operations strictly contained in the (rv, qv) window\n                subset = [o for o in ops if r[o] >= rv and q[o] >= qv]\n                if not subset: continue\n                \n                # Carlier Bound Logic: r + sum(p) + q\n                lb = rv + sum(m.p[o] for o in subset) + qv\n                if lb > best_lb:\n                    best_lb = lb\n                    bn_mid = mid\n                    bn_subset = subset\n                    bn_r_crit = rv\n                    bn_q_crit = qv\n\n    m.hybrid_cuts = pyo.ConstraintList()\n\n    # 4. Enforce Global Lower Bound\n    if best_lb > 0:\n        m.hybrid_cuts.add(m.Cmax >= best_lb)\n\n    # 5. Apply Dual-Layer Displacement Cuts (Broad + Targeted)\n    if bn_mid is not None:\n        all_ops = mach_ops[bn_mid]\n        omega_set = set(bn_subset)\n        \n        # Calculate broad bounds for the entire bottleneck machine\n        min_r_broad = min(r[o] for o in all_ops)\n        min_q_broad = min(q[o] for o in all_ops)\n        \n        # Helper: returns expression for y[u->v] (1 if u precedes v)\n        def get_y_uv(u, v):\n            # m.Pairs is ordered; check tuple order to access correct variable\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        for u in all_ops:\n            # Layer A: Broad Cuts (Parent 2 Strength)\n            # Applies to ALL ops on the bottleneck machine using loose global bounds.\n            # Ensures general coherence against machine-wide contention.\n            pred_work_broad = sum(m.p[v] * get_y_uv(v, u) for v in all_ops if v != u)\n            m.hybrid_cuts.add(m.S[u] >= min_r_broad + pred_work_broad)\n            \n            succ_work_broad = sum(m.p[v] * get_y_uv(u, v) for v in all_ops if v != u)\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_broad + min_q_broad)\n            \n            # Layer B: Targeted Cuts (Parent 1 Strength)\n            # Applies ONLY to the Critical Subset Omega using tight critical bounds.\n            # Creates a 'vise' effect on the most contented operations.\n            if u in omega_set:\n                pred_work_tight = sum(m.p[v] * get_y_uv(v, u) for v in bn_subset if v != u)\n                m.hybrid_cuts.add(m.S[u] >= bn_r_crit + pred_work_tight)\n                \n                succ_work_tight = sum(m.p[v] * get_y_uv(u, v) for v in bn_subset if v != u)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work_tight + bn_q_crit)\n\nadd_multi_level_bottleneck_cuts(model)",
                        "idea": "This constraint fuses Parent 1's precision with Parent 2's coverage by applying a multi-level cut strategy on the bottleneck machine. First, it identifies the machine and 'critical subset' (Omega) that define the maximum Carlier Lower Bound. It then enforces two layers of displacement cuts: (1) **Broad Cuts** on all operations of the bottleneck machine using machine-wide minimum heads/tails (from Parent 2) to ensure robust sequencing for the whole resource, and (2) **Targeted Cuts** strictly on Omega using the tighter critical window bounds (from Parent 1). This combination ensures that the most contended operations are tightly bound by the peak load window, while non-critical operations are still constrained by the machine's overall workload."
                    },
                    "fitness": 17.733295279661874,
                    "solver_reports": [
                        {
                            "total_time": 9.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 27116,
                            "explored_time": 9.42,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 7.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 20599,
                            "explored_time": 7.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 41479,
                            "explored_time": 8.16,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.5623,
                            "total_time": 11.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 48086,
                            "explored_time": 11.01,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 25103,
                            "explored_time": 7.03,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.1183,
                            "total_time": 11.89,
                            "explored_nodes": 173,
                            "simplex_iterations": 58833,
                            "explored_time": 11.89,
                            "work_units": 12.18
                        },
                        {
                            "gap": 42.592,
                            "total_time": 10.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 29564,
                            "explored_time": 10.93,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 23359,
                            "explored_time": 9.67,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "1118323a-bd1c-481f-914b-b5e3b01b201f",
                        "e769c71a-be7c-4d3c-80ea-06118adb74c6"
                    ]
                },
                {
                    "id": "d17c06f5-2612-4be4-b3f0-a413f81d38ad",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # ----------------------------------------------------------------\n    # Mutation: Multi-Machine Critical Subset Displacement\n    # ----------------------------------------------------------------\n    # Instead of targeting only the single global bottleneck, this mutation\n    # identifies the critical subset (Omega) for EACH machine independently.\n    # It applies displacement cuts to tighten start times and makespan\n    # based on the specific contention window [r_min, q_min] of every machine.\n    \n    model.multi_machine_cuts = pyo.ConstraintList()\n    \n    # 1. Precompute Static Heads (r) and Tails (q)\n    r_map = {}\n    q_map = {}\n    mach_bins = {}\n    \n    # Calculate Heads (Forward)\n    for j in model.J:\n        t = 0\n        for k in model.K:\n            op = (j, k)\n            r_map[op] = t\n            t += model.p[op]\n            mid = model.mach[op]\n            if mid not in mach_bins:\n                mach_bins[mid] = []\n            mach_bins[mid].append(op)\n    \n    # Calculate Tails (Backward)\n    for j in model.J:\n        t = 0\n        for k in range(n_machines - 1, -1, -1):\n            op = (j, k)\n            q_map[op] = t\n            t += model.p[op]\n    \n    # Helper: Retrieve sequence variable y_{u,v} (1 if u precedes v)\n    def get_y_var(u, v):\n        # model.y is indexed by (j1, k1, j2, k2) where tuple(u) < tuple(v)\n        if u < v:\n            return model.y[u[0], u[1], v[0], v[1]]\n        else:\n            # if v < u, y[v,u] is 1 if v->u. Thus u->v is (1 - y[v,u]).\n            return 1 - model.y[v[0], v[1], u[0], u[1]]\n    \n    # 2. Iterate over EACH machine to find its local critical subset\n    for mid, ops in mach_bins.items():\n        if not ops:\n            continue\n    \n        # Optimization: Filter unique r and q values relevant to this machine\n        # to efficiently search for the tightest window.\n        r_distinct = sorted(list(set(r_map[o] for o in ops)))\n        q_distinct = sorted(list(set(q_map[o] for o in ops)))\n    \n        best_lb = -1\n        best_subset = []\n        best_r = 0\n        best_q = 0\n    \n        # Find the subset Omega that maximizes: r_min + sum(p) + q_min\n        for r_val in r_distinct:\n            for q_val in q_distinct:\n                subset = [o for o in ops if r_map[o] >= r_val and q_map[o] >= q_val]\n                if not subset:\n                    continue\n                \n                p_sum = sum(model.p[o] for o in subset)\n                current_lb = r_val + p_sum + q_val\n                \n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    best_subset = subset\n                    best_r = r_val\n                    best_q = q_val\n    \n        # 3. Apply Cuts for this machine's critical subset\n        if best_subset and len(best_subset) > 1:\n            # A. Local Lower Bound: The global Cmax must respect this machine's bottleneck\n            model.multi_machine_cuts.add(model.Cmax >= best_lb)\n    \n            # B. Displacement Cuts (Input/Output Adjustment)\n            # Constrain each operation 'u' in the subset based on its relationship\n            # with other operations in the same critical window.\n            for u in best_subset:\n                # Forward Cut: S_u >= WindowStart + Work(Predecessors in subset)\n                pred_work = sum(model.p[v] * get_y_var(v, u) for v in best_subset if v != u)\n                model.multi_machine_cuts.add(model.S[u] >= best_r + pred_work)\n    \n                # Backward Cut: Cmax >= S_u + p_u + Work(Successors in subset) + WindowTail\n                succ_work = sum(model.p[v] * get_y_var(u, v) for v in best_subset if v != u)\n                model.multi_machine_cuts.add(\n                    model.Cmax >= model.S[u] + model.p[u] + succ_work + best_q\n                )\n\n    return model\n",
                        "added_cut": "# ----------------------------------------------------------------\n# Mutation: Multi-Machine Critical Subset Displacement\n# ----------------------------------------------------------------\n# Instead of targeting only the single global bottleneck, this mutation\n# identifies the critical subset (Omega) for EACH machine independently.\n# It applies displacement cuts to tighten start times and makespan\n# based on the specific contention window [r_min, q_min] of every machine.\n\nmodel.multi_machine_cuts = pyo.ConstraintList()\n\n# 1. Precompute Static Heads (r) and Tails (q)\nr_map = {}\nq_map = {}\nmach_bins = {}\n\n# Calculate Heads (Forward)\nfor j in model.J:\n    t = 0\n    for k in model.K:\n        op = (j, k)\n        r_map[op] = t\n        t += model.p[op]\n        mid = model.mach[op]\n        if mid not in mach_bins:\n            mach_bins[mid] = []\n        mach_bins[mid].append(op)\n\n# Calculate Tails (Backward)\nfor j in model.J:\n    t = 0\n    for k in range(n_machines - 1, -1, -1):\n        op = (j, k)\n        q_map[op] = t\n        t += model.p[op]\n\n# Helper: Retrieve sequence variable y_{u,v} (1 if u precedes v)\ndef get_y_var(u, v):\n    # model.y is indexed by (j1, k1, j2, k2) where tuple(u) < tuple(v)\n    if u < v:\n        return model.y[u[0], u[1], v[0], v[1]]\n    else:\n        # if v < u, y[v,u] is 1 if v->u. Thus u->v is (1 - y[v,u]).\n        return 1 - model.y[v[0], v[1], u[0], u[1]]\n\n# 2. Iterate over EACH machine to find its local critical subset\nfor mid, ops in mach_bins.items():\n    if not ops:\n        continue\n\n    # Optimization: Filter unique r and q values relevant to this machine\n    # to efficiently search for the tightest window.\n    r_distinct = sorted(list(set(r_map[o] for o in ops)))\n    q_distinct = sorted(list(set(q_map[o] for o in ops)))\n\n    best_lb = -1\n    best_subset = []\n    best_r = 0\n    best_q = 0\n\n    # Find the subset Omega that maximizes: r_min + sum(p) + q_min\n    for r_val in r_distinct:\n        for q_val in q_distinct:\n            subset = [o for o in ops if r_map[o] >= r_val and q_map[o] >= q_val]\n            if not subset:\n                continue\n            \n            p_sum = sum(model.p[o] for o in subset)\n            current_lb = r_val + p_sum + q_val\n            \n            if current_lb > best_lb:\n                best_lb = current_lb\n                best_subset = subset\n                best_r = r_val\n                best_q = q_val\n\n    # 3. Apply Cuts for this machine's critical subset\n    if best_subset and len(best_subset) > 1:\n        # A. Local Lower Bound: The global Cmax must respect this machine's bottleneck\n        model.multi_machine_cuts.add(model.Cmax >= best_lb)\n\n        # B. Displacement Cuts (Input/Output Adjustment)\n        # Constrain each operation 'u' in the subset based on its relationship\n        # with other operations in the same critical window.\n        for u in best_subset:\n            # Forward Cut: S_u >= WindowStart + Work(Predecessors in subset)\n            pred_work = sum(model.p[v] * get_y_var(v, u) for v in best_subset if v != u)\n            model.multi_machine_cuts.add(model.S[u] >= best_r + pred_work)\n\n            # Backward Cut: Cmax >= S_u + p_u + Work(Successors in subset) + WindowTail\n            succ_work = sum(model.p[v] * get_y_var(u, v) for v in best_subset if v != u)\n            model.multi_machine_cuts.add(\n                model.Cmax >= model.S[u] + model.p[u] + succ_work + best_q\n            )",
                        "idea": "Generalizes the Critical Subset Displacement strategy by applying it to **every machine** independently, rather than just the single global bottleneck. By dynamically identifying the subset $\\Omega_m$ that maximizes the 1-machine lower bound ($r_{min} + \\sum p + q_{min}$) for each machine $m$, we generate distinct displacement cuts ($S_u \\ge r + \\dots$ and $C_{max} \\ge S_u + \\dots$) for all contended resources. This creates a shop-wide 'vise' that simultaneously tightens start times and makespan bounds across all machines, capturing secondary bottlenecks and reducing the search space more effectively than a single global cut."
                    },
                    "fitness": 13.746802536725564,
                    "solver_reports": [
                        {
                            "total_time": 7.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 21364,
                            "explored_time": 7.19,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 22549,
                            "explored_time": 7.24,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 32749,
                            "explored_time": 8.23,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 5.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 18100,
                            "explored_time": 5.8,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 33790,
                            "explored_time": 8.23,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.449,
                            "total_time": 8.88,
                            "explored_nodes": 49,
                            "simplex_iterations": 56808,
                            "explored_time": 8.87,
                            "work_units": 10.5
                        },
                        {
                            "total_time": 5.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 21882,
                            "explored_time": 5.4,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 22885,
                            "explored_time": 7.02,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "1118323a-bd1c-481f-914b-b5e3b01b201f"
                    ]
                }
            ],
            19.745839703599053
        ],
        [
            [
                {
                    "id": "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_lifted_bottleneck_cuts(m):\n        # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n        # to ensure self-contained execution.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Container for new constraints\n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        for mid, ops in mach_ops.items():\n            # Data: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Sort unique thresholds\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n            for r in rs:\n                for q in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            # Add cut: Cmax must be >= tightest 1-machine relaxation\n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n        # Only applied to the identified bottleneck machine to keep size manageable.\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to get the expression for \"u precedes v\"\n            # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n            def get_precedence_expr(u, v):\n                if u < v:\n                    # Variable exists as y[u, v]\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n            # We limit n_cuts to avoid memory explosion if the machine has many ops\n            cut_count = 0\n            limit = 100 \n            \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Base precedence var: i -> j\n                    y_ij = get_precedence_expr(i, j)\n                    \n                    # Identify intermediate node k\n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_precedence_expr(i, k)\n                        y_kj = get_precedence_expr(k, j)\n                        \n                        # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                        # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        # Logic: \n                        #   If y_ij=1 (i->j active):\n                        #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                        #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                        #      Else:\n                        #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                        #   If y_ij=0 (i->j inactive):\n                        #      RHS is large negative (Valid due to bigM)\n                        \n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count > limit: break\n                if cut_count > limit: break\n    \n    apply_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_lifted_bottleneck_cuts(m):\n    # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n    # to ensure self-contained execution.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Container for new constraints\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    for mid, ops in mach_ops.items():\n        # Data: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Sort unique thresholds\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n        for r in rs:\n            for q in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        # Add cut: Cmax must be >= tightest 1-machine relaxation\n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n    # Only applied to the identified bottleneck machine to keep size manageable.\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to get the expression for \"u precedes v\"\n        # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n        def get_precedence_expr(u, v):\n            if u < v:\n                # Variable exists as y[u, v]\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n        # We limit n_cuts to avoid memory explosion if the machine has many ops\n        cut_count = 0\n        limit = 100 \n        \n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Base precedence var: i -> j\n                y_ij = get_precedence_expr(i, j)\n                \n                # Identify intermediate node k\n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_precedence_expr(i, k)\n                    y_kj = get_precedence_expr(k, j)\n                    \n                    # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                    # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    # Logic: \n                    #   If y_ij=1 (i->j active):\n                    #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                    #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                    #      Else:\n                    #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                    #   If y_ij=0 (i->j inactive):\n                    #      RHS is large negative (Valid due to bigM)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count > limit: break\n            if cut_count > limit: break\n\napply_lifted_bottleneck_cuts(model)",
                        "idea": "We apply **Bottleneck-Focused Triangle Lifting**. First, we strengthen the global lower bound by computing the **Carlier Bound** for every machine; this effectively lifts the `Cmax` constraint by solving the 1-machine head-tail problem exactly. Second, we identify the bottleneck machine (the one generating the max Carlier bound) and apply **Triangle Precedence Cuts** to it. These cuts lift the pairwise disjunctive constraints $S_j \\ge S_i + p_i$ by incorporating intermediate operations $k$: if $i \\to k \\to j$, the delay must include $p_k$. This creates a tighter polyhedral approximation for the critical machine, pruning fractional solutions where precedence is intransitive."
                    },
                    "fitness": 19.745839703599053,
                    "solver_reports": [
                        {
                            "gap": 22.6009,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 34291,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3984,
                            "total_time": 12.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 35151,
                            "explored_time": 12.71,
                            "work_units": 10.28
                        },
                        {
                            "gap": 34.8922,
                            "total_time": 11.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 30987,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6984,
                            "total_time": 13.28,
                            "explored_nodes": 59,
                            "simplex_iterations": 45527,
                            "explored_time": 13.27,
                            "work_units": 10.17
                        },
                        {
                            "total_time": 11.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34484,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.2529,
                            "total_time": 10.35,
                            "explored_nodes": 1497,
                            "simplex_iterations": 87588,
                            "explored_time": 10.34,
                            "work_units": 10.88
                        },
                        {
                            "gap": 25.8837,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 49577,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 39685,
                            "explored_time": 10.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "953456bd-bd70-4803-ab54-4778ff8de5b6"
                    ]
                },
                {
                    "id": "87255be1-c692-4d81-9983-d479e5d28363",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_displacement_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Heads (r) and Tails (q) dynamically\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.critical_cuts = pyo.ConstraintList()\n    \n        # Track the single most critical window across all machines\n        global_max_lb = -1\n        bottleneck_subset = []\n        bottleneck_r = 0\n        bottleneck_q = 0\n    \n        # 3. Scan all machines for Carlier Bounds (Global Lifting)\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Identify unique start (r) and end (q) thresholds\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            local_max = -1\n            \n            # Find the tightest [r, q] window for this machine\n            for r in r_vals:\n                for q in q_vals:\n                    # Operations strictly contained in window\n                    subset = [op for op in ops if heads[op] >= r and tails[op] >= q]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    lb = r + p_sum + q\n                    \n                    if lb > local_max:\n                        local_max = lb\n                        # Update global bottleneck tracking\n                        if lb > global_max_lb:\n                            global_max_lb = lb\n                            bottleneck_subset = subset\n                            bottleneck_r = r\n                            bottleneck_q = q\n            \n            # Add valid lower bound cut for every machine\n            if local_max > 0:\n                m.critical_cuts.add(m.Cmax >= local_max)\n    \n        # 4. Apply Displacement Cuts only to the Critical Subset (Bottleneck Strengthening)\n        if bottleneck_subset:\n            # Helper: returns expression for 'source -> target'\n            def get_direction(source, target):\n                s_j, s_k = source\n                t_j, t_k = target\n                # y is defined for lexicographically sorted pairs\n                if source < target:\n                    return m.y[s_j, s_k, t_j, t_k]\n                else:\n                    return 1 - m.y[t_j, t_k, s_j, s_k]\n    \n            for u in bottleneck_subset:\n                # Input Bound: S[u] >= r_subset + sum(p[v] for v in subset if v -> u)\n                preds = sum(m.p[v] * get_direction(v, u) for v in bottleneck_subset if v != u)\n                m.critical_cuts.add(m.S[u] >= bottleneck_r + preds)\n                \n                # Output Bound: Cmax >= S[u] + p[u] + sum(p[v] for v in subset if u -> v) + q_subset\n                succs = sum(m.p[v] * get_direction(u, v) for v in bottleneck_subset if v != u)\n                m.critical_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succs + bottleneck_q)\n    \n    add_critical_displacement_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_critical_displacement_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Heads (r) and Tails (q) dynamically\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.critical_cuts = pyo.ConstraintList()\n\n    # Track the single most critical window across all machines\n    global_max_lb = -1\n    bottleneck_subset = []\n    bottleneck_r = 0\n    bottleneck_q = 0\n\n    # 3. Scan all machines for Carlier Bounds (Global Lifting)\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Identify unique start (r) and end (q) thresholds\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        local_max = -1\n        \n        # Find the tightest [r, q] window for this machine\n        for r in r_vals:\n            for q in q_vals:\n                # Operations strictly contained in window\n                subset = [op for op in ops if heads[op] >= r and tails[op] >= q]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                lb = r + p_sum + q\n                \n                if lb > local_max:\n                    local_max = lb\n                    # Update global bottleneck tracking\n                    if lb > global_max_lb:\n                        global_max_lb = lb\n                        bottleneck_subset = subset\n                        bottleneck_r = r\n                        bottleneck_q = q\n        \n        # Add valid lower bound cut for every machine\n        if local_max > 0:\n            m.critical_cuts.add(m.Cmax >= local_max)\n\n    # 4. Apply Displacement Cuts only to the Critical Subset (Bottleneck Strengthening)\n    if bottleneck_subset:\n        # Helper: returns expression for 'source -> target'\n        def get_direction(source, target):\n            s_j, s_k = source\n            t_j, t_k = target\n            # y is defined for lexicographically sorted pairs\n            if source < target:\n                return m.y[s_j, s_k, t_j, t_k]\n            else:\n                return 1 - m.y[t_j, t_k, s_j, s_k]\n\n        for u in bottleneck_subset:\n            # Input Bound: S[u] >= r_subset + sum(p[v] for v in subset if v -> u)\n            preds = sum(m.p[v] * get_direction(v, u) for v in bottleneck_subset if v != u)\n            m.critical_cuts.add(m.S[u] >= bottleneck_r + preds)\n            \n            # Output Bound: Cmax >= S[u] + p[u] + sum(p[v] for v in subset if u -> v) + q_subset\n            succs = sum(m.p[v] * get_direction(u, v) for v in bottleneck_subset if v != u)\n            m.critical_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succs + bottleneck_q)\n\nadd_critical_displacement_cuts(model)",
                        "idea": "Combines Parent 1's robust **Global Carlier Bound** scan (which lifts Cmax using the 1-machine relaxation on every machine) with Parent 2's concept of a **Critical Subset**. Instead of Parent 1's dense triangle cuts or Parent 2's loose machine-wide cuts, we apply **Displacement (Input/Output) Cuts** strictly to the most contended window of the bottleneck machine. These cuts ($S_u \\ge r_{subset} + \\sum_{v \\to u} p_v$) approximate the convex hull of the disjunctive constraints for the critical set, enforcing that a job's start time must account for the processing of all selected predecessors within that tight window."
                    },
                    "fitness": 11.577906911452558,
                    "solver_reports": [
                        {
                            "total_time": 8.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 19095,
                            "explored_time": 8.45,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 20032,
                            "explored_time": 10.57,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 22975,
                            "explored_time": 8.9,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.06,
                            "explored_nodes": 2174,
                            "simplex_iterations": 191225,
                            "explored_time": 10.05,
                            "work_units": 10.14
                        },
                        {
                            "gap": 93.3388,
                            "total_time": 7.76,
                            "explored_nodes": 1,
                            "simplex_iterations": 16907,
                            "explored_time": 7.66,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.821,
                            "total_time": 11.23,
                            "explored_nodes": 171,
                            "simplex_iterations": 86048,
                            "explored_time": 11.22,
                            "work_units": 12.78
                        },
                        {
                            "gap": 91.6942,
                            "total_time": 18.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 21095,
                            "explored_time": 18.94,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 21757,
                            "explored_time": 9.19,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "b165c800-214c-4492-bc72-b2ac1e8a9671"
                    ]
                },
                {
                    "id": "f30d9933-e31f-4b30-9c2b-2d1ab76bbf46",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_subset_cuts(m):\n        # 1. Static Lookahead: Calculate Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Bottleneck Subset via Carlier Bound\n        # We seek the subset maximizing: r_min + sum(p) + q_min\n        best_lb = -1\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Candidate r and q values defining the window\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            for r_val in r_vals:\n                for q_val in q_vals:\n                    # Select ops that fit within the [r_val, ..., q_val] window\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    lb = r_val + p_sum + q_val\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n        # Helper to access precedence variables y(u->v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.critical_cuts = pyo.ConstraintList()\n    \n        if best_lb > 0:\n            # A. Lift Global Makespan\n            m.critical_cuts.add(m.Cmax >= best_lb)\n            \n            # B. Synergistic Cuts on the Critical Subset\n            if crit_subset:\n                # 1. Tight Displacement Cuts (from Parent 1)\n                # Lift start times based on the aggregate processing of predecessors within the subset.\n                # This is stronger than simple big-M because it sums multiple p_v terms.\n                for u in crit_subset:\n                    pred_work = sum(m.p[v] * (1 - get_y(u, v)) for v in crit_subset if v != u)\n                    succ_work = sum(m.p[v] * get_y(u, v)       for v in crit_subset if v != u)\n                    \n                    m.critical_cuts.add(m.S[u] >= crit_r + pred_work)\n                    m.critical_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n                \n                # 2. Subset Transitivity Cuts (from Parent 2)\n                # Enforce triangular consistency specifically on the critical subset.\n                # This ensures the binary variables driving the Displacement Cuts above\n                # form a valid permutation, tightening the relaxation where it matters most.\n                # We limit to subsets <= 20 to avoid O(k^3) explosion on large instances.\n                if len(crit_subset) <= 20:\n                    sorted_sub = sorted(crit_subset)\n                    for i in sorted_sub:\n                        for j in sorted_sub:\n                            if i == j: continue\n                            y_ij = get_y(i, j)\n                            for k in sorted_sub:\n                                if k == i or k == j: continue\n                                y_ik = get_y(i, k)\n                                y_kj = get_y(k, j)\n                                # if i->k and k->j, then i->j must not be false (cycle prevention)\n                                m.critical_cuts.add(y_ik + y_kj - y_ij <= 1)\n\n    return model\n",
                        "added_cut": "def add_critical_subset_cuts(m):\n    # 1. Static Lookahead: Calculate Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Bottleneck Subset via Carlier Bound\n    # We seek the subset maximizing: r_min + sum(p) + q_min\n    best_lb = -1\n    crit_subset = []\n    crit_r = 0\n    crit_q = 0\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Candidate r and q values defining the window\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        for r_val in r_vals:\n            for q_val in q_vals:\n                # Select ops that fit within the [r_val, ..., q_val] window\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                lb = r_val + p_sum + q_val\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n    # Helper to access precedence variables y(u->v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.critical_cuts = pyo.ConstraintList()\n\n    if best_lb > 0:\n        # A. Lift Global Makespan\n        m.critical_cuts.add(m.Cmax >= best_lb)\n        \n        # B. Synergistic Cuts on the Critical Subset\n        if crit_subset:\n            # 1. Tight Displacement Cuts (from Parent 1)\n            # Lift start times based on the aggregate processing of predecessors within the subset.\n            # This is stronger than simple big-M because it sums multiple p_v terms.\n            for u in crit_subset:\n                pred_work = sum(m.p[v] * (1 - get_y(u, v)) for v in crit_subset if v != u)\n                succ_work = sum(m.p[v] * get_y(u, v)       for v in crit_subset if v != u)\n                \n                m.critical_cuts.add(m.S[u] >= crit_r + pred_work)\n                m.critical_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n            \n            # 2. Subset Transitivity Cuts (from Parent 2)\n            # Enforce triangular consistency specifically on the critical subset.\n            # This ensures the binary variables driving the Displacement Cuts above\n            # form a valid permutation, tightening the relaxation where it matters most.\n            # We limit to subsets <= 20 to avoid O(k^3) explosion on large instances.\n            if len(crit_subset) <= 20:\n                sorted_sub = sorted(crit_subset)\n                for i in sorted_sub:\n                    for j in sorted_sub:\n                        if i == j: continue\n                        y_ij = get_y(i, j)\n                        for k in sorted_sub:\n                            if k == i or k == j: continue\n                            y_ik = get_y(i, k)\n                            y_kj = get_y(k, j)\n                            # if i->k and k->j, then i->j must not be false (cycle prevention)\n                            m.critical_cuts.add(y_ik + y_kj - y_ij <= 1)",
                        "idea": "We combine Parent 1's Critical Subset Displacement with Parent 2's Triangle Transitivity in a targeted manner. We first identify the bottleneck machine and its most constrained subset of operations (the Carlier set). On this subset, we apply (1) Tight Displacement cuts (S_u >= r_min + sum(p_pred)), which act as strong cumulative resource bounds, and (2) Subset Transitivity cuts (y_ik + y_kj - y_ij <= 1), which enforce logical consistency of the precedence variables specifically within this high-contention window. This synergy prevents fractional cycles in the bottleneck from weakening the displacement bounds, providing a tighter convex hull approximation than either method alone."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.97,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 14.98,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 14.94,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.44,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.33,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.32,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.24,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.46,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.97,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.95,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.91,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "b165c800-214c-4492-bc72-b2ac1e8a9671",
                        "00dfdfed-5771-4e8f-b23b-0ce2031a4b38"
                    ]
                },
                {
                    "id": "7e111dde-288a-4f56-b45d-a88d3c2817e7",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_per_machine_hybrid_cuts(m):\n        # 1. Calculate static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            # Safely iterate backwards over K\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n    \n        # Helper returns expression for \"u precedes v\" (u -> v)\n        def pred_expr(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # If v < u, y[v, u] is \"v -> u\", so \"u -> v\" is 1 - y[v, u]\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Apply Logic to EVERY Machine (Generalization)\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n    \n            # A. Broad Bounds (Full Machine)\n            broad_r = min(heads[op] for op in ops)\n            broad_q = min(tails[op] for op in ops)\n    \n            # B. Identify Critical Subset (Maximize 1-machine LB)\n            best_lb = -1\n            crit_subset = []\n            crit_r = 0\n            crit_q = 0\n            \n            r_candidates = sorted(list(set(heads[op] for op in ops)))\n            q_candidates = sorted(list(set(tails[op] for op in ops)))\n    \n            for r_val in r_candidates:\n                for q_val in q_candidates:\n                    # Ops strictly inside the window defined by r_val and q_val\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if not subset: continue\n                    \n                    # 1-Machine LB for this subset\n                    current_lb = r_val + sum(m.p[op] for op in subset) + q_val\n                    if current_lb > best_lb:\n                        best_lb = current_lb\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n            # C. Add Cuts\n            # Global LB from this machine\n            if best_lb > 0:\n                m.hybrid_cuts.add(m.Cmax >= best_lb)\n    \n            crit_set = set(crit_subset)\n            is_subset_strict = (len(crit_subset) < len(ops))\n    \n            for u in ops:\n                # Broad Cuts: Apply to ALL operations on the machine using loose bounds\n                # S_u >= broad_r + sum(p_v * (v->u))\n                sum_pred_broad = sum(m.p[v] * pred_expr(v, u) for v in ops if v != u)\n                sum_succ_broad = sum(m.p[v] * pred_expr(u, v) for v in ops if v != u)\n                \n                m.hybrid_cuts.add(m.S[u] >= broad_r + sum_pred_broad)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + sum_succ_broad + broad_q)\n    \n                # Tight Cuts: Apply only to Critical Subset using strict bounds\n                # This tightens the relaxation for the most contended window\n                if is_subset_strict and u in crit_set:\n                    sum_pred_tight = sum(m.p[v] * pred_expr(v, u) for v in crit_subset if v != u)\n                    sum_succ_tight = sum(m.p[v] * pred_expr(u, v) for v in crit_subset if v != u)\n                    \n                    m.hybrid_cuts.add(m.S[u] >= crit_r + sum_pred_tight)\n                    m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + sum_succ_tight + crit_q)\n    \n    add_per_machine_hybrid_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_per_machine_hybrid_cuts(m):\n    # 1. Calculate static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        # Safely iterate backwards over K\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.hybrid_cuts = pyo.ConstraintList()\n\n    # Helper returns expression for \"u precedes v\" (u -> v)\n    def pred_expr(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            # If v < u, y[v, u] is \"v -> u\", so \"u -> v\" is 1 - y[v, u]\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Apply Logic to EVERY Machine (Generalization)\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n\n        # A. Broad Bounds (Full Machine)\n        broad_r = min(heads[op] for op in ops)\n        broad_q = min(tails[op] for op in ops)\n\n        # B. Identify Critical Subset (Maximize 1-machine LB)\n        best_lb = -1\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n        \n        r_candidates = sorted(list(set(heads[op] for op in ops)))\n        q_candidates = sorted(list(set(tails[op] for op in ops)))\n\n        for r_val in r_candidates:\n            for q_val in q_candidates:\n                # Ops strictly inside the window defined by r_val and q_val\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if not subset: continue\n                \n                # 1-Machine LB for this subset\n                current_lb = r_val + sum(m.p[op] for op in subset) + q_val\n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n        # C. Add Cuts\n        # Global LB from this machine\n        if best_lb > 0:\n            m.hybrid_cuts.add(m.Cmax >= best_lb)\n\n        crit_set = set(crit_subset)\n        is_subset_strict = (len(crit_subset) < len(ops))\n\n        for u in ops:\n            # Broad Cuts: Apply to ALL operations on the machine using loose bounds\n            # S_u >= broad_r + sum(p_v * (v->u))\n            sum_pred_broad = sum(m.p[v] * pred_expr(v, u) for v in ops if v != u)\n            sum_succ_broad = sum(m.p[v] * pred_expr(u, v) for v in ops if v != u)\n            \n            m.hybrid_cuts.add(m.S[u] >= broad_r + sum_pred_broad)\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + sum_succ_broad + broad_q)\n\n            # Tight Cuts: Apply only to Critical Subset using strict bounds\n            # This tightens the relaxation for the most contended window\n            if is_subset_strict and u in crit_set:\n                sum_pred_tight = sum(m.p[v] * pred_expr(v, u) for v in crit_subset if v != u)\n                sum_succ_tight = sum(m.p[v] * pred_expr(u, v) for v in crit_subset if v != u)\n                \n                m.hybrid_cuts.add(m.S[u] >= crit_r + sum_pred_tight)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + sum_succ_tight + crit_q)\n\nadd_per_machine_hybrid_cuts(model)",
                        "idea": "Generalizes the hybrid bottleneck strategy by applying it to **every** machine rather than just the single global bottleneck. For each machine, the mutation identifies both broad bounds (using all operations) and tight bounds (using the critical subset that maximizes the local 1-machine lower bound). This creates a pervasive multi-machine relaxation that tightens start times and makespan across the entire schedule, preventing non-bottleneck machines from allowing loose, infeasible partial schedules."
                    },
                    "fitness": 11.465282133571844,
                    "solver_reports": [
                        {
                            "total_time": 7.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 21374,
                            "explored_time": 7.04,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 21917,
                            "explored_time": 6.97,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 32703,
                            "explored_time": 8.09,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 6.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 21516,
                            "explored_time": 6.01,
                            "work_units": 10.03
                        },
                        {
                            "total_time": 8.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 33411,
                            "explored_time": 8.42,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.4247,
                            "total_time": 7.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 31091,
                            "explored_time": 7.48,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 5.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 17320,
                            "explored_time": 5.85,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 21851,
                            "explored_time": 7.1,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "b165c800-214c-4492-bc72-b2ac1e8a9671"
                    ]
                },
                {
                    "id": "c22c7a45-fd8d-4124-83c2-95e11776d020",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_window_cuts(m):\n        # 1. Recompute Heads (r) and Tails (q) dynamically\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        bottleneck_mach = None\n        max_lb = -1\n        best_window = (0, 0) # stores (r, q) for the critical block\n    \n        # 3. Carlier Bound Calculation to find Critical Window\n        for mid, ops in mach_ops.items():\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            local_window = (0, 0)\n            \n            # Brute-force 1-machine Carlier bound\n            for r in rs:\n                for q in qs:\n                    # Sum processing times strictly inside the window [r, end-q]\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n                            local_window = (r, q)\n            \n            # Apply Global Lower Bound Cut (Feature from Parent 1 & 2)\n            if local_max > 0:\n                m.hybrid_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_lb:\n                max_lb = local_max\n                bottleneck_mach = mid\n                best_window = local_window\n    \n        # 4. Targeted Lifting on Critical Block (Hybrid Strategy)\n        if bottleneck_mach is not None:\n            ops = mach_ops[bottleneck_mach]\n            r_crit, q_crit = best_window\n            \n            # Filter ops: only those contributing to the active Carlier bound\n            # This isolates the \"Critical Block\" to avoid O(N^3) bloat\n            crit_ops = [op for op in ops if heads[op] >= r_crit and tails[op] >= q_crit]\n            \n            # Fallback if block is trivial\n            if len(crit_ops) < 3:\n                crit_ops = ops\n                \n            # Helper for precedence variables y(u->v)\n            def get_y(u, v):\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            cut_limit = 200\n            count = 0\n            \n            for i in crit_ops:\n                for j in crit_ops:\n                    if i == j: continue\n                    y_ij = get_y(i, j)\n                    \n                    for k in crit_ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Logical Transitivity (Parent 2 Feature)\n                        # Enforce consistency within the critical block: i->k->j implies i->j\n                        m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting (Parent 1 Feature)\n                        # Tighten start times: S_j >= S_i + p_i + p_k if path i->k->j active\n                        # Synergy: Transitivity forces y_ij=1 when i->k->j, activating this tight bound.\n                        m.hybrid_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        count += 1\n                        if count >= cut_limit: break\n                    if count >= cut_limit: break\n                if count >= cut_limit: break\n    \n    add_critical_window_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_critical_window_cuts(m):\n    # 1. Recompute Heads (r) and Tails (q) dynamically\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    bottleneck_mach = None\n    max_lb = -1\n    best_window = (0, 0) # stores (r, q) for the critical block\n\n    # 3. Carlier Bound Calculation to find Critical Window\n    for mid, ops in mach_ops.items():\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        local_window = (0, 0)\n        \n        # Brute-force 1-machine Carlier bound\n        for r in rs:\n            for q in qs:\n                # Sum processing times strictly inside the window [r, end-q]\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n                        local_window = (r, q)\n        \n        # Apply Global Lower Bound Cut (Feature from Parent 1 & 2)\n        if local_max > 0:\n            m.hybrid_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_lb:\n            max_lb = local_max\n            bottleneck_mach = mid\n            best_window = local_window\n\n    # 4. Targeted Lifting on Critical Block (Hybrid Strategy)\n    if bottleneck_mach is not None:\n        ops = mach_ops[bottleneck_mach]\n        r_crit, q_crit = best_window\n        \n        # Filter ops: only those contributing to the active Carlier bound\n        # This isolates the \"Critical Block\" to avoid O(N^3) bloat\n        crit_ops = [op for op in ops if heads[op] >= r_crit and tails[op] >= q_crit]\n        \n        # Fallback if block is trivial\n        if len(crit_ops) < 3:\n            crit_ops = ops\n            \n        # Helper for precedence variables y(u->v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        cut_limit = 200\n        count = 0\n        \n        for i in crit_ops:\n            for j in crit_ops:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in crit_ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Logical Transitivity (Parent 2 Feature)\n                    # Enforce consistency within the critical block: i->k->j implies i->j\n                    m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting (Parent 1 Feature)\n                    # Tighten start times: S_j >= S_i + p_i + p_k if path i->k->j active\n                    # Synergy: Transitivity forces y_ij=1 when i->k->j, activating this tight bound.\n                    m.hybrid_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    count += 1\n                    if count >= cut_limit: break\n                if count >= cut_limit: break\n            if count >= cut_limit: break\n\nadd_critical_window_cuts(model)",
                        "idea": "We implement **Critical Window Lifting**, a hybrid strategy that uses Parent 1's numerical Carlier Bound analysis to identify the exact subset of operations (the 'Critical Window') defining the bottleneck, and then applies Parent 2's **Transitivity** logic alongside Parent 1's **Metric Lifting** exclusively to this subset. By enforcing transitivity ($y_{ik} + y_{kj} \\le 1 + y_{ij}$) only within the critical block, we ensure that the metric cuts ($S_j \\ge S_i + p_i + p_k$) are logically tight and active for the most constraining operations, strengthening the convex hull of the bottleneck without the computational cost of global transitivity."
                    },
                    "fitness": 18.81273679852184,
                    "solver_reports": [
                        {
                            "gap": 33.1213,
                            "total_time": 14.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 33722,
                            "explored_time": 14.34,
                            "work_units": 10.22
                        },
                        {
                            "gap": 29.6481,
                            "total_time": 13.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 35384,
                            "explored_time": 13.8,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 11.95,
                            "explored_nodes": 1,
                            "simplex_iterations": 31839,
                            "explored_time": 11.89,
                            "work_units": 10.01
                        },
                        {
                            "gap": 19.5465,
                            "total_time": 13.7,
                            "explored_nodes": 115,
                            "simplex_iterations": 69394,
                            "explored_time": 13.68,
                            "work_units": 10.82
                        },
                        {
                            "total_time": 9.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 34934,
                            "explored_time": 9.82,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.6329,
                            "total_time": 11.41,
                            "explored_nodes": 1853,
                            "simplex_iterations": 100933,
                            "explored_time": 11.4,
                            "work_units": 10.51
                        },
                        {
                            "gap": 32.1955,
                            "total_time": 11.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 45126,
                            "explored_time": 11.6,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 35737,
                            "explored_time": 11.6,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "00dfdfed-5771-4e8f-b23b-0ce2031a4b38"
                    ]
                },
                {
                    "id": "3aba2531-5802-4bdf-ada5-99653698108f",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_combined_bottleneck_cuts(m):\n        # 1. Calculate Heads (r) and Tails (q) for all operations\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Subset (Bottleneck Identification)\n        # We search for the subset of operations on a single machine that maximizes\n        # the 1-machine Carlier bound: r_min + sum(p) + q_min.\n        best_lb = -1\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Candidate start (r) and end (q) thresholds\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            for r_val in r_vals:\n                for q_val in q_vals:\n                    # Filter operations strictly contained in the window [r_val, ..., q_val]\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    current_lb = r_val + p_sum + q_val\n                    \n                    if current_lb > best_lb:\n                        best_lb = current_lb\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n        m.combined_cuts = pyo.ConstraintList()\n    \n        # 4. Global Cmax Lift\n        # Apply the strongest identified 1-machine bound to the objective\n        if best_lb > 0:\n            m.combined_cuts.add(m.Cmax >= best_lb)\n    \n        # 5. Apply Focused Cuts on the Critical Subset\n        # We restrict computationally expensive cuts to this subset to tighten the bottleneck.\n        if crit_subset:\n            \n            # Helper: Returns expression for \"u precedes v\" (y_uv)\n            def get_y_expr(u, v):\n                if u < v:\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # A. Tight Displacement Cuts (from Parent 1)\n            # Linearize the schedule of u based on predecessors within the critical subset.\n            # This pushes S[u] forward if it must be preceded by other ops in the contended window.\n            for u in crit_subset:\n                pred_term = sum(m.p[v] * get_y_expr(v, u) for v in crit_subset if v != u)\n                succ_term = sum(m.p[v] * get_y_expr(u, v) for v in crit_subset if v != u)\n                \n                m.combined_cuts.add(m.S[u] >= crit_r + pred_term)\n                m.combined_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_term + crit_q)\n    \n            # B. Triangle Precedence Cuts (from Parent 2)\n            # Enforce local transitivity (i->k->j) specifically within the critical subset.\n            # This strengthens pairwise disjunctions using intermediate nodes k.\n            triplet_count = 0\n            limit = 200  # Safety limit to prevent O(n^3) explosion\n            \n            for i in crit_subset:\n                for j in crit_subset:\n                    if i == j: continue\n                    \n                    y_ij = get_y_expr(i, j)\n                    \n                    for k in crit_subset:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_y_expr(i, k)\n                        y_kj = get_y_expr(k, j)\n                        \n                        # If i->k and k->j, then S[j] >= S[i] + p[i] + p[k]\n                        # The term (y_ik + y_kj - 1) becomes 1 only if path i->k->j is active.\n                        m.combined_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        triplet_count += 1\n                        if triplet_count >= limit: break\n                if triplet_count >= limit: break\n\n    return model\n",
                        "added_cut": "def add_combined_bottleneck_cuts(m):\n    # 1. Calculate Heads (r) and Tails (q) for all operations\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Subset (Bottleneck Identification)\n    # We search for the subset of operations on a single machine that maximizes\n    # the 1-machine Carlier bound: r_min + sum(p) + q_min.\n    best_lb = -1\n    crit_subset = []\n    crit_r = 0\n    crit_q = 0\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Candidate start (r) and end (q) thresholds\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        for r_val in r_vals:\n            for q_val in q_vals:\n                # Filter operations strictly contained in the window [r_val, ..., q_val]\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                current_lb = r_val + p_sum + q_val\n                \n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n    m.combined_cuts = pyo.ConstraintList()\n\n    # 4. Global Cmax Lift\n    # Apply the strongest identified 1-machine bound to the objective\n    if best_lb > 0:\n        m.combined_cuts.add(m.Cmax >= best_lb)\n\n    # 5. Apply Focused Cuts on the Critical Subset\n    # We restrict computationally expensive cuts to this subset to tighten the bottleneck.\n    if crit_subset:\n        \n        # Helper: Returns expression for \"u precedes v\" (y_uv)\n        def get_y_expr(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # A. Tight Displacement Cuts (from Parent 1)\n        # Linearize the schedule of u based on predecessors within the critical subset.\n        # This pushes S[u] forward if it must be preceded by other ops in the contended window.\n        for u in crit_subset:\n            pred_term = sum(m.p[v] * get_y_expr(v, u) for v in crit_subset if v != u)\n            succ_term = sum(m.p[v] * get_y_expr(u, v) for v in crit_subset if v != u)\n            \n            m.combined_cuts.add(m.S[u] >= crit_r + pred_term)\n            m.combined_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_term + crit_q)\n\n        # B. Triangle Precedence Cuts (from Parent 2)\n        # Enforce local transitivity (i->k->j) specifically within the critical subset.\n        # This strengthens pairwise disjunctions using intermediate nodes k.\n        triplet_count = 0\n        limit = 200  # Safety limit to prevent O(n^3) explosion\n        \n        for i in crit_subset:\n            for j in crit_subset:\n                if i == j: continue\n                \n                y_ij = get_y_expr(i, j)\n                \n                for k in crit_subset:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_y_expr(i, k)\n                    y_kj = get_y_expr(k, j)\n                    \n                    # If i->k and k->j, then S[j] >= S[i] + p[i] + p[k]\n                    # The term (y_ik + y_kj - 1) becomes 1 only if path i->k->j is active.\n                    m.combined_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    triplet_count += 1\n                    if triplet_count >= limit: break\n            if triplet_count >= limit: break",
                        "idea": "This cut combines the **Carlier Critical Subset** identification (Parent 1) with **Triangle Precedence Lifting** (Parent 2). It first identifies the specific subset of operations on the bottleneck machine that yields the tightest 1-machine lower bound. It then applies two synergistic strengthening layers strictly to this subset: (1) **Tight Displacement Cuts**, which lift start times based on the aggregate duration of predecessors in the critical window, and (2) **Triangle Cuts**, which enforce local transitivity ($i \\to k \\to j \\implies S_j \\ge S_i + p_i + p_k$). This focuses the computational effort of the $O(n^3)$ triangle cuts solely on the most contended operations, creating a tighter polyhedral approximation where it matters most."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.86,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 16.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 16.0,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 16.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.96,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.52,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.51,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.85,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.87,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.86,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.78,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.63,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "b165c800-214c-4492-bc72-b2ac1e8a9671",
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                },
                {
                    "id": "8f6cfb21-b9fc-4995-9dad-257ccacfbd18",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_distributed_bottleneck_cuts(m):\n        # 1. Calculate static Heads (r) and Tails (q)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper: Returns expression for 'u precedes v'\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.dist_cuts = pyo.ConstraintList()\n    \n        # 3. Iterate over ALL machines to find local critical subsets\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n    \n            # Identify the critical subset maximizing LB on this specific machine\n            best_lb = -1\n            crit_subset = []\n            crit_r = 0\n            crit_q = 0\n            \n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n    \n            for r_val in r_vals:\n                for q_val in q_vals:\n                    # Operations strictly inside the window defined by r_val and q_val\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if len(subset) < 2: continue\n    \n                    current_lb = r_val + sum(m.p[op] for op in subset) + q_val\n                    if current_lb > best_lb:\n                        best_lb = current_lb\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n            # 4. Apply Tight Displacement Cuts to the machine's critical subset\n            if crit_subset:\n                for u in crit_subset:\n                    # Enforce: S[u] >= min_head + sum(p_v * y_vu for v in subset)\n                    pred_work = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n                    m.dist_cuts.add(m.S[u] >= crit_r + pred_work)\n    \n                    # Enforce: Cmax >= S[u] + p[u] + sum(p_v * y_uv for v in subset) + min_tail\n                    succ_work = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n                    m.dist_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n\n    return model\n",
                        "added_cut": "def add_distributed_bottleneck_cuts(m):\n    # 1. Calculate static Heads (r) and Tails (q)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper: Returns expression for 'u precedes v'\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.dist_cuts = pyo.ConstraintList()\n\n    # 3. Iterate over ALL machines to find local critical subsets\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n\n        # Identify the critical subset maximizing LB on this specific machine\n        best_lb = -1\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n        \n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n\n        for r_val in r_vals:\n            for q_val in q_vals:\n                # Operations strictly inside the window defined by r_val and q_val\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if len(subset) < 2: continue\n\n                current_lb = r_val + sum(m.p[op] for op in subset) + q_val\n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n        # 4. Apply Tight Displacement Cuts to the machine's critical subset\n        if crit_subset:\n            for u in crit_subset:\n                # Enforce: S[u] >= min_head + sum(p_v * y_vu for v in subset)\n                pred_work = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n                m.dist_cuts.add(m.S[u] >= crit_r + pred_work)\n\n                # Enforce: Cmax >= S[u] + p[u] + sum(p_v * y_uv for v in subset) + min_tail\n                succ_work = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n                m.dist_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)",
                        "idea": "Distributed Critical Displacement: Unlike the parent approach which focused solely on the single global bottleneck, this strategy computes the critical subset (the set of operations maximizing the 1-machine lower bound) for *every* machine independently. It then applies tight edge-finding-style displacement cuts to each of these local subsets. This prevents 'bottleneck shifting'where fixing the primary bottleneck allows the solver to exploit slack in secondary bottlenecksand creates a uniformly stronger LP relaxation across the entire shop floor."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.98,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.72,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.54,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.4,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.39,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.93,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.86,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.68,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.67,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.8,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.01,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "b165c800-214c-4492-bc72-b2ac1e8a9671"
                    ]
                },
                {
                    "id": "b4bcfe80-260e-45c6-9356-6ee51cbd9483",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_subset_hybrid_cuts(m):\n        # 1. Compute Heads (r) and Tails (q) based on job precedence\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify the Global Critical Subset (Bottleneck)\n        # We search for the machine and time interval [r, q] that maximizes the\n        # Carlier Lower Bound: LB = r + sum(p) + q.\n        best_lb = -1\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Candidate r and q values come from the operations themselves\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            for r_val in r_vals:\n                for q_val in q_vals:\n                    # Operations fully contained in the window\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    current_lb = r_val + p_sum + q_val\n                    \n                    if current_lb > best_lb:\n                        best_lb = current_lb\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n    \n        # 4. Lift Global Lower Bound\n        if best_lb > 0:\n            m.hybrid_cuts.add(m.Cmax >= best_lb)\n    \n        # 5. Apply Hybrid Cuts on the Critical Subset\n        # We combine Parent 1's \"Tight Displacement\" and Parent 2's \"Triangle Precedence\"\n        # exclusively on the critical subset. This concentrates solver effort where it matters most.\n        if crit_subset:\n            \n            # Helper: returns expression for \"u precedes v\" (binary)\n            def get_y(u, v):\n                # m.y is defined for pairs sorted lexicographically\n                if u < v:\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # A. Input/Output Displacement Cuts (Parent 1)\n            # These bind the start times and Cmax tightly using the subset's specific r/q bounds.\n            # S_u >= r_subset + sum(p_v) for all v preceding u in the subset.\n            for u in crit_subset:\n                pred_work = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n                m.hybrid_cuts.add(m.S[u] >= crit_r + pred_work)\n                \n                succ_work = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n    \n            # B. Triangle Precedence Cuts (Parent 2)\n            # Enforces local transitivity (i->k->j) specifically within the high-contention subset.\n            # This strengthens the binary polyhedron, helping the Displacement cuts (which rely on y) work better.\n            tri_count = 0\n            tri_limit = 100\n            \n            for i in crit_subset:\n                for j in crit_subset:\n                    if i == j: continue\n                    y_ij = get_y(i, j)\n                    \n                    for k in crit_subset:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # If i->k and k->j, the delay between i and j must include p[k]\n                        m.hybrid_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        tri_count += 1\n                        if tri_count >= tri_limit: break\n                if tri_count >= tri_limit: break\n    \n    add_critical_subset_hybrid_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_critical_subset_hybrid_cuts(m):\n    # 1. Compute Heads (r) and Tails (q) based on job precedence\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify the Global Critical Subset (Bottleneck)\n    # We search for the machine and time interval [r, q] that maximizes the\n    # Carlier Lower Bound: LB = r + sum(p) + q.\n    best_lb = -1\n    crit_subset = []\n    crit_r = 0\n    crit_q = 0\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Candidate r and q values come from the operations themselves\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        for r_val in r_vals:\n            for q_val in q_vals:\n                # Operations fully contained in the window\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                current_lb = r_val + p_sum + q_val\n                \n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n    m.hybrid_cuts = pyo.ConstraintList()\n\n    # 4. Lift Global Lower Bound\n    if best_lb > 0:\n        m.hybrid_cuts.add(m.Cmax >= best_lb)\n\n    # 5. Apply Hybrid Cuts on the Critical Subset\n    # We combine Parent 1's \"Tight Displacement\" and Parent 2's \"Triangle Precedence\"\n    # exclusively on the critical subset. This concentrates solver effort where it matters most.\n    if crit_subset:\n        \n        # Helper: returns expression for \"u precedes v\" (binary)\n        def get_y(u, v):\n            # m.y is defined for pairs sorted lexicographically\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # A. Input/Output Displacement Cuts (Parent 1)\n        # These bind the start times and Cmax tightly using the subset's specific r/q bounds.\n        # S_u >= r_subset + sum(p_v) for all v preceding u in the subset.\n        for u in crit_subset:\n            pred_work = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n            m.hybrid_cuts.add(m.S[u] >= crit_r + pred_work)\n            \n            succ_work = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n\n        # B. Triangle Precedence Cuts (Parent 2)\n        # Enforces local transitivity (i->k->j) specifically within the high-contention subset.\n        # This strengthens the binary polyhedron, helping the Displacement cuts (which rely on y) work better.\n        tri_count = 0\n        tri_limit = 100\n        \n        for i in crit_subset:\n            for j in crit_subset:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in crit_subset:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # If i->k and k->j, the delay between i and j must include p[k]\n                    m.hybrid_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    tri_count += 1\n                    if tri_count >= tri_limit: break\n            if tri_count >= tri_limit: break\n\nadd_critical_subset_hybrid_cuts(model)",
                        "idea": "We integrate Parent 1's critical subset identification with the strengths of both parents to form a unified bottleneck cut. First, we identify the specific subset of operations (on one machine) that generates the maximal Carlier Lower Bound ($r_{min} + \\sum p + q_{min}$). We lift the global $C_{max}$ with this bound. Then, exclusively on this critical subset, we apply (A) Parent 1's Displacement cuts (which tightly bind start times based on predecessor volume relative to the subset's $r_{min}$) and (B) Parent 2's Triangle cuts (which enforce transitivity $i \\to k \\to j$). This targets the computationally expensive triangle cuts only where contention is highest, while the displacement cuts leverage the strengthened binary variables to propagate tight time bounds."
                    },
                    "fitness": 16.955297677649053,
                    "solver_reports": [
                        {
                            "total_time": 9.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 23867,
                            "explored_time": 9.07,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 27133,
                            "explored_time": 9.75,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 32768,
                            "explored_time": 9.18,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.97,
                            "explored_nodes": 29,
                            "simplex_iterations": 45139,
                            "explored_time": 8.96,
                            "work_units": 10.08
                        },
                        {
                            "total_time": 9.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 33011,
                            "explored_time": 9.4,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.4286,
                            "total_time": 12.68,
                            "explored_nodes": 172,
                            "simplex_iterations": 75109,
                            "explored_time": 12.67,
                            "work_units": 12.55
                        },
                        {
                            "gap": 27.0019,
                            "total_time": 11.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 40309,
                            "explored_time": 11.95,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 9.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 20582,
                            "explored_time": 9.4,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "b165c800-214c-4492-bc72-b2ac1e8a9671",
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                }
            ],
            19.745839703599053
        ],
        [
            [
                {
                    "id": "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_lifted_bottleneck_cuts(m):\n        # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n        # to ensure self-contained execution.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Container for new constraints\n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        for mid, ops in mach_ops.items():\n            # Data: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Sort unique thresholds\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n            for r in rs:\n                for q in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            # Add cut: Cmax must be >= tightest 1-machine relaxation\n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n        # Only applied to the identified bottleneck machine to keep size manageable.\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to get the expression for \"u precedes v\"\n            # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n            def get_precedence_expr(u, v):\n                if u < v:\n                    # Variable exists as y[u, v]\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n            # We limit n_cuts to avoid memory explosion if the machine has many ops\n            cut_count = 0\n            limit = 100 \n            \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Base precedence var: i -> j\n                    y_ij = get_precedence_expr(i, j)\n                    \n                    # Identify intermediate node k\n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_precedence_expr(i, k)\n                        y_kj = get_precedence_expr(k, j)\n                        \n                        # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                        # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        # Logic: \n                        #   If y_ij=1 (i->j active):\n                        #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                        #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                        #      Else:\n                        #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                        #   If y_ij=0 (i->j inactive):\n                        #      RHS is large negative (Valid due to bigM)\n                        \n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count > limit: break\n                if cut_count > limit: break\n    \n    apply_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_lifted_bottleneck_cuts(m):\n    # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n    # to ensure self-contained execution.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Container for new constraints\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    for mid, ops in mach_ops.items():\n        # Data: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Sort unique thresholds\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n        for r in rs:\n            for q in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        # Add cut: Cmax must be >= tightest 1-machine relaxation\n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n    # Only applied to the identified bottleneck machine to keep size manageable.\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to get the expression for \"u precedes v\"\n        # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n        def get_precedence_expr(u, v):\n            if u < v:\n                # Variable exists as y[u, v]\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n        # We limit n_cuts to avoid memory explosion if the machine has many ops\n        cut_count = 0\n        limit = 100 \n        \n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Base precedence var: i -> j\n                y_ij = get_precedence_expr(i, j)\n                \n                # Identify intermediate node k\n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_precedence_expr(i, k)\n                    y_kj = get_precedence_expr(k, j)\n                    \n                    # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                    # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    # Logic: \n                    #   If y_ij=1 (i->j active):\n                    #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                    #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                    #      Else:\n                    #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                    #   If y_ij=0 (i->j inactive):\n                    #      RHS is large negative (Valid due to bigM)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count > limit: break\n            if cut_count > limit: break\n\napply_lifted_bottleneck_cuts(model)",
                        "idea": "We apply **Bottleneck-Focused Triangle Lifting**. First, we strengthen the global lower bound by computing the **Carlier Bound** for every machine; this effectively lifts the `Cmax` constraint by solving the 1-machine head-tail problem exactly. Second, we identify the bottleneck machine (the one generating the max Carlier bound) and apply **Triangle Precedence Cuts** to it. These cuts lift the pairwise disjunctive constraints $S_j \\ge S_i + p_i$ by incorporating intermediate operations $k$: if $i \\to k \\to j$, the delay must include $p_k$. This creates a tighter polyhedral approximation for the critical machine, pruning fractional solutions where precedence is intransitive."
                    },
                    "fitness": 19.745839703599053,
                    "solver_reports": [
                        {
                            "gap": 22.6009,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 34291,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3984,
                            "total_time": 12.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 35151,
                            "explored_time": 12.71,
                            "work_units": 10.28
                        },
                        {
                            "gap": 34.8922,
                            "total_time": 11.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 30987,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6984,
                            "total_time": 13.28,
                            "explored_nodes": 59,
                            "simplex_iterations": 45527,
                            "explored_time": 13.27,
                            "work_units": 10.17
                        },
                        {
                            "total_time": 11.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34484,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.2529,
                            "total_time": 10.35,
                            "explored_nodes": 1497,
                            "simplex_iterations": 87588,
                            "explored_time": 10.34,
                            "work_units": 10.88
                        },
                        {
                            "gap": 25.8837,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 49577,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 39685,
                            "explored_time": 10.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "953456bd-bd70-4803-ab54-4778ff8de5b6"
                    ]
                },
                {
                    "id": "db1f7a09-dcc7-46d3-aff5-55d75688677f",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_lifted_bottleneck_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Static Heads (r) and Tails (q) based on Job Precedence\n        # Using sorted lists to ensure deterministic iteration order\n        J_sorted = sorted(m.J)\n        K_sorted = sorted(m.K)\n        \n        heads = {}\n        tails = {}\n        \n        for j in J_sorted:\n            t = 0\n            for k in K_sorted:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        for j in J_sorted:\n            t = 0\n            for k in reversed(K_sorted):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify the Critical Subset (Machine & Interval maximizing Carlier LB)\n        # Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = pyo.value(m.mach[j, k])\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        best_lb = -1\n        crit_subset = []\n        crit_r = 0\n        crit_q = 0\n    \n        for mid in mach_ops:\n            ops = mach_ops[mid]\n            if not ops: continue\n            \n            # Candidate r and q values from the operations in this machine group\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            for r_val in r_vals:\n                for q_val in q_vals:\n                    # Operations fully contained in the window [r, q]\n                    subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    current_lb = r_val + p_sum + q_val\n                    \n                    if current_lb > best_lb:\n                        best_lb = current_lb\n                        crit_subset = subset\n                        crit_r = r_val\n                        crit_q = q_val\n    \n        m.lifted_cuts = pyo.ConstraintList()\n    \n        if not crit_subset:\n            return\n    \n        # 3. Lift Global Lower Bound\n        if best_lb > 0:\n            m.lifted_cuts.add(m.Cmax >= best_lb)\n    \n        # Helper to access binary variables directionally\n        def get_y(u, v):\n            # m.y is defined for pairs (j1, k1, j2, k2) with (j1, k1) < (j2, k2)\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Input/Output Displacement Cuts\n        # Propagate the critical subset's bounds to individual start times and Cmax\n        for u in crit_subset:\n            # Input: S_u >= r_subset + sum(p_v for v in subset if v -> u)\n            pred_work = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n            m.lifted_cuts.add(m.S[u] >= crit_r + pred_work)\n            \n            # Output: Cmax >= S_u + p_u + sum(p_v for v in subset if u -> v) + q_subset\n            succ_work = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n            m.lifted_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n    \n        # 5. Pairwise Carlier Lifting\n        # Adds conditional lower bounds for pairs in the critical subset\n        for i in crit_subset:\n            for j in crit_subset:\n                if i >= j: continue\n                \n                # Calculate conditional LB if i->j or j->i\n                lb_ij = heads[i] + m.p[i] + m.p[j] + tails[j]\n                lb_ji = heads[j] + m.p[j] + m.p[i] + tails[i]\n    \n                # Add cut only if it tightens the static best_lb\n                if lb_ij > best_lb or lb_ji > best_lb:\n                    y_ij = get_y(i, j)\n                    m.lifted_cuts.add(\n                        m.Cmax >= lb_ij * y_ij + lb_ji * (1 - y_ij)\n                    )\n    \n        # 6. Triangle Transitivity Cuts\n        # Enforce i -> k -> j delay using global BigM for safety\n        tri_count = 0\n        tri_limit = 50\n        \n        for i in crit_subset:\n            for j in crit_subset:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in crit_subset:\n                    if k == i or k == j: continue\n                    \n                    # If i -> k and k -> j, then S_j >= S_i + p_i + p_k\n                    # This is only active if y_ik=1 and y_kj=1. If y_ij=0 (j->i), BigM relaxes it.\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    tri_count += 1\n                    if tri_count >= tri_limit: break\n            if tri_count >= tri_limit: break\n    \n    add_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_lifted_bottleneck_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Static Heads (r) and Tails (q) based on Job Precedence\n    # Using sorted lists to ensure deterministic iteration order\n    J_sorted = sorted(m.J)\n    K_sorted = sorted(m.K)\n    \n    heads = {}\n    tails = {}\n    \n    for j in J_sorted:\n        t = 0\n        for k in K_sorted:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    for j in J_sorted:\n        t = 0\n        for k in reversed(K_sorted):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify the Critical Subset (Machine & Interval maximizing Carlier LB)\n    # Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = pyo.value(m.mach[j, k])\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    best_lb = -1\n    crit_subset = []\n    crit_r = 0\n    crit_q = 0\n\n    for mid in mach_ops:\n        ops = mach_ops[mid]\n        if not ops: continue\n        \n        # Candidate r and q values from the operations in this machine group\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        for r_val in r_vals:\n            for q_val in q_vals:\n                # Operations fully contained in the window [r, q]\n                subset = [op for op in ops if heads[op] >= r_val and tails[op] >= q_val]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                current_lb = r_val + p_sum + q_val\n                \n                if current_lb > best_lb:\n                    best_lb = current_lb\n                    crit_subset = subset\n                    crit_r = r_val\n                    crit_q = q_val\n\n    m.lifted_cuts = pyo.ConstraintList()\n\n    if not crit_subset:\n        return\n\n    # 3. Lift Global Lower Bound\n    if best_lb > 0:\n        m.lifted_cuts.add(m.Cmax >= best_lb)\n\n    # Helper to access binary variables directionally\n    def get_y(u, v):\n        # m.y is defined for pairs (j1, k1, j2, k2) with (j1, k1) < (j2, k2)\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Input/Output Displacement Cuts\n    # Propagate the critical subset's bounds to individual start times and Cmax\n    for u in crit_subset:\n        # Input: S_u >= r_subset + sum(p_v for v in subset if v -> u)\n        pred_work = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n        m.lifted_cuts.add(m.S[u] >= crit_r + pred_work)\n        \n        # Output: Cmax >= S_u + p_u + sum(p_v for v in subset if u -> v) + q_subset\n        succ_work = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n        m.lifted_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_work + crit_q)\n\n    # 5. Pairwise Carlier Lifting\n    # Adds conditional lower bounds for pairs in the critical subset\n    for i in crit_subset:\n        for j in crit_subset:\n            if i >= j: continue\n            \n            # Calculate conditional LB if i->j or j->i\n            lb_ij = heads[i] + m.p[i] + m.p[j] + tails[j]\n            lb_ji = heads[j] + m.p[j] + m.p[i] + tails[i]\n\n            # Add cut only if it tightens the static best_lb\n            if lb_ij > best_lb or lb_ji > best_lb:\n                y_ij = get_y(i, j)\n                m.lifted_cuts.add(\n                    m.Cmax >= lb_ij * y_ij + lb_ji * (1 - y_ij)\n                )\n\n    # 6. Triangle Transitivity Cuts\n    # Enforce i -> k -> j delay using global BigM for safety\n    tri_count = 0\n    tri_limit = 50\n    \n    for i in crit_subset:\n        for j in crit_subset:\n            if i == j: continue\n            y_ij = get_y(i, j)\n            \n            for k in crit_subset:\n                if k == i or k == j: continue\n                \n                # If i -> k and k -> j, then S_j >= S_i + p_i + p_k\n                # This is only active if y_ik=1 and y_kj=1. If y_ij=0 (j->i), BigM relaxes it.\n                y_ik = get_y(i, k)\n                y_kj = get_y(k, j)\n                \n                m.lifted_cuts.add(\n                    m.S[j] >= m.S[i] + m.p[i] + \n                    m.p[k] * (y_ik + y_kj - 1) - \n                    m.bigM * (1 - y_ij)\n                )\n                \n                tri_count += 1\n                if tri_count >= tri_limit: break\n        if tri_count >= tri_limit: break\n\nadd_lifted_bottleneck_cuts(model)",
                        "idea": "We perform a lifting-based mutation of the provided idea by focusing on the **Carlier Bottleneck Subset** $\\Omega$ of a single machine. First, we identify $\\Omega$ that maximizes the static lower bound $LB = r_{\\min} + \\sum_{v \\in \\Omega} p_v + q_{\\min}$. We lift the global $C_{\\max}$ with this bound. We then apply **Input/Output Displacement cuts**, which lift the release and tail bounds of individual operations $u \\in \\Omega$ by adding the processing times of their sequenced predecessors/successors ($S_u \\ge r_{\\Omega} + \\sum_{v \\to u} p_v$). Finally, we incorporate **Pairwise Carlier cuts** that enforce sequence-dependent lower bounds stronger than the static bottleneck value, and **Triangle cuts** with Big-M relaxation to enforce local transitivity within the critical cluster."
                    },
                    "fitness": 18.610234053132718,
                    "solver_reports": [
                        {
                            "total_time": 9.42,
                            "explored_nodes": 1,
                            "simplex_iterations": 28837,
                            "explored_time": 9.37,
                            "work_units": 10.0
                        },
                        {
                            "gap": 32.5698,
                            "total_time": 12.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 30883,
                            "explored_time": 11.99,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 19410,
                            "explored_time": 9.98,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.982,
                            "total_time": 10.85,
                            "explored_nodes": 27,
                            "simplex_iterations": 50098,
                            "explored_time": 10.84,
                            "work_units": 10.07
                        },
                        {
                            "total_time": 8.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 17317,
                            "explored_time": 8.93,
                            "work_units": 10.01
                        },
                        {
                            "gap": 19.201,
                            "total_time": 11.69,
                            "explored_nodes": 172,
                            "simplex_iterations": 72068,
                            "explored_time": 11.68,
                            "work_units": 11.76
                        },
                        {
                            "total_time": 10.13,
                            "explored_nodes": 1,
                            "simplex_iterations": 40383,
                            "explored_time": 10.1,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.57,
                            "explored_nodes": 1,
                            "simplex_iterations": 23903,
                            "explored_time": 9.51,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "b4bcfe80-260e-45c6-9356-6ee51cbd9483"
                    ]
                },
                {
                    "id": "d3e4eff1-1e92-4806-8440-0bb888f03531",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_position_based_cuts(m):\n        \"\"\"\n        Applies Position-Based Cumulative Cuts to the bottleneck machine.\n        These cuts enforce that an operation's start time must account for the \n        sum of processing times of all operations sequenced before it, plus the \n        machine's earliest availability.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # 1. Compute Static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Bottleneck Machine (using Carlier Bound heuristic)\n        bottleneck_mach = None\n        max_lb = -1\n        \n        for mid, ops in mach_ops.items():\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            local_max = 0\n            for r in rs:\n                for q in qs:\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            if local_max > max_lb:\n                max_lb = local_max\n                bottleneck_mach = mid\n    \n        # Container for new cuts\n        m.position_cuts = pyo.ConstraintList()\n    \n        # 4. Apply Cumulative Cuts on Bottleneck\n        if bottleneck_mach is not None:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Bounds for the machine's active window\n            min_head = min(heads[op] for op in ops)\n            min_tail = min(tails[op] for op in ops)\n            \n            # Helper: returns expression for \"j precedes i\" (value 1 if j->i, else 0)\n            def get_prec_expr(j, i):\n                # Check lexicographical order to access the correct binary variable\n                if j < i:\n                    # Variable is y[j, i]. If 1, j->i.\n                    return m.y[j[0], j[1], i[0], i[1]]\n                else:\n                    # Variable is y[i, j]. If 0, j->i.\n                    return 1 - m.y[i[0], i[1], j[0], j[1]]\n    \n            for i in ops:\n                # (A) Predecessor Cumulative Cut\n                # S_i >= MinHead + Sum(processing_time[j] * is_predecessor(j,i))\n                # This aggregates the \"volume\" of all operations j that precede i.\n                pred_sum = sum(m.p[j] * get_prec_expr(j, i) for j in ops if j != i)\n                m.position_cuts.add(\n                    m.S[i] >= min_head + pred_sum\n                )\n                \n                # (B) Successor Cumulative Cut\n                # Cmax >= S_i + p_i + Sum(processing_time[j] * is_successor(j,i)) + MinTail\n                # This links the remaining processing volume after i to the makespan.\n                succ_sum = sum(m.p[j] * get_prec_expr(i, j) for j in ops if j != i)\n                m.position_cuts.add(\n                    m.Cmax >= m.S[i] + m.p[i] + succ_sum + min_tail\n                )\n    \n    add_position_based_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_position_based_cuts(m):\n    \"\"\"\n    Applies Position-Based Cumulative Cuts to the bottleneck machine.\n    These cuts enforce that an operation's start time must account for the \n    sum of processing times of all operations sequenced before it, plus the \n    machine's earliest availability.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # 1. Compute Static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Bottleneck Machine (using Carlier Bound heuristic)\n    bottleneck_mach = None\n    max_lb = -1\n    \n    for mid, ops in mach_ops.items():\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        local_max = 0\n        for r in rs:\n            for q in qs:\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        if local_max > max_lb:\n            max_lb = local_max\n            bottleneck_mach = mid\n\n    # Container for new cuts\n    m.position_cuts = pyo.ConstraintList()\n\n    # 4. Apply Cumulative Cuts on Bottleneck\n    if bottleneck_mach is not None:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Bounds for the machine's active window\n        min_head = min(heads[op] for op in ops)\n        min_tail = min(tails[op] for op in ops)\n        \n        # Helper: returns expression for \"j precedes i\" (value 1 if j->i, else 0)\n        def get_prec_expr(j, i):\n            # Check lexicographical order to access the correct binary variable\n            if j < i:\n                # Variable is y[j, i]. If 1, j->i.\n                return m.y[j[0], j[1], i[0], i[1]]\n            else:\n                # Variable is y[i, j]. If 0, j->i.\n                return 1 - m.y[i[0], i[1], j[0], j[1]]\n\n        for i in ops:\n            # (A) Predecessor Cumulative Cut\n            # S_i >= MinHead + Sum(processing_time[j] * is_predecessor(j,i))\n            # This aggregates the \"volume\" of all operations j that precede i.\n            pred_sum = sum(m.p[j] * get_prec_expr(j, i) for j in ops if j != i)\n            m.position_cuts.add(\n                m.S[i] >= min_head + pred_sum\n            )\n            \n            # (B) Successor Cumulative Cut\n            # Cmax >= S_i + p_i + Sum(processing_time[j] * is_successor(j,i)) + MinTail\n            # This links the remaining processing volume after i to the makespan.\n            succ_sum = sum(m.p[j] * get_prec_expr(i, j) for j in ops if j != i)\n            m.position_cuts.add(\n                m.Cmax >= m.S[i] + m.p[i] + succ_sum + min_tail\n            )\n\nadd_position_based_cuts(model)",
                        "idea": "We introduce **Position-Based Cumulative Cuts** (or Linearized Disjunctive Rank Cuts) on the bottleneck machine. Unlike the parents which rely on local **triplet** logic ($i, j, k$) to lift precedence bounds, this strategy applies **global aggregation** constraints. For every operation $i$, we enforce that its start time must exceed the machine's earliest availability plus the sum of processing times of *all* operations sequenced before it ($S_i \\ge r_{\\min} + \\sum_{j \\ne i} p_j y_{ji}$). This approach provides a complementary strengthening of the LP relaxation by forcing continuous start times to align with the 'volume' of fractional binary precedence variables, directly counteracting the weakness of Big-M constraints without requiring the enumeration of subsets or triangles."
                    },
                    "fitness": 14.495031027409846,
                    "solver_reports": [
                        {
                            "total_time": 9.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 21950,
                            "explored_time": 9.61,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 27579,
                            "explored_time": 9.67,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 23774,
                            "explored_time": 9.66,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.1,
                            "explored_nodes": 259,
                            "simplex_iterations": 124379,
                            "explored_time": 9.09,
                            "work_units": 10.65
                        },
                        {
                            "gap": 93.5315,
                            "total_time": 8.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 17099,
                            "explored_time": 8.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.0445,
                            "total_time": 8.79,
                            "explored_nodes": 4201,
                            "simplex_iterations": 278692,
                            "explored_time": 8.78,
                            "work_units": 10.1
                        },
                        {
                            "gap": 31.6047,
                            "total_time": 10.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 29393,
                            "explored_time": 10.82,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 22428,
                            "explored_time": 9.46,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "c22c7a45-fd8d-4124-83c2-95e11776d020"
                    ]
                },
                {
                    "id": "191b37c8-0c43-4cb7-8602-4a89b5858fa0",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_bottleneck_transitivity_cuts(m):\n        # 1. Compute Release (heads) and Tail (tails) times for all operations\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Bottleneck and Apply Global Cuts\n        max_lb = 0\n        bottleneck_mach = None\n        m.transitivity_cuts = pyo.ConstraintList()\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # 1-Machine Lower Bound: min(heads) + sum(p) + min(tails)\n            r_min = min(heads[op] for op in ops)\n            q_min = min(tails[op] for op in ops)\n            p_sum = sum(m.p[op] for op in ops)\n            lb = r_min + p_sum + q_min\n            \n            # Strengthen global makespan\n            if lb > 0:\n                m.transitivity_cuts.add(m.Cmax >= lb)\n                \n            if lb > max_lb:\n                max_lb = lb\n                bottleneck_mach = mid\n    \n        # 4. Apply Logic & Time Lifting on Bottleneck Machine\n        if bottleneck_mach is not None:\n            ops = mach_ops[bottleneck_mach]\n            # Sort ops by release time; focuses cuts on likely sequences\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            \n            def get_y(u, v):\n                # Helper: returns y[u,v] if u<v else 1-y[v,u]\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n                \n            # Apply cuts to triplets (i, k, j) within a sliding window\n            window = 8\n            n_ops = len(sorted_ops)\n            for idx_i in range(n_ops):\n                i = sorted_ops[idx_i]\n                for idx_j in range(idx_i + 1, min(idx_i + window, n_ops)):\n                    j = sorted_ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = sorted_ops[idx_k]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Logical Transitivity: Prevent cycles in LP relaxation\n                        # If i->k and k->j, force i->j (y_ij=1)\n                        m.transitivity_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Lifted Precedence: S_j >= S_i + p_i + p_k\n                        # If path i->k->j is active, we get tighter bound than S_i + p_i\n                        # The term (y_ik + y_kj - 1) becomes 1 if both active, 0 or -1 otherwise.\n                        m.transitivity_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + m.p[k] * (y_ik + y_kj - 1) - m.bigM * (1 - y_ij)\n                        )\n    \n    apply_bottleneck_transitivity_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_bottleneck_transitivity_cuts(m):\n    # 1. Compute Release (heads) and Tail (tails) times for all operations\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Bottleneck and Apply Global Cuts\n    max_lb = 0\n    bottleneck_mach = None\n    m.transitivity_cuts = pyo.ConstraintList()\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # 1-Machine Lower Bound: min(heads) + sum(p) + min(tails)\n        r_min = min(heads[op] for op in ops)\n        q_min = min(tails[op] for op in ops)\n        p_sum = sum(m.p[op] for op in ops)\n        lb = r_min + p_sum + q_min\n        \n        # Strengthen global makespan\n        if lb > 0:\n            m.transitivity_cuts.add(m.Cmax >= lb)\n            \n        if lb > max_lb:\n            max_lb = lb\n            bottleneck_mach = mid\n\n    # 4. Apply Logic & Time Lifting on Bottleneck Machine\n    if bottleneck_mach is not None:\n        ops = mach_ops[bottleneck_mach]\n        # Sort ops by release time; focuses cuts on likely sequences\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        \n        def get_y(u, v):\n            # Helper: returns y[u,v] if u<v else 1-y[v,u]\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        # Apply cuts to triplets (i, k, j) within a sliding window\n        window = 8\n        n_ops = len(sorted_ops)\n        for idx_i in range(n_ops):\n            i = sorted_ops[idx_i]\n            for idx_j in range(idx_i + 1, min(idx_i + window, n_ops)):\n                j = sorted_ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = sorted_ops[idx_k]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Logical Transitivity: Prevent cycles in LP relaxation\n                    # If i->k and k->j, force i->j (y_ij=1)\n                    m.transitivity_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Lifted Precedence: S_j >= S_i + p_i + p_k\n                    # If path i->k->j is active, we get tighter bound than S_i + p_i\n                    # The term (y_ik + y_kj - 1) becomes 1 if both active, 0 or -1 otherwise.\n                    m.transitivity_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + m.p[k] * (y_ik + y_kj - 1) - m.bigM * (1 - y_ij)\n                    )\n\napply_bottleneck_transitivity_cuts(model)",
                        "idea": "We apply **Bottleneck Transitivity & Head-Tail Lifting**. We compute release ($r$) and tail ($q$) times to impose a 1-machine lower bound on $C_{max}$ globally. Focusing on the bottleneck machine (highest bound), we sort operations by $r$ and iterate through triplets $(i, k, j)$. We add logical transitivity cuts $y_{ik} + y_{kj} - y_{ij} \\le 1$ and lifted precedence cuts $S_j \\ge S_i + p_i + p_k (y_{ik} + y_{kj} - 1) - M(1 - y_{ij})$. This prunes fractional cycles and strengthens the relaxation by linking binary transitivity with continuous temporal bounds."
                    },
                    "fitness": 19.416394640737803,
                    "solver_reports": [
                        {
                            "gap": 19.4444,
                            "total_time": 13.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 32361,
                            "explored_time": 13.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.127,
                            "total_time": 13.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 34785,
                            "explored_time": 13.32,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 29224,
                            "explored_time": 10.57,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.929,
                            "total_time": 13.68,
                            "explored_nodes": 1,
                            "simplex_iterations": 40502,
                            "explored_time": 13.66,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 9.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 35170,
                            "explored_time": 9.57,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.0927,
                            "total_time": 9.74,
                            "explored_nodes": 171,
                            "simplex_iterations": 43258,
                            "explored_time": 9.73,
                            "work_units": 10.61
                        },
                        {
                            "gap": 32.0134,
                            "total_time": 12.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 50941,
                            "explored_time": 12.46,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 35267,
                            "explored_time": 11.75,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                },
                {
                    "id": "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_multi_bottleneck_transitivity(m):\n        # 1. Dynamic Heads (r) and Tails (q) Calculation\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            # Iterate backwards safely using sorted list\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.multi_transitivity = pyo.ConstraintList()\n    \n        # Helper to access or construct precedence variables y_uv (u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Identify Critical Blocks for ALL machines (1-Machine Carlier Bound)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Prepare data: (r, p, q, op)\n            op_data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n            \n            # Optimization: only define windows based on existing r and q values\n            rs = sorted(list(set(d[0] for d in op_data)))\n            qs = sorted(list(set(d[2] for d in op_data)))\n            \n            best_lb = -1\n            best_subset = []\n            \n            # Brute-force window search for this machine\n            for r in rs:\n                for q in qs:\n                    # Select operations strictly contained in the window [r, end-q]\n                    sub = [d for d in op_data if d[0] >= r and d[2] >= q]\n                    if not sub: continue\n                    \n                    # Calculate 1-machine LB\n                    lb = r + sum(d[1] for d in sub) + q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_subset = [d[3] for d in sub]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_subset})\n    \n        if not candidates: return\n    \n        # 4. Select Top Bottlenecks (Hybrid Logic)\n        # Sort machines by their local lower bound descending\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        # Add the strongest discovered global lower bound\n        m.multi_transitivity.add(m.Cmax >= global_max)\n    \n        # Target machines that are active bottlenecks (e.g., within 85% of global max)\n        # This prevents focusing only on one machine while others are nearly critical\n        targets = [c for c in candidates if c['lb'] >= 0.85 * global_max]\n        \n        # Cap at top 3 to manage model size (Pareto efficiency)\n        targets = targets[:3]\n    \n        # 5. Apply Transitivity & Lifting Cuts to Critical Blocks\n        TOTAL_BUDGET = 500\n        cuts_added = 0\n    \n        for target in targets:\n            crit_ops = target['ops']\n            if len(crit_ops) < 3: continue\n            \n            # Sort heuristic: process by earliest release time\n            crit_ops.sort(key=lambda op: heads[op])\n    \n            for i in crit_ops:\n                for j in crit_ops:\n                    if i == j: continue\n                    y_ij = get_y(i, j)\n                    \n                    for k in crit_ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Transitivity: Enforce logical consistency in the critical block\n                        # If i->k and k->j, then i->j must be true\n                        m.multi_transitivity.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times based on path existence\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        # If y_ik=1 and y_kj=1, the term (y_ik + y_kj - 1) becomes 1, adding p_k\n                        m.multi_transitivity.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= TOTAL_BUDGET: break\n                    if cuts_added >= TOTAL_BUDGET: break\n                if cuts_added >= TOTAL_BUDGET: break\n            if cuts_added >= TOTAL_BUDGET: break\n    \n    add_multi_bottleneck_transitivity(model)\n\n    return model\n",
                        "added_cut": "def add_multi_bottleneck_transitivity(m):\n    # 1. Dynamic Heads (r) and Tails (q) Calculation\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        # Iterate backwards safely using sorted list\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.multi_transitivity = pyo.ConstraintList()\n\n    # Helper to access or construct precedence variables y_uv (u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Identify Critical Blocks for ALL machines (1-Machine Carlier Bound)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Prepare data: (r, p, q, op)\n        op_data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n        \n        # Optimization: only define windows based on existing r and q values\n        rs = sorted(list(set(d[0] for d in op_data)))\n        qs = sorted(list(set(d[2] for d in op_data)))\n        \n        best_lb = -1\n        best_subset = []\n        \n        # Brute-force window search for this machine\n        for r in rs:\n            for q in qs:\n                # Select operations strictly contained in the window [r, end-q]\n                sub = [d for d in op_data if d[0] >= r and d[2] >= q]\n                if not sub: continue\n                \n                # Calculate 1-machine LB\n                lb = r + sum(d[1] for d in sub) + q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_subset = [d[3] for d in sub]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_subset})\n\n    if not candidates: return\n\n    # 4. Select Top Bottlenecks (Hybrid Logic)\n    # Sort machines by their local lower bound descending\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    # Add the strongest discovered global lower bound\n    m.multi_transitivity.add(m.Cmax >= global_max)\n\n    # Target machines that are active bottlenecks (e.g., within 85% of global max)\n    # This prevents focusing only on one machine while others are nearly critical\n    targets = [c for c in candidates if c['lb'] >= 0.85 * global_max]\n    \n    # Cap at top 3 to manage model size (Pareto efficiency)\n    targets = targets[:3]\n\n    # 5. Apply Transitivity & Lifting Cuts to Critical Blocks\n    TOTAL_BUDGET = 500\n    cuts_added = 0\n\n    for target in targets:\n        crit_ops = target['ops']\n        if len(crit_ops) < 3: continue\n        \n        # Sort heuristic: process by earliest release time\n        crit_ops.sort(key=lambda op: heads[op])\n\n        for i in crit_ops:\n            for j in crit_ops:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in crit_ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity: Enforce logical consistency in the critical block\n                    # If i->k and k->j, then i->j must be true\n                    m.multi_transitivity.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times based on path existence\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    # If y_ik=1 and y_kj=1, the term (y_ik + y_kj - 1) becomes 1, adding p_k\n                    m.multi_transitivity.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= TOTAL_BUDGET: break\n                if cuts_added >= TOTAL_BUDGET: break\n            if cuts_added >= TOTAL_BUDGET: break\n        if cuts_added >= TOTAL_BUDGET: break\n\nadd_multi_bottleneck_transitivity(model)",
                        "idea": "We introduce **Multi-Bottleneck Transitivity**, a hybrid strategy that generalizes the critical window logic of Parent 1 to the top $k$ competing bottlenecks identified via Carlier bound analysis. Instead of indiscriminately applying loose bounds to all machines (Parent 2) or focusing solely on the single global maximum (Parent 1), this approach targets the specific subsets of operations ('Critical Blocks') on the most contentious machines. Within these blocks, it enforces strict **Transitivity** ($y_{ik} + y_{kj} \\le 1 + y_{ij}$) and **Metric Lifting** ($S_j \\ge S_i + p_i + p_k$ via binary activation). This creates a tight, robust polyhedral approximation that prevents infeasibilities from simply shifting to secondary bottlenecks when the primary one is resolved."
                    },
                    "fitness": 19.36876975326374,
                    "solver_reports": [
                        {
                            "gap": 16.7693,
                            "total_time": 13.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 36467,
                            "explored_time": 13.25,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.5741,
                            "total_time": 12.61,
                            "explored_nodes": 1,
                            "simplex_iterations": 34860,
                            "explored_time": 12.56,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 32578,
                            "explored_time": 12.16,
                            "work_units": 10.01
                        },
                        {
                            "gap": 25.0211,
                            "total_time": 12.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 37159,
                            "explored_time": 12.49,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 31772,
                            "explored_time": 10.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.8333,
                            "total_time": 12.37,
                            "explored_nodes": 1173,
                            "simplex_iterations": 90510,
                            "explored_time": 12.36,
                            "work_units": 11.31
                        },
                        {
                            "gap": 39.7317,
                            "total_time": 12.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 55092,
                            "explored_time": 12.12,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.9943,
                            "total_time": 12.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 35217,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "c22c7a45-fd8d-4124-83c2-95e11776d020",
                        "7e111dde-288a-4f56-b45d-a88d3c2817e7"
                    ]
                },
                {
                    "id": "282fa1e0-2b05-4421-9081-0be620845965",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_refined_block_displacement_cuts(m):\n        # 1. Compute Static Heads (r) and Tails (q)\n        # These serve as valid lower bounds for earliest start and time-to-end\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # Helper: Access disjunctive variable y_uv correctly based on index order\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.block_disp_cuts = pyo.ConstraintList()\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks and Apply Cuts\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n    \n            # Sort operations by their static release times (heads)\n            # This allows scanning contiguous time-blocks efficiently\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Find the interval [i, j] maximizing the 1-machine Carlier Bound\n            # LB = min(heads) + sum(p) + min(tails) within the subset\n            best_lb = -1\n            crit_subset = []\n            block_r = 0\n            block_q = 0\n    \n            # Iterate over all contiguous sub-sequences (blocks)\n            for i in range(n):\n                current_p = 0\n                # Since sorted by head, min_head for range [i, j] is heads[sorted_ops[i]]\n                current_r = heads[sorted_ops[i]]\n                \n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    current_p += m.p[op]\n                    \n                    subset = sorted_ops[i : j+1]\n                    # Calculate min tail for this specific subset\n                    current_q = min(tails[o] for o in subset)\n                    \n                    lb = current_r + current_p + current_q\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        crit_subset = subset\n                        block_r = current_r\n                        block_q = current_q\n    \n            # 4. Add Displacement Cuts for the tightest block found\n            # These cuts lift the start times and makespan based on internal sequencing\n            if len(crit_subset) >= 2:\n                for u in crit_subset:\n                    # Forward Displacement: S_u >= r_block + Sum(p_v * y_vu for v in block)\n                    # u must start after the block's earliest start plus all predecessors in the block\n                    pred_term = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n                    m.block_disp_cuts.add(m.S[u] >= block_r + pred_term)\n    \n                    # Backward/Makespan Displacement: \n                    # Cmax >= S_u + p_u + Sum(p_v * y_uv for v in block) + q_block\n                    # The makespan accommodates u, all its successors in the block, and the block's tail\n                    succ_term = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n                    m.block_disp_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_term + block_q)\n\n    return model\n",
                        "added_cut": "def add_refined_block_displacement_cuts(m):\n    # 1. Compute Static Heads (r) and Tails (q)\n    # These serve as valid lower bounds for earliest start and time-to-end\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # Helper: Access disjunctive variable y_uv correctly based on index order\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.block_disp_cuts = pyo.ConstraintList()\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks and Apply Cuts\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n\n        # Sort operations by their static release times (heads)\n        # This allows scanning contiguous time-blocks efficiently\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Find the interval [i, j] maximizing the 1-machine Carlier Bound\n        # LB = min(heads) + sum(p) + min(tails) within the subset\n        best_lb = -1\n        crit_subset = []\n        block_r = 0\n        block_q = 0\n\n        # Iterate over all contiguous sub-sequences (blocks)\n        for i in range(n):\n            current_p = 0\n            # Since sorted by head, min_head for range [i, j] is heads[sorted_ops[i]]\n            current_r = heads[sorted_ops[i]]\n            \n            for j in range(i, n):\n                op = sorted_ops[j]\n                current_p += m.p[op]\n                \n                subset = sorted_ops[i : j+1]\n                # Calculate min tail for this specific subset\n                current_q = min(tails[o] for o in subset)\n                \n                lb = current_r + current_p + current_q\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    crit_subset = subset\n                    block_r = current_r\n                    block_q = current_q\n\n        # 4. Add Displacement Cuts for the tightest block found\n        # These cuts lift the start times and makespan based on internal sequencing\n        if len(crit_subset) >= 2:\n            for u in crit_subset:\n                # Forward Displacement: S_u >= r_block + Sum(p_v * y_vu for v in block)\n                # u must start after the block's earliest start plus all predecessors in the block\n                pred_term = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n                m.block_disp_cuts.add(m.S[u] >= block_r + pred_term)\n\n                # Backward/Makespan Displacement: \n                # Cmax >= S_u + p_u + Sum(p_v * y_uv for v in block) + q_block\n                # The makespan accommodates u, all its successors in the block, and the block's tail\n                succ_term = sum(m.p[v] * get_y(u, v) for v in crit_subset if v != u)\n                m.block_disp_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_term + block_q)",
                        "idea": "Refined Block Displacement: This mutation strengthens the original distributed strategy by replacing the heuristic threshold search with a rigorous interval-based scan. By sorting operations on each machine by release times and checking all contiguous subsequences (blocks), it guarantees finding the specific subset with the maximal Carlier bound (Lower Bound). It then imposes displacement cuts using the exact minimal head and tail of this critical block. These cuts tighten the feasible region by enforcing that every operation in the block must accommodate the processing times of its variable-defined predecessors (relative to the block's earliest start) and successors (relative to the block's minimum tail), preventing slack exploitation in secondary constraints."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.94,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.68,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.64,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.31,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.67,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.66,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.28,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.49,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.11,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.1,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.67,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.63,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "8f6cfb21-b9fc-4995-9dad-257ccacfbd18"
                    ]
                },
                {
                    "id": "9a87ffe4-1596-48e6-82ed-1e21b06725b6",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_cumulative_machine_load_cuts(m):\n        # 1. Calculate static Earliest Start Times (heads) based on job predecessors\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.load_cuts = pyo.ConstraintList()\n    \n        # Helper to get the binary expression for \"u precedes v\"\n        def get_prec_var(u, v):\n            # m.y is indexed by Pairs (j1, k1, j2, k2) where (j1, k1) < (j2, k2)\n            # If u < v, y[u,v]=1 means u->v.\n            # If u > v, y[v,u]=1 means v->u, so u->v is 1 - y[v,u].\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Generate Cumulative Load Cuts\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            \n            # The earliest absolute time this machine can start processing anything\n            min_machine_head = min(heads[op] for op in ops)\n    \n            for j in ops:\n                # Construct the cumulative volume of all operations 'i' that precede 'j'\n                # S_j >= min_machine_head + sum(p_i * y_ij)\n                load_expr = 0\n                for i in ops:\n                    if i == j: continue\n                    load_expr += m.p[i] * get_prec_var(i, j)\n                \n                m.load_cuts.add(m.S[j] >= min_machine_head + load_expr)\n\n    return model\n",
                        "added_cut": "def add_cumulative_machine_load_cuts(m):\n    # 1. Calculate static Earliest Start Times (heads) based on job predecessors\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.load_cuts = pyo.ConstraintList()\n\n    # Helper to get the binary expression for \"u precedes v\"\n    def get_prec_var(u, v):\n        # m.y is indexed by Pairs (j1, k1, j2, k2) where (j1, k1) < (j2, k2)\n        # If u < v, y[u,v]=1 means u->v.\n        # If u > v, y[v,u]=1 means v->u, so u->v is 1 - y[v,u].\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Generate Cumulative Load Cuts\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        \n        # The earliest absolute time this machine can start processing anything\n        min_machine_head = min(heads[op] for op in ops)\n\n        for j in ops:\n            # Construct the cumulative volume of all operations 'i' that precede 'j'\n            # S_j >= min_machine_head + sum(p_i * y_ij)\n            load_expr = 0\n            for i in ops:\n                if i == j: continue\n                load_expr += m.p[i] * get_prec_var(i, j)\n            \n            m.load_cuts.add(m.S[j] >= min_machine_head + load_expr)",
                        "idea": "We implement **Cumulative Machine-Load Cuts**, a volume-based relaxation strategy. Unlike the input's focus on local critical paths (3-op sequences) and Carlier bounds, this strategy aggregates the total processing volume of all predecessors on a machine. By enforcing $S_j \\ge \\min(r_{mach}) + \\sum_{i \\in M} p_i y_{ij}$, we create a dense linear constraint linking the continuous start time $S_j$ to the global sum of binary precedence decisions. This cuts off fractional solutions where locally valid Big-M constraints are satisfied but the 'volume' of time required by chosen predecessors exceeds the variable's value, effectively lifting the floor of the schedule based on machine load."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.19,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.77,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.67,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.04,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.02,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.88,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.95,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.94,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.77,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.89,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "c22c7a45-fd8d-4124-83c2-95e11776d020"
                    ]
                },
                {
                    "id": "922c0ad8-0e6f-4a0f-878b-a47282b1b83d",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_windowed_transitivity_cuts(m):\n        # 1. Compute Heads (earliest start times) for sorting operations\n        # This helps identify operations that compete for the same time window.\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.trans_cuts = pyo.ConstraintList()\n    \n        # Helper to get the boolean expression for \"u precedes v\" (u -> v)\n        # Handles the fact that Pyomo var y is only defined for sorted pairs.\n        def y_expr(u, v):\n            if u < v:\n                # y[u,v]=1 means u->v\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # y[v,u]=1 means v->u, so u->v is 1 - y[v,u]\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Apply Local Transitivity Cuts\n        # Window size determines how many neighbors we consider. \n        # Small windows (e.g. 6) capture local contention efficiently O(N*W^3).\n        WINDOW = 6\n    \n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n    \n            # Sort operations by Release Time (Heads) to cluster competing tasks\n            sorted_ops = sorted(ops, key=lambda o: heads[o])\n            N = len(sorted_ops)\n    \n            for i in range(N):\n                # First op in triplet\n                op_a = sorted_ops[i]\n                \n                # Second op in triplet (from immediate neighbors)\n                for j in range(i + 1, min(N, i + WINDOW)):\n                    op_b = sorted_ops[j]\n                    \n                    # Third op in triplet\n                    for k in range(j + 1, min(N, i + WINDOW)):\n                        op_c = sorted_ops[k]\n                        \n                        # Expressions for edges a->b, b->c, a->c\n                        y_ab = y_expr(op_a, op_b)\n                        y_bc = y_expr(op_b, op_c)\n                        y_ac = y_expr(op_a, op_c)\n    \n                        # Enforce acyclicity / transitivity for the triplet (a,b,c)\n                        # For a set of 3 ops, there are only 2 invalid cyclic configurations in the binary variables:\n                        \n                        # 1. Cycle a->b->c->a implies y_ab=1, y_bc=1, y_ac=0.\n                        #    Cut: y_ab + y_bc - y_ac <= 1\n                        m.trans_cuts.add(y_ab + y_bc - y_ac <= 1)\n    \n                        # 2. Cycle a<-b<-c<-a implies y_ab=0, y_bc=0, y_ac=1.\n                        #    Cut: y_ac - y_ab - y_bc <= 0\n                        m.trans_cuts.add(y_ac - y_ab - y_bc <= 0)\n    \n    add_windowed_transitivity_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_windowed_transitivity_cuts(m):\n    # 1. Compute Heads (earliest start times) for sorting operations\n    # This helps identify operations that compete for the same time window.\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.trans_cuts = pyo.ConstraintList()\n\n    # Helper to get the boolean expression for \"u precedes v\" (u -> v)\n    # Handles the fact that Pyomo var y is only defined for sorted pairs.\n    def y_expr(u, v):\n        if u < v:\n            # y[u,v]=1 means u->v\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            # y[v,u]=1 means v->u, so u->v is 1 - y[v,u]\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Apply Local Transitivity Cuts\n    # Window size determines how many neighbors we consider. \n    # Small windows (e.g. 6) capture local contention efficiently O(N*W^3).\n    WINDOW = 6\n\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n\n        # Sort operations by Release Time (Heads) to cluster competing tasks\n        sorted_ops = sorted(ops, key=lambda o: heads[o])\n        N = len(sorted_ops)\n\n        for i in range(N):\n            # First op in triplet\n            op_a = sorted_ops[i]\n            \n            # Second op in triplet (from immediate neighbors)\n            for j in range(i + 1, min(N, i + WINDOW)):\n                op_b = sorted_ops[j]\n                \n                # Third op in triplet\n                for k in range(j + 1, min(N, i + WINDOW)):\n                    op_c = sorted_ops[k]\n                    \n                    # Expressions for edges a->b, b->c, a->c\n                    y_ab = y_expr(op_a, op_b)\n                    y_bc = y_expr(op_b, op_c)\n                    y_ac = y_expr(op_a, op_c)\n\n                    # Enforce acyclicity / transitivity for the triplet (a,b,c)\n                    # For a set of 3 ops, there are only 2 invalid cyclic configurations in the binary variables:\n                    \n                    # 1. Cycle a->b->c->a implies y_ab=1, y_bc=1, y_ac=0.\n                    #    Cut: y_ab + y_bc - y_ac <= 1\n                    m.trans_cuts.add(y_ab + y_bc - y_ac <= 1)\n\n                    # 2. Cycle a<-b<-c<-a implies y_ab=0, y_bc=0, y_ac=1.\n                    #    Cut: y_ac - y_ab - y_bc <= 0\n                    m.trans_cuts.add(y_ac - y_ab - y_bc <= 0)\n\nadd_windowed_transitivity_cuts(model)",
                        "idea": "We introduce **Windowed Binary Transitivity Cuts**, a strategy that enforces 3-cycle elimination (transitivity) purely on the binary precedence variables ($y$) within localized time windows. Unlike the parentswhich rely on mixed-integer lifting of continuous Start Times ($S$) via Big-M logicthis approach directly tightens the boolean hull of the precedence polytope. By sorting operations by their release times and applying cuts like $y_{ab} + y_{bc} - y_{ac} \\le 1$ only to temporally adjacent triplets, we efficiently prune fractional cycles (e.g., $i \\to j \\to k \\to i$ with $y=0.5$) that often escape standard disjunctive constraints. This complements the parents' energetic reasoning by forcing the integer consistency required for their Start Time cuts to be effective."
                    },
                    "fitness": 9.863353674739786,
                    "solver_reports": [
                        {
                            "gap": 95.6881,
                            "total_time": 10.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 40701,
                            "explored_time": 10.86,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.2068,
                            "total_time": 11.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 37841,
                            "explored_time": 11.39,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 10.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 39750,
                            "explored_time": 10.78,
                            "work_units": 10.0
                        },
                        {
                            "gap": 91.9301,
                            "total_time": 19.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 17340,
                            "explored_time": 19.49,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 10.56,
                            "explored_nodes": 1,
                            "simplex_iterations": 42596,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "gap": 36.4079,
                            "total_time": 9.69,
                            "explored_nodes": 115,
                            "simplex_iterations": 59376,
                            "explored_time": 9.68,
                            "work_units": 10.68
                        },
                        {
                            "gap": 93.1252,
                            "total_time": 17.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 18248,
                            "explored_time": 17.62,
                            "work_units": 10.01
                        },
                        {
                            "gap": 96.8583,
                            "total_time": 14.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 33763,
                            "explored_time": 14.8,
                            "work_units": 10.02
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "7e111dde-288a-4f56-b45d-a88d3c2817e7"
                    ]
                }
            ],
            19.745839703599053
        ],
        [
            [
                {
                    "id": "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_lifted_bottleneck_cuts(m):\n        # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n        # to ensure self-contained execution.\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: \n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Container for new constraints\n        m.lifted_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        for mid, ops in mach_ops.items():\n            # Data: (r, p, q)\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            \n            # Sort unique thresholds\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n            for r in rs:\n                for q in qs:\n                    # Sum processing times of ops strictly within the window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            # Add cut: Cmax must be >= tightest 1-machine relaxation\n            if local_max > 0:\n                m.lifted_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n        # Only applied to the identified bottleneck machine to keep size manageable.\n        if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n            ops = mach_ops[bottleneck_mach]\n            \n            # Helper to get the expression for \"u precedes v\"\n            # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n            def get_precedence_expr(u, v):\n                if u < v:\n                    # Variable exists as y[u, v]\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n            # We limit n_cuts to avoid memory explosion if the machine has many ops\n            cut_count = 0\n            limit = 100 \n            \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    \n                    # Base precedence var: i -> j\n                    y_ij = get_precedence_expr(i, j)\n                    \n                    # Identify intermediate node k\n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_precedence_expr(i, k)\n                        y_kj = get_precedence_expr(k, j)\n                        \n                        # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                        # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        # Logic: \n                        #   If y_ij=1 (i->j active):\n                        #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                        #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                        #      Else:\n                        #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                        #   If y_ij=0 (i->j inactive):\n                        #      RHS is large negative (Valid due to bigM)\n                        \n                        m.lifted_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        cut_count += 1\n                        if cut_count > limit: break\n                if cut_count > limit: break\n    \n    apply_lifted_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_lifted_bottleneck_cuts(m):\n    # 1. Re-compute Heads (r) and Tails (q) dynamically from the model parameters\n    # to ensure self-contained execution.\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: \n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Container for new constraints\n    m.lifted_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    for mid, ops in mach_ops.items():\n        # Data: (r, p, q)\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        \n        # Sort unique thresholds\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest subset interval [r_min, ... , end - q_min]\n        for r in rs:\n            for q in qs:\n                # Sum processing times of ops strictly within the window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        # Add cut: Cmax must be >= tightest 1-machine relaxation\n        if local_max > 0:\n            m.lifted_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Triangle Precedence Lifting (Local Cuts on Bottleneck)\n    # Only applied to the identified bottleneck machine to keep size manageable.\n    if bottleneck_mach is not None and bottleneck_mach in mach_ops:\n        ops = mach_ops[bottleneck_mach]\n        \n        # Helper to get the expression for \"u precedes v\"\n        # y[u, v] = 1 means u->v. If v < u in lexicographical order, the var is y[v, u] and 0 means u->v.\n        def get_precedence_expr(u, v):\n            if u < v:\n                # Variable exists as y[u, v]\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # Variable exists as y[v, u], so u->v is represented by (1 - y[v, u])\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        # Iterate triplets (i, j, k) to lift the disjunctive constraint between i and j\n        # We limit n_cuts to avoid memory explosion if the machine has many ops\n        cut_count = 0\n        limit = 100 \n        \n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                \n                # Base precedence var: i -> j\n                y_ij = get_precedence_expr(i, j)\n                \n                # Identify intermediate node k\n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_precedence_expr(i, k)\n                    y_kj = get_precedence_expr(k, j)\n                    \n                    # Constraint: S_j >= S_i + p_i + p_k if i->k->j\n                    # Formulation: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    # Logic: \n                    #   If y_ij=1 (i->j active):\n                    #      If y_ik=1 and y_kj=1 (path i->k->j active):\n                    #         RHS = S_i + p_i + p_k. (Stronger than basic S_i + p_i)\n                    #      Else:\n                    #         RHS <= S_i + p_i (Redundant/Weak, but valid)\n                    #   If y_ij=0 (i->j inactive):\n                    #      RHS is large negative (Valid due to bigM)\n                    \n                    m.lifted_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    cut_count += 1\n                    if cut_count > limit: break\n            if cut_count > limit: break\n\napply_lifted_bottleneck_cuts(model)",
                        "idea": "We apply **Bottleneck-Focused Triangle Lifting**. First, we strengthen the global lower bound by computing the **Carlier Bound** for every machine; this effectively lifts the `Cmax` constraint by solving the 1-machine head-tail problem exactly. Second, we identify the bottleneck machine (the one generating the max Carlier bound) and apply **Triangle Precedence Cuts** to it. These cuts lift the pairwise disjunctive constraints $S_j \\ge S_i + p_i$ by incorporating intermediate operations $k$: if $i \\to k \\to j$, the delay must include $p_k$. This creates a tighter polyhedral approximation for the critical machine, pruning fractional solutions where precedence is intransitive."
                    },
                    "fitness": 19.745839703599053,
                    "solver_reports": [
                        {
                            "gap": 22.6009,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 34291,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3984,
                            "total_time": 12.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 35151,
                            "explored_time": 12.71,
                            "work_units": 10.28
                        },
                        {
                            "gap": 34.8922,
                            "total_time": 11.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 30987,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6984,
                            "total_time": 13.28,
                            "explored_nodes": 59,
                            "simplex_iterations": 45527,
                            "explored_time": 13.27,
                            "work_units": 10.17
                        },
                        {
                            "total_time": 11.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 34484,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.2529,
                            "total_time": 10.35,
                            "explored_nodes": 1497,
                            "simplex_iterations": 87588,
                            "explored_time": 10.34,
                            "work_units": 10.88
                        },
                        {
                            "gap": 25.8837,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 49577,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 39685,
                            "explored_time": 10.33,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "953456bd-bd70-4803-ab54-4778ff8de5b6"
                    ]
                },
                {
                    "id": "b763d984-9e74-4147-9c69-3368492db45a",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_bottleneck_cycle_cuts(m):\n        # 1. Identify the bottleneck machine (highest total processing time)\n        mach_loads = {}\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            mach_loads[mid] = mach_loads.get(mid, 0) + m.p[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n        \n        if not mach_loads:\n            return\n        \n        bottleneck_mach = max(mach_loads, key=mach_loads.get)\n        ops = mach_ops[bottleneck_mach]\n        n_ops = len(ops)\n        \n        # Need at least 3 operations to form a cycle\n        if n_ops < 3:\n            return\n            \n        m.cycle_cuts = pyo.ConstraintList()\n        \n        # Helper to access binary precedence variable y_{u,v} (1 if u -> v)\n        def y_uv(u, v):\n            # Model stores y for pairs sorted lexicographically\n            if u < v: \n                return m.y[u[0], u[1], v[0], v[1]]\n            else:     \n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n        # 2. Add 3-Cycle Elimination Cuts on the bottleneck machine\n        # These prevent fractional cycles like y_ab=0.7, y_bc=0.7, y_ca=0.7\n        count = 0\n        limit = 200  # Limit number of cuts to maintain performance\n        \n        for i in range(n_ops):\n            for j in range(i + 1, n_ops):\n                for k in range(j + 1, n_ops):\n                    u, v, w = ops[i], ops[j], ops[k]\n                    \n                    # Forbid cycle u -> v -> w -> u\n                    # Valid integer solutions must satisfy y_uv + y_vw + y_wu <= 2\n                    m.cycle_cuts.add(y_uv(u, v) + y_uv(v, w) + y_uv(w, u) <= 2)\n                    \n                    # Forbid cycle u -> w -> v -> u\n                    m.cycle_cuts.add(y_uv(u, w) + y_uv(w, v) + y_uv(v, u) <= 2)\n                    \n                    count += 2\n                    if count >= limit: break\n                if count >= limit: break\n            if count >= limit: break\n    \n    apply_bottleneck_cycle_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_bottleneck_cycle_cuts(m):\n    # 1. Identify the bottleneck machine (highest total processing time)\n    mach_loads = {}\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        mach_loads[mid] = mach_loads.get(mid, 0) + m.p[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n    \n    if not mach_loads:\n        return\n    \n    bottleneck_mach = max(mach_loads, key=mach_loads.get)\n    ops = mach_ops[bottleneck_mach]\n    n_ops = len(ops)\n    \n    # Need at least 3 operations to form a cycle\n    if n_ops < 3:\n        return\n        \n    m.cycle_cuts = pyo.ConstraintList()\n    \n    # Helper to access binary precedence variable y_{u,v} (1 if u -> v)\n    def y_uv(u, v):\n        # Model stores y for pairs sorted lexicographically\n        if u < v: \n            return m.y[u[0], u[1], v[0], v[1]]\n        else:     \n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n    # 2. Add 3-Cycle Elimination Cuts on the bottleneck machine\n    # These prevent fractional cycles like y_ab=0.7, y_bc=0.7, y_ca=0.7\n    count = 0\n    limit = 200  # Limit number of cuts to maintain performance\n    \n    for i in range(n_ops):\n        for j in range(i + 1, n_ops):\n            for k in range(j + 1, n_ops):\n                u, v, w = ops[i], ops[j], ops[k]\n                \n                # Forbid cycle u -> v -> w -> u\n                # Valid integer solutions must satisfy y_uv + y_vw + y_wu <= 2\n                m.cycle_cuts.add(y_uv(u, v) + y_uv(v, w) + y_uv(w, u) <= 2)\n                \n                # Forbid cycle u -> w -> v -> u\n                m.cycle_cuts.add(y_uv(u, w) + y_uv(w, v) + y_uv(v, u) <= 2)\n                \n                count += 2\n                if count >= limit: break\n            if count >= limit: break\n        if count >= limit: break\n\napply_bottleneck_cycle_cuts(model)",
                        "idea": "We implement **Bottleneck 3-Cycle Elimination**. Unlike the provided cut which lifts the metric inequalities (Start Times) using Carlier bounds, this strategy strengthens the **Boolean Polytope** of the precedence variables on the bottleneck machine. Standard Big-M constraints implicitly enforce transitivity but often allow fractional cycles (e.g., $y_{ij}=y_{jk}=y_{ki}=0.66$) in the LP relaxation. By explicitly forbidding 3-cycles ($y_{ij} + y_{jk} + y_{ki} \\le 2$) for triplets of operations on the critical machine, we force the solver to resolve sequencing decisions earlier, tightening the lower bound without requiring external branch-and-bound logic."
                    },
                    "fitness": 9.940604102393673,
                    "solver_reports": [
                        {
                            "gap": 95.8345,
                            "total_time": 12.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 35330,
                            "explored_time": 12.21,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 27895,
                            "explored_time": 15.79,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.8266,
                            "total_time": 14.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 29999,
                            "explored_time": 14.45,
                            "work_units": 10.02
                        },
                        {
                            "gap": 91.2634,
                            "total_time": 19.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 19461,
                            "explored_time": 19.6,
                            "work_units": 10.01
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 30128,
                            "explored_time": 14.55,
                            "work_units": 10.01
                        },
                        {
                            "gap": 34.4028,
                            "total_time": 10.51,
                            "explored_nodes": 143,
                            "simplex_iterations": 45727,
                            "explored_time": 10.48,
                            "work_units": 10.43
                        },
                        {
                            "gap": 93.2333,
                            "total_time": 19.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 13638,
                            "explored_time": 19.56,
                            "work_units": 10.03
                        },
                        {
                            "gap": 96.6247,
                            "total_time": 15.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 28804,
                            "explored_time": 15.4,
                            "work_units": 10.05
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                },
                {
                    "id": "8a14a0af-e1bd-4b78-b72a-7bdfea8929fa",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_heuristic_triplet_lifting(m):\n        # 1. Compute Heads (r) and Tails (q) for Carlier Bound Logic\n        heads = {}\n        tails = {}\n        # Forward pass for heads\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass for tails\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n    \n        # 3. Identify the Single Global Bottleneck via Carlier Bound\n        global_max_lb = 0\n        bottleneck_mach = None\n    \n        for mid, ops in mach_ops.items():\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force the tightest 1-machine window\n            for r in rs:\n                for q in qs:\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max: local_max = bound\n            \n            if local_max > global_max_lb:\n                global_max_lb = local_max\n                bottleneck_mach = mid\n    \n        # Apply Global Lower Bound Cut\n        if global_max_lb > 0:\n            m.hybrid_cuts.add(m.Cmax >= global_max_lb)\n    \n        if bottleneck_mach is None: return\n    \n        # 4. Apply Hybrid Cuts to the Bottleneck Machine\n        # Focus strategy from Parent 1, Sorting strategy from Parent 2\n        ops = mach_ops[bottleneck_mach]\n        # Sort by release times (Heuristic: likely order i->j)\n        ops.sort(key=lambda x: heads[x])\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        cut_count = 0\n        BUDGET = 200  # Cap to prevent model bloat\n    \n        # Iterate pairs (i, j) in sorted order\n        for idx_i in range(len(ops)):\n            for idx_j in range(idx_i + 1, len(ops)):\n                i = ops[idx_i]\n                j = ops[idx_j]\n                \n                # Identify potential intermediates k\n                candidates = [k for k in ops if k != i and k != j]\n                \n                # NEW: Sort intermediates by Processing Time (Descending)\n                # This prioritizes cuts that add the largest delay (p_k) when active.\n                candidates.sort(key=lambda x: m.p[x], reverse=True)\n                \n                # Add cuts for the top 2 strongest intermediates\n                for k in candidates[:2]:\n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity (from Parent 2): Logical consistency\n                    m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting (from Parent 1/2): Tighten start times\n                    # If path i->k->j is active, delay is p_i + p_k\n                    m.hybrid_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cut_count += 2\n                    if cut_count >= BUDGET: break\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n    \n    add_heuristic_triplet_lifting(model)\n\n    return model\n",
                        "added_cut": "def add_heuristic_triplet_lifting(m):\n    # 1. Compute Heads (r) and Tails (q) for Carlier Bound Logic\n    heads = {}\n    tails = {}\n    # Forward pass for heads\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass for tails\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.hybrid_cuts = pyo.ConstraintList()\n\n    # 3. Identify the Single Global Bottleneck via Carlier Bound\n    global_max_lb = 0\n    bottleneck_mach = None\n\n    for mid, ops in mach_ops.items():\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force the tightest 1-machine window\n        for r in rs:\n            for q in qs:\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max: local_max = bound\n        \n        if local_max > global_max_lb:\n            global_max_lb = local_max\n            bottleneck_mach = mid\n\n    # Apply Global Lower Bound Cut\n    if global_max_lb > 0:\n        m.hybrid_cuts.add(m.Cmax >= global_max_lb)\n\n    if bottleneck_mach is None: return\n\n    # 4. Apply Hybrid Cuts to the Bottleneck Machine\n    # Focus strategy from Parent 1, Sorting strategy from Parent 2\n    ops = mach_ops[bottleneck_mach]\n    # Sort by release times (Heuristic: likely order i->j)\n    ops.sort(key=lambda x: heads[x])\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    cut_count = 0\n    BUDGET = 200  # Cap to prevent model bloat\n\n    # Iterate pairs (i, j) in sorted order\n    for idx_i in range(len(ops)):\n        for idx_j in range(idx_i + 1, len(ops)):\n            i = ops[idx_i]\n            j = ops[idx_j]\n            \n            # Identify potential intermediates k\n            candidates = [k for k in ops if k != i and k != j]\n            \n            # NEW: Sort intermediates by Processing Time (Descending)\n            # This prioritizes cuts that add the largest delay (p_k) when active.\n            candidates.sort(key=lambda x: m.p[x], reverse=True)\n            \n            # Add cuts for the top 2 strongest intermediates\n            for k in candidates[:2]:\n                y_ij = get_y(i, j)\n                y_ik = get_y(i, k)\n                y_kj = get_y(k, j)\n                \n                # (A) Transitivity (from Parent 2): Logical consistency\n                m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                \n                # (B) Metric Lifting (from Parent 1/2): Tighten start times\n                # If path i->k->j is active, delay is p_i + p_k\n                m.hybrid_cuts.add(\n                    m.S[j] >= m.S[i] + m.p[i] + \n                    m.p[k] * (y_ik + y_kj - 1) - \n                    m.bigM * (1 - y_ij)\n                )\n                \n                cut_count += 2\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n        if cut_count >= BUDGET: break\n\nadd_heuristic_triplet_lifting(model)",
                        "idea": "We implement **Heuristic Triplet Lifting** on the single global bottleneck. We first strengthen the global relaxation using **Carlier Bounds** to find the most critical machine. Then, we apply a hybrid cutting strategy: we iterate through operation pairs sorted by release times (Parent 2's heuristic) but exclusively target intermediate nodes $k$ with the **largest processing times** (Novel priority). This ensures that the added **Transitivity** and **Metric Lifting** cuts maximize the enforced delay ($p_k$) within a limited cut budget, effectively tightening the polyhedron around the most contentious operations."
                    },
                    "fitness": 19.21668582886848,
                    "solver_reports": [
                        {
                            "total_time": 10.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 36139,
                            "explored_time": 10.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.0032,
                            "total_time": 12.76,
                            "explored_nodes": 1,
                            "simplex_iterations": 35713,
                            "explored_time": 12.69,
                            "work_units": 10.37
                        },
                        {
                            "gap": 29.0977,
                            "total_time": 11.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 29959,
                            "explored_time": 11.41,
                            "work_units": 10.24
                        },
                        {
                            "gap": 20.1261,
                            "total_time": 13.49,
                            "explored_nodes": 113,
                            "simplex_iterations": 66781,
                            "explored_time": 13.48,
                            "work_units": 11.19
                        },
                        {
                            "total_time": 10.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 31618,
                            "explored_time": 9.94,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.677,
                            "total_time": 11.97,
                            "explored_nodes": 1417,
                            "simplex_iterations": 61262,
                            "explored_time": 11.96,
                            "work_units": 10.95
                        },
                        {
                            "gap": 32.9901,
                            "total_time": 13.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 47518,
                            "explored_time": 13.75,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 37469,
                            "explored_time": 10.86,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56"
                    ]
                },
                {
                    "id": "6107275e-ce57-4c88-9ae3-c54885342a51",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_window_transitivity(m):\n        # 1. Compute Heads (r) and Tails (q) for all operations\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access precedence variables safely\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.critical_cuts = pyo.ConstraintList()\n    \n        # 3. Identify Critical Blocks (Carlier Bound Approximation)\n        # We look for the subset of operations on each machine that yields the max LB.\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Sort ops by release time to efficiently scan contiguous time blocks\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_subset = []\n            \n            # Scan contiguous subsets [i, j] to find the 'active' bottleneck interval\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                current_subset = []\n                r_val = heads[sorted_ops[i]] # r_min for this subset\n                \n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_subset.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_subset = list(current_subset)\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_subset})\n    \n        if not candidates: return\n    \n        # 4. Global Cuts & Target Selection\n        # Sort machines by their critical lower bound\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        # (A) Global Lower Bound Cut\n        m.critical_cuts.add(m.Cmax >= global_max)\n    \n        # (B) Select Top Bottlenecks (Top 3 within 90% of global max)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    \n        # 5. Apply Windowed Transitivity to Critical Subsets\n        WINDOW = 6 \n        \n        for target in targets:\n            crit_ops = target['ops']\n            # Ensure sorted by head time for sliding window logic\n            crit_ops.sort(key=lambda x: heads[x])\n            n_crit = len(crit_ops)\n            \n            if n_crit < 3: continue\n            \n            for i_idx in range(n_crit):\n                op_i = crit_ops[i_idx]\n                \n                # Sliding window constraint generation\n                limit = min(i_idx + WINDOW, n_crit)\n                for j_idx in range(i_idx + 1, limit):\n                    op_j = crit_ops[j_idx]\n                    \n                    # Intermediate node k\n                    for k_idx in range(i_idx + 1, j_idx):\n                        op_k = crit_ops[k_idx]\n                        \n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Cut 1: Transitivity (Logical Consistency)\n                        # If i->k and k->j, then i->j must be true\n                        m.critical_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Cut 2: Lifted Precedence (Metric Consistency)\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists.\n                        # The term (y_ik + y_kj - 1) activates the extra p_k only if both edges are 1.\n                        m.critical_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n    \n    add_critical_window_transitivity(model)\n\n    return model\n",
                        "added_cut": "def add_critical_window_transitivity(m):\n    # 1. Compute Heads (r) and Tails (q) for all operations\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access precedence variables safely\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.critical_cuts = pyo.ConstraintList()\n\n    # 3. Identify Critical Blocks (Carlier Bound Approximation)\n    # We look for the subset of operations on each machine that yields the max LB.\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Sort ops by release time to efficiently scan contiguous time blocks\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_subset = []\n        \n        # Scan contiguous subsets [i, j] to find the 'active' bottleneck interval\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            current_subset = []\n            r_val = heads[sorted_ops[i]] # r_min for this subset\n            \n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_subset.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_subset = list(current_subset)\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_subset})\n\n    if not candidates: return\n\n    # 4. Global Cuts & Target Selection\n    # Sort machines by their critical lower bound\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    # (A) Global Lower Bound Cut\n    m.critical_cuts.add(m.Cmax >= global_max)\n\n    # (B) Select Top Bottlenecks (Top 3 within 90% of global max)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n\n    # 5. Apply Windowed Transitivity to Critical Subsets\n    WINDOW = 6 \n    \n    for target in targets:\n        crit_ops = target['ops']\n        # Ensure sorted by head time for sliding window logic\n        crit_ops.sort(key=lambda x: heads[x])\n        n_crit = len(crit_ops)\n        \n        if n_crit < 3: continue\n        \n        for i_idx in range(n_crit):\n            op_i = crit_ops[i_idx]\n            \n            # Sliding window constraint generation\n            limit = min(i_idx + WINDOW, n_crit)\n            for j_idx in range(i_idx + 1, limit):\n                op_j = crit_ops[j_idx]\n                \n                # Intermediate node k\n                for k_idx in range(i_idx + 1, j_idx):\n                    op_k = crit_ops[k_idx]\n                    \n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Cut 1: Transitivity (Logical Consistency)\n                    # If i->k and k->j, then i->j must be true\n                    m.critical_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Cut 2: Lifted Precedence (Metric Consistency)\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists.\n                    # The term (y_ik + y_kj - 1) activates the extra p_k only if both edges are 1.\n                    m.critical_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n\nadd_critical_window_transitivity(model)",
                        "idea": "We combine Parent 1's sliding window efficiency with Parent 2's rigorous Carlier-bound subset detection. By identifying 'Critical Blocks' (subsets of operations maximizing $r_{min} + \\sum p + q_{min}$) on the top competing bottleneck machines, we isolate the most contentious time intervals. We then apply transitivity ($y_{ik} + y_{kj} \\le 1 + y_{ij}$) and path-lifted temporal cuts ($S_j \\ge S_i + p_i + p_k$) exclusively within these blocks using a tight sliding window. This strategy strengthens the relaxation exactly where infeasibilities cluster, improving bound quality with minimal model overhead."
                    },
                    "fitness": 18.49537936073994,
                    "solver_reports": [
                        {
                            "gap": 24.7349,
                            "total_time": 12.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 31724,
                            "explored_time": 12.87,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 35802,
                            "explored_time": 11.49,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 31114,
                            "explored_time": 10.44,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.2945,
                            "total_time": 12.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 39524,
                            "explored_time": 12.1,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 31676,
                            "explored_time": 12.04,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.0765,
                            "total_time": 10.62,
                            "explored_nodes": 1310,
                            "simplex_iterations": 83053,
                            "explored_time": 10.61,
                            "work_units": 10.58
                        },
                        {
                            "gap": 32.6662,
                            "total_time": 12.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 43164,
                            "explored_time": 12.82,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 10.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 37635,
                            "explored_time": 10.53,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0",
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56"
                    ]
                },
                {
                    "id": "eeeb8a94-334c-4e13-ab94-21fcdf7d89d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_block_transitivity_cuts(m):\n        # 1. Compute Heads (r) and Tails (q) for all operations\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # Helper: Access disjunctive variable y_uv correctly based on index order\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.crit_block_cuts = pyo.ConstraintList()\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks and Apply Hybrid Cuts\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n    \n            # Sort operations by release times (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Find the block [i..j] maximizing LB = r_min + sum(p) + q_min\n            best_lb = -1\n            crit_subset = []\n            block_r = 0\n            \n            for i in range(n):\n                current_p = 0\n                # Min head of subset [i..j] is head[i] due to sorting\n                current_r = heads[sorted_ops[i]]\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    current_p += m.p[op]\n                    \n                    subset = sorted_ops[i : j+1]\n                    current_q = min(tails[o] for o in subset)\n                    lb = current_r + current_p + current_q\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        crit_subset = subset\n                        block_r = current_r\n    \n            if len(crit_subset) < 2: continue\n    \n            # (A) Displacement Cuts: Tighten start times relative to block bounds\n            # This leverages the strength of Parent 2's bound tightening\n            for u in crit_subset:\n                # S_u >= r_block + sum(p_v * y_vu for v in block)\n                pred_term = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n                m.crit_block_cuts.add(m.S[u] >= block_r + pred_term)\n    \n            # (B) Transitivity & Lifting: Internal Logic Strengthening (from Parent 1)\n            # Applied ONLY within the critical block to prevent local cycles and lift paths\n            subset_len = len(crit_subset)\n            if subset_len >= 3:\n                # Iterate triplets within the block\n                for i_idx in range(subset_len):\n                    i = crit_subset[i_idx]\n                    for j_idx in range(i_idx + 1, subset_len):\n                        j = crit_subset[j_idx]\n                        \n                        # Intermediate node k\n                        for k_idx in range(i_idx + 1, j_idx):\n                            k = crit_subset[k_idx]\n                            \n                            y_ij = get_y(i, j)\n                            y_ik = get_y(i, k)\n                            y_kj = get_y(k, j)\n                            \n                            # Logical Transitivity: i->k and k->j implies i->j\n                            m.crit_block_cuts.add(y_ik + y_kj - y_ij <= 1)\n                            \n                            # Lifted Precedence: S_j >= S_i + p_i + p_k if path i->k->j exists\n                            m.crit_block_cuts.add(\n                                m.S[j] >= m.S[i] + m.p[i] + m.p[k] * (y_ik + y_kj - 1) - m.bigM * (1 - y_ij)\n                            )\n    \n    add_critical_block_transitivity_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_critical_block_transitivity_cuts(m):\n    # 1. Compute Heads (r) and Tails (q) for all operations\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # Helper: Access disjunctive variable y_uv correctly based on index order\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.crit_block_cuts = pyo.ConstraintList()\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks and Apply Hybrid Cuts\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n\n        # Sort operations by release times (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Find the block [i..j] maximizing LB = r_min + sum(p) + q_min\n        best_lb = -1\n        crit_subset = []\n        block_r = 0\n        \n        for i in range(n):\n            current_p = 0\n            # Min head of subset [i..j] is head[i] due to sorting\n            current_r = heads[sorted_ops[i]]\n            for j in range(i, n):\n                op = sorted_ops[j]\n                current_p += m.p[op]\n                \n                subset = sorted_ops[i : j+1]\n                current_q = min(tails[o] for o in subset)\n                lb = current_r + current_p + current_q\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    crit_subset = subset\n                    block_r = current_r\n\n        if len(crit_subset) < 2: continue\n\n        # (A) Displacement Cuts: Tighten start times relative to block bounds\n        # This leverages the strength of Parent 2's bound tightening\n        for u in crit_subset:\n            # S_u >= r_block + sum(p_v * y_vu for v in block)\n            pred_term = sum(m.p[v] * get_y(v, u) for v in crit_subset if v != u)\n            m.crit_block_cuts.add(m.S[u] >= block_r + pred_term)\n\n        # (B) Transitivity & Lifting: Internal Logic Strengthening (from Parent 1)\n        # Applied ONLY within the critical block to prevent local cycles and lift paths\n        subset_len = len(crit_subset)\n        if subset_len >= 3:\n            # Iterate triplets within the block\n            for i_idx in range(subset_len):\n                i = crit_subset[i_idx]\n                for j_idx in range(i_idx + 1, subset_len):\n                    j = crit_subset[j_idx]\n                    \n                    # Intermediate node k\n                    for k_idx in range(i_idx + 1, j_idx):\n                        k = crit_subset[k_idx]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Logical Transitivity: i->k and k->j implies i->j\n                        m.crit_block_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Lifted Precedence: S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.crit_block_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + m.p[k] * (y_ik + y_kj - 1) - m.bigM * (1 - y_ij)\n                        )\n\nadd_critical_block_transitivity_cuts(model)",
                        "idea": "We apply **Critical Block Transitivity**, a hybrid strategy that fuses the rigorous Carlier-bound block detection from Parent 2 with the logical transitivity and precedence lifting of Parent 1. By identifying the specific contiguous operation sequence (critical block) responsible for the strongest machine lower bound, we apply **Displacement cuts** ($S_u \\ge r_{block} + \\sum p_v y_{vu}$) to tighten global timing. Simultaneously, we enforce **Transitivity and Lifted Precedence** ($S_j \\ge S_i + p_i + p_k$) on triplets specifically within this block. This targets the computationally expensive lifting cuts exactly where the schedule is tightest, preventing fractional cycles and slack exploitation in the bottleneck region."
                    },
                    "fitness": 5.823401701490907,
                    "solver_reports": [
                        {
                            "total_time": 11.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.75,
                            "work_units": 10.02
                        },
                        {
                            "total_time": 11.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.99,
                            "work_units": 10.09
                        },
                        {
                            "total_time": 11.97,
                            "explored_nodes": 0,
                            "simplex_iterations": 0,
                            "explored_time": 11.32,
                            "work_units": 11.19
                        },
                        {
                            "total_time": 6.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 6994,
                            "explored_time": 5.96,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.69,
                            "explored_nodes": 0,
                            "simplex_iterations": 0,
                            "explored_time": 11.14,
                            "work_units": 11.08
                        },
                        {
                            "gap": 50.7308,
                            "total_time": 9.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 18225,
                            "explored_time": 9.81,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 8326,
                            "explored_time": 5.99,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 0,
                            "explored_time": 10.55,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0",
                        "282fa1e0-2b05-4421-9081-0be620845965"
                    ]
                },
                {
                    "id": "b3a902f5-0ee3-49b8-8ea9-de3af68e22b3",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_combined_bottleneck_cuts(m):\n        # 1. Calculate Static Heads (r) and Tails (q)\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in reversed(list(m.K)):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access precedence variables y_uv (u -> v)\n        def get_y(u, v):\n            # m.y is defined for (j1,k1,j2,k2) where (j1,k1) < (j2,k2)\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Identify Critical Blocks across all machines\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Collect distinct r and q values for this machine's operations\n            r_values = sorted(list(set(heads[op] for op in ops)))\n            q_values = sorted(list(set(tails[op] for op in ops)))\n            \n            best_local_lb = -1\n            best_subset = []\n            best_r = 0\n            best_q = 0\n            \n            # Find the window [r, q] maximizing the 1-machine Carlier bound\n            for r in r_values:\n                for q in q_values:\n                    subset = [op for op in ops if heads[op] >= r and tails[op] >= q]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    lb = r + p_sum + q\n                    \n                    if lb > best_local_lb:\n                        best_local_lb = lb\n                        best_subset = subset\n                        best_r = r\n                        best_q = q\n            \n            if best_local_lb > 0:\n                candidates.append({\n                    'mid': mid,\n                    'lb': best_local_lb,\n                    'subset': best_subset,\n                    'r': best_r,\n                    'q': best_q\n                })\n    \n        if not candidates: return\n    \n        # 4. Multi-Bottleneck Selection (Parent 1 Strategy)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max_lb = candidates[0]['lb']\n        \n        # Constraint List initialization\n        m.combined_cuts = pyo.ConstraintList()\n        \n        # Always lift global lower bound\n        m.combined_cuts.add(m.Cmax >= global_max_lb)\n        \n        # Select top competing bottlenecks (within 85% of global max)\n        targets = [c for c in candidates if c['lb'] >= 0.85 * global_max_lb]\n        targets = targets[:3]  # Limit to top 3 to manage model size\n    \n        # 5. Apply Hybrid Cuts (Parent 2 Cut Types on Parent 1 Selection)\n        cut_count = 0\n        MAX_CUTS = 300\n    \n        for target in targets:\n            subset = target['subset']\n            r_block = target['r']\n            q_block = target['q']\n            \n            # (A) Input/Output Displacement Cuts\n            # Stronger than basic transitivity: aggregates all predecessors/successors within the block\n            for u in subset:\n                # Input: S_u >= r_block + sum(p_v * y_vu for v in subset)\n                preds_sum = sum(m.p[v] * get_y(v, u) for v in subset if v != u)\n                m.combined_cuts.add(m.S[u] >= r_block + preds_sum)\n                \n                # Output: Cmax >= S_u + p_u + sum(p_v * y_uv for v in subset) + q_block\n                succs_sum = sum(m.p[v] * get_y(u, v) for v in subset if v != u)\n                m.combined_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succs_sum + q_block)\n                \n                cut_count += 2\n    \n            # (B) Pairwise Carlier Cuts\n            # Check if specific pair orderings enforce a bound higher than the block LB\n            if len(subset) < 12:  # Only for reasonably sized blocks\n                for i in subset:\n                    for j in subset:\n                        if i >= j: continue\n                        \n                        lb_ij = heads[i] + m.p[i] + m.p[j] + tails[j]\n                        lb_ji = heads[j] + m.p[j] + m.p[i] + tails[i]\n                        \n                        if lb_ij > target['lb'] or lb_ji > target['lb']:\n                            y_ij = get_y(i, j)\n                            m.combined_cuts.add(m.Cmax >= lb_ij * y_ij + lb_ji * (1 - y_ij))\n                            cut_count += 1\n            \n            if cut_count >= MAX_CUTS: break\n    \n    add_combined_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_combined_bottleneck_cuts(m):\n    # 1. Calculate Static Heads (r) and Tails (q)\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in reversed(list(m.K)):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access precedence variables y_uv (u -> v)\n    def get_y(u, v):\n        # m.y is defined for (j1,k1,j2,k2) where (j1,k1) < (j2,k2)\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Identify Critical Blocks across all machines\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Collect distinct r and q values for this machine's operations\n        r_values = sorted(list(set(heads[op] for op in ops)))\n        q_values = sorted(list(set(tails[op] for op in ops)))\n        \n        best_local_lb = -1\n        best_subset = []\n        best_r = 0\n        best_q = 0\n        \n        # Find the window [r, q] maximizing the 1-machine Carlier bound\n        for r in r_values:\n            for q in q_values:\n                subset = [op for op in ops if heads[op] >= r and tails[op] >= q]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                lb = r + p_sum + q\n                \n                if lb > best_local_lb:\n                    best_local_lb = lb\n                    best_subset = subset\n                    best_r = r\n                    best_q = q\n        \n        if best_local_lb > 0:\n            candidates.append({\n                'mid': mid,\n                'lb': best_local_lb,\n                'subset': best_subset,\n                'r': best_r,\n                'q': best_q\n            })\n\n    if not candidates: return\n\n    # 4. Multi-Bottleneck Selection (Parent 1 Strategy)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max_lb = candidates[0]['lb']\n    \n    # Constraint List initialization\n    m.combined_cuts = pyo.ConstraintList()\n    \n    # Always lift global lower bound\n    m.combined_cuts.add(m.Cmax >= global_max_lb)\n    \n    # Select top competing bottlenecks (within 85% of global max)\n    targets = [c for c in candidates if c['lb'] >= 0.85 * global_max_lb]\n    targets = targets[:3]  # Limit to top 3 to manage model size\n\n    # 5. Apply Hybrid Cuts (Parent 2 Cut Types on Parent 1 Selection)\n    cut_count = 0\n    MAX_CUTS = 300\n\n    for target in targets:\n        subset = target['subset']\n        r_block = target['r']\n        q_block = target['q']\n        \n        # (A) Input/Output Displacement Cuts\n        # Stronger than basic transitivity: aggregates all predecessors/successors within the block\n        for u in subset:\n            # Input: S_u >= r_block + sum(p_v * y_vu for v in subset)\n            preds_sum = sum(m.p[v] * get_y(v, u) for v in subset if v != u)\n            m.combined_cuts.add(m.S[u] >= r_block + preds_sum)\n            \n            # Output: Cmax >= S_u + p_u + sum(p_v * y_uv for v in subset) + q_block\n            succs_sum = sum(m.p[v] * get_y(u, v) for v in subset if v != u)\n            m.combined_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succs_sum + q_block)\n            \n            cut_count += 2\n\n        # (B) Pairwise Carlier Cuts\n        # Check if specific pair orderings enforce a bound higher than the block LB\n        if len(subset) < 12:  # Only for reasonably sized blocks\n            for i in subset:\n                for j in subset:\n                    if i >= j: continue\n                    \n                    lb_ij = heads[i] + m.p[i] + m.p[j] + tails[j]\n                    lb_ji = heads[j] + m.p[j] + m.p[i] + tails[i]\n                    \n                    if lb_ij > target['lb'] or lb_ji > target['lb']:\n                        y_ij = get_y(i, j)\n                        m.combined_cuts.add(m.Cmax >= lb_ij * y_ij + lb_ji * (1 - y_ij))\n                        cut_count += 1\n        \n        if cut_count >= MAX_CUTS: break\n\nadd_combined_bottleneck_cuts(model)",
                        "idea": "We integrate Parent 1's Multi-Bottleneck selection with Parent 2's advanced Displacement cuts. Instead of focusing solely on the global maximum bottleneck, we identify the top $k$ competing machine intervals (within 85% of the max LB) to prevent infeasibility shifting. For each critical block $\\Omega$, we apply Input/Output Displacement cuts ($S_u \\ge r_\\Omega + \\sum_{v \\to u} p_v$) and conditional Pairwise Carlier cuts. These cuts are strictly stronger than standard transitivity as they aggregate processing times of all sequenced predecessors in the clique to tightly bound start times and the makespan."
                    },
                    "fitness": 10.71876564292709,
                    "solver_reports": [
                        {
                            "total_time": 6.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 25405,
                            "explored_time": 6.1,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 6.11,
                            "explored_nodes": 1,
                            "simplex_iterations": 25210,
                            "explored_time": 6.06,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 31050,
                            "explored_time": 6.64,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 36208,
                            "explored_time": 8.81,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 32365,
                            "explored_time": 6.47,
                            "work_units": 10.0
                        },
                        {
                            "gap": 30.6416,
                            "total_time": 10.35,
                            "explored_nodes": 171,
                            "simplex_iterations": 75514,
                            "explored_time": 10.34,
                            "work_units": 10.23
                        },
                        {
                            "total_time": 8.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 47677,
                            "explored_time": 8.96,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 26018,
                            "explored_time": 6.3,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                        "db1f7a09-dcc7-46d3-aff5-55d75688677f"
                    ]
                },
                {
                    "id": "9ff6637c-b48f-4329-bff1-733898e9a954",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_span_cuts(m):\n        # 1. Calculate Heads and Tails (Est. Release and Delivery times)\n        # Heads: Earliest start based on job predecessors\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        # Tails: Time required to finish job after operation completes\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Subsets (Blocks) per machine\n        # We select the subset of operations that maximizes the Carlier Bound (r + sum(p) + q)\n        critical_subsets = {}\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Prepare data: (head, p, tail, op_key)\n            data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n            \n            # Candidate window start/end points\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Brute-force window search\n            for r in rs:\n                for q in qs:\n                    # Select operations fully inside the window [r, ... q]\n                    # i.e., head >= r and tail >= q\n                    sub = [d for d in data if d[0] >= r and d[2] >= q]\n                    if not sub: continue\n                    \n                    # Carlier LB for this window\n                    lb = r + sum(d[1] for d in sub) + q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = [d[3] for d in sub]\n            \n            # Only store if subset has at least 2 operations (otherwise trivial)\n            if len(best_sub) > 1:\n                critical_subsets[mid] = best_sub\n    \n        if not critical_subsets: return\n    \n        # 4. Add Span Variables and Cuts\n        # We create auxiliary variables representing the start and end of the critical block\n        m.subset_mids = pyo.Set(initialize=critical_subsets.keys())\n        m.span_start = pyo.Var(m.subset_mids, domain=pyo.NonNegativeReals)\n        m.span_end   = pyo.Var(m.subset_mids, domain=pyo.NonNegativeReals)\n        m.span_cuts  = pyo.ConstraintList()\n    \n        for mid, subset in critical_subsets.items():\n            total_p = sum(m.p[op] for op in subset)\n            \n            # Constraint A: The span (end - start) must accommodate the total processing time\n            # This is a valid energetic cut for any disjunctive set\n            m.span_cuts.add(m.span_end[mid] - m.span_start[mid] >= total_p)\n            \n            # Constraint B: Bounding box definitions\n            # span_start <= StartTime of every op in subset\n            # span_end   >= FinishTime of every op in subset\n            for op in subset:\n                m.span_cuts.add(m.span_start[mid] <= m.S[op])\n                m.span_cuts.add(m.span_end[mid]   >= m.S[op] + m.p[op])\n    \n    add_critical_span_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_critical_span_cuts(m):\n    # 1. Calculate Heads and Tails (Est. Release and Delivery times)\n    # Heads: Earliest start based on job predecessors\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    # Tails: Time required to finish job after operation completes\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Subsets (Blocks) per machine\n    # We select the subset of operations that maximizes the Carlier Bound (r + sum(p) + q)\n    critical_subsets = {}\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Prepare data: (head, p, tail, op_key)\n        data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n        \n        # Candidate window start/end points\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Brute-force window search\n        for r in rs:\n            for q in qs:\n                # Select operations fully inside the window [r, ... q]\n                # i.e., head >= r and tail >= q\n                sub = [d for d in data if d[0] >= r and d[2] >= q]\n                if not sub: continue\n                \n                # Carlier LB for this window\n                lb = r + sum(d[1] for d in sub) + q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = [d[3] for d in sub]\n        \n        # Only store if subset has at least 2 operations (otherwise trivial)\n        if len(best_sub) > 1:\n            critical_subsets[mid] = best_sub\n\n    if not critical_subsets: return\n\n    # 4. Add Span Variables and Cuts\n    # We create auxiliary variables representing the start and end of the critical block\n    m.subset_mids = pyo.Set(initialize=critical_subsets.keys())\n    m.span_start = pyo.Var(m.subset_mids, domain=pyo.NonNegativeReals)\n    m.span_end   = pyo.Var(m.subset_mids, domain=pyo.NonNegativeReals)\n    m.span_cuts  = pyo.ConstraintList()\n\n    for mid, subset in critical_subsets.items():\n        total_p = sum(m.p[op] for op in subset)\n        \n        # Constraint A: The span (end - start) must accommodate the total processing time\n        # This is a valid energetic cut for any disjunctive set\n        m.span_cuts.add(m.span_end[mid] - m.span_start[mid] >= total_p)\n        \n        # Constraint B: Bounding box definitions\n        # span_start <= StartTime of every op in subset\n        # span_end   >= FinishTime of every op in subset\n        for op in subset:\n            m.span_cuts.add(m.span_start[mid] <= m.S[op])\n            m.span_cuts.add(m.span_end[mid]   >= m.S[op] + m.p[op])\n\nadd_critical_span_cuts(model)",
                        "idea": "We introduce **Critical Block Span Relaxation**, an exploratory cut that shifts focus from binary precedence logic to aggregate temporal properties. By identifying the 'Critical Block' (the subset of operations maximizing the Carlier lower bound) on each machine, we introduce continuous auxiliary variables ($v_{start}, v_{end}$) that bound the temporal footprint of this block. We then enforce the energetic constraint $v_{end} - v_{start} \\ge \\sum p_{ops}$. This valid inequality approximates the convex hull of the disjunctive clique by forcing the start times to spread out globally to accommodate the total workload, effectively pruning solutions where operations overlap significantly in the LP relaxation."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.29,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.04,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.09,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.9,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.88,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.13,
                            "work_units": 10.0
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.01,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.0,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.85,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.1,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56"
                    ]
                },
                {
                    "id": "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_adaptive_carlier_cuts(m):\n        # 1. Compute Release (heads) and Delivery (tails) times for all ops\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Carlier-style subsets)\n        # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time (heads) for efficient scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Scan all contiguous sub-segments [u, v]\n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global LB Cut and Adaptive Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.adaptive_carlier = pyo.ConstraintList()\n        m.adaptive_carlier.add(m.Cmax >= global_max)\n    \n        # Select bottlenecks strictly within 90% of global max to target active constraints\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        # Helper to access y variables (u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 5. Apply Sliding Window Cuts to Critical Blocks\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 6\n        \n        # Limit to top 3 competing blocks to manage complexity\n        for target in targets[:3]:\n            ops = target['ops']  # Already sorted by release time\n            if len(ops) < 3: continue\n            \n            cuts_added = 0\n            n_sub = len(ops)\n            \n            for idx_i in range(n_sub):\n                i = ops[idx_i]\n                # Restrict j to a local window to capture dense conflicts\n                for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                    j = ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = ops[idx_k]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Transitivity: Prevent cycles i->k->j->i\n                        # If i->k and k->j, then i->j must hold\n                        m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.adaptive_carlier.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_adaptive_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_adaptive_carlier_cuts(m):\n    # 1. Compute Release (heads) and Delivery (tails) times for all ops\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Carlier-style subsets)\n    # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time (heads) for efficient scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Scan all contiguous sub-segments [u, v]\n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global LB Cut and Adaptive Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.adaptive_carlier = pyo.ConstraintList()\n    m.adaptive_carlier.add(m.Cmax >= global_max)\n\n    # Select bottlenecks strictly within 90% of global max to target active constraints\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    # Helper to access y variables (u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 5. Apply Sliding Window Cuts to Critical Blocks\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 6\n    \n    # Limit to top 3 competing blocks to manage complexity\n    for target in targets[:3]:\n        ops = target['ops']  # Already sorted by release time\n        if len(ops) < 3: continue\n        \n        cuts_added = 0\n        n_sub = len(ops)\n        \n        for idx_i in range(n_sub):\n            i = ops[idx_i]\n            # Restrict j to a local window to capture dense conflicts\n            for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                j = ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = ops[idx_k]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity: Prevent cycles i->k->j->i\n                    # If i->k and k->j, then i->j must hold\n                    m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.adaptive_carlier.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_adaptive_carlier_cuts(model)",
                        "idea": "We introduce **Adaptive Carlier-Window Transitivity**, a hybrid strategy merging the precise bottleneck detection of Parent 1 with the efficient windowed cuts of Parent 2. We first identify **Critical Blocks**contiguous operation subsets on each machine that maximize the Carlier lower bound ($r_{min} + \\sum p + q_{min}$)rather than treating the entire machine sequence as the bottleneck. On the top competing blocks (within 90% of the global maximum LB), we apply **Sliding Window Transitivity** and **Metric Lifting** cuts. This focuses constraints specifically on the tightest temporal clusters where infeasibilities originate, strengthening the relaxation locally while maintaining global scalability."
                    },
                    "fitness": 21.57318116708071,
                    "solver_reports": [
                        {
                            "gap": 17.4837,
                            "total_time": 12.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 35163,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.6348,
                            "total_time": 12.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 35618,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 33382,
                            "explored_time": 10.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.8406,
                            "total_time": 12.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 45451,
                            "explored_time": 12.06,
                            "work_units": 10.01
                        },
                        {
                            "gap": 29.7072,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 31899,
                            "explored_time": 11.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 2.3011,
                            "total_time": 10.85,
                            "explored_nodes": 3709,
                            "simplex_iterations": 288150,
                            "explored_time": 10.84,
                            "work_units": 10.3
                        },
                        {
                            "gap": 27.8426,
                            "total_time": 11.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 49164,
                            "explored_time": 11.62,
                            "work_units": 10.01
                        },
                        {
                            "gap": 24.6852,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 35149,
                            "explored_time": 11.83,
                            "work_units": 10.25
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0"
                    ]
                }
            ],
            21.57318116708071
        ],
        [
            [
                {
                    "id": "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_adaptive_carlier_cuts(m):\n        # 1. Compute Release (heads) and Delivery (tails) times for all ops\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Carlier-style subsets)\n        # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time (heads) for efficient scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Scan all contiguous sub-segments [u, v]\n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global LB Cut and Adaptive Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.adaptive_carlier = pyo.ConstraintList()\n        m.adaptive_carlier.add(m.Cmax >= global_max)\n    \n        # Select bottlenecks strictly within 90% of global max to target active constraints\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        # Helper to access y variables (u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 5. Apply Sliding Window Cuts to Critical Blocks\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 6\n        \n        # Limit to top 3 competing blocks to manage complexity\n        for target in targets[:3]:\n            ops = target['ops']  # Already sorted by release time\n            if len(ops) < 3: continue\n            \n            cuts_added = 0\n            n_sub = len(ops)\n            \n            for idx_i in range(n_sub):\n                i = ops[idx_i]\n                # Restrict j to a local window to capture dense conflicts\n                for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                    j = ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = ops[idx_k]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Transitivity: Prevent cycles i->k->j->i\n                        # If i->k and k->j, then i->j must hold\n                        m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.adaptive_carlier.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_adaptive_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_adaptive_carlier_cuts(m):\n    # 1. Compute Release (heads) and Delivery (tails) times for all ops\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Carlier-style subsets)\n    # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time (heads) for efficient scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Scan all contiguous sub-segments [u, v]\n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global LB Cut and Adaptive Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.adaptive_carlier = pyo.ConstraintList()\n    m.adaptive_carlier.add(m.Cmax >= global_max)\n\n    # Select bottlenecks strictly within 90% of global max to target active constraints\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    # Helper to access y variables (u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 5. Apply Sliding Window Cuts to Critical Blocks\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 6\n    \n    # Limit to top 3 competing blocks to manage complexity\n    for target in targets[:3]:\n        ops = target['ops']  # Already sorted by release time\n        if len(ops) < 3: continue\n        \n        cuts_added = 0\n        n_sub = len(ops)\n        \n        for idx_i in range(n_sub):\n            i = ops[idx_i]\n            # Restrict j to a local window to capture dense conflicts\n            for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                j = ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = ops[idx_k]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity: Prevent cycles i->k->j->i\n                    # If i->k and k->j, then i->j must hold\n                    m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.adaptive_carlier.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_adaptive_carlier_cuts(model)",
                        "idea": "We introduce **Adaptive Carlier-Window Transitivity**, a hybrid strategy merging the precise bottleneck detection of Parent 1 with the efficient windowed cuts of Parent 2. We first identify **Critical Blocks**contiguous operation subsets on each machine that maximize the Carlier lower bound ($r_{min} + \\sum p + q_{min}$)rather than treating the entire machine sequence as the bottleneck. On the top competing blocks (within 90% of the global maximum LB), we apply **Sliding Window Transitivity** and **Metric Lifting** cuts. This focuses constraints specifically on the tightest temporal clusters where infeasibilities originate, strengthening the relaxation locally while maintaining global scalability."
                    },
                    "fitness": 21.57318116708071,
                    "solver_reports": [
                        {
                            "gap": 17.4837,
                            "total_time": 12.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 35163,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.6348,
                            "total_time": 12.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 35618,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 33382,
                            "explored_time": 10.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.8406,
                            "total_time": 12.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 45451,
                            "explored_time": 12.06,
                            "work_units": 10.01
                        },
                        {
                            "gap": 29.7072,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 31899,
                            "explored_time": 11.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 2.3011,
                            "total_time": 10.85,
                            "explored_nodes": 3709,
                            "simplex_iterations": 288150,
                            "explored_time": 10.84,
                            "work_units": 10.3
                        },
                        {
                            "gap": 27.8426,
                            "total_time": 11.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 49164,
                            "explored_time": 11.62,
                            "work_units": 10.01
                        },
                        {
                            "gap": 24.6852,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 35149,
                            "explored_time": 11.83,
                            "work_units": 10.25
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0"
                    ]
                },
                {
                    "id": "d66d936e-0a71-4cbc-bc7c-c5d614da48d3",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_combined_bottleneck_cuts(m):\n        # 1. Compute Heads (earliest start) and Tails (min time to end) statically\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.combined_cuts = pyo.ConstraintList()\n        \n        # 3. Carlier Bound Logic: Global LB & Bottleneck Identification\n        max_carlier_lb = 0\n        bottleneck_mach = None\n    \n        for mid, ops in mach_ops.items():\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Brute-force tightest subset window [r, ..., end-q]\n            for r in rs:\n                for q in qs:\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max: local_max = bound\n            \n            if local_max > max_carlier_lb:\n                max_carlier_lb = local_max\n                bottleneck_mach = mid\n                \n        if max_carlier_lb > 0:\n            m.combined_cuts.add(m.Cmax >= max_carlier_lb)\n    \n        # 4. Metric Triplet Lifting on the Bottleneck Machine\n        # Only adds cuts to the single most critical machine to manage complexity.\n        if bottleneck_mach is not None:\n            ops = mach_ops[bottleneck_mach]\n            # Sort ops by release time (Heuristic: likely topological order)\n            ops.sort(key=lambda x: heads[x])\n            \n            def get_y(u, v):\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n            cut_count = 0\n            CUT_LIMIT = 150  # Prevent model bloat\n            \n            # Iterate pairs (i, j) likely to have i -> j\n            for idx_i in range(len(ops)):\n                for idx_j in range(idx_i + 1, len(ops)):\n                    i = ops[idx_i]\n                    j = ops[idx_j]\n                    \n                    # Select intermediate k candidates\n                    candidates = [k for k in ops if k != i and k != j]\n                    \n                    # CRITICAL: Sort k by processing time (descending).\n                    # We want k that adds the largest delay (p_k) to the path.\n                    candidates.sort(key=lambda x: m.p[x], reverse=True)\n                    \n                    # Add lift cuts for the top 2 candidates\n                    for k in candidates[:2]:\n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Cut: If i->k->j, minimum delay is p_i + p_k.\n                        # Formally: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                        m.combined_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cut_count += 1\n                        if cut_count >= CUT_LIMIT: break\n                    if cut_count >= CUT_LIMIT: break\n                if cut_count >= CUT_LIMIT: break\n    \n    add_combined_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_combined_bottleneck_cuts(m):\n    # 1. Compute Heads (earliest start) and Tails (min time to end) statically\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.combined_cuts = pyo.ConstraintList()\n    \n    # 3. Carlier Bound Logic: Global LB & Bottleneck Identification\n    max_carlier_lb = 0\n    bottleneck_mach = None\n\n    for mid, ops in mach_ops.items():\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Brute-force tightest subset window [r, ..., end-q]\n        for r in rs:\n            for q in qs:\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max: local_max = bound\n        \n        if local_max > max_carlier_lb:\n            max_carlier_lb = local_max\n            bottleneck_mach = mid\n            \n    if max_carlier_lb > 0:\n        m.combined_cuts.add(m.Cmax >= max_carlier_lb)\n\n    # 4. Metric Triplet Lifting on the Bottleneck Machine\n    # Only adds cuts to the single most critical machine to manage complexity.\n    if bottleneck_mach is not None:\n        ops = mach_ops[bottleneck_mach]\n        # Sort ops by release time (Heuristic: likely topological order)\n        ops.sort(key=lambda x: heads[x])\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n        cut_count = 0\n        CUT_LIMIT = 150  # Prevent model bloat\n        \n        # Iterate pairs (i, j) likely to have i -> j\n        for idx_i in range(len(ops)):\n            for idx_j in range(idx_i + 1, len(ops)):\n                i = ops[idx_i]\n                j = ops[idx_j]\n                \n                # Select intermediate k candidates\n                candidates = [k for k in ops if k != i and k != j]\n                \n                # CRITICAL: Sort k by processing time (descending).\n                # We want k that adds the largest delay (p_k) to the path.\n                candidates.sort(key=lambda x: m.p[x], reverse=True)\n                \n                # Add lift cuts for the top 2 candidates\n                for k in candidates[:2]:\n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # Cut: If i->k->j, minimum delay is p_i + p_k.\n                    # Formally: S_j >= S_i + p_i + p_k * (y_ik + y_kj - 1) - M * (1 - y_ij)\n                    m.combined_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cut_count += 1\n                    if cut_count >= CUT_LIMIT: break\n                if cut_count >= CUT_LIMIT: break\n            if cut_count >= CUT_LIMIT: break\n\nadd_combined_bottleneck_cuts(model)",
                        "idea": "We combine **Bottleneck Detection** with **Heuristic Triplet Lifting**. First, we compute **Carlier Bounds** for all machines to establish a tight global lower bound on `Cmax` and identify the single most constrained machine. Second, we strengthen the formulation on this bottleneck using **Metric Lifting** cuts. By iterating through operation pairs $(i, j)$ (sorted by release times) and inserting intermediate operations $k$ with the **largest processing times**, we generate valid inequalities $S_j \\ge S_i + p_i + p_k(y_{ik} + y_{kj} - 1) - M(1 - y_{ij})$. This selectively tightens the time variables around the critical path by enforcing transitive delays where they matter most."
                    },
                    "fitness": 19.57305339519508,
                    "solver_reports": [
                        {
                            "gap": 14.4622,
                            "total_time": 14.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 29864,
                            "explored_time": 14.12,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 38784,
                            "explored_time": 11.28,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 33022,
                            "explored_time": 11.65,
                            "work_units": 10.01
                        },
                        {
                            "gap": 24.0907,
                            "total_time": 13.02,
                            "explored_nodes": 87,
                            "simplex_iterations": 60764,
                            "explored_time": 13.01,
                            "work_units": 10.41
                        },
                        {
                            "total_time": 10.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 36283,
                            "explored_time": 10.03,
                            "work_units": 10.03
                        },
                        {
                            "gap": 19.4087,
                            "total_time": 12.01,
                            "explored_nodes": 7574,
                            "simplex_iterations": 290290,
                            "explored_time": 11.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.7387,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42720,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 37439,
                            "explored_time": 10.15,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "8a14a0af-e1bd-4b78-b72a-7bdfea8929fa"
                    ]
                },
                {
                    "id": "9d532fc9-4e25-4780-9cdd-abd854b91fd2",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_optimized_carlier_triplets(m):\n        # 1. Compute Heads (r) and Tails (q) for Carlier Bound Logic\n        heads = {}\n        tails = {}\n        # Forward pass\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.opt_cuts = pyo.ConstraintList()\n        \n        max_carlier_val = 0\n        bottleneck_mach = None\n    \n        # 3. Apply Carlier Bound Lifting (Global Cuts)\n        # We apply bounds to ALL machines (Parent 2 strategy) to lift Cmax tighter globally.\n        for mid, ops in mach_ops.items():\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            # Exact 1-machine head-tail relaxation\n            for r in rs:\n                for q in qs:\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max: local_max = bound\n            \n            if local_max > 0:\n                m.opt_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Bottleneck Triplet Lifting\n        # Apply cuts only to the bottleneck machine, using Parent 1's heuristic sorting.\n        if bottleneck_mach is not None:\n            ops = mach_ops[bottleneck_mach]\n            # Sort by Heads: priority to pairs likely to be ordered i->j naturally\n            ops.sort(key=lambda x: heads[x])\n            \n            def get_y(u, v):\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            cut_count = 0\n            BUDGET = 200\n    \n            for i_idx in range(len(ops)):\n                for j_idx in range(i_idx + 1, len(ops)):\n                    u = ops[i_idx]\n                    v = ops[j_idx]\n                    \n                    # Identify candidates k and sort by Processing Time Descending (Parent 1)\n                    # This prioritizes cuts that impose the largest delay penalty (p_k).\n                    candidates = [k for k in ops if k != u and k != v]\n                    candidates.sort(key=lambda x: m.p[x], reverse=True)\n                    \n                    # Apply lifting for the top 2 candidates\n                    for k in candidates[:2]:\n                        y_uv = get_y(u, v)\n                        y_uk = get_y(u, k)\n                        y_kv = get_y(k, v)\n                        \n                        # (A) Transitivity Cut: Enforce logical consistency on binary vars\n                        m.opt_cuts.add(y_uk + y_kv - y_uv <= 1)\n                        \n                        # (B) Metric Lifting Cut: Tighten start times based on path u->k->v\n                        # S_v >= S_u + p_u + p_k (if u->k->v active)\n                        m.opt_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[k] * (y_uk + y_kv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        cut_count += 2\n                        if cut_count >= BUDGET: break\n                    if cut_count >= BUDGET: break\n                if cut_count >= BUDGET: break\n    \n    add_optimized_carlier_triplets(model)\n\n    return model\n",
                        "added_cut": "def add_optimized_carlier_triplets(m):\n    # 1. Compute Heads (r) and Tails (q) for Carlier Bound Logic\n    heads = {}\n    tails = {}\n    # Forward pass\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.opt_cuts = pyo.ConstraintList()\n    \n    max_carlier_val = 0\n    bottleneck_mach = None\n\n    # 3. Apply Carlier Bound Lifting (Global Cuts)\n    # We apply bounds to ALL machines (Parent 2 strategy) to lift Cmax tighter globally.\n    for mid, ops in mach_ops.items():\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        # Exact 1-machine head-tail relaxation\n        for r in rs:\n            for q in qs:\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max: local_max = bound\n        \n        if local_max > 0:\n            m.opt_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Bottleneck Triplet Lifting\n    # Apply cuts only to the bottleneck machine, using Parent 1's heuristic sorting.\n    if bottleneck_mach is not None:\n        ops = mach_ops[bottleneck_mach]\n        # Sort by Heads: priority to pairs likely to be ordered i->j naturally\n        ops.sort(key=lambda x: heads[x])\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        cut_count = 0\n        BUDGET = 200\n\n        for i_idx in range(len(ops)):\n            for j_idx in range(i_idx + 1, len(ops)):\n                u = ops[i_idx]\n                v = ops[j_idx]\n                \n                # Identify candidates k and sort by Processing Time Descending (Parent 1)\n                # This prioritizes cuts that impose the largest delay penalty (p_k).\n                candidates = [k for k in ops if k != u and k != v]\n                candidates.sort(key=lambda x: m.p[x], reverse=True)\n                \n                # Apply lifting for the top 2 candidates\n                for k in candidates[:2]:\n                    y_uv = get_y(u, v)\n                    y_uk = get_y(u, k)\n                    y_kv = get_y(k, v)\n                    \n                    # (A) Transitivity Cut: Enforce logical consistency on binary vars\n                    m.opt_cuts.add(y_uk + y_kv - y_uv <= 1)\n                    \n                    # (B) Metric Lifting Cut: Tighten start times based on path u->k->v\n                    # S_v >= S_u + p_u + p_k (if u->k->v active)\n                    m.opt_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[k] * (y_uk + y_kv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    cut_count += 2\n                    if cut_count >= BUDGET: break\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n\nadd_optimized_carlier_triplets(model)",
                        "idea": "We implement **Optimized Carlier Triplet Lifting** by synthesizing the strongest features of both parents. First, we apply **Carlier Bounds** to *all* machines (adopting Parent 2's robust global bounding) to lift the `Cmax` lower bound. Second, we identify the single bottleneck machine and apply cut generation. We use Parent 1's **Processing-Time Sorting** for intermediate nodes k. By prioritising intermediates with the largest processing times p_k, the added **Metric Lifting** (S_j >= S_i + p_i + p_k*(y_ik+y_kj-1)) and **Transitivity** cuts impose the maximum possible delay on the bottleneck sequence within a fixed budget, tightening the relaxation where it matters most."
                    },
                    "fitness": 19.605970103237805,
                    "solver_reports": [
                        {
                            "gap": 27.1865,
                            "total_time": 12.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 33016,
                            "explored_time": 12.1,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.0032,
                            "total_time": 12.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 35713,
                            "explored_time": 12.63,
                            "work_units": 10.37
                        },
                        {
                            "gap": 29.0977,
                            "total_time": 11.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 29959,
                            "explored_time": 11.29,
                            "work_units": 10.25
                        },
                        {
                            "gap": 19.7285,
                            "total_time": 14.0,
                            "explored_nodes": 114,
                            "simplex_iterations": 81794,
                            "explored_time": 13.99,
                            "work_units": 11.43
                        },
                        {
                            "total_time": 10.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 31618,
                            "explored_time": 10.17,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.6243,
                            "total_time": 14.17,
                            "explored_nodes": 1355,
                            "simplex_iterations": 58938,
                            "explored_time": 14.17,
                            "work_units": 12.52
                        },
                        {
                            "gap": 28.2782,
                            "total_time": 12.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 51541,
                            "explored_time": 12.32,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.13,
                            "explored_nodes": 1,
                            "simplex_iterations": 37522,
                            "explored_time": 11.08,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "8a14a0af-e1bd-4b78-b72a-7bdfea8929fa",
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                },
                {
                    "id": "35e4c99d-cd5a-44e1-98e7-0af1293c544a",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_bottleneck_cuts(m):\n        # 1. Compute Heads (r) and Tails (q) dynamically\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K):\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify the Single Most Critical Block (Global Bottleneck)\n        # We seek the subset of operations on a single machine maximizing the Carlier Bound.\n        best_lb = -1\n        critical_block = [] # List of (j, k)\n        \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Data: (r, p, q, op_key)\n            data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            for r in rs:\n                for q in qs:\n                    # Subset strictly inside the window [r, ... , end-q]\n                    # i.e., head >= r and tail >= q\n                    sub = [d for d in data if d[0] >= r and d[2] >= q]\n                    if not sub: continue\n                    lb = r + sum(d[1] for d in sub) + q\n                    if lb > best_lb:\n                        best_lb = lb\n                        critical_block = [d[3] for d in sub]\n    \n        if not critical_block or len(critical_block) < 2: return\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        # 4. Global Lower Bound Cut (Strengthening Cmax)\n        m.hybrid_cuts.add(m.Cmax >= best_lb)\n    \n        # 5. Energetic Span Constraints (From Parent 2)\n        # We introduce auxiliary variables to bound the start and end of this specific critical block.\n        # This forces the continuous relaxation to respect the total duration of the block.\n        m.blk_start = pyo.Var(domain=pyo.NonNegativeReals)\n        m.blk_end   = pyo.Var(domain=pyo.NonNegativeReals)\n        \n        total_p = sum(m.p[op] for op in critical_block)\n        \n        # The block duration must be at least the sum of processing times\n        m.hybrid_cuts.add(m.blk_end - m.blk_start >= total_p)\n        \n        for op in critical_block:\n            # Bounding box constraints\n            m.hybrid_cuts.add(m.blk_start <= m.S[op])\n            m.hybrid_cuts.add(m.blk_end   >= m.S[op] + m.p[op])\n    \n        # 6. Restricted Triangle Precedence Cuts (From Parent 1)\n        # We apply the expensive triangle cuts ONLY to the members of the critical block.\n        # This captures the local sequencing logic needed to resolve the bottleneck.\n        def get_y(u, v):\n            # Helper to handle the symmetry of the y variable\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        if len(critical_block) >= 3:\n            cut_limit = 200\n            cut_count = 0\n            # Iterate triplets only within the critical block\n            for i in critical_block:\n                for j in critical_block:\n                    if i == j: continue\n                    y_ij = get_y(i, j)\n                    \n                    for k in critical_block:\n                        if k == i or k == j: continue\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Logic: If i -> k and k -> j, then S[j] >= S[i] + p[i] + p[k]\n                        # Lifted form: S[j] >= S[i] + p[i] + p[k]*(y_ik + y_kj - 1) - M*(1 - y_ij)\n                        m.hybrid_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cut_count += 1\n                        if cut_count >= cut_limit: break\n                if cut_count >= cut_limit: break\n    \n    add_hybrid_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_bottleneck_cuts(m):\n    # 1. Compute Heads (r) and Tails (q) dynamically\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K):\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify the Single Most Critical Block (Global Bottleneck)\n    # We seek the subset of operations on a single machine maximizing the Carlier Bound.\n    best_lb = -1\n    critical_block = [] # List of (j, k)\n    \n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Data: (r, p, q, op_key)\n        data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        for r in rs:\n            for q in qs:\n                # Subset strictly inside the window [r, ... , end-q]\n                # i.e., head >= r and tail >= q\n                sub = [d for d in data if d[0] >= r and d[2] >= q]\n                if not sub: continue\n                lb = r + sum(d[1] for d in sub) + q\n                if lb > best_lb:\n                    best_lb = lb\n                    critical_block = [d[3] for d in sub]\n\n    if not critical_block or len(critical_block) < 2: return\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    # 4. Global Lower Bound Cut (Strengthening Cmax)\n    m.hybrid_cuts.add(m.Cmax >= best_lb)\n\n    # 5. Energetic Span Constraints (From Parent 2)\n    # We introduce auxiliary variables to bound the start and end of this specific critical block.\n    # This forces the continuous relaxation to respect the total duration of the block.\n    m.blk_start = pyo.Var(domain=pyo.NonNegativeReals)\n    m.blk_end   = pyo.Var(domain=pyo.NonNegativeReals)\n    \n    total_p = sum(m.p[op] for op in critical_block)\n    \n    # The block duration must be at least the sum of processing times\n    m.hybrid_cuts.add(m.blk_end - m.blk_start >= total_p)\n    \n    for op in critical_block:\n        # Bounding box constraints\n        m.hybrid_cuts.add(m.blk_start <= m.S[op])\n        m.hybrid_cuts.add(m.blk_end   >= m.S[op] + m.p[op])\n\n    # 6. Restricted Triangle Precedence Cuts (From Parent 1)\n    # We apply the expensive triangle cuts ONLY to the members of the critical block.\n    # This captures the local sequencing logic needed to resolve the bottleneck.\n    def get_y(u, v):\n        # Helper to handle the symmetry of the y variable\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    if len(critical_block) >= 3:\n        cut_limit = 200\n        cut_count = 0\n        # Iterate triplets only within the critical block\n        for i in critical_block:\n            for j in critical_block:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in critical_block:\n                    if k == i or k == j: continue\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # Logic: If i -> k and k -> j, then S[j] >= S[i] + p[i] + p[k]\n                    # Lifted form: S[j] >= S[i] + p[i] + p[k]*(y_ik + y_kj - 1) - M*(1 - y_ij)\n                    m.hybrid_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cut_count += 1\n                    if cut_count >= cut_limit: break\n            if cut_count >= cut_limit: break\n\nadd_hybrid_bottleneck_cuts(model)",
                        "idea": "We apply **Critical Block Triangle Lifting**. This hybrid strategy identifies the single most critical set of operations (the 'Critical Block' maximizing the Carlier Lower Bound) and strengthens the formulation locally on that subset. We combine Parent 2's **Energetic Span** constraints (introducing continuous variables to enforce $v_{end} - v_{start} \\ge \\sum p_{ops}$) with Parent 1's **Triangle Precedence** cuts, restricted solely to this block. This dual approach tightens the relaxation by enforcing both aggregate capacity requirements (via span vars) and precise ordering logic (via lifted precedence cuts) where they matter most, improving the bound without the overhead of global cuts."
                    },
                    "fitness": 19.87567633597984,
                    "solver_reports": [
                        {
                            "gap": 16.0308,
                            "total_time": 13.57,
                            "explored_nodes": 1,
                            "simplex_iterations": 34790,
                            "explored_time": 13.51,
                            "work_units": 10.0
                        },
                        {
                            "gap": 30.034,
                            "total_time": 13.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 35704,
                            "explored_time": 13.34,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 33311,
                            "explored_time": 10.29,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.9877,
                            "total_time": 13.43,
                            "explored_nodes": 87,
                            "simplex_iterations": 52780,
                            "explored_time": 13.42,
                            "work_units": 10.6
                        },
                        {
                            "total_time": 10.42,
                            "explored_nodes": 1,
                            "simplex_iterations": 37331,
                            "explored_time": 10.37,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.5122,
                            "total_time": 11.81,
                            "explored_nodes": 1249,
                            "simplex_iterations": 75531,
                            "explored_time": 11.8,
                            "work_units": 10.49
                        },
                        {
                            "gap": 24.3081,
                            "total_time": 13.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 45063,
                            "explored_time": 13.24,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.5414,
                            "total_time": 12.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 37446,
                            "explored_time": 12.4,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "9ff6637c-b48f-4329-bff1-733898e9a954"
                    ]
                },
                {
                    "id": "83a97914-4c29-41e9-b8f3-7f956afb31a9",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_carlier_cuts(m):\n        # 1. Precompute Timing (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper for precedence vars\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n    \n        # 3. Identify Critical Carlier Blocks (Parent 1's rigorous detection)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n    \n            # Scan for max LB subset [i, j]\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                current_sub = []\n                r_val = heads[sorted_ops[i]]\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global Cuts & Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.hybrid_cuts.add(m.Cmax >= global_max)\n    \n        # Select top bottlenecks (Parent 2's adaptive targeting)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        # 5. Apply Budgeted Sliding Window Cuts\n        CUT_BUDGET = 200\n        WINDOW = 6\n        cuts_added = 0\n        \n        for target in targets[:3]:\n            ops = target['ops']\n            if len(ops) < 3: continue\n            \n            for i_idx in range(len(ops)):\n                u = ops[i_idx]\n                limit = min(i_idx + WINDOW, len(ops))\n                for j_idx in range(i_idx + 1, limit):\n                    v = ops[j_idx]\n                    \n                    # Intermediate node w\n                    for k_idx in range(i_idx + 1, j_idx):\n                        w = ops[k_idx]\n                        \n                        # Access binary variables\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        y_uv = get_y(u, v)\n                        \n                        # Cut A: Transitivity (Logical)\n                        # u->w and w->v implies u->v\n                        m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n                        \n                        # Cut B: Metric Lifting (Temporal)\n                        # S_v >= S_u + p_u + p_w if path u->w->v exists\n                        m.hybrid_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[w] * (y_uw + y_wv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_hybrid_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_carlier_cuts(m):\n    # 1. Precompute Timing (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper for precedence vars\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.hybrid_cuts = pyo.ConstraintList()\n\n    # 3. Identify Critical Carlier Blocks (Parent 1's rigorous detection)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n\n        # Scan for max LB subset [i, j]\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            current_sub = []\n            r_val = heads[sorted_ops[i]]\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global Cuts & Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.hybrid_cuts.add(m.Cmax >= global_max)\n\n    # Select top bottlenecks (Parent 2's adaptive targeting)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    # 5. Apply Budgeted Sliding Window Cuts\n    CUT_BUDGET = 200\n    WINDOW = 6\n    cuts_added = 0\n    \n    for target in targets[:3]:\n        ops = target['ops']\n        if len(ops) < 3: continue\n        \n        for i_idx in range(len(ops)):\n            u = ops[i_idx]\n            limit = min(i_idx + WINDOW, len(ops))\n            for j_idx in range(i_idx + 1, limit):\n                v = ops[j_idx]\n                \n                # Intermediate node w\n                for k_idx in range(i_idx + 1, j_idx):\n                    w = ops[k_idx]\n                    \n                    # Access binary variables\n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    y_uv = get_y(u, v)\n                    \n                    # Cut A: Transitivity (Logical)\n                    # u->w and w->v implies u->v\n                    m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n                    \n                    # Cut B: Metric Lifting (Temporal)\n                    # S_v >= S_u + p_u + p_w if path u->w->v exists\n                    m.hybrid_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[w] * (y_uw + y_wv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_hybrid_carlier_cuts(model)",
                        "idea": "We merge Parent 1's rigorous Carlier-bound detection (checking r_min + sum(p) + q_min for subsets) with Parent 2's adaptive budgeting and sliding window strategy. This isolates the specific operation blocks causing the global bottleneck. Within these high-contention intervals, we apply a sliding window to enforce transitivity (y_uw + y_wv - y_uv <= 1) and metric lifting (S_v >= S_u + p_u + p_w), effectively tightening the relaxation exactly where the schedule is most constrained while limiting model growth."
                    },
                    "fitness": 19.83417144596678,
                    "solver_reports": [
                        {
                            "gap": 14.0998,
                            "total_time": 13.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 33572,
                            "explored_time": 13.04,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 35434,
                            "explored_time": 11.15,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 10.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 35208,
                            "explored_time": 10.2,
                            "work_units": 10.0
                        },
                        {
                            "gap": 24.1556,
                            "total_time": 13.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 42577,
                            "explored_time": 13.17,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 10.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 31542,
                            "explored_time": 10.67,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.6625,
                            "total_time": 12.23,
                            "explored_nodes": 8755,
                            "simplex_iterations": 322265,
                            "explored_time": 12.2,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.7,
                            "explored_nodes": 378,
                            "simplex_iterations": 75180,
                            "explored_time": 11.68,
                            "work_units": 10.02
                        },
                        {
                            "total_time": 10.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 38769,
                            "explored_time": 10.69,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "6107275e-ce57-4c88-9ae3-c54885342a51",
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86"
                    ]
                },
                {
                    "id": "34d4a37e-3a24-452f-a8ce-de67f0626e10",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_carlier_critical_window_cuts(m):\n        # 1. Calculate Heads (r) and Tails (q) dynamically\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access precedence variables safely\n        def get_y(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                # y[v, u] represents v->u, so u->v is 1 - y[v, u]\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        candidates = []\n    \n        # 3. Exact Carlier Subset Detection (Parent 1 Logic)\n        # We identify the exact subset of ops maximizing the 1-machine LB\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Boundary candidates\n            r_vals = sorted(list(set(heads[op] for op in ops)))\n            q_vals = sorted(list(set(tails[op] for op in ops)))\n            \n            best_lb = -1\n            best_subset = []\n            \n            # Brute-force check to find the tightest core [r, ..., q]\n            for r in r_vals:\n                for q in q_vals:\n                    # Filter ops contained strictly within logical window\n                    subset = [op for op in ops if heads[op] >= r and tails[op] >= q]\n                    if not subset: continue\n                    \n                    p_sum = sum(m.p[op] for op in subset)\n                    lb = r + p_sum + q\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_subset = subset\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_subset})\n    \n        if not candidates: return\n    \n        # 4. Global Cuts\n        # Sort candidates by bound strength\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.hybrid_cuts.add(m.Cmax >= global_max)\n    \n        # 5. Targeted Lifting on Critical Subsets (Parent 2 Window Logic)\n        # Apply cuts only to the top bottlenecks\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        for target in targets[:3]: # Limit to top 3 machines\n            crit_ops = target['ops']\n            # Sort by head time to linearize the precedence flow\n            crit_ops.sort(key=lambda x: heads[x])\n            \n            n_crit = len(crit_ops)\n            if n_crit < 3: continue\n                \n            # Sliding window logic within the critical subset\n            # A window size of 5 captures local interference without N^3 explosion\n            WINDOW = 5\n            \n            for i in range(n_crit):\n                op_i = crit_ops[i]\n                limit = min(i + WINDOW, n_crit)\n                \n                for j in range(i + 1, limit):\n                    op_j = crit_ops[j]\n                    \n                    # Intermediate node k\n                    for k in range(i + 1, j):\n                        op_k = crit_ops[k]\n                        \n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # (A) Transitivity Cut: i->k and k->j => i->j\n                        m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Triangle Precedence Lifting (Parent 1)\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        # (y_ik + y_kj - 1) forces p_k only when both arcs are active\n                        m.hybrid_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n    \n    add_carlier_critical_window_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_carlier_critical_window_cuts(m):\n    # 1. Calculate Heads (r) and Tails (q) dynamically\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access precedence variables safely\n    def get_y(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            # y[v, u] represents v->u, so u->v is 1 - y[v, u]\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    candidates = []\n\n    # 3. Exact Carlier Subset Detection (Parent 1 Logic)\n    # We identify the exact subset of ops maximizing the 1-machine LB\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Boundary candidates\n        r_vals = sorted(list(set(heads[op] for op in ops)))\n        q_vals = sorted(list(set(tails[op] for op in ops)))\n        \n        best_lb = -1\n        best_subset = []\n        \n        # Brute-force check to find the tightest core [r, ..., q]\n        for r in r_vals:\n            for q in q_vals:\n                # Filter ops contained strictly within logical window\n                subset = [op for op in ops if heads[op] >= r and tails[op] >= q]\n                if not subset: continue\n                \n                p_sum = sum(m.p[op] for op in subset)\n                lb = r + p_sum + q\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_subset = subset\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_subset})\n\n    if not candidates: return\n\n    # 4. Global Cuts\n    # Sort candidates by bound strength\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.hybrid_cuts.add(m.Cmax >= global_max)\n\n    # 5. Targeted Lifting on Critical Subsets (Parent 2 Window Logic)\n    # Apply cuts only to the top bottlenecks\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    for target in targets[:3]: # Limit to top 3 machines\n        crit_ops = target['ops']\n        # Sort by head time to linearize the precedence flow\n        crit_ops.sort(key=lambda x: heads[x])\n        \n        n_crit = len(crit_ops)\n        if n_crit < 3: continue\n            \n        # Sliding window logic within the critical subset\n        # A window size of 5 captures local interference without N^3 explosion\n        WINDOW = 5\n        \n        for i in range(n_crit):\n            op_i = crit_ops[i]\n            limit = min(i + WINDOW, n_crit)\n            \n            for j in range(i + 1, limit):\n                op_j = crit_ops[j]\n                \n                # Intermediate node k\n                for k in range(i + 1, j):\n                    op_k = crit_ops[k]\n                    \n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # (A) Transitivity Cut: i->k and k->j => i->j\n                    m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Triangle Precedence Lifting (Parent 1)\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    # (y_ik + y_kj - 1) forces p_k only when both arcs are active\n                    m.hybrid_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n\nadd_carlier_critical_window_cuts(model)",
                        "idea": "We combine Parent 1's rigorous **Exact Carlier Subset Detection** with Parent 2's efficient **Windowed Transitivity**. Instead of scanning the entire machine (as in Parent 1) or approximating blocks (as in Parent 2), we first identify the exact subset of operations responsible for the strongest 1-machine lower bound. Within this high-contention core, we apply a tight sliding window of **Triangle Precedence** and **Transitivity** cuts. This focuses the strongest polyhedral tightening (lifting) exactly where the bottleneck bound is determined, efficiently strengthening the convex hull in the most critical subspace."
                    },
                    "fitness": 18.64822837620996,
                    "solver_reports": [
                        {
                            "total_time": 10.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 34837,
                            "explored_time": 10.75,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.6111,
                            "total_time": 13.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 23190,
                            "explored_time": 13.85,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 34970,
                            "explored_time": 10.39,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.4001,
                            "total_time": 12.68,
                            "explored_nodes": 87,
                            "simplex_iterations": 73961,
                            "explored_time": 12.67,
                            "work_units": 10.52
                        },
                        {
                            "total_time": 10.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 33655,
                            "explored_time": 10.14,
                            "work_units": 10.02
                        },
                        {
                            "gap": 18.4125,
                            "total_time": 12.22,
                            "explored_nodes": 1399,
                            "simplex_iterations": 81486,
                            "explored_time": 12.21,
                            "work_units": 11.67
                        },
                        {
                            "gap": 37.7433,
                            "total_time": 13.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 52838,
                            "explored_time": 13.02,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 34279,
                            "explored_time": 10.94,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff",
                        "6107275e-ce57-4c88-9ae3-c54885342a51"
                    ]
                },
                {
                    "id": "bdbe6b34-2649-417d-94d8-021a8a417041",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def apply_enhanced_bottleneck_cuts(m):\n        # 1. Dynamic calculation of heads (r) and tails (q)\n        # These represent the earliest start and minimum tail latency based on job sequence\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in reversed(list(m.K)):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops:\n                mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.enhanced_cuts = pyo.ConstraintList()\n        max_carlier_val = -1\n        bottleneck_mach = None\n    \n        # 3. Global Carlier Bound Lifting\n        # Strengthens Cmax >= r_min + sum(p) + q_min for all subsets on each machine\n        for mid, ops in mach_ops.items():\n            data = [(heads[op], m.p[op], tails[op]) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            for r in rs:\n                for q in qs:\n                    # Sum processing times for ops strictly within the [r, q] window\n                    p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                    if p_sum > 0:\n                        bound = r + p_sum + q\n                        if bound > local_max:\n                            local_max = bound\n            \n            if local_max > 0:\n                m.enhanced_cuts.add(m.Cmax >= local_max)\n                \n            if local_max > max_carlier_val:\n                max_carlier_val = local_max\n                bottleneck_mach = mid\n    \n        # 4. Transitivity-Enforced Triangle Lifting on Bottleneck\n        # If machine is critical, enforce logic consistency (transitivity) and lift Start times\n        if bottleneck_mach is not None:\n            ops = mach_ops[bottleneck_mach]\n            limit = 100  # Prevent O(N^3) explosion\n            count = 0\n            \n            # Helper to retrieve binary precedence variable y_{uv} (1 if u -> v)\n            def get_y(u, v):\n                if u < v:\n                    return m.y[u[0], u[1], v[0], v[1]]\n                else:\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n            for i in ops:\n                for j in ops:\n                    if i == j: continue\n                    y_ij = get_y(i, j)\n                    \n                    for k in ops:\n                        if k == i or k == j: continue\n                        \n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # MUTATION: Explicit Transitivity Constraint\n                        # If i->k and k->j, then i->j must be true. \n                        # This tightens the boolean polytope, making the Big-M liftings active.\n                        m.enhanced_cuts.add(y_ik + y_kj - 1 <= y_ij)\n                        \n                        # Triangle Precedence Lifting (Strengthened by Transitivity)\n                        # S_j >= S_i + p_i + p_k if i->k->j\n                        m.enhanced_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        count += 1\n                        if count >= limit: break\n                if count >= limit: break\n    \n    apply_enhanced_bottleneck_cuts(model)\n\n    return model\n",
                        "added_cut": "def apply_enhanced_bottleneck_cuts(m):\n    # 1. Dynamic calculation of heads (r) and tails (q)\n    # These represent the earliest start and minimum tail latency based on job sequence\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in reversed(list(m.K)):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops:\n            mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.enhanced_cuts = pyo.ConstraintList()\n    max_carlier_val = -1\n    bottleneck_mach = None\n\n    # 3. Global Carlier Bound Lifting\n    # Strengthens Cmax >= r_min + sum(p) + q_min for all subsets on each machine\n    for mid, ops in mach_ops.items():\n        data = [(heads[op], m.p[op], tails[op]) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        for r in rs:\n            for q in qs:\n                # Sum processing times for ops strictly within the [r, q] window\n                p_sum = sum(d[1] for d in data if d[0] >= r and d[2] >= q)\n                if p_sum > 0:\n                    bound = r + p_sum + q\n                    if bound > local_max:\n                        local_max = bound\n        \n        if local_max > 0:\n            m.enhanced_cuts.add(m.Cmax >= local_max)\n            \n        if local_max > max_carlier_val:\n            max_carlier_val = local_max\n            bottleneck_mach = mid\n\n    # 4. Transitivity-Enforced Triangle Lifting on Bottleneck\n    # If machine is critical, enforce logic consistency (transitivity) and lift Start times\n    if bottleneck_mach is not None:\n        ops = mach_ops[bottleneck_mach]\n        limit = 100  # Prevent O(N^3) explosion\n        count = 0\n        \n        # Helper to retrieve binary precedence variable y_{uv} (1 if u -> v)\n        def get_y(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n        for i in ops:\n            for j in ops:\n                if i == j: continue\n                y_ij = get_y(i, j)\n                \n                for k in ops:\n                    if k == i or k == j: continue\n                    \n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # MUTATION: Explicit Transitivity Constraint\n                    # If i->k and k->j, then i->j must be true. \n                    # This tightens the boolean polytope, making the Big-M liftings active.\n                    m.enhanced_cuts.add(y_ik + y_kj - 1 <= y_ij)\n                    \n                    # Triangle Precedence Lifting (Strengthened by Transitivity)\n                    # S_j >= S_i + p_i + p_k if i->k->j\n                    m.enhanced_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    count += 1\n                    if count >= limit: break\n            if count >= limit: break\n\napply_enhanced_bottleneck_cuts(model)",
                        "idea": "We preserve the bottleneck detection via Carlier Bounds but mutate the lifting strategy by adding **Triangle Transitivity Constraints** ($y_{ik} + y_{kj} - 1 \\le y_{ij}$) alongside the precedence lifting. In the original approach, lifting start times based on intermediate nodes ($S_j \\ge S_i + p_i + p_k$) is often weakened by fractional values of the binary variables $y$ in the LP relaxation. By explicitly enforcing transitivity on the bottleneck machine, we prune inconsistent partial orderings (e.g., $i \\to k \\to j$ but not $i \\to j$), ensuring the lifting cuts are active and tighter in the search tree."
                    },
                    "fitness": 19.89222850550005,
                    "solver_reports": [
                        {
                            "gap": 17.853,
                            "total_time": 12.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 33652,
                            "explored_time": 12.66,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 36119,
                            "explored_time": 10.21,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 33496,
                            "explored_time": 12.06,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.6974,
                            "total_time": 12.88,
                            "explored_nodes": 115,
                            "simplex_iterations": 74660,
                            "explored_time": 12.86,
                            "work_units": 11.06
                        },
                        {
                            "total_time": 10.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 32985,
                            "explored_time": 10.69,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.1462,
                            "total_time": 12.19,
                            "explored_nodes": 5376,
                            "simplex_iterations": 200635,
                            "explored_time": 12.16,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.9555,
                            "total_time": 12.23,
                            "explored_nodes": 1,
                            "simplex_iterations": 41479,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.4869,
                            "total_time": 13.11,
                            "explored_nodes": 1,
                            "simplex_iterations": 38908,
                            "explored_time": 13.07,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "896d3ed3-5dc2-4da0-9f37-8e47cb9ef4ff"
                    ]
                },
                {
                    "id": "632fc546-f223-4d34-8ce8-f4fc49fd82ef",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_optimized_carlier_cuts(m):\n        # 1. Compute Heads (earliest start) and Tails (min time to end)\n        heads = {}\n        tails = {}\n        # Forward pass for heads\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass for tails\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Carlier subsets)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (head) to efficiently find bottleneck intervals\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            \n            # Scan all contiguous sub-segments [u, v]\n            for u in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n):\n                    op = sorted_ops[v]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    \n                    # 1-machine LB: min_r + sum_p + min_q\n                    lb = r_u + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global Cuts & Selection\n        m.carlier_cuts = pyo.ConstraintList()\n        \n        # Sort candidates by LB to find global max\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        # (A) Global Lower Bound Cut\n        m.carlier_cuts.add(m.Cmax >= global_max)\n    \n        # Select bottlenecks strictly within 90% of global max\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n        # Helper to access y variables safely\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 5. Apply Windowed Transitivity and Lifting\n        CUT_LIMIT = 200  # Budget per bottleneck to prevent bloating\n        WINDOW = 6       # Lookahead window for dense conflicts\n        \n        for target in targets[:3]: # Focus on top 3 bottlenecks\n            ops = target['ops']\n            n_ops = len(ops)\n            if n_ops < 3: continue\n            \n            cuts_added = 0\n            for i in range(n_ops):\n                op_i = ops[i]\n                limit = min(i + WINDOW, n_ops)\n                for j in range(i + 1, limit):\n                    op_j = ops[j]\n                    \n                    # Intermediate node k\n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Check transitivity triplet (i, k, j) inside the critical block\n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Cut 1: Transitivity (Logical Consistency)\n                        # i->k and k->j => i->j\n                        m.carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Cut 2: Lifted Precedence (Metric Consistency)\n                        # S_j >= S_i + p_i + p_k if path i->k->j is active\n                        m.carlier_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_LIMIT: break\n                    if cuts_added >= CUT_LIMIT: break\n                if cuts_added >= CUT_LIMIT: break\n    \n    add_optimized_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_optimized_carlier_cuts(m):\n    # 1. Compute Heads (earliest start) and Tails (min time to end)\n    heads = {}\n    tails = {}\n    # Forward pass for heads\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass for tails\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Carlier subsets)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (head) to efficiently find bottleneck intervals\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        \n        # Scan all contiguous sub-segments [u, v]\n        for u in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n):\n                op = sorted_ops[v]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                \n                # 1-machine LB: min_r + sum_p + min_q\n                lb = r_u + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global Cuts & Selection\n    m.carlier_cuts = pyo.ConstraintList()\n    \n    # Sort candidates by LB to find global max\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    # (A) Global Lower Bound Cut\n    m.carlier_cuts.add(m.Cmax >= global_max)\n\n    # Select bottlenecks strictly within 90% of global max\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n\n    # Helper to access y variables safely\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 5. Apply Windowed Transitivity and Lifting\n    CUT_LIMIT = 200  # Budget per bottleneck to prevent bloating\n    WINDOW = 6       # Lookahead window for dense conflicts\n    \n    for target in targets[:3]: # Focus on top 3 bottlenecks\n        ops = target['ops']\n        n_ops = len(ops)\n        if n_ops < 3: continue\n        \n        cuts_added = 0\n        for i in range(n_ops):\n            op_i = ops[i]\n            limit = min(i + WINDOW, n_ops)\n            for j in range(i + 1, limit):\n                op_j = ops[j]\n                \n                # Intermediate node k\n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Check transitivity triplet (i, k, j) inside the critical block\n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Cut 1: Transitivity (Logical Consistency)\n                    # i->k and k->j => i->j\n                    m.carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Cut 2: Lifted Precedence (Metric Consistency)\n                    # S_j >= S_i + p_i + p_k if path i->k->j is active\n                    m.carlier_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_LIMIT: break\n                if cuts_added >= CUT_LIMIT: break\n            if cuts_added >= CUT_LIMIT: break\n\nadd_optimized_carlier_cuts(model)",
                        "idea": "We implement Critical Block Carlier-Cuts. By scanning contiguous operation subsets on each machine, we identify 'Critical Blocks' that maximize the 1-machine lower bound ($r_{\\min} + \\sum p + q_{\\min}$). This yields a rigorous global lower bound on $C_{max}$. We then target the most critical blocks (within 90% of the max LB) and apply Windowed Transitivity and Path-Lifted Precedence cuts. This focuses the expensive cuts solely on the time intervals and machines that actively drive the makespan, reducing search space without overwhelming the solver."
                    },
                    "fitness": 19.011834236432858,
                    "solver_reports": [
                        {
                            "gap": 23.0832,
                            "total_time": 10.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 35226,
                            "explored_time": 10.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 33.4906,
                            "total_time": 12.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 37872,
                            "explored_time": 12.8,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 34047,
                            "explored_time": 9.93,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.0905,
                            "total_time": 12.5,
                            "explored_nodes": 87,
                            "simplex_iterations": 59193,
                            "explored_time": 12.49,
                            "work_units": 10.36
                        },
                        {
                            "total_time": 10.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 35896,
                            "explored_time": 10.36,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.2806,
                            "total_time": 11.62,
                            "explored_nodes": 1412,
                            "simplex_iterations": 87142,
                            "explored_time": 11.61,
                            "work_units": 10.21
                        },
                        {
                            "total_time": 10.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 45988,
                            "explored_time": 10.49,
                            "work_units": 10.09
                        },
                        {
                            "gap": 30.4054,
                            "total_time": 11.13,
                            "explored_nodes": 1,
                            "simplex_iterations": 36725,
                            "explored_time": 11.08,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "6107275e-ce57-4c88-9ae3-c54885342a51",
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86"
                    ]
                }
            ],
            21.57318116708071
        ],
        [
            [
                {
                    "id": "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_adaptive_carlier_cuts(m):\n        # 1. Compute Release (heads) and Delivery (tails) times for all ops\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Carlier-style subsets)\n        # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time (heads) for efficient scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Scan all contiguous sub-segments [u, v]\n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global LB Cut and Adaptive Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.adaptive_carlier = pyo.ConstraintList()\n        m.adaptive_carlier.add(m.Cmax >= global_max)\n    \n        # Select bottlenecks strictly within 90% of global max to target active constraints\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        # Helper to access y variables (u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 5. Apply Sliding Window Cuts to Critical Blocks\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 6\n        \n        # Limit to top 3 competing blocks to manage complexity\n        for target in targets[:3]:\n            ops = target['ops']  # Already sorted by release time\n            if len(ops) < 3: continue\n            \n            cuts_added = 0\n            n_sub = len(ops)\n            \n            for idx_i in range(n_sub):\n                i = ops[idx_i]\n                # Restrict j to a local window to capture dense conflicts\n                for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                    j = ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = ops[idx_k]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Transitivity: Prevent cycles i->k->j->i\n                        # If i->k and k->j, then i->j must hold\n                        m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.adaptive_carlier.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_adaptive_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_adaptive_carlier_cuts(m):\n    # 1. Compute Release (heads) and Delivery (tails) times for all ops\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Carlier-style subsets)\n    # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time (heads) for efficient scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Scan all contiguous sub-segments [u, v]\n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global LB Cut and Adaptive Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.adaptive_carlier = pyo.ConstraintList()\n    m.adaptive_carlier.add(m.Cmax >= global_max)\n\n    # Select bottlenecks strictly within 90% of global max to target active constraints\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    # Helper to access y variables (u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 5. Apply Sliding Window Cuts to Critical Blocks\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 6\n    \n    # Limit to top 3 competing blocks to manage complexity\n    for target in targets[:3]:\n        ops = target['ops']  # Already sorted by release time\n        if len(ops) < 3: continue\n        \n        cuts_added = 0\n        n_sub = len(ops)\n        \n        for idx_i in range(n_sub):\n            i = ops[idx_i]\n            # Restrict j to a local window to capture dense conflicts\n            for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                j = ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = ops[idx_k]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity: Prevent cycles i->k->j->i\n                    # If i->k and k->j, then i->j must hold\n                    m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.adaptive_carlier.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_adaptive_carlier_cuts(model)",
                        "idea": "We introduce **Adaptive Carlier-Window Transitivity**, a hybrid strategy merging the precise bottleneck detection of Parent 1 with the efficient windowed cuts of Parent 2. We first identify **Critical Blocks**contiguous operation subsets on each machine that maximize the Carlier lower bound ($r_{min} + \\sum p + q_{min}$)rather than treating the entire machine sequence as the bottleneck. On the top competing blocks (within 90% of the global maximum LB), we apply **Sliding Window Transitivity** and **Metric Lifting** cuts. This focuses constraints specifically on the tightest temporal clusters where infeasibilities originate, strengthening the relaxation locally while maintaining global scalability."
                    },
                    "fitness": 21.57318116708071,
                    "solver_reports": [
                        {
                            "gap": 17.4837,
                            "total_time": 12.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 35163,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.6348,
                            "total_time": 12.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 35618,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 33382,
                            "explored_time": 10.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.8406,
                            "total_time": 12.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 45451,
                            "explored_time": 12.06,
                            "work_units": 10.01
                        },
                        {
                            "gap": 29.7072,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 31899,
                            "explored_time": 11.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 2.3011,
                            "total_time": 10.85,
                            "explored_nodes": 3709,
                            "simplex_iterations": 288150,
                            "explored_time": 10.84,
                            "work_units": 10.3
                        },
                        {
                            "gap": 27.8426,
                            "total_time": 11.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 49164,
                            "explored_time": 11.62,
                            "work_units": 10.01
                        },
                        {
                            "gap": 24.6852,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 35149,
                            "explored_time": 11.83,
                            "work_units": 10.25
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0"
                    ]
                },
                {
                    "id": "65a72354-ecfa-4163-b531-3d500068d0e1",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_critical_span_lifting(m):\n        # 1. Precompute Heads and Tails for Carlier Bounds\n        heads = {}\n        tails = {}\n        # Forward pass (Heads)\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K):\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass (Tails)\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        best_lb_overall = -1\n        critical_block = [] # Stores (j,k) of the worst block found\n    \n        # 3. Global Carlier Bounds (Parent 2 strategy: Apply to all machines)\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Data structure: (r, p, q, op_key)\n            data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            local_max = 0\n            block_candidate = []\n            \n            for r in rs:\n                for q in qs:\n                    # Select operations within window [r, ..., T-q]\n                    sub = [d for d in data if d[0] >= r and d[2] >= q]\n                    if not sub: continue\n                    \n                    p_sum = sum(d[1] for d in sub)\n                    lb = r + p_sum + q\n                    \n                    # Update local max for this machine\n                    if lb > local_max:\n                        local_max = lb\n                        # Track the ops responsible for this bound\n                        block_candidate = [d[3] for d in sub]\n            \n            if local_max > 0:\n                m.hybrid_cuts.add(m.Cmax >= local_max)\n                \n            # Check if this is the global critical bottleneck (Parent 1 logic)\n            if local_max > best_lb_overall:\n                best_lb_overall = local_max\n                critical_block = block_candidate\n    \n        # 4. Critical Block Energetic Span (Parent 1 specific feature)\n        # Introduce variables to tightly bound the start and end of the critical block.\n        if critical_block and len(critical_block) >= 2:\n            m.cb_start = pyo.Var(domain=pyo.NonNegativeReals)\n            m.cb_end   = pyo.Var(domain=pyo.NonNegativeReals)\n            \n            total_p = sum(m.p[op] for op in critical_block)\n            m.hybrid_cuts.add(m.cb_end - m.cb_start >= total_p)\n            \n            for op in critical_block:\n                m.hybrid_cuts.add(m.cb_start <= m.S[op])\n                m.hybrid_cuts.add(m.cb_end   >= m.S[op] + m.p[op])\n    \n            # 5. Heuristic Triplet Lifting (Parent 2 sorting on Parent 1 scope)\n            # Apply expensive cuts only to the critical block, using p_k sorting.\n            \n            # Helper for y variables (handling symmetry)\n            def get_y(u, v):\n                if u < v: return m.y[u[0], u[1], v[0], v[1]]\n                else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n            # Sort ops by Head time (topological sort approx)\n            critical_block.sort(key=lambda x: heads[x])\n            \n            cut_count = 0\n            CUT_LIMIT = 200\n            ops = critical_block\n            n_ops = len(ops)\n    \n            for i in range(n_ops):\n                for j in range(i + 1, n_ops):\n                    u = ops[i]\n                    v = ops[j]\n                    \n                    # Intermediate candidates k must be in the block\n                    candidates = [k for k in ops if k != u and k != v]\n                    # Parent 2 Heuristic: Sort k by processing time (descending) to maximize lift\n                    candidates.sort(key=lambda x: m.p[x], reverse=True)\n                    \n                    # Apply to top 2 strongest intermediates\n                    for k in candidates[:2]:\n                        y_uv = get_y(u, v)\n                        y_uk = get_y(u, k)\n                        y_kv = get_y(k, v)\n                        \n                        # Transitivity (Parent 2)\n                        m.hybrid_cuts.add(y_uk + y_kv - y_uv <= 1)\n                        \n                        # Metric Lifting (S_v >= S_u + p_u + p_k if u->k->v)\n                        # Lifted form: S[v] >= S[u] + p[u] + p[k]*(y_uk + y_kv - 1) - M*(1-y_uv)\n                        m.hybrid_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[k] * (y_uk + y_kv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        cut_count += 2\n                        if cut_count >= CUT_LIMIT: break\n                    if cut_count >= CUT_LIMIT: break\n                if cut_count >= CUT_LIMIT: break\n    \n    add_hybrid_critical_span_lifting(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_critical_span_lifting(m):\n    # 1. Precompute Heads and Tails for Carlier Bounds\n    heads = {}\n    tails = {}\n    # Forward pass (Heads)\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K):\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass (Tails)\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    best_lb_overall = -1\n    critical_block = [] # Stores (j,k) of the worst block found\n\n    # 3. Global Carlier Bounds (Parent 2 strategy: Apply to all machines)\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Data structure: (r, p, q, op_key)\n        data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        local_max = 0\n        block_candidate = []\n        \n        for r in rs:\n            for q in qs:\n                # Select operations within window [r, ..., T-q]\n                sub = [d for d in data if d[0] >= r and d[2] >= q]\n                if not sub: continue\n                \n                p_sum = sum(d[1] for d in sub)\n                lb = r + p_sum + q\n                \n                # Update local max for this machine\n                if lb > local_max:\n                    local_max = lb\n                    # Track the ops responsible for this bound\n                    block_candidate = [d[3] for d in sub]\n        \n        if local_max > 0:\n            m.hybrid_cuts.add(m.Cmax >= local_max)\n            \n        # Check if this is the global critical bottleneck (Parent 1 logic)\n        if local_max > best_lb_overall:\n            best_lb_overall = local_max\n            critical_block = block_candidate\n\n    # 4. Critical Block Energetic Span (Parent 1 specific feature)\n    # Introduce variables to tightly bound the start and end of the critical block.\n    if critical_block and len(critical_block) >= 2:\n        m.cb_start = pyo.Var(domain=pyo.NonNegativeReals)\n        m.cb_end   = pyo.Var(domain=pyo.NonNegativeReals)\n        \n        total_p = sum(m.p[op] for op in critical_block)\n        m.hybrid_cuts.add(m.cb_end - m.cb_start >= total_p)\n        \n        for op in critical_block:\n            m.hybrid_cuts.add(m.cb_start <= m.S[op])\n            m.hybrid_cuts.add(m.cb_end   >= m.S[op] + m.p[op])\n\n        # 5. Heuristic Triplet Lifting (Parent 2 sorting on Parent 1 scope)\n        # Apply expensive cuts only to the critical block, using p_k sorting.\n        \n        # Helper for y variables (handling symmetry)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n        # Sort ops by Head time (topological sort approx)\n        critical_block.sort(key=lambda x: heads[x])\n        \n        cut_count = 0\n        CUT_LIMIT = 200\n        ops = critical_block\n        n_ops = len(ops)\n\n        for i in range(n_ops):\n            for j in range(i + 1, n_ops):\n                u = ops[i]\n                v = ops[j]\n                \n                # Intermediate candidates k must be in the block\n                candidates = [k for k in ops if k != u and k != v]\n                # Parent 2 Heuristic: Sort k by processing time (descending) to maximize lift\n                candidates.sort(key=lambda x: m.p[x], reverse=True)\n                \n                # Apply to top 2 strongest intermediates\n                for k in candidates[:2]:\n                    y_uv = get_y(u, v)\n                    y_uk = get_y(u, k)\n                    y_kv = get_y(k, v)\n                    \n                    # Transitivity (Parent 2)\n                    m.hybrid_cuts.add(y_uk + y_kv - y_uv <= 1)\n                    \n                    # Metric Lifting (S_v >= S_u + p_u + p_k if u->k->v)\n                    # Lifted form: S[v] >= S[u] + p[u] + p[k]*(y_uk + y_kv - 1) - M*(1-y_uv)\n                    m.hybrid_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[k] * (y_uk + y_kv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    cut_count += 2\n                    if cut_count >= CUT_LIMIT: break\n                if cut_count >= CUT_LIMIT: break\n            if cut_count >= CUT_LIMIT: break\n\nadd_hybrid_critical_span_lifting(model)",
                        "idea": "We apply a **Hybrid Critical Span & Sorted Lifting** strategy. This method synthesizes Parent 1's local tightening with Parent 2's global bounding and heuristic selection. First, we apply Carlier bounds to **all machines** (Parent 2) to globally lift the `Cmax`. Second, we identify the single **Critical Block** (operations maximizing the lower bound) and apply Parent 1's **Energetic Span** constraints (introducing `start` and `end` variables constrained by sum-of-processing-times) to approximate the convex hull of this bottleneck. Finally, within this critical block, we generate **Transitivity** and **Metric Lifting** cuts, utilizing Parent 2's heuristic of selecting intermediate nodes $k$ with the largest processing times $p_k$. This maximizes the delay penalty enforced by the cuts while restricting the computational overhead to the most active bottleneck."
                    },
                    "fitness": 19.594393964251992,
                    "solver_reports": [
                        {
                            "gap": 26.5079,
                            "total_time": 12.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 31605,
                            "explored_time": 12.81,
                            "work_units": 10.01
                        },
                        {
                            "gap": 28.0032,
                            "total_time": 12.61,
                            "explored_nodes": 1,
                            "simplex_iterations": 35713,
                            "explored_time": 12.53,
                            "work_units": 10.37
                        },
                        {
                            "gap": 29.0977,
                            "total_time": 11.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 29959,
                            "explored_time": 11.13,
                            "work_units": 10.24
                        },
                        {
                            "gap": 20.1261,
                            "total_time": 14.45,
                            "explored_nodes": 113,
                            "simplex_iterations": 66781,
                            "explored_time": 14.43,
                            "work_units": 11.19
                        },
                        {
                            "total_time": 9.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 35971,
                            "explored_time": 9.59,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.677,
                            "total_time": 12.31,
                            "explored_nodes": 1417,
                            "simplex_iterations": 61262,
                            "explored_time": 12.3,
                            "work_units": 10.95
                        },
                        {
                            "gap": 28.7117,
                            "total_time": 13.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 46098,
                            "explored_time": 13.74,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 37469,
                            "explored_time": 9.81,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "35e4c99d-cd5a-44e1-98e7-0af1293c544a",
                        "9d532fc9-4e25-4780-9cdd-abd854b91fd2"
                    ]
                },
                {
                    "id": "960251d1-f7a9-4cc2-bdf7-9b2fc1c5b409",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_global_transitivity_cuts(m):\n        # 1. Compute time windows (Heads and Tails)\n        # This approximates the earliest start and latest finish times for operations.\n        heads = {}\n        tails = {}\n        job_lens = {}\n        \n        # Forward pass\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K):\n                heads[j, k] = t\n                t += m.p[j, k]\n            job_lens[j] = t\n            \n        # Backward pass\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n                \n        # Global LB for defining window horizons\n        global_lb = max(job_lens.values())\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to retrieve y variables respecting the (u < v) definition\n        # Returns an expression representing 'op1 precedes op2'\n        def get_precedence_expr(op1, op2):\n            # model.y[u, v] is 1 if u precedes v (where u < v strictly in tuple comparison)\n            if op1 < op2:\n                return m.y[op1[0], op1[1], op2[0], op2[1]]\n            else:\n                # if op1 > op2, then 'op1 precedes op2' is (1 - y[op2, op1])\n                return 1 - m.y[op2[0], op2[1], op1[0], op1[1]]\n    \n        m.transitivity_cuts = pyo.ConstraintList()\n        max_cuts = 100  # Limit to prevent bloating\n        count = 0\n    \n        # 3. Generate Transitivity Cuts on Conflict Cliques\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            if count >= max_cuts: break\n            \n            # Sort ops by release time (Head) to find likely neighbors\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Iterate through triplets (i, j, k)\n            for i in range(n_ops):\n                u = sorted_ops[i]\n                # Approximate window for u: [heads[u], global_lb - tails[u]]\n                start_u = heads[u]\n                end_u = global_lb - tails[u]\n                \n                for j in range(i + 1, n_ops):\n                    v = sorted_ops[j]\n                    start_v = heads[v]\n                    end_v = global_lb - tails[v]\n                    \n                    # Check overlap between u and v\n                    if not (start_u < end_v and start_v < end_u):\n                        continue\n                        \n                    for k in range(j + 1, n_ops):\n                        w = sorted_ops[k]\n                        start_w = heads[w]\n                        end_w = global_lb - tails[w]\n                        \n                        # Check overlaps for the rest of the triangle\n                        if not (start_v < end_w and start_w < end_v): continue\n                        if not (start_u < end_w and start_w < end_u): continue\n                        \n                        # If all three time windows overlap, ordering is ambiguous and fractional cycles are likely.\n                        # Enforce strict partial ordering constraints.\n                        \n                        # Expressions for: u->v, v->w, u->w\n                        y_uv = get_precedence_expr(u, v)\n                        y_vw = get_precedence_expr(v, w)\n                        y_uw = get_precedence_expr(u, w)\n                        \n                        # Cut 1: Transitivity (u->v AND v->w => u->w)\n                        # y_uv + y_vw - 1 <= y_uw  =>  y_uv + y_vw - y_uw <= 1\n                        m.transitivity_cuts.add(y_uv + y_vw - y_uw <= 1)\n                        \n                        # Cut 2: No cycles (u->v->w->u impossible)\n                        # Actually covered by above if applied to all permutations, but we add the symmetric implication:\n                        # If u->w and w->v => u->v implies y_uw + (1-y_vw) - 1 <= y_uv\n                        # Simplifying: y_uw - y_vw - y_uv <= 0\n                        m.transitivity_cuts.add(y_uw - y_vw - y_uv <= 0)\n                        \n                        count += 2\n                        if count >= max_cuts: break\n                    if count >= max_cuts: break\n                if count >= max_cuts: break\n\n    return model\n",
                        "added_cut": "def add_global_transitivity_cuts(m):\n    # 1. Compute time windows (Heads and Tails)\n    # This approximates the earliest start and latest finish times for operations.\n    heads = {}\n    tails = {}\n    job_lens = {}\n    \n    # Forward pass\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K):\n            heads[j, k] = t\n            t += m.p[j, k]\n        job_lens[j] = t\n        \n    # Backward pass\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n            \n    # Global LB for defining window horizons\n    global_lb = max(job_lens.values())\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to retrieve y variables respecting the (u < v) definition\n    # Returns an expression representing 'op1 precedes op2'\n    def get_precedence_expr(op1, op2):\n        # model.y[u, v] is 1 if u precedes v (where u < v strictly in tuple comparison)\n        if op1 < op2:\n            return m.y[op1[0], op1[1], op2[0], op2[1]]\n        else:\n            # if op1 > op2, then 'op1 precedes op2' is (1 - y[op2, op1])\n            return 1 - m.y[op2[0], op2[1], op1[0], op1[1]]\n\n    m.transitivity_cuts = pyo.ConstraintList()\n    max_cuts = 100  # Limit to prevent bloating\n    count = 0\n\n    # 3. Generate Transitivity Cuts on Conflict Cliques\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        if count >= max_cuts: break\n        \n        # Sort ops by release time (Head) to find likely neighbors\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Iterate through triplets (i, j, k)\n        for i in range(n_ops):\n            u = sorted_ops[i]\n            # Approximate window for u: [heads[u], global_lb - tails[u]]\n            start_u = heads[u]\n            end_u = global_lb - tails[u]\n            \n            for j in range(i + 1, n_ops):\n                v = sorted_ops[j]\n                start_v = heads[v]\n                end_v = global_lb - tails[v]\n                \n                # Check overlap between u and v\n                if not (start_u < end_v and start_v < end_u):\n                    continue\n                    \n                for k in range(j + 1, n_ops):\n                    w = sorted_ops[k]\n                    start_w = heads[w]\n                    end_w = global_lb - tails[w]\n                    \n                    # Check overlaps for the rest of the triangle\n                    if not (start_v < end_w and start_w < end_v): continue\n                    if not (start_u < end_w and start_w < end_u): continue\n                    \n                    # If all three time windows overlap, ordering is ambiguous and fractional cycles are likely.\n                    # Enforce strict partial ordering constraints.\n                    \n                    # Expressions for: u->v, v->w, u->w\n                    y_uv = get_precedence_expr(u, v)\n                    y_vw = get_precedence_expr(v, w)\n                    y_uw = get_precedence_expr(u, w)\n                    \n                    # Cut 1: Transitivity (u->v AND v->w => u->w)\n                    # y_uv + y_vw - 1 <= y_uw  =>  y_uv + y_vw - y_uw <= 1\n                    m.transitivity_cuts.add(y_uv + y_vw - y_uw <= 1)\n                    \n                    # Cut 2: No cycles (u->v->w->u impossible)\n                    # Actually covered by above if applied to all permutations, but we add the symmetric implication:\n                    # If u->w and w->v => u->v implies y_uw + (1-y_vw) - 1 <= y_uv\n                    # Simplifying: y_uw - y_vw - y_uv <= 0\n                    m.transitivity_cuts.add(y_uw - y_vw - y_uv <= 0)\n                    \n                    count += 2\n                    if count >= max_cuts: break\n                if count >= max_cuts: break\n            if count >= max_cuts: break",
                        "idea": "We apply **Global Conflict-Based Transitivity Cuts**. Unlike the previous 'Critical Block' approach which focused on lifting precedence variables ($S$) on a single bottleneck machine, this strategy targets the boolean ordering variables ($y$) across **all machines**. By detecting 'conflict cliques'triplets of operations with mutually overlapping time windowswe enforce 3-cycle constraints (e.g., if $i \\to j$ and $j \\to k$, then $i \\to k$). This strengthens the boolean relaxation globally, preventing the solver from assigning fractional values that imply impossible cycles (like $i \\to j \\to k \\to i$) in dense schedule regions, thereby tightening the lower bound."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.68,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 14.95,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.35,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.08,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.07,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.48,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.68,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.67,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.01,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.91,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "35e4c99d-cd5a-44e1-98e7-0af1293c544a"
                    ]
                },
                {
                    "id": "449ecd5b-5655-4f11-aba1-11d0e9e36156",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_precedence_mass_cuts(m):\n        # 1. Compute Heads and Tails (Rigorous Parent 2 style)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access binary precedence variables safely\n        def get_y(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.mass_lifting_cuts = pyo.ConstraintList()\n    \n        # 3. Detect Critical Blocks (Best LB per machine)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_local_lb = -1\n            best_local_sub = []\n            r_min_best = 0\n            \n            # Scan contiguous sub-segments\n            for i in range(n_ops):\n                p_sum = 0\n                min_q = float('inf')\n                current_r = heads[sorted_ops[i]]\n                for j in range(i, n_ops):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    # Track min tail in the subset\n                    if tails[op] < min_q: min_q = tails[op]\n                    \n                    # Carlier Lower Bound for this block\n                    lb = current_r + p_sum + min_q\n                    \n                    if lb > best_local_lb:\n                        best_local_lb = lb\n                        best_local_sub = sorted_ops[i : j+1]\n                        r_min_best = current_r\n            \n            if best_local_lb > 0:\n                candidates.append({\n                    'lb': best_local_lb, \n                    'ops': best_local_sub, \n                    'r_min': r_min_best\n                })\n    \n        if not candidates: return\n    \n        # 4. Global Cut and Target Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.mass_lifting_cuts.add(m.Cmax >= global_max)\n    \n        # Select top distinctive blocks (within 90% of max)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        CUT_BUDGET = 200\n        cuts_added = 0\n    \n        # 5. Apply Hybrid Cuts: Precedence Mass Lifting + Transitivity\n        for target in targets[:3]:\n            block_ops = target['ops']\n            r_min = target['r_min']\n            \n            # A. Precedence Mass Lifting\n            # S_u >= r_min + sum(p_v * y_vu) for all v in block\n            # This anchors the start time to the block's head plus the processing mass of predecessors.\n            for u in block_ops:\n                prec_mass = 0\n                for v in block_ops:\n                    if u == v: continue\n                    # Term: p_v * (1 if v precedes u else 0)\n                    prec_mass += m.p[v] * get_y(v, u)\n                \n                m.mass_lifting_cuts.add(m.S[u] >= r_min + prec_mass)\n                cuts_added += 1\n            \n            if cuts_added >= CUT_BUDGET: break\n    \n            # B. Windowed Transitivity (Parent 1/2 Strategy)\n            # Enforces logic required for Mass Lifting to be tight\n            WINDOW = 6\n            for i_idx in range(len(block_ops)):\n                u = block_ops[i_idx]\n                limit = min(i_idx + WINDOW, len(block_ops))\n                for j_idx in range(i_idx + 1, limit):\n                    v = block_ops[j_idx]\n                    for k_idx in range(i_idx + 1, j_idx):\n                        w = block_ops[k_idx]\n                        \n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        y_uv = get_y(u, v)\n                        \n                        # Triangle inequality on precedence: u->w + w->v - u->v <= 1\n                        m.mass_lifting_cuts.add(y_uw + y_wv - y_uv <= 1)\n                        cuts_added += 1\n                        \n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_precedence_mass_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_precedence_mass_cuts(m):\n    # 1. Compute Heads and Tails (Rigorous Parent 2 style)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access binary precedence variables safely\n    def get_y(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.mass_lifting_cuts = pyo.ConstraintList()\n\n    # 3. Detect Critical Blocks (Best LB per machine)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_local_lb = -1\n        best_local_sub = []\n        r_min_best = 0\n        \n        # Scan contiguous sub-segments\n        for i in range(n_ops):\n            p_sum = 0\n            min_q = float('inf')\n            current_r = heads[sorted_ops[i]]\n            for j in range(i, n_ops):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                # Track min tail in the subset\n                if tails[op] < min_q: min_q = tails[op]\n                \n                # Carlier Lower Bound for this block\n                lb = current_r + p_sum + min_q\n                \n                if lb > best_local_lb:\n                    best_local_lb = lb\n                    best_local_sub = sorted_ops[i : j+1]\n                    r_min_best = current_r\n        \n        if best_local_lb > 0:\n            candidates.append({\n                'lb': best_local_lb, \n                'ops': best_local_sub, \n                'r_min': r_min_best\n            })\n\n    if not candidates: return\n\n    # 4. Global Cut and Target Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.mass_lifting_cuts.add(m.Cmax >= global_max)\n\n    # Select top distinctive blocks (within 90% of max)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    CUT_BUDGET = 200\n    cuts_added = 0\n\n    # 5. Apply Hybrid Cuts: Precedence Mass Lifting + Transitivity\n    for target in targets[:3]:\n        block_ops = target['ops']\n        r_min = target['r_min']\n        \n        # A. Precedence Mass Lifting\n        # S_u >= r_min + sum(p_v * y_vu) for all v in block\n        # This anchors the start time to the block's head plus the processing mass of predecessors.\n        for u in block_ops:\n            prec_mass = 0\n            for v in block_ops:\n                if u == v: continue\n                # Term: p_v * (1 if v precedes u else 0)\n                prec_mass += m.p[v] * get_y(v, u)\n            \n            m.mass_lifting_cuts.add(m.S[u] >= r_min + prec_mass)\n            cuts_added += 1\n        \n        if cuts_added >= CUT_BUDGET: break\n\n        # B. Windowed Transitivity (Parent 1/2 Strategy)\n        # Enforces logic required for Mass Lifting to be tight\n        WINDOW = 6\n        for i_idx in range(len(block_ops)):\n            u = block_ops[i_idx]\n            limit = min(i_idx + WINDOW, len(block_ops))\n            for j_idx in range(i_idx + 1, limit):\n                v = block_ops[j_idx]\n                for k_idx in range(i_idx + 1, j_idx):\n                    w = block_ops[k_idx]\n                    \n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    y_uv = get_y(u, v)\n                    \n                    # Triangle inequality on precedence: u->w + w->v - u->v <= 1\n                    m.mass_lifting_cuts.add(y_uw + y_wv - y_uv <= 1)\n                    cuts_added += 1\n                    \n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_precedence_mass_cuts(model)",
                        "idea": "We introduce **Precedence Mass Lifting**, a hybrid cut strategy that combines Parent 2's rigorous Carlier-bound detection (checking $r_{min} + \\sum p + q_{min}$) with a novel linear lifting constraint. For operations in critical bottleneck blocks, we enforce $S_u \\ge r_{min} + \\sum_{v \\in Block \\setminus \\{u\\}} p_v y_{vu}$. This effectively anchors the start time of every operation to the block's earliest release time plus the total duration of its dynamically determined predecessors, strengthening the convex hull significantly more than standard Big-M constraints. We reinforce this with **Windowed Transitivity** cuts from Parent 1 to ensure the binary precedence variables ($y$) forming these sums are logically consistent."
                    },
                    "fitness": 18.30343395509394,
                    "solver_reports": [
                        {
                            "total_time": 11.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 25033,
                            "explored_time": 11.67,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 40461,
                            "explored_time": 8.9,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 39341,
                            "explored_time": 8.14,
                            "work_units": 10.02
                        },
                        {
                            "gap": 25.3681,
                            "total_time": 13.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 57174,
                            "explored_time": 13.47,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 41042,
                            "explored_time": 8.83,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.0643,
                            "total_time": 10.88,
                            "explored_nodes": 1796,
                            "simplex_iterations": 123007,
                            "explored_time": 10.87,
                            "work_units": 10.17
                        },
                        {
                            "gap": 38.9896,
                            "total_time": 10.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 46389,
                            "explored_time": 10.21,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 10.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 43973,
                            "explored_time": 10.65,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "83a97914-4c29-41e9-b8f3-7f956afb31a9"
                    ]
                },
                {
                    "id": "280208fb-b3b4-4d12-95af-f147f31bd565",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_focused_sequence_cuts(m):\n        # 1. Precompute Timing (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper for precedence vars y_{uv} (1 if u->v)\n        def get_y(u, v):\n            # u, v are (job, task) tuples; m.y is defined for sorted pairs\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.focused_seq_cuts = pyo.ConstraintList()\n    \n        # 3. Identify Critical Blocks (Carlier Subsets)\n        # We scan for the subset maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads) to facilitate subset scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n    \n            # Scan contiguous sub-segments\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                current_sub = []\n                r_val = heads[sorted_ops[i]] # min r in this window (since sorted)\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # Sort candidates by LB descending\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        # Global Lower Bound Cut\n        m.focused_seq_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Generate Cuts for Top Critical Blocks\n        CUT_BUDGET = 150\n        cuts_added = 0\n        WINDOW = 6\n    \n        # Target top bottlenecks (usually just 1, but include close seconds)\n        targets = [c for c in candidates if c['lb'] >= 0.95 * global_max]\n    \n        for target in targets:\n            ops = target['ops'] # Already sorted by heads from detection phase\n            n_ops = len(ops)\n            if n_ops < 2: continue\n    \n            for i in range(n_ops):\n                u = ops[i]\n                limit = min(i + WINDOW, n_ops)\n                \n                for j in range(i + 1, limit):\n                    v = ops[j]\n                    y_uv = get_y(u, v)\n                    \n                    # A. Sequence-Dependent Bound Cut\n                    # If u->v, Cmax >= r_u + p_u + p_v + q_v\n                    # Valid inequality tightening Cmax based on local sequence choice\n                    seq_bound = heads[u] + m.p[u] + m.p[v] + tails[v]\n                    if seq_bound > global_max:\n                         m.focused_seq_cuts.add(\n                             m.Cmax >= seq_bound - m.bigM * (1 - y_uv)\n                         )\n                         cuts_added += 1\n    \n                    # B. Triplet Cuts (Transitivity & Lifting)\n                    # Iterate intermediate nodes w strictly within the critical block\n                    for k in range(i + 1, j):\n                        w = ops[k]\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        \n                        # 1. Triangle Transitivity: y_uw + y_wv - 1 <= y_uv\n                        # Enforces consistency: u->w and w->v => u->v\n                        m.focused_seq_cuts.add(y_uw + y_wv - 1 <= y_uv)\n                        \n                        # 2. Metric Lifting: S_v >= S_u + p_u + p_w if u->w->v\n                        # Logic: If u->w and w->v, then p_w must contribute to spacing between u and v.\n                        # (y_uw + y_wv - 1) becomes 1 if both are true, activating p_w.\n                        m.focused_seq_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[w] * (y_uw + y_wv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n    \n    add_focused_sequence_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_focused_sequence_cuts(m):\n    # 1. Precompute Timing (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper for precedence vars y_{uv} (1 if u->v)\n    def get_y(u, v):\n        # u, v are (job, task) tuples; m.y is defined for sorted pairs\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.focused_seq_cuts = pyo.ConstraintList()\n\n    # 3. Identify Critical Blocks (Carlier Subsets)\n    # We scan for the subset maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads) to facilitate subset scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n\n        # Scan contiguous sub-segments\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            current_sub = []\n            r_val = heads[sorted_ops[i]] # min r in this window (since sorted)\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # Sort candidates by LB descending\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    # Global Lower Bound Cut\n    m.focused_seq_cuts.add(m.Cmax >= global_max)\n\n    # 4. Generate Cuts for Top Critical Blocks\n    CUT_BUDGET = 150\n    cuts_added = 0\n    WINDOW = 6\n\n    # Target top bottlenecks (usually just 1, but include close seconds)\n    targets = [c for c in candidates if c['lb'] >= 0.95 * global_max]\n\n    for target in targets:\n        ops = target['ops'] # Already sorted by heads from detection phase\n        n_ops = len(ops)\n        if n_ops < 2: continue\n\n        for i in range(n_ops):\n            u = ops[i]\n            limit = min(i + WINDOW, n_ops)\n            \n            for j in range(i + 1, limit):\n                v = ops[j]\n                y_uv = get_y(u, v)\n                \n                # A. Sequence-Dependent Bound Cut\n                # If u->v, Cmax >= r_u + p_u + p_v + q_v\n                # Valid inequality tightening Cmax based on local sequence choice\n                seq_bound = heads[u] + m.p[u] + m.p[v] + tails[v]\n                if seq_bound > global_max:\n                     m.focused_seq_cuts.add(\n                         m.Cmax >= seq_bound - m.bigM * (1 - y_uv)\n                     )\n                     cuts_added += 1\n\n                # B. Triplet Cuts (Transitivity & Lifting)\n                # Iterate intermediate nodes w strictly within the critical block\n                for k in range(i + 1, j):\n                    w = ops[k]\n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    \n                    # 1. Triangle Transitivity: y_uw + y_wv - 1 <= y_uv\n                    # Enforces consistency: u->w and w->v => u->v\n                    m.focused_seq_cuts.add(y_uw + y_wv - 1 <= y_uv)\n                    \n                    # 2. Metric Lifting: S_v >= S_u + p_u + p_w if u->w->v\n                    # Logic: If u->w and w->v, then p_w must contribute to spacing between u and v.\n                    # (y_uw + y_wv - 1) becomes 1 if both are true, activating p_w.\n                    m.focused_seq_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[w] * (y_uw + y_wv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n        if cuts_added >= CUT_BUDGET: break\n\nadd_focused_sequence_cuts(model)",
                        "idea": "We merge Parent 1's rigorous critical-block detection with Parent 2's explicit transitivity logic, adding a new class of **Sequence-Dependent Lower Bound cuts**. We identify the exact subset of operations forming the global Carlier bottleneck and sort them by release time. Within this focused window, we enforce (1) Triangle Transitivity ($y_{uw} + y_{wv} \\le 1 + y_{uv}$), (2) Metric Lifting ($S_v \\ge S_u + p_u + p_w$ if $u \\to w \\to v$), and (3) a novel objective cut ($C_{max} \\ge r_u + p_u + p_v + q_v - M(1-y_{uv})$). This third component explicitly lifts the makespan bound based on specific pairwise orderings in the bottleneck, tightening the relaxation exactly where the schedule is most constrained."
                    },
                    "fitness": 19.952181684365573,
                    "solver_reports": [
                        {
                            "gap": 16.7937,
                            "total_time": 13.42,
                            "explored_nodes": 1,
                            "simplex_iterations": 35963,
                            "explored_time": 13.35,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.6361,
                            "total_time": 13.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 33229,
                            "explored_time": 13.12,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 32338,
                            "explored_time": 11.32,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.5909,
                            "total_time": 13.91,
                            "explored_nodes": 115,
                            "simplex_iterations": 63948,
                            "explored_time": 13.9,
                            "work_units": 11.68
                        },
                        {
                            "total_time": 12.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 34427,
                            "explored_time": 12.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.5542,
                            "total_time": 13.1,
                            "explored_nodes": 1141,
                            "simplex_iterations": 71237,
                            "explored_time": 13.1,
                            "work_units": 12.11
                        },
                        {
                            "gap": 29.3323,
                            "total_time": 11.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 48745,
                            "explored_time": 11.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 38933,
                            "explored_time": 10.22,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "83a97914-4c29-41e9-b8f3-7f956afb31a9",
                        "bdbe6b34-2649-417d-94d8-021a8a417041"
                    ]
                },
                {
                    "id": "4c029eb7-54b3-4bff-a682-033a2cdf6edc",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_deep_carlier_cuts(m):\n        # 1. Timing Analysis (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper for precedence variables (handles direction)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.deep_carlier = pyo.ConstraintList()\n    \n        # 3. Robust Critical Block Detection (Parent 2's Min-Queue Logic)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n    \n            # Scan for subset maximizing Carlier Bound: r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                min_r = heads[sorted_ops[i]]\n                current_sub = []\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = min_r + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global Lower Bound Cut\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.deep_carlier.add(m.Cmax >= global_max)\n    \n        # 5. Hybrid Lifting on Top Bottlenecks\n        # Select blocks strictly within 90% of global max\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        CUT_BUDGET = 200\n        cuts_added = 0\n        \n        for target in targets[:3]:\n            ops = target['ops']\n            if len(ops) < 2: continue\n            \n            # Block properties\n            r_vals = [heads[op] for op in ops]\n            q_vals = [tails[op] for op in ops]\n            r_min = min(r_vals)\n            q_min = min(q_vals)\n    \n            # (A) Aggregate Input/Output Lifting (Novel Feature)\n            # Links continuous variables S to the sum of all predecessor binaries in the block.\n            # S_u >= r_min + sum(p_v * y_vu) for all v in block\n            for u in ops:\n                # Input Sequence Cut\n                m.deep_carlier.add(\n                    m.S[u] >= r_min + sum(m.p[v] * get_y(v, u) for v in ops if v != u)\n                )\n                # Output Sequence Cut\n                # Cmax >= S_u + p_u + sum(p_v * y_uv) + q_min\n                m.deep_carlier.add(\n                    m.Cmax >= m.S[u] + m.p[u] + \n                              sum(m.p[v] * get_y(u, v) for v in ops if v != u) + \n                              q_min\n                )\n    \n            # (B) Windowed Triplet Lifting (Parent 1's Structural Feature)\n            # Fine-grained spacing adjustments for local windows\n            WINDOW = 6\n            n_ops = len(ops)\n            for i_idx in range(n_ops):\n                u = ops[i_idx]\n                # Limit window size to manage complexity\n                for j_idx in range(i_idx + 1, min(i_idx + WINDOW, n_ops)):\n                    v = ops[j_idx]\n                    # Intermediate node w\n                    for k_idx in range(i_idx + 1, j_idx):\n                        w = ops[k_idx]\n                        \n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        y_uv = get_y(u, v)\n                        \n                        # Transitivity: u->w and w->v => u->v\n                        m.deep_carlier.add(y_uw + y_wv - y_uv <= 1)\n                        \n                        # Metric Lifting: S_v >= S_u + p_u + p_w if path exists\n                        m.deep_carlier.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[w] * (y_uw + y_wv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_deep_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_deep_carlier_cuts(m):\n    # 1. Timing Analysis (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper for precedence variables (handles direction)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.deep_carlier = pyo.ConstraintList()\n\n    # 3. Robust Critical Block Detection (Parent 2's Min-Queue Logic)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n\n        # Scan for subset maximizing Carlier Bound: r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            min_r = heads[sorted_ops[i]]\n            current_sub = []\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = min_r + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global Lower Bound Cut\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.deep_carlier.add(m.Cmax >= global_max)\n\n    # 5. Hybrid Lifting on Top Bottlenecks\n    # Select blocks strictly within 90% of global max\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    CUT_BUDGET = 200\n    cuts_added = 0\n    \n    for target in targets[:3]:\n        ops = target['ops']\n        if len(ops) < 2: continue\n        \n        # Block properties\n        r_vals = [heads[op] for op in ops]\n        q_vals = [tails[op] for op in ops]\n        r_min = min(r_vals)\n        q_min = min(q_vals)\n\n        # (A) Aggregate Input/Output Lifting (Novel Feature)\n        # Links continuous variables S to the sum of all predecessor binaries in the block.\n        # S_u >= r_min + sum(p_v * y_vu) for all v in block\n        for u in ops:\n            # Input Sequence Cut\n            m.deep_carlier.add(\n                m.S[u] >= r_min + sum(m.p[v] * get_y(v, u) for v in ops if v != u)\n            )\n            # Output Sequence Cut\n            # Cmax >= S_u + p_u + sum(p_v * y_uv) + q_min\n            m.deep_carlier.add(\n                m.Cmax >= m.S[u] + m.p[u] + \n                          sum(m.p[v] * get_y(u, v) for v in ops if v != u) + \n                          q_min\n            )\n\n        # (B) Windowed Triplet Lifting (Parent 1's Structural Feature)\n        # Fine-grained spacing adjustments for local windows\n        WINDOW = 6\n        n_ops = len(ops)\n        for i_idx in range(n_ops):\n            u = ops[i_idx]\n            # Limit window size to manage complexity\n            for j_idx in range(i_idx + 1, min(i_idx + WINDOW, n_ops)):\n                v = ops[j_idx]\n                # Intermediate node w\n                for k_idx in range(i_idx + 1, j_idx):\n                    w = ops[k_idx]\n                    \n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    y_uv = get_y(u, v)\n                    \n                    # Transitivity: u->w and w->v => u->v\n                    m.deep_carlier.add(y_uw + y_wv - y_uv <= 1)\n                    \n                    # Metric Lifting: S_v >= S_u + p_u + p_w if path exists\n                    m.deep_carlier.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[w] * (y_uw + y_wv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_deep_carlier_cuts(model)",
                        "idea": "We introduce **Deep Carlier-Block Lifting**, a hybrid combining the robust bottleneck detection of Parent 2 (using $r_{min} + \\sum p + q_{min}$) with a two-tiered lifting strategy. First, we apply **Aggregate Input/Output Cuts** to the critical block; these constraints ($S_u \\ge r_{min} + \\sum_{v \\neq u} p_v y_{vu}$) enforce that a job's start time must account for the processing volume of all its predecessors within the bottleneck, creating a strong global link between sequence variables and time. Second, we integrate Parent 1's **Windowed Triplet Lifting** ($S_v \\ge S_u + p_u + p_w$ if $u \\to w \\to v$) to tighten local spacing within the block. This dual approach simultaneously lifts the global block schedule and resolves internal path conflicts."
                    },
                    "fitness": 17.67348910911994,
                    "solver_reports": [
                        {
                            "total_time": 5.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 24158,
                            "explored_time": 5.72,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 24252,
                            "explored_time": 6.0,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 30908,
                            "explored_time": 6.86,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.1792,
                            "total_time": 10.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 40755,
                            "explored_time": 10.17,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.93,
                            "explored_nodes": 1,
                            "simplex_iterations": 31315,
                            "explored_time": 6.88,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.3569,
                            "total_time": 10.12,
                            "explored_nodes": 176,
                            "simplex_iterations": 66521,
                            "explored_time": 10.11,
                            "work_units": 10.18
                        },
                        {
                            "total_time": 7.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 35011,
                            "explored_time": 7.7,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 23990,
                            "explored_time": 5.95,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "83a97914-4c29-41e9-b8f3-7f956afb31a9"
                    ]
                },
                {
                    "id": "42238318-f6de-46cd-ade2-043e04605bab",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_exploratory_window_cuts(m):\n        # 1. Compute Heads (earliest start) and Tails (min time to end)\n        heads = {}\n        tails = {}\n        # Forward pass\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Apply Windowed Cuts (Clique Bound + Transitivity)\n        m.window_cuts = pyo.ConstraintList()\n        WINDOW_SIZE = 4\n    \n        # Helper to get y[u,v] expression (1 if u->v, 0 if v->u)\n        def get_y_expr(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for mid, ops in mach_ops.items():\n            if len(ops) < WINDOW_SIZE: continue\n            \n            # Sort by release time to identify temporal clusters\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            \n            # Sliding window scan\n            for i in range(len(sorted_ops) - WINDOW_SIZE + 1):\n                window = sorted_ops[i : i + WINDOW_SIZE]\n                \n                # (A) Local Clique Lower Bound Cut\n                # For any subset of ops on one machine: Cmax >= min_r + sum_p + min_q\n                min_r = min(heads[op] for op in window)\n                min_q = min(tails[op] for op in window)\n                sum_p = sum(m.p[op] for op in window)\n                m.window_cuts.add(m.Cmax >= min_r + sum_p + min_q)\n                \n                # (B) Triangular Transitivity\n                # Enforce logical consistency on all triples in the window\n                # This cuts off fractional solutions with cyclic precedence logic\n                for idx1 in range(WINDOW_SIZE):\n                    for idx2 in range(idx1 + 1, WINDOW_SIZE):\n                        for idx3 in range(idx2 + 1, WINDOW_SIZE):\n                            u, v, w = window[idx1], window[idx2], window[idx3]\n                            \n                            y_uv = get_y_expr(u, v)\n                            y_vw = get_y_expr(v, w)\n                            y_uw = get_y_expr(u, w)\n                            \n                            # 1. Prevent u->v->w->u cycle\n                            # If u->v (1) and v->w (1), then u->w must be 1\n                            m.window_cuts.add(y_uv + y_vw - y_uw <= 1)\n                            \n                            # 2. Prevent v->u->w->v cycle\n                            # If v->u (y_uv=0) and w->v (y_vw=0), then w->u (y_uw=0) \n                            # Equivalent to y_uw <= y_uv + y_vw\n                            m.window_cuts.add(y_uw <= y_uv + y_vw)\n    \n    add_exploratory_window_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_exploratory_window_cuts(m):\n    # 1. Compute Heads (earliest start) and Tails (min time to end)\n    heads = {}\n    tails = {}\n    # Forward pass\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Apply Windowed Cuts (Clique Bound + Transitivity)\n    m.window_cuts = pyo.ConstraintList()\n    WINDOW_SIZE = 4\n\n    # Helper to get y[u,v] expression (1 if u->v, 0 if v->u)\n    def get_y_expr(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for mid, ops in mach_ops.items():\n        if len(ops) < WINDOW_SIZE: continue\n        \n        # Sort by release time to identify temporal clusters\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        \n        # Sliding window scan\n        for i in range(len(sorted_ops) - WINDOW_SIZE + 1):\n            window = sorted_ops[i : i + WINDOW_SIZE]\n            \n            # (A) Local Clique Lower Bound Cut\n            # For any subset of ops on one machine: Cmax >= min_r + sum_p + min_q\n            min_r = min(heads[op] for op in window)\n            min_q = min(tails[op] for op in window)\n            sum_p = sum(m.p[op] for op in window)\n            m.window_cuts.add(m.Cmax >= min_r + sum_p + min_q)\n            \n            # (B) Triangular Transitivity\n            # Enforce logical consistency on all triples in the window\n            # This cuts off fractional solutions with cyclic precedence logic\n            for idx1 in range(WINDOW_SIZE):\n                for idx2 in range(idx1 + 1, WINDOW_SIZE):\n                    for idx3 in range(idx2 + 1, WINDOW_SIZE):\n                        u, v, w = window[idx1], window[idx2], window[idx3]\n                        \n                        y_uv = get_y_expr(u, v)\n                        y_vw = get_y_expr(v, w)\n                        y_uw = get_y_expr(u, w)\n                        \n                        # 1. Prevent u->v->w->u cycle\n                        # If u->v (1) and v->w (1), then u->w must be 1\n                        m.window_cuts.add(y_uv + y_vw - y_uw <= 1)\n                        \n                        # 2. Prevent v->u->w->v cycle\n                        # If v->u (y_uv=0) and w->v (y_vw=0), then w->u (y_uw=0) \n                        # Equivalent to y_uw <= y_uv + y_vw\n                        m.window_cuts.add(y_uw <= y_uv + y_vw)\n\nadd_exploratory_window_cuts(model)",
                        "idea": "We introduce **Windowed Clique Cuts** to explore local bottlenecks across all machines, contrasting with the previous method's focus on a single global critical block. By applying a sliding window (size 4) over operations sorted by release time, we identify 'dense' local cliques. For each clique, we generate two types of cuts: (1) **Local Carlier Bounds**, which enforce that the global makespan must respect the local 1-machine relaxation ($C_{\\max} \\ge r_{\\min} + \\sum p + q_{\\min}$), and (2) **Triangular Transitivity**, which enforces logical consistency (preventing cycles like $i \\to j \\to k \\to i$) within these tight clusters. This strategy provides a dense 'mesh' of validity constraints and bounds throughout the scheduling horizon, pruning the search space of logically inconsistent fractional solutions in secondary bottlenecks."
                    },
                    "fitness": 9.906107080727985,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 34401,
                            "explored_time": 12.26,
                            "work_units": 10.01
                        },
                        {
                            "gap": 96.4541,
                            "total_time": 13.23,
                            "explored_nodes": 1,
                            "simplex_iterations": 35333,
                            "explored_time": 13.18,
                            "work_units": 10.01
                        },
                        {
                            "gap": 96.6931,
                            "total_time": 10.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 39100,
                            "explored_time": 10.18,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.2965,
                            "total_time": 18.13,
                            "explored_nodes": 1,
                            "simplex_iterations": 24950,
                            "explored_time": 18.11,
                            "work_units": 10.01
                        },
                        {
                            "gap": 96.766,
                            "total_time": 10.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 38922,
                            "explored_time": 10.58,
                            "work_units": 10.0
                        },
                        {
                            "gap": 35.2087,
                            "total_time": 9.47,
                            "explored_nodes": 2069,
                            "simplex_iterations": 218652,
                            "explored_time": 9.46,
                            "work_units": 10.04
                        },
                        {
                            "gap": 93.1194,
                            "total_time": 19.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 16935,
                            "explored_time": 18.97,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.5345,
                            "total_time": 14.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 29079,
                            "explored_time": 14.29,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "632fc546-f223-4d34-8ce8-f4fc49fd82ef"
                    ]
                },
                {
                    "id": "a287fd7a-dda8-465c-b0b5-1bc49990e465",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_critical_block_cuts(m):\n        # 1. Compute Heads (r) and Tails (q) for all operations\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K):\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify the Single Most Critical Block (Parent 2 Strategy)\n        # Find the subset of operations on one machine maximizing the Carlier Bound.\n        best_lb = -1\n        critical_block = []\n        \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Collect data: (head, p, tail, op_key)\n            data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n            \n            # Consider all time windows defined by r and q in the data\n            rs = sorted(list(set(d[0] for d in data)))\n            qs = sorted(list(set(d[2] for d in data)))\n            \n            for r in rs:\n                for q in qs:\n                    # Filter operations strictly inside the window [r, ... , Cmax - q]\n                    subset = [d for d in data if d[0] >= r and d[2] >= q]\n                    if not subset: continue\n                    \n                    # Calculate Carlier Bound for this block\n                    lb = r + sum(d[1] for d in subset) + q\n                    if lb > best_lb:\n                        best_lb = lb\n                        critical_block = [d[3] for d in subset]\n    \n        if not critical_block or len(critical_block) < 2:\n            return\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n    \n        # 4. Global Lower Bound (Parent 2)\n        m.hybrid_cuts.add(m.Cmax >= best_lb)\n    \n        # 5. Energetic Span Constraints (Parent 2)\n        # Introduce auxiliary variables to enclose the critical block tightly.\n        m.blk_start = pyo.Var(domain=pyo.NonNegativeReals)\n        m.blk_end   = pyo.Var(domain=pyo.NonNegativeReals)\n        \n        total_p = sum(m.p[op] for op in critical_block)\n        \n        # The block's duration must at least equal the sum of processing times\n        m.hybrid_cuts.add(m.blk_end - m.blk_start >= total_p)\n        \n        # Bound the span variables by the operations in the block\n        for op in critical_block:\n            m.hybrid_cuts.add(m.blk_start <= m.S[op])\n            m.hybrid_cuts.add(m.blk_end   >= m.S[op] + m.p[op])\n    \n        # 6. Metric Lifting on the Critical Block (Parent 1 Logic)\n        # We use Parent 1's stronger \"Metric Lifting\" cuts and processing-time sorting,\n        # but restrict them to the identified critical block for efficiency.\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # Sort block by heads (heuristic for likely order u->v)\n        critical_block.sort(key=lambda x: heads[x])\n        \n        cut_count = 0\n        BUDGET = 200\n    \n        for i in range(len(critical_block)):\n            for j in range(i + 1, len(critical_block)):\n                u = critical_block[i]\n                v = critical_block[j]\n                \n                # Identify intermediates k within the block\n                intermediates = [k for k in critical_block if k != u and k != v]\n                \n                # Parent 1 Heuristic: Sort intermediates by Processing Time (descending)\n                # This prioritizes cuts that impose the largest delay penalty p_k.\n                intermediates.sort(key=lambda x: m.p[x], reverse=True)\n                \n                for k in intermediates[:2]: # Top 2 strongest intermediates\n                    y_uv = get_y(u, v)\n                    y_uk = get_y(u, k)\n                    y_kv = get_y(k, v)\n                    \n                    # (A) Transitivity Cut\n                    m.hybrid_cuts.add(y_uk + y_kv - y_uv <= 1)\n                    \n                    # (B) Metric Lifting Cut (Stronger than simple Triangle)\n                    # S_v >= S_u + p_u + p_k * (y_uk + y_kv - 1) - M(1 - y_uv)\n                    m.hybrid_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[k] * (y_uk + y_kv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    cut_count += 2\n                    if cut_count >= BUDGET: break\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n    \n    add_hybrid_critical_block_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_critical_block_cuts(m):\n    # 1. Compute Heads (r) and Tails (q) for all operations\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K):\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify the Single Most Critical Block (Parent 2 Strategy)\n    # Find the subset of operations on one machine maximizing the Carlier Bound.\n    best_lb = -1\n    critical_block = []\n    \n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Collect data: (head, p, tail, op_key)\n        data = [(heads[op], m.p[op], tails[op], op) for op in ops]\n        \n        # Consider all time windows defined by r and q in the data\n        rs = sorted(list(set(d[0] for d in data)))\n        qs = sorted(list(set(d[2] for d in data)))\n        \n        for r in rs:\n            for q in qs:\n                # Filter operations strictly inside the window [r, ... , Cmax - q]\n                subset = [d for d in data if d[0] >= r and d[2] >= q]\n                if not subset: continue\n                \n                # Calculate Carlier Bound for this block\n                lb = r + sum(d[1] for d in subset) + q\n                if lb > best_lb:\n                    best_lb = lb\n                    critical_block = [d[3] for d in subset]\n\n    if not critical_block or len(critical_block) < 2:\n        return\n\n    m.hybrid_cuts = pyo.ConstraintList()\n\n    # 4. Global Lower Bound (Parent 2)\n    m.hybrid_cuts.add(m.Cmax >= best_lb)\n\n    # 5. Energetic Span Constraints (Parent 2)\n    # Introduce auxiliary variables to enclose the critical block tightly.\n    m.blk_start = pyo.Var(domain=pyo.NonNegativeReals)\n    m.blk_end   = pyo.Var(domain=pyo.NonNegativeReals)\n    \n    total_p = sum(m.p[op] for op in critical_block)\n    \n    # The block's duration must at least equal the sum of processing times\n    m.hybrid_cuts.add(m.blk_end - m.blk_start >= total_p)\n    \n    # Bound the span variables by the operations in the block\n    for op in critical_block:\n        m.hybrid_cuts.add(m.blk_start <= m.S[op])\n        m.hybrid_cuts.add(m.blk_end   >= m.S[op] + m.p[op])\n\n    # 6. Metric Lifting on the Critical Block (Parent 1 Logic)\n    # We use Parent 1's stronger \"Metric Lifting\" cuts and processing-time sorting,\n    # but restrict them to the identified critical block for efficiency.\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # Sort block by heads (heuristic for likely order u->v)\n    critical_block.sort(key=lambda x: heads[x])\n    \n    cut_count = 0\n    BUDGET = 200\n\n    for i in range(len(critical_block)):\n        for j in range(i + 1, len(critical_block)):\n            u = critical_block[i]\n            v = critical_block[j]\n            \n            # Identify intermediates k within the block\n            intermediates = [k for k in critical_block if k != u and k != v]\n            \n            # Parent 1 Heuristic: Sort intermediates by Processing Time (descending)\n            # This prioritizes cuts that impose the largest delay penalty p_k.\n            intermediates.sort(key=lambda x: m.p[x], reverse=True)\n            \n            for k in intermediates[:2]: # Top 2 strongest intermediates\n                y_uv = get_y(u, v)\n                y_uk = get_y(u, k)\n                y_kv = get_y(k, v)\n                \n                # (A) Transitivity Cut\n                m.hybrid_cuts.add(y_uk + y_kv - y_uv <= 1)\n                \n                # (B) Metric Lifting Cut (Stronger than simple Triangle)\n                # S_v >= S_u + p_u + p_k * (y_uk + y_kv - 1) - M(1 - y_uv)\n                m.hybrid_cuts.add(\n                    m.S[v] >= m.S[u] + m.p[u] + \n                    m.p[k] * (y_uk + y_kv - 1) - \n                    m.bigM * (1 - y_uv)\n                )\n                \n                cut_count += 2\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n        if cut_count >= BUDGET: break\n\nadd_hybrid_critical_block_cuts(model)",
                        "idea": "We implement **Critical Block Metric Lifting**. This strategy isolates the single most binding subset of operations (the 'Critical Block' from Parent 2) and reinforces it with Parent 1's **Metric Lifting** cuts. By defining **Energetic Span** variables (`blk_end - blk_start >= sum(p)`) for this block, we enclose the operations in a tight continuous hull. Within this hull, we apply lifted precedence cuts ($S_v \\ge S_u + p_u + p_k(y_{uk} + y_{kv} - 1)$), prioritizing intermediate nodes $k$ with large processing times (sorted by $p_k$ per Parent 1). This fuses Parent 2's localization logic with Parent 1's stronger coefficient tightening."
                    },
                    "fitness": 19.594393964251992,
                    "solver_reports": [
                        {
                            "gap": 26.5079,
                            "total_time": 13.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 31605,
                            "explored_time": 13.44,
                            "work_units": 10.01
                        },
                        {
                            "gap": 28.0032,
                            "total_time": 12.61,
                            "explored_nodes": 1,
                            "simplex_iterations": 35713,
                            "explored_time": 12.55,
                            "work_units": 10.37
                        },
                        {
                            "gap": 29.0977,
                            "total_time": 11.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 29959,
                            "explored_time": 11.17,
                            "work_units": 10.24
                        },
                        {
                            "gap": 20.1261,
                            "total_time": 13.48,
                            "explored_nodes": 113,
                            "simplex_iterations": 66781,
                            "explored_time": 13.46,
                            "work_units": 11.19
                        },
                        {
                            "total_time": 9.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 35971,
                            "explored_time": 9.75,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.677,
                            "total_time": 12.04,
                            "explored_nodes": 1417,
                            "simplex_iterations": 61262,
                            "explored_time": 12.03,
                            "work_units": 10.95
                        },
                        {
                            "gap": 28.7117,
                            "total_time": 13.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 46098,
                            "explored_time": 13.97,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 37469,
                            "explored_time": 9.61,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "9d532fc9-4e25-4780-9cdd-abd854b91fd2",
                        "35e4c99d-cd5a-44e1-98e7-0af1293c544a"
                    ]
                }
            ],
            21.57318116708071
        ],
        [
            [
                {
                    "id": "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_adaptive_carlier_cuts(m):\n        # 1. Compute Release (heads) and Delivery (tails) times for all ops\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Carlier-style subsets)\n        # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time (heads) for efficient scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Scan all contiguous sub-segments [u, v]\n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global LB Cut and Adaptive Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.adaptive_carlier = pyo.ConstraintList()\n        m.adaptive_carlier.add(m.Cmax >= global_max)\n    \n        # Select bottlenecks strictly within 90% of global max to target active constraints\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        # Helper to access y variables (u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 5. Apply Sliding Window Cuts to Critical Blocks\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 6\n        \n        # Limit to top 3 competing blocks to manage complexity\n        for target in targets[:3]:\n            ops = target['ops']  # Already sorted by release time\n            if len(ops) < 3: continue\n            \n            cuts_added = 0\n            n_sub = len(ops)\n            \n            for idx_i in range(n_sub):\n                i = ops[idx_i]\n                # Restrict j to a local window to capture dense conflicts\n                for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                    j = ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = ops[idx_k]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Transitivity: Prevent cycles i->k->j->i\n                        # If i->k and k->j, then i->j must hold\n                        m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.adaptive_carlier.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_adaptive_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_adaptive_carlier_cuts(m):\n    # 1. Compute Release (heads) and Delivery (tails) times for all ops\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Carlier-style subsets)\n    # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time (heads) for efficient scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Scan all contiguous sub-segments [u, v]\n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global LB Cut and Adaptive Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.adaptive_carlier = pyo.ConstraintList()\n    m.adaptive_carlier.add(m.Cmax >= global_max)\n\n    # Select bottlenecks strictly within 90% of global max to target active constraints\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    # Helper to access y variables (u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 5. Apply Sliding Window Cuts to Critical Blocks\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 6\n    \n    # Limit to top 3 competing blocks to manage complexity\n    for target in targets[:3]:\n        ops = target['ops']  # Already sorted by release time\n        if len(ops) < 3: continue\n        \n        cuts_added = 0\n        n_sub = len(ops)\n        \n        for idx_i in range(n_sub):\n            i = ops[idx_i]\n            # Restrict j to a local window to capture dense conflicts\n            for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                j = ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = ops[idx_k]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity: Prevent cycles i->k->j->i\n                    # If i->k and k->j, then i->j must hold\n                    m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.adaptive_carlier.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_adaptive_carlier_cuts(model)",
                        "idea": "We introduce **Adaptive Carlier-Window Transitivity**, a hybrid strategy merging the precise bottleneck detection of Parent 1 with the efficient windowed cuts of Parent 2. We first identify **Critical Blocks**contiguous operation subsets on each machine that maximize the Carlier lower bound ($r_{min} + \\sum p + q_{min}$)rather than treating the entire machine sequence as the bottleneck. On the top competing blocks (within 90% of the global maximum LB), we apply **Sliding Window Transitivity** and **Metric Lifting** cuts. This focuses constraints specifically on the tightest temporal clusters where infeasibilities originate, strengthening the relaxation locally while maintaining global scalability."
                    },
                    "fitness": 21.57318116708071,
                    "solver_reports": [
                        {
                            "gap": 17.4837,
                            "total_time": 12.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 35163,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.6348,
                            "total_time": 12.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 35618,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 33382,
                            "explored_time": 10.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.8406,
                            "total_time": 12.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 45451,
                            "explored_time": 12.06,
                            "work_units": 10.01
                        },
                        {
                            "gap": 29.7072,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 31899,
                            "explored_time": 11.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 2.3011,
                            "total_time": 10.85,
                            "explored_nodes": 3709,
                            "simplex_iterations": 288150,
                            "explored_time": 10.84,
                            "work_units": 10.3
                        },
                        {
                            "gap": 27.8426,
                            "total_time": 11.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 49164,
                            "explored_time": 11.62,
                            "work_units": 10.01
                        },
                        {
                            "gap": 24.6852,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 35149,
                            "explored_time": 11.83,
                            "work_units": 10.25
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0"
                    ]
                },
                {
                    "id": "eb996d32-feb6-444d-990a-d39823c6e0f0",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_symmetric_mass_flow_cuts(m):\n        \"\"\"\n        Hybrid Strategy: Symmetric Mass Flow Cuts\n        Combines Parent 1's Precedence Mass Lifting with Parent 2's Carlier-based Tail Lifting.\n        1. Identifies critical machine blocks maximizing Carlier Bound (r_min + sum(p) + q_min).\n        2. Enforces 'Forward Mass': S_u >= r_min + sum(p_v * y_vu) for v preceding u.\n        3. Enforces 'Backward Mass': Cmax >= S_u + p_u + sum(p_v * y_uv) + q_min for v succeeding u.\n        4. Supports with Triangle Transitivity to ensure binary sums are logical.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Timing (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access binary precedence variables safely\n        def get_y(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.mass_flow_cuts = pyo.ConstraintList()\n    \n        # 3. Detect Critical Blocks (Carlier)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time for contiguous scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            r_min_best = 0\n            q_min_best = 0\n            \n            # Scan sub-segments\n            for i in range(n):\n                p_sum = 0\n                current_q_min = float('inf')\n                current_r = heads[sorted_ops[i]]\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < current_q_min: current_q_min = tails[op]\n                    \n                    lb = current_r + p_sum + current_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n                        r_min_best = current_r\n                        q_min_best = current_q_min\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, \n                    'ops': best_sub, \n                    'r': r_min_best, \n                    'q': q_min_best\n                })\n    \n        if not candidates: return\n    \n        # Sort by LB and Apply Global Cut\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.mass_flow_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Generate Hybrid Cuts for Top Blocks\n        targets = [c for c in candidates if c['lb'] >= 0.95 * global_max]\n        CUT_BUDGET = 200\n        cuts_added = 0\n    \n        for target in targets:\n            block = target['ops']\n            r_min = target['r']\n            q_min = target['q']\n            if len(block) < 2: continue\n    \n            # A. Symmetric Mass Lifting (Forward & Backward)\n            for u in block:\n                # Forward: Start time anchor\n                # S_u >= r_min + Sum(p_v if v -> u)\n                forward_mass = 0\n                # Backward: Makespan anchor\n                # Cmax >= S_u + p_u + Sum(p_v if u -> v) + q_min\n                backward_mass = 0\n                \n                for v in block:\n                    if u == v: continue\n                    y_vu = get_y(v, u)\n                    y_uv = get_y(u, v) # Equal to 1 - y_vu in value\n                    \n                    forward_mass += m.p[v] * y_vu\n                    backward_mass += m.p[v] * y_uv\n                \n                m.mass_flow_cuts.add(m.S[u] >= r_min + forward_mass)\n                m.mass_flow_cuts.add(m.Cmax >= m.S[u] + m.p[u] + backward_mass + q_min)\n                cuts_added += 2\n            \n            if cuts_added >= CUT_BUDGET: break\n    \n            # B. Windowed Transitivity (Consistency for Mass Sums)\n            # Enforces y_uw + y_wv - 1 <= y_uv\n            WINDOW = 6\n            for i in range(len(block)):\n                u = block[i]\n                limit = min(i + WINDOW, len(block))\n                for j in range(i + 1, limit):\n                    v = block[j]\n                    # Iterate intermediates strictly between i and j\n                    for k in range(i + 1, j):\n                        w = block[k]\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        y_uv = get_y(u, v)\n                        \n                        m.mass_flow_cuts.add(y_uw + y_wv - 1 <= y_uv)\n                        cuts_added += 1\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            \n            if cuts_added >= CUT_BUDGET: break\n    \n    add_symmetric_mass_flow_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_symmetric_mass_flow_cuts(m):\n    \"\"\"\n    Hybrid Strategy: Symmetric Mass Flow Cuts\n    Combines Parent 1's Precedence Mass Lifting with Parent 2's Carlier-based Tail Lifting.\n    1. Identifies critical machine blocks maximizing Carlier Bound (r_min + sum(p) + q_min).\n    2. Enforces 'Forward Mass': S_u >= r_min + sum(p_v * y_vu) for v preceding u.\n    3. Enforces 'Backward Mass': Cmax >= S_u + p_u + sum(p_v * y_uv) + q_min for v succeeding u.\n    4. Supports with Triangle Transitivity to ensure binary sums are logical.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # 1. Precompute Timing (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access binary precedence variables safely\n    def get_y(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.mass_flow_cuts = pyo.ConstraintList()\n\n    # 3. Detect Critical Blocks (Carlier)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time for contiguous scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        r_min_best = 0\n        q_min_best = 0\n        \n        # Scan sub-segments\n        for i in range(n):\n            p_sum = 0\n            current_q_min = float('inf')\n            current_r = heads[sorted_ops[i]]\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < current_q_min: current_q_min = tails[op]\n                \n                lb = current_r + p_sum + current_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n                    r_min_best = current_r\n                    q_min_best = current_q_min\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, \n                'ops': best_sub, \n                'r': r_min_best, \n                'q': q_min_best\n            })\n\n    if not candidates: return\n\n    # Sort by LB and Apply Global Cut\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.mass_flow_cuts.add(m.Cmax >= global_max)\n\n    # 4. Generate Hybrid Cuts for Top Blocks\n    targets = [c for c in candidates if c['lb'] >= 0.95 * global_max]\n    CUT_BUDGET = 200\n    cuts_added = 0\n\n    for target in targets:\n        block = target['ops']\n        r_min = target['r']\n        q_min = target['q']\n        if len(block) < 2: continue\n\n        # A. Symmetric Mass Lifting (Forward & Backward)\n        for u in block:\n            # Forward: Start time anchor\n            # S_u >= r_min + Sum(p_v if v -> u)\n            forward_mass = 0\n            # Backward: Makespan anchor\n            # Cmax >= S_u + p_u + Sum(p_v if u -> v) + q_min\n            backward_mass = 0\n            \n            for v in block:\n                if u == v: continue\n                y_vu = get_y(v, u)\n                y_uv = get_y(u, v) # Equal to 1 - y_vu in value\n                \n                forward_mass += m.p[v] * y_vu\n                backward_mass += m.p[v] * y_uv\n            \n            m.mass_flow_cuts.add(m.S[u] >= r_min + forward_mass)\n            m.mass_flow_cuts.add(m.Cmax >= m.S[u] + m.p[u] + backward_mass + q_min)\n            cuts_added += 2\n        \n        if cuts_added >= CUT_BUDGET: break\n\n        # B. Windowed Transitivity (Consistency for Mass Sums)\n        # Enforces y_uw + y_wv - 1 <= y_uv\n        WINDOW = 6\n        for i in range(len(block)):\n            u = block[i]\n            limit = min(i + WINDOW, len(block))\n            for j in range(i + 1, limit):\n                v = block[j]\n                # Iterate intermediates strictly between i and j\n                for k in range(i + 1, j):\n                    w = block[k]\n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    y_uv = get_y(u, v)\n                    \n                    m.mass_flow_cuts.add(y_uw + y_wv - 1 <= y_uv)\n                    cuts_added += 1\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n        \n        if cuts_added >= CUT_BUDGET: break\n\nadd_symmetric_mass_flow_cuts(model)",
                        "idea": "We introduce **Symmetric Mass Flow Cuts**, a hybrid strategy that sandwiches the critical path between release and deadline constraints using a flow-based perspective. Leveraging Parent 2's rigorous bottleneck detection, we apply two complementary sets of linear cuts for the critical block: (1) **Forward Mass Lifting** (from Parent 1) which anchors start times $S_u$ to the block's release time plus the sum of dynamic predecessors ($r_{min} + \\sum p_v y_{vu}$), and (2) a novel **Backward Mass Lifting** which pushes the makespan $C_{max}$ based on $S_u$ and the sum of dynamic successors ($S_u + p_u + \\sum p_v y_{uv} + q_{min}$). This creates a bidirectional tightening of the schedule variables, reinforced by triangle transitivity to ensure the binary sums are logically consistent, significantly strengthening the convex hull."
                    },
                    "fitness": 17.827895550188842,
                    "solver_reports": [
                        {
                            "total_time": 10.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 29288,
                            "explored_time": 10.63,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 19954,
                            "explored_time": 9.35,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 37369,
                            "explored_time": 8.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.41,
                            "explored_nodes": 200,
                            "simplex_iterations": 74524,
                            "explored_time": 9.39,
                            "work_units": 10.03
                        },
                        {
                            "total_time": 8.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 30700,
                            "explored_time": 8.04,
                            "work_units": 10.03
                        },
                        {
                            "gap": 17.9319,
                            "total_time": 12.11,
                            "explored_nodes": 143,
                            "simplex_iterations": 84705,
                            "explored_time": 12.1,
                            "work_units": 11.43
                        },
                        {
                            "gap": 27.5385,
                            "total_time": 10.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 33189,
                            "explored_time": 10.69,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 22865,
                            "explored_time": 9.4,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "449ecd5b-5655-4f11-aba1-11d0e9e36156",
                        "280208fb-b3b4-4d12-95af-f147f31bd565"
                    ]
                },
                {
                    "id": "dd001188-dbd3-4350-9c35-5cf076fe0fd4",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    # Assumes 'pyo' is already imported and available in the scope as used in create_model\n    \n    def add_bi_directional_mass_cuts(m):\n        # 1. Compute Timing (Heads/Tails) for Carlier estimation\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access y_{uv} safely using sorted pairs\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.bi_dir_mass_cuts = pyo.ConstraintList()\n    \n        # 3. Detect Critical Blocks (Carlier Bottlenecks)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            best_r = 0\n            best_q = 0\n            \n            # Scan for sub-segment maximizing r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                current_min_q = float('inf')\n                r_val = heads[sorted_ops[i]]\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < current_min_q: current_min_q = tails[op]\n                    \n                    lb = r_val + p_sum + current_min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n                        best_r = r_val\n                        best_q = current_min_q\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, 'ops': best_sub, \n                    'r': best_r, 'q': best_q\n                })\n    \n        if not candidates: return\n    \n        # Sort candidates by LB descending\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        # Global Lower Bound Cut\n        m.bi_dir_mass_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Apply Bi-Directional Mass Lifting to Critical Blocks\n        # Filter to top bottlenecks close to the global max\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        CUT_BUDGET = 200\n        cuts_added = 0\n        TRANSITIVITY_WINDOW = 6\n    \n        for target in targets:\n            ops = target['ops']\n            r_blk = target['r']\n            q_blk = target['q']\n            \n            # A. Mass Lifting (Head & Tail)\n            for u in ops:\n                # Head Lifting (From Parent 2): S_u >= r_blk + sum(p_v * y_vu)\n                # Anchors u relative to the block start\n                prec_sum = sum(m.p[v] * get_y(v, u) for v in ops if v != u)\n                m.bi_dir_mass_cuts.add(m.S[u] >= r_blk + prec_sum)\n                \n                # Tail Lifting (Generalized Parent 1): Cmax >= S_u + p_u + sum(p_v * y_uv) + q_blk\n                # Anchors Cmax relative to u's position and the block end\n                succ_sum = sum(m.p[v] * get_y(u, v) for v in ops if v != u)\n                m.bi_dir_mass_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_sum + q_blk)\n                \n                cuts_added += 2\n            \n            if cuts_added >= CUT_BUDGET: break\n    \n            # B. Windowed Transitivity (From Parent 1)\n            # Ensures the binary sums above are consistent with linear ordering\n            for i in range(len(ops)):\n                u = ops[i]\n                limit = min(i + TRANSITIVITY_WINDOW, len(ops))\n                for j in range(i + 1, limit):\n                    v = ops[j]\n                    # Enforce triangle inequality for intermediates w\n                    for k in range(i + 1, j):\n                        w = ops[k]\n                        # y_uw + y_wv - 1 <= y_uv\n                        m.bi_dir_mass_cuts.add(\n                            get_y(u, w) + get_y(w, v) - 1 <= get_y(u, v)\n                        )\n                        cuts_added += 1\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            \n            if cuts_added >= CUT_BUDGET: break\n    \n    add_bi_directional_mass_cuts(model)\n\n    return model\n",
                        "added_cut": "# Assumes 'pyo' is already imported and available in the scope as used in create_model\n\ndef add_bi_directional_mass_cuts(m):\n    # 1. Compute Timing (Heads/Tails) for Carlier estimation\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access y_{uv} safely using sorted pairs\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.bi_dir_mass_cuts = pyo.ConstraintList()\n\n    # 3. Detect Critical Blocks (Carlier Bottlenecks)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        best_r = 0\n        best_q = 0\n        \n        # Scan for sub-segment maximizing r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            current_min_q = float('inf')\n            r_val = heads[sorted_ops[i]]\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < current_min_q: current_min_q = tails[op]\n                \n                lb = r_val + p_sum + current_min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n                    best_r = r_val\n                    best_q = current_min_q\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, 'ops': best_sub, \n                'r': best_r, 'q': best_q\n            })\n\n    if not candidates: return\n\n    # Sort candidates by LB descending\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    # Global Lower Bound Cut\n    m.bi_dir_mass_cuts.add(m.Cmax >= global_max)\n\n    # 4. Apply Bi-Directional Mass Lifting to Critical Blocks\n    # Filter to top bottlenecks close to the global max\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    CUT_BUDGET = 200\n    cuts_added = 0\n    TRANSITIVITY_WINDOW = 6\n\n    for target in targets:\n        ops = target['ops']\n        r_blk = target['r']\n        q_blk = target['q']\n        \n        # A. Mass Lifting (Head & Tail)\n        for u in ops:\n            # Head Lifting (From Parent 2): S_u >= r_blk + sum(p_v * y_vu)\n            # Anchors u relative to the block start\n            prec_sum = sum(m.p[v] * get_y(v, u) for v in ops if v != u)\n            m.bi_dir_mass_cuts.add(m.S[u] >= r_blk + prec_sum)\n            \n            # Tail Lifting (Generalized Parent 1): Cmax >= S_u + p_u + sum(p_v * y_uv) + q_blk\n            # Anchors Cmax relative to u's position and the block end\n            succ_sum = sum(m.p[v] * get_y(u, v) for v in ops if v != u)\n            m.bi_dir_mass_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_sum + q_blk)\n            \n            cuts_added += 2\n        \n        if cuts_added >= CUT_BUDGET: break\n\n        # B. Windowed Transitivity (From Parent 1)\n        # Ensures the binary sums above are consistent with linear ordering\n        for i in range(len(ops)):\n            u = ops[i]\n            limit = min(i + TRANSITIVITY_WINDOW, len(ops))\n            for j in range(i + 1, limit):\n                v = ops[j]\n                # Enforce triangle inequality for intermediates w\n                for k in range(i + 1, j):\n                    w = ops[k]\n                    # y_uw + y_wv - 1 <= y_uv\n                    m.bi_dir_mass_cuts.add(\n                        get_y(u, w) + get_y(w, v) - 1 <= get_y(u, v)\n                    )\n                    cuts_added += 1\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n        \n        if cuts_added >= CUT_BUDGET: break\n\nadd_bi_directional_mass_cuts(model)",
                        "idea": "We combine the rigorous 'Precedence Mass Lifting' from Parent 2 with the objective-bounding logic of Parent 1 into a **Bi-Directional Mass Lifting** strategy. For operations in critical Carlier bottlenecks, we enforce two linear bounds simultaneously: (1) **Head Lifting:** $S_u \\ge r_{min} + \\sum_{v \\neq u} p_v y_{vu}$, anchoring start times to the block's release; and (2) **Tail Lifting:** $C_{max} \\ge S_u + p_u + \\sum_{v \\neq u} p_v y_{uv} + q_{min}$, which dynamically pushes the makespan lower bound based on the remaining processing mass after $u$. This tightly bounds the feasible region from both temporal directions. We reinforce these sums with **Windowed Transitivity** cuts (from Parent 1) to ensure the binary precedence variables remain consistent within the critical block."
                    },
                    "fitness": 17.99858375473353,
                    "solver_reports": [
                        {
                            "total_time": 8.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 30098,
                            "explored_time": 8.65,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 21948,
                            "explored_time": 6.95,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 38595,
                            "explored_time": 7.67,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.0901,
                            "total_time": 11.67,
                            "explored_nodes": 52,
                            "simplex_iterations": 39611,
                            "explored_time": 11.66,
                            "work_units": 10.12
                        },
                        {
                            "total_time": 10.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 22008,
                            "explored_time": 10.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.9745,
                            "total_time": 12.04,
                            "explored_nodes": 143,
                            "simplex_iterations": 79300,
                            "explored_time": 12.03,
                            "work_units": 11.78
                        },
                        {
                            "total_time": 8.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 28836,
                            "explored_time": 8.22,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 21239,
                            "explored_time": 9.27,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "280208fb-b3b4-4d12-95af-f147f31bd565",
                        "449ecd5b-5655-4f11-aba1-11d0e9e36156"
                    ]
                },
                {
                    "id": "8ec448b0-d163-4217-ad6e-b98a040191bd",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_twin_anchor_cuts(m):\n        # 1. Compute Heads (Earliest Start) and Tails (Minimum Time to End) globally\n        heads = {}\n        tails = {}\n        \n        # Forward pass (Heads)\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K):\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        # Backward pass (Tails)\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks per Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n            \n        blocks = []\n        \n        # Scan for blocks with high Carlier Lower Bounds\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (Head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                min_r = heads[sorted_ops[i]]\n                \n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    \n                    lb = min_r + p_sum + min_q\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n            \n            if best_lb > 0:\n                blocks.append({'lb': best_lb, 'ops': best_sub})\n    \n        # Sort blocks by LB descending to prioritize bottlenecks\n        blocks.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # 3. Apply Twin-Anchor Cuts to Top Blocks\n        m.twin_anchor_cuts = pyo.ConstraintList()\n        \n        # Helper for binary variables to handle symmetry\n        def get_y(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n                \n        # Process top 3 distinctive blocks\n        processed_count = 0\n        CUT_LIMIT = 200\n        \n        for block in blocks[:3]:\n            ops = block['ops']\n            if len(ops) < 2: continue\n            \n            # Block-wide constants\n            r_min = min(heads[op] for op in ops)\n            q_min = min(tails[op] for op in ops)\n            \n            for u in ops:\n                # Construct Mass Expressions using binary vars\n                # Succ Mass: sum(p_v * y_uv) for v != u\n                # Pred Mass: sum(p_v * y_vu) for v != u\n                \n                succ_mass_expr = 0\n                pred_mass_expr = 0\n                \n                for v in ops:\n                    if u == v: continue\n                    y_uv = get_y(u, v) # 1 if u before v\n                    y_vu = get_y(v, u) # 1 if v before u\n                    \n                    succ_mass_expr += m.p[v] * y_uv\n                    pred_mass_expr += m.p[v] * y_vu\n                \n                # A. Forward Anchor (Squeeze Start from Left)\n                # S_u >= r_min + sum(p_v * IsPred(v))\n                m.twin_anchor_cuts.add(\n                    m.S[u] >= r_min + pred_mass_expr\n                )\n                \n                # B. Backward Anchor (Squeeze Cmax from Right)\n                # Cmax >= S_u + p_u + sum(p_v * IsSucc(v)) + q_min\n                # This links Cmax capacity directly to sequencing decisions\n                m.twin_anchor_cuts.add(\n                    m.Cmax >= m.S[u] + m.p[u] + succ_mass_expr + q_min\n                )\n                \n                processed_count += 2\n            if processed_count >= CUT_LIMIT: break\n    \n    add_twin_anchor_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_twin_anchor_cuts(m):\n    # 1. Compute Heads (Earliest Start) and Tails (Minimum Time to End) globally\n    heads = {}\n    tails = {}\n    \n    # Forward pass (Heads)\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K):\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    # Backward pass (Tails)\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks per Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n        \n    blocks = []\n    \n    # Scan for blocks with high Carlier Lower Bounds\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (Head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            min_r = heads[sorted_ops[i]]\n            \n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                \n                lb = min_r + p_sum + min_q\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n        \n        if best_lb > 0:\n            blocks.append({'lb': best_lb, 'ops': best_sub})\n\n    # Sort blocks by LB descending to prioritize bottlenecks\n    blocks.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # 3. Apply Twin-Anchor Cuts to Top Blocks\n    m.twin_anchor_cuts = pyo.ConstraintList()\n    \n    # Helper for binary variables to handle symmetry\n    def get_y(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n    # Process top 3 distinctive blocks\n    processed_count = 0\n    CUT_LIMIT = 200\n    \n    for block in blocks[:3]:\n        ops = block['ops']\n        if len(ops) < 2: continue\n        \n        # Block-wide constants\n        r_min = min(heads[op] for op in ops)\n        q_min = min(tails[op] for op in ops)\n        \n        for u in ops:\n            # Construct Mass Expressions using binary vars\n            # Succ Mass: sum(p_v * y_uv) for v != u\n            # Pred Mass: sum(p_v * y_vu) for v != u\n            \n            succ_mass_expr = 0\n            pred_mass_expr = 0\n            \n            for v in ops:\n                if u == v: continue\n                y_uv = get_y(u, v) # 1 if u before v\n                y_vu = get_y(v, u) # 1 if v before u\n                \n                succ_mass_expr += m.p[v] * y_uv\n                pred_mass_expr += m.p[v] * y_vu\n            \n            # A. Forward Anchor (Squeeze Start from Left)\n            # S_u >= r_min + sum(p_v * IsPred(v))\n            m.twin_anchor_cuts.add(\n                m.S[u] >= r_min + pred_mass_expr\n            )\n            \n            # B. Backward Anchor (Squeeze Cmax from Right)\n            # Cmax >= S_u + p_u + sum(p_v * IsSucc(v)) + q_min\n            # This links Cmax capacity directly to sequencing decisions\n            m.twin_anchor_cuts.add(\n                m.Cmax >= m.S[u] + m.p[u] + succ_mass_expr + q_min\n            )\n            \n            processed_count += 2\n        if processed_count >= CUT_LIMIT: break\n\nadd_twin_anchor_cuts(model)",
                        "idea": "We implement 'Twin-Anchor Mass Lifting', a strategy that squeezes operation schedules from both timeline directions. While Parent 2 anchors start times to release dates ($r_{min}$) via predecessor mass, this cut adds a novel **Backward Anchor** that ties the global $C_{max}$ variable to the operation's completion plus its **successor mass** and minimum tail ($q_{min}$). By enforcing $C_{max} \\ge S_u + p_u + \\sum p_v y_{uv} + q_{min}$, the solver recognizes that prioritizing $u$ early forces a chain of successors that must fit within the makespan, creating a tight 'Knapsack' constraint on time capacity that propagates from the objective function down to binary sequencing variables."
                    },
                    "fitness": 15.705022702984426,
                    "solver_reports": [
                        {
                            "total_time": 5.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 24399,
                            "explored_time": 5.9,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 29372,
                            "explored_time": 6.41,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 31500,
                            "explored_time": 6.34,
                            "work_units": 10.0
                        },
                        {
                            "gap": 36.9581,
                            "total_time": 9.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 39881,
                            "explored_time": 9.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 31866,
                            "explored_time": 6.32,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.9256,
                            "total_time": 11.39,
                            "explored_nodes": 112,
                            "simplex_iterations": 64074,
                            "explored_time": 11.38,
                            "work_units": 13.59
                        },
                        {
                            "total_time": 7.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 33714,
                            "explored_time": 7.32,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 28237,
                            "explored_time": 6.24,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "65a72354-ecfa-4163-b531-3d500068d0e1",
                        "449ecd5b-5655-4f11-aba1-11d0e9e36156"
                    ]
                },
                {
                    "id": "15672d5b-ca14-4b2d-aa51-eb221a77d9c6",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_carlier_overlap_cuts(m):\n        # 1. Compute Timing (Heads/Tails)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier Subsets - Parent 1 Logic)\n        # Scan each machine for the subset maximizing r_min + sum(p) + q_min\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads for Carlier detection\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n    \n            # O(N^2) scan for max LB on this machine\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                current_sub = []\n                r_val = heads[sorted_ops[i]] \n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Use the tightest bottleneck LB found to define the global horizon (Parent 1/2 Synergy)\n        carlier_lb = candidates[0]['lb']\n        \n        # Add Global Lower Bound Cut\n        m.hybrid_cuts = pyo.ConstraintList()\n        m.hybrid_cuts.add(m.Cmax >= carlier_lb)\n    \n        # 3. Hybrid Logic: Overlap-Conditioned Lifting on Critical Block\n        # Filter ops to just the most critical sequence\n        block = candidates[0]['ops']\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        count = 0\n        MAX_CUTS = 150\n        \n        # Iterate triplets (u, w, v) within the critical block\n        # Logic: Use Parent 2's overlap check to identify ambiguous orderings within the Parent 1 block\n        # Note: block is already sorted by heads, but overlaps are the key to 'ambiguity'\n        for i in range(len(block)):\n            u = block[i]\n            for j in range(len(block)):\n                if i == j: continue\n                v = block[j]\n                \n                for k in range(len(block)):\n                    if k == i or k == j: continue\n                    w = block[k]\n                    \n                    # Check Overlap: [Start, End] derived from Carlier LB\n                    # Start = Head, End = LB - Tail\n                    s_u, e_u = heads[u], carlier_lb - tails[u]\n                    s_v, e_v = heads[v], carlier_lb - tails[v]\n                    s_w, e_w = heads[w], carlier_lb - tails[w]\n                    \n                    # Intersection of all three windows (Parent 2 Condition)\n                    start_overlap = max(s_u, s_v, s_w)\n                    end_overlap = min(e_u, e_v, e_w)\n                    \n                    if start_overlap < end_overlap:\n                        # Windows overlap significantly; ordering is ambiguous in relaxation.\n                        # Enforce Triangle Transitivity and Metric Lifting.\n                        \n                        y_uv = get_y(u, v)\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        \n                        # 1. Transitivity: u->w and w->v => u->v\n                        m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n                        \n                        # 2. Metric Lifting: If u->w->v, ensure S_v accounts for p_w\n                        # This lifts the disjunctive constraint between u and v using w\n                        m.hybrid_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[w] * (y_uw + y_wv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        count += 2\n                        if count >= MAX_CUTS: return\n    \n    add_hybrid_carlier_overlap_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_carlier_overlap_cuts(m):\n    # 1. Compute Timing (Heads/Tails)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier Subsets - Parent 1 Logic)\n    # Scan each machine for the subset maximizing r_min + sum(p) + q_min\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads for Carlier detection\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n\n        # O(N^2) scan for max LB on this machine\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            current_sub = []\n            r_val = heads[sorted_ops[i]] \n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Use the tightest bottleneck LB found to define the global horizon (Parent 1/2 Synergy)\n    carlier_lb = candidates[0]['lb']\n    \n    # Add Global Lower Bound Cut\n    m.hybrid_cuts = pyo.ConstraintList()\n    m.hybrid_cuts.add(m.Cmax >= carlier_lb)\n\n    # 3. Hybrid Logic: Overlap-Conditioned Lifting on Critical Block\n    # Filter ops to just the most critical sequence\n    block = candidates[0]['ops']\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    count = 0\n    MAX_CUTS = 150\n    \n    # Iterate triplets (u, w, v) within the critical block\n    # Logic: Use Parent 2's overlap check to identify ambiguous orderings within the Parent 1 block\n    # Note: block is already sorted by heads, but overlaps are the key to 'ambiguity'\n    for i in range(len(block)):\n        u = block[i]\n        for j in range(len(block)):\n            if i == j: continue\n            v = block[j]\n            \n            for k in range(len(block)):\n                if k == i or k == j: continue\n                w = block[k]\n                \n                # Check Overlap: [Start, End] derived from Carlier LB\n                # Start = Head, End = LB - Tail\n                s_u, e_u = heads[u], carlier_lb - tails[u]\n                s_v, e_v = heads[v], carlier_lb - tails[v]\n                s_w, e_w = heads[w], carlier_lb - tails[w]\n                \n                # Intersection of all three windows (Parent 2 Condition)\n                start_overlap = max(s_u, s_v, s_w)\n                end_overlap = min(e_u, e_v, e_w)\n                \n                if start_overlap < end_overlap:\n                    # Windows overlap significantly; ordering is ambiguous in relaxation.\n                    # Enforce Triangle Transitivity and Metric Lifting.\n                    \n                    y_uv = get_y(u, v)\n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    \n                    # 1. Transitivity: u->w and w->v => u->v\n                    m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n                    \n                    # 2. Metric Lifting: If u->w->v, ensure S_v accounts for p_w\n                    # This lifts the disjunctive constraint between u and v using w\n                    m.hybrid_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + \n                        m.p[w] * (y_uw + y_wv - 1) - \n                        m.bigM * (1 - y_uv)\n                    )\n                    \n                    count += 2\n                    if count >= MAX_CUTS: return\n\nadd_hybrid_carlier_overlap_cuts(model)",
                        "idea": "We combine Parent 1's Critical Block Detection (Carlier sets) with Parent 2's Conflict Clique logic to generate Overlap-Conditioned Metric Lifting cuts. Instead of blindly lifting precedence variables based on static release-time sorting (P1), we calculate a high-quality global lower bound (Carlier LB) and use it to define dynamic time windows for operations in the bottleneck (P2 logic). We then scan for 'dense' triplets (u, w, v) where these windows strictly overlap. For these ambiguous cliques, we enforce triangle transitivity and a strengthened metric lifting cut (S_v >= S_u + p_u + p_w(y_uw + y_wv - 1)). This focuses computational effort on resolving the specific sub-sequences that drive the makespan but are most prone to fractional relaxation."
                    },
                    "fitness": 19.909849474947222,
                    "solver_reports": [
                        {
                            "gap": 13.682,
                            "total_time": 14.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 28894,
                            "explored_time": 14.0,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 38493,
                            "explored_time": 10.98,
                            "work_units": 10.01
                        },
                        {
                            "gap": 30.202,
                            "total_time": 11.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 29997,
                            "explored_time": 11.2,
                            "work_units": 10.08
                        },
                        {
                            "gap": 22.0905,
                            "total_time": 13.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 45779,
                            "explored_time": 13.51,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.71,
                            "explored_nodes": 1,
                            "simplex_iterations": 30079,
                            "explored_time": 9.66,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.4125,
                            "total_time": 12.86,
                            "explored_nodes": 6552,
                            "simplex_iterations": 198661,
                            "explored_time": 12.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 30.5053,
                            "total_time": 12.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 46681,
                            "explored_time": 12.27,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.3701,
                            "total_time": 13.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 40097,
                            "explored_time": 13.27,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "280208fb-b3b4-4d12-95af-f147f31bd565",
                        "960251d1-f7a9-4cc2-bdf7-9b2fc1c5b409"
                    ]
                },
                {
                    "id": "30ed18b9-c0e8-4337-8396-dd29dd079798",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_lifted_sequence_cuts(m):\n        # 1. Precompute static heads and tails for tightness calculation\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access y variables regardless of index order\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.lifted_seq_cuts = pyo.ConstraintList()\n        \n        # 3. Detect Carlier-like Critical Blocks\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Find sub-segments maximizing LB\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                current_block = []\n                r_val = heads[sorted_ops[i]]\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_block.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    candidates.append({'lb': lb, 'ops': list(current_block)})\n    \n        if not candidates: return\n        \n        # Filter for top critical blocks\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        best_lb = candidates[0]['lb']\n        targets = [c for c in candidates if c['lb'] >= 0.95 * best_lb]\n    \n        added_cuts = 0\n        CUT_BUDGET = 150\n        added_triplets = set()\n    \n        for target in targets:\n            ops = target['ops']\n            if len(ops) < 2: continue\n            \n            # Restrict pair window to avoid O(N^2) explosion on large blocks\n            window = 6\n            \n            for i in range(len(ops)):\n                u = ops[i]\n                limit = min(i + window + 1, len(ops))\n                for j in range(i + 1, limit):\n                    v = ops[j]\n                    \n                    # Identify intermediate operations 'w' within the block\n                    intermediates = ops[i+1 : j]\n                    \n                    # Term to capture intermediate processing times dynamically\n                    # If u -> w -> v, then (y_uw + y_wv - 1) = 1, adding p_w to the bound.\n                    intermediate_term = 0\n                    y_uv = get_y(u, v)\n                    \n                    for w in intermediates:\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        \n                        # (Optional) Enforce Triangle Transitivity to tighten relaxation\n                        # u->w and w->v => u->v\n                        triplet_key = tuple(sorted((u, v, w)))\n                        if triplet_key not in added_triplets:\n                            m.lifted_seq_cuts.add(y_uw + y_wv - 1 <= y_uv)\n                            added_triplets.add(triplet_key)\n    \n                        intermediate_term += m.p[w] * (y_uw + y_wv - 1)\n    \n                    # LIFTED CUT: Link Makespan to dynamic Start Time of u\n                    # Cmax >= S_u + p_u + p_v + q_v + sum(p_w * I(u->w->v)) - M(1 - y_uv)\n                    # This replaces static 'heads[u]' with variable 'S[u]' for tighter bounds.\n                    \n                    rhs = (m.S[u] + m.p[u] + m.p[v] + tails[v] + \n                           intermediate_term - m.bigM * (1 - y_uv))\n                    \n                    m.lifted_seq_cuts.add(m.Cmax >= rhs)\n                    \n                    added_cuts += 1\n                    if added_cuts >= CUT_BUDGET: return\n\n    return model\n",
                        "added_cut": "def add_lifted_sequence_cuts(m):\n    # 1. Precompute static heads and tails for tightness calculation\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access y variables regardless of index order\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.lifted_seq_cuts = pyo.ConstraintList()\n    \n    # 3. Detect Carlier-like Critical Blocks\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Find sub-segments maximizing LB\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            current_block = []\n            r_val = heads[sorted_ops[i]]\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_block.append(op)\n                \n                lb = r_val + p_sum + min_q\n                candidates.append({'lb': lb, 'ops': list(current_block)})\n\n    if not candidates: return\n    \n    # Filter for top critical blocks\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    best_lb = candidates[0]['lb']\n    targets = [c for c in candidates if c['lb'] >= 0.95 * best_lb]\n\n    added_cuts = 0\n    CUT_BUDGET = 150\n    added_triplets = set()\n\n    for target in targets:\n        ops = target['ops']\n        if len(ops) < 2: continue\n        \n        # Restrict pair window to avoid O(N^2) explosion on large blocks\n        window = 6\n        \n        for i in range(len(ops)):\n            u = ops[i]\n            limit = min(i + window + 1, len(ops))\n            for j in range(i + 1, limit):\n                v = ops[j]\n                \n                # Identify intermediate operations 'w' within the block\n                intermediates = ops[i+1 : j]\n                \n                # Term to capture intermediate processing times dynamically\n                # If u -> w -> v, then (y_uw + y_wv - 1) = 1, adding p_w to the bound.\n                intermediate_term = 0\n                y_uv = get_y(u, v)\n                \n                for w in intermediates:\n                    y_uw = get_y(u, w)\n                    y_wv = get_y(w, v)\n                    \n                    # (Optional) Enforce Triangle Transitivity to tighten relaxation\n                    # u->w and w->v => u->v\n                    triplet_key = tuple(sorted((u, v, w)))\n                    if triplet_key not in added_triplets:\n                        m.lifted_seq_cuts.add(y_uw + y_wv - 1 <= y_uv)\n                        added_triplets.add(triplet_key)\n\n                    intermediate_term += m.p[w] * (y_uw + y_wv - 1)\n\n                # LIFTED CUT: Link Makespan to dynamic Start Time of u\n                # Cmax >= S_u + p_u + p_v + q_v + sum(p_w * I(u->w->v)) - M(1 - y_uv)\n                # This replaces static 'heads[u]' with variable 'S[u]' for tighter bounds.\n                \n                rhs = (m.S[u] + m.p[u] + m.p[v] + tails[v] + \n                       intermediate_term - m.bigM * (1 - y_uv))\n                \n                m.lifted_seq_cuts.add(m.Cmax >= rhs)\n                \n                added_cuts += 1\n                if added_cuts >= CUT_BUDGET: return",
                        "idea": "We apply **Dynamic Start-Time Lifting** to the Sequence-Dependent cuts. Instead of relying on static release times ($r_u$) for the lower bound, we lift the inequality to use the variable start time $S_u$. The new cut form is $C_{max} \\ge S_u + p_u + p_v + q_v + \\sum_{w} p_w(y_{uw} + y_{wv} - 1) - M(1 - y_{uv})$. This formulation dynamically incorporates the actual delay of operation $u$ (which accounts for all predecessors) and conditionally adds the processing times of intermediate operations $w$ via the superadditive term $(y_{uw} + y_{wv} - 1)$. We also implicitly enforce triangle transitivity to ensure the intermediate term behaves correctly in the relaxation, tightening the makespan bound specifically along the critical path of the bottleneck machine."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.1,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.84,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.18,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.5,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.47,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.96,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 11.78,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 11.77,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.94,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.99,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "280208fb-b3b4-4d12-95af-f147f31bd565"
                    ]
                },
                {
                    "id": "1a191370-45de-41ef-b02e-cb4aa65d81c8",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_adaptive_span_lifting(m):\n        # 1. Compute Heads and Tails for Carlier Bounds\n        heads = {}\n        tails = {}\n        # Forward pass (Heads)\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass (Tails)\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Parent 1 Strategy)\n        # Find contiguous sub-segments maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time (approx topological order on machine)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Adaptive Selection (Parent 1 Logic)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        # Target blocks within 90% of global max to handle competing bottlenecks (limit 3)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    \n        m.adaptive_span_cuts = pyo.ConstraintList()\n        m.adaptive_span_cuts.add(m.Cmax >= global_max)\n    \n        # 5. Hybrid: Energetic Span Variables on Adaptive Blocks\n        # Use Parent 2's Span variables, but apply to ALL Parent 1 target blocks\n        m.span_blk = pyo.RangeSet(0, len(targets) - 1)\n        m.span_start = pyo.Var(m.span_blk, domain=pyo.NonNegativeReals)\n        m.span_end   = pyo.Var(m.span_blk, domain=pyo.NonNegativeReals)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_BUDGET = 300\n        cuts_added = 0\n        WINDOW_SIZE = 6\n    \n        for idx, target in enumerate(targets):\n            ops = target['ops']\n            if len(ops) < 2: continue\n            \n            # (A) Energetic Span: Box the bottleneck duration\n            total_p = sum(m.p[op] for op in ops)\n            m.adaptive_span_cuts.add(m.span_end[idx] - m.span_start[idx] >= total_p)\n            \n            for op in ops:\n                m.adaptive_span_cuts.add(m.span_start[idx] <= m.S[op])\n                m.adaptive_span_cuts.add(m.span_end[idx]   >= m.S[op] + m.p[op])\n                \n            # (B) Sorted Window Lifting (Hybrid of P1 Window & P2 Sorting)\n            n_sub = len(ops)\n            for i_idx in range(n_sub):\n                i = ops[i_idx]\n                # Local window scan\n                for j_idx in range(i_idx + 1, min(i_idx + WINDOW_SIZE, n_sub)):\n                    j = ops[j_idx]\n                    \n                    # Intermediates k strictly between i and j\n                    intermediates = [ops[k] for k in range(i_idx + 1, j_idx)]\n                    # Parent 2 Heuristic: Sort k by p_k desc to maximize lift penalty\n                    intermediates.sort(key=lambda x: m.p[x], reverse=True)\n                    \n                    # Apply cuts for top 2 strongest intermediates\n                    for k in intermediates[:2]:\n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Transitivity\n                        m.adaptive_span_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Metric Lifting\n                        m.adaptive_span_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n    \n    add_adaptive_span_lifting(model)\n\n    return model\n",
                        "added_cut": "def add_adaptive_span_lifting(m):\n    # 1. Compute Heads and Tails for Carlier Bounds\n    heads = {}\n    tails = {}\n    # Forward pass (Heads)\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass (Tails)\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Parent 1 Strategy)\n    # Find contiguous sub-segments maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time (approx topological order on machine)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Adaptive Selection (Parent 1 Logic)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    # Target blocks within 90% of global max to handle competing bottlenecks (limit 3)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n\n    m.adaptive_span_cuts = pyo.ConstraintList()\n    m.adaptive_span_cuts.add(m.Cmax >= global_max)\n\n    # 5. Hybrid: Energetic Span Variables on Adaptive Blocks\n    # Use Parent 2's Span variables, but apply to ALL Parent 1 target blocks\n    m.span_blk = pyo.RangeSet(0, len(targets) - 1)\n    m.span_start = pyo.Var(m.span_blk, domain=pyo.NonNegativeReals)\n    m.span_end   = pyo.Var(m.span_blk, domain=pyo.NonNegativeReals)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_BUDGET = 300\n    cuts_added = 0\n    WINDOW_SIZE = 6\n\n    for idx, target in enumerate(targets):\n        ops = target['ops']\n        if len(ops) < 2: continue\n        \n        # (A) Energetic Span: Box the bottleneck duration\n        total_p = sum(m.p[op] for op in ops)\n        m.adaptive_span_cuts.add(m.span_end[idx] - m.span_start[idx] >= total_p)\n        \n        for op in ops:\n            m.adaptive_span_cuts.add(m.span_start[idx] <= m.S[op])\n            m.adaptive_span_cuts.add(m.span_end[idx]   >= m.S[op] + m.p[op])\n            \n        # (B) Sorted Window Lifting (Hybrid of P1 Window & P2 Sorting)\n        n_sub = len(ops)\n        for i_idx in range(n_sub):\n            i = ops[i_idx]\n            # Local window scan\n            for j_idx in range(i_idx + 1, min(i_idx + WINDOW_SIZE, n_sub)):\n                j = ops[j_idx]\n                \n                # Intermediates k strictly between i and j\n                intermediates = [ops[k] for k in range(i_idx + 1, j_idx)]\n                # Parent 2 Heuristic: Sort k by p_k desc to maximize lift penalty\n                intermediates.sort(key=lambda x: m.p[x], reverse=True)\n                \n                # Apply cuts for top 2 strongest intermediates\n                for k in intermediates[:2]:\n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # Transitivity\n                    m.adaptive_span_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Metric Lifting\n                    m.adaptive_span_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n        if cuts_added >= CUT_BUDGET: break\n\nadd_adaptive_span_lifting(model)",
                        "idea": "We introduce **Adaptive Span & Sorted Lifting**, a hybrid strategy merging the multi-bottleneck targeting of Parent 1 with the energetic bounds and heuristic sorting of Parent 2. We identify multiple **Critical Blocks** (contiguous operations maximizing Carlier bounds) within 90% of the global maximum. For each competing block, we introduce **Energetic Span** variables ($End - Start \\ge \\sum p_i$) to enforce a tight convex hull on the resource duration (an extension of Parent 2's single-block span). Inside these blocks, we apply **Sorted Window Lifting**: utilizing Parent 1's sliding window for scalability, but selecting intermediate nodes $k$ based on descending processing time $p_k$ (Parent 2's heuristic) to inject the strongest possible precedence and metric lifting cuts."
                    },
                    "fitness": 21.41909413767573,
                    "solver_reports": [
                        {
                            "total_time": 11.98,
                            "explored_nodes": 1,
                            "simplex_iterations": 29673,
                            "explored_time": 11.93,
                            "work_units": 10.0
                        },
                        {
                            "gap": 32.6665,
                            "total_time": 12.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 33258,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 32034,
                            "explored_time": 10.11,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.2532,
                            "total_time": 13.31,
                            "explored_nodes": 3,
                            "simplex_iterations": 39585,
                            "explored_time": 13.29,
                            "work_units": 10.05
                        },
                        {
                            "total_time": 9.95,
                            "explored_nodes": 1,
                            "simplex_iterations": 34073,
                            "explored_time": 9.89,
                            "work_units": 10.0
                        },
                        {
                            "gap": 1.5894,
                            "total_time": 10.85,
                            "explored_nodes": 6196,
                            "simplex_iterations": 352864,
                            "explored_time": 10.85,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.8538,
                            "total_time": 13.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 48194,
                            "explored_time": 13.02,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.3279,
                            "total_time": 13.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 32938,
                            "explored_time": 13.76,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "65a72354-ecfa-4163-b531-3d500068d0e1"
                    ]
                },
                {
                    "id": "e2649fcd-770b-4786-aa1e-ec10502d4732",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_block_energy_cuts(m):\n        # 1. Precompute static 'heads' (earliest start times) for sorting\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine to identify blocks\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access precedence variable y(u -> v)\n        def get_y_expr(u, v):\n            # u, v are tuples (job, k)\n            if u < v:\n                if (u[0], u[1], v[0], v[1]) in m.Pairs:\n                    return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                if (v[0], v[1], u[0], u[1]) in m.Pairs:\n                    return 1 - m.y[v[0], v[1], u[0], u[1]]\n            return 0 # Should not happen for ops on same machine\n    \n        m.block_energy_cuts = pyo.ConstraintList()\n        MAX_CUTS = 200  # Budget to prevent model bloat\n        WINDOW = 8      # Sliding window size for local energy lifting\n    \n        # 3. Apply Block Energy Lifting\n        # Sort machines by total processing time (proxy for criticality) to prioritize\n        sorted_mids = sorted(mach_ops.keys(), \n                             key=lambda mid: sum(m.p[op] for op in mach_ops[mid]), \n                             reverse=True)\n    \n        cuts_added = 0\n        for mid in sorted_mids:\n            ops = mach_ops[mid]\n            if len(ops) < 3: continue\n            \n            # Sort operations by static release time (heads) to form a likely sequence\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n    \n            # Sliding window over the block\n            for i in range(n_ops):\n                u = sorted_ops[i]\n                # Look ahead in the window\n                for j in range(i + 1, min(i + WINDOW, n_ops)):\n                    v = sorted_ops[j]\n                    \n                    # Collect intermediate \"energy\" from nodes k strictly between i and j in the window\n                    # If u -> v is active, we check if u -> k -> v is active for any k\n                    intermediate_expr = 0\n                    term_count = 0\n                    \n                    for k_idx in range(i + 1, j):\n                        k = sorted_ops[k_idx]\n                        y_uk = get_y_expr(u, k)\n                        y_kv = get_y_expr(k, v)\n                        \n                        # The term (y_uk + y_kv - 1) is 1 iff k is between u and v, else <= 0\n                        # We lift the cut by adding p[k] * indicator(k is between u and v)\n                        intermediate_expr += m.p[k] * (y_uk + y_kv - 1)\n                        term_count += 1\n                    \n                    if term_count > 0:\n                        y_uv = get_y_expr(u, v)\n                        # Lifted Cut: S_v >= S_u + p_u + Sum(p_k if k between u,v) - M if not(u->v)\n                        # This aggregates multiple transitivity constraints into one tight bound\n                        m.block_energy_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + intermediate_expr - m.bigM * (1 - y_uv)\n                        )\n                        cuts_added += 1\n                if cuts_added >= MAX_CUTS: break\n            if cuts_added >= MAX_CUTS: break\n    \n    add_block_energy_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_block_energy_cuts(m):\n    # 1. Precompute static 'heads' (earliest start times) for sorting\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine to identify blocks\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access precedence variable y(u -> v)\n    def get_y_expr(u, v):\n        # u, v are tuples (job, k)\n        if u < v:\n            if (u[0], u[1], v[0], v[1]) in m.Pairs:\n                return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            if (v[0], v[1], u[0], u[1]) in m.Pairs:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n        return 0 # Should not happen for ops on same machine\n\n    m.block_energy_cuts = pyo.ConstraintList()\n    MAX_CUTS = 200  # Budget to prevent model bloat\n    WINDOW = 8      # Sliding window size for local energy lifting\n\n    # 3. Apply Block Energy Lifting\n    # Sort machines by total processing time (proxy for criticality) to prioritize\n    sorted_mids = sorted(mach_ops.keys(), \n                         key=lambda mid: sum(m.p[op] for op in mach_ops[mid]), \n                         reverse=True)\n\n    cuts_added = 0\n    for mid in sorted_mids:\n        ops = mach_ops[mid]\n        if len(ops) < 3: continue\n        \n        # Sort operations by static release time (heads) to form a likely sequence\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n\n        # Sliding window over the block\n        for i in range(n_ops):\n            u = sorted_ops[i]\n            # Look ahead in the window\n            for j in range(i + 1, min(i + WINDOW, n_ops)):\n                v = sorted_ops[j]\n                \n                # Collect intermediate \"energy\" from nodes k strictly between i and j in the window\n                # If u -> v is active, we check if u -> k -> v is active for any k\n                intermediate_expr = 0\n                term_count = 0\n                \n                for k_idx in range(i + 1, j):\n                    k = sorted_ops[k_idx]\n                    y_uk = get_y_expr(u, k)\n                    y_kv = get_y_expr(k, v)\n                    \n                    # The term (y_uk + y_kv - 1) is 1 iff k is between u and v, else <= 0\n                    # We lift the cut by adding p[k] * indicator(k is between u and v)\n                    intermediate_expr += m.p[k] * (y_uk + y_kv - 1)\n                    term_count += 1\n                \n                if term_count > 0:\n                    y_uv = get_y_expr(u, v)\n                    # Lifted Cut: S_v >= S_u + p_u + Sum(p_k if k between u,v) - M if not(u->v)\n                    # This aggregates multiple transitivity constraints into one tight bound\n                    m.block_energy_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + intermediate_expr - m.bigM * (1 - y_uv)\n                    )\n                    cuts_added += 1\n            if cuts_added >= MAX_CUTS: break\n        if cuts_added >= MAX_CUTS: break\n\nadd_block_energy_cuts(model)",
                        "idea": "We implement **Block-Level Precedence Energy Cuts**, a lifting of the individual's metric cuts. Instead of simple pairwise transitivity or static Carlier bounds, we identify critical blocks of operations on each machine and sort them by release times. For pairs of operations $(u, v)$ within a local window, we formulate a single aggregated constraint that enforces $S_v \\ge S_u + p_u + \\sum p_k$ for *all* intermediate operations $k$ sequenced between $u$ and $v$. The term $(y_{uk} + y_{kv} - 1)$ acts as a dynamic indicator that is exactly 1 when $u \\to k \\to v$. This tightens the relaxation by coupling the start time difference $S_v - S_u$ to the total 'energy' (processing time) of the dynamically determined sub-sequence between them, effectively creating a superadditive valid inequality that prunes invalid schedules more aggressively than standard disjunctive constraints."
                    },
                    "fitness": 9.438239737574012,
                    "solver_reports": [
                        {
                            "total_time": 11.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 82015,
                            "explored_time": 11.94,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 15.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 78555,
                            "explored_time": 15.53,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 17.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 63313,
                            "explored_time": 17.16,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.94,
                            "explored_nodes": 3541,
                            "simplex_iterations": 436328,
                            "explored_time": 9.92,
                            "work_units": 10.05
                        },
                        {
                            "total_time": 18.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 61145,
                            "explored_time": 18.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 34.8308,
                            "total_time": 9.79,
                            "explored_nodes": 331,
                            "simplex_iterations": 68153,
                            "explored_time": 9.78,
                            "work_units": 10.21
                        },
                        {
                            "total_time": 9.49,
                            "explored_nodes": 765,
                            "simplex_iterations": 146940,
                            "explored_time": 9.47,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 15.57,
                            "explored_nodes": 1,
                            "simplex_iterations": 60529,
                            "explored_time": 15.52,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86"
                    ]
                }
            ],
            21.57318116708071
        ],
        [
            [
                {
                    "id": "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_adaptive_carlier_cuts(m):\n        # 1. Compute Release (heads) and Delivery (tails) times for all ops\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Carlier-style subsets)\n        # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by release time (heads) for efficient scanning\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Scan all contiguous sub-segments [u, v]\n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 4. Global LB Cut and Adaptive Selection\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.adaptive_carlier = pyo.ConstraintList()\n        m.adaptive_carlier.add(m.Cmax >= global_max)\n    \n        # Select bottlenecks strictly within 90% of global max to target active constraints\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        # Helper to access y variables (u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 5. Apply Sliding Window Cuts to Critical Blocks\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 6\n        \n        # Limit to top 3 competing blocks to manage complexity\n        for target in targets[:3]:\n            ops = target['ops']  # Already sorted by release time\n            if len(ops) < 3: continue\n            \n            cuts_added = 0\n            n_sub = len(ops)\n            \n            for idx_i in range(n_sub):\n                i = ops[idx_i]\n                # Restrict j to a local window to capture dense conflicts\n                for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                    j = ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = ops[idx_k]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # (A) Transitivity: Prevent cycles i->k->j->i\n                        # If i->k and k->j, then i->j must hold\n                        m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.adaptive_carlier.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_adaptive_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_adaptive_carlier_cuts(m):\n    # 1. Compute Release (heads) and Delivery (tails) times for all ops\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Carlier-style subsets)\n    # A critical block is a contiguous subset maximizing r_min + sum(p) + q_min\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by release time (heads) for efficient scanning\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Scan all contiguous sub-segments [u, v]\n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 4. Global LB Cut and Adaptive Selection\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.adaptive_carlier = pyo.ConstraintList()\n    m.adaptive_carlier.add(m.Cmax >= global_max)\n\n    # Select bottlenecks strictly within 90% of global max to target active constraints\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    # Helper to access y variables (u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 5. Apply Sliding Window Cuts to Critical Blocks\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 6\n    \n    # Limit to top 3 competing blocks to manage complexity\n    for target in targets[:3]:\n        ops = target['ops']  # Already sorted by release time\n        if len(ops) < 3: continue\n        \n        cuts_added = 0\n        n_sub = len(ops)\n        \n        for idx_i in range(n_sub):\n            i = ops[idx_i]\n            # Restrict j to a local window to capture dense conflicts\n            for idx_j in range(idx_i + 1, min(idx_i + WINDOW_SIZE, n_sub)):\n                j = ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = ops[idx_k]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # (A) Transitivity: Prevent cycles i->k->j->i\n                    # If i->k and k->j, then i->j must hold\n                    m.adaptive_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.adaptive_carlier.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_adaptive_carlier_cuts(model)",
                        "idea": "We introduce **Adaptive Carlier-Window Transitivity**, a hybrid strategy merging the precise bottleneck detection of Parent 1 with the efficient windowed cuts of Parent 2. We first identify **Critical Blocks**contiguous operation subsets on each machine that maximize the Carlier lower bound ($r_{min} + \\sum p + q_{min}$)rather than treating the entire machine sequence as the bottleneck. On the top competing blocks (within 90% of the global maximum LB), we apply **Sliding Window Transitivity** and **Metric Lifting** cuts. This focuses constraints specifically on the tightest temporal clusters where infeasibilities originate, strengthening the relaxation locally while maintaining global scalability."
                    },
                    "fitness": 21.57318116708071,
                    "solver_reports": [
                        {
                            "gap": 17.4837,
                            "total_time": 12.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 35163,
                            "explored_time": 12.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.6348,
                            "total_time": 12.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 35618,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 33382,
                            "explored_time": 10.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.8406,
                            "total_time": 12.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 45451,
                            "explored_time": 12.06,
                            "work_units": 10.01
                        },
                        {
                            "gap": 29.7072,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 31899,
                            "explored_time": 11.84,
                            "work_units": 10.0
                        },
                        {
                            "gap": 2.3011,
                            "total_time": 10.85,
                            "explored_nodes": 3709,
                            "simplex_iterations": 288150,
                            "explored_time": 10.84,
                            "work_units": 10.3
                        },
                        {
                            "gap": 27.8426,
                            "total_time": 11.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 49164,
                            "explored_time": 11.62,
                            "work_units": 10.01
                        },
                        {
                            "gap": 24.6852,
                            "total_time": 11.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 35149,
                            "explored_time": 11.83,
                            "work_units": 10.25
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "e9c2e46d-6837-48a3-8181-2d154ee60f56",
                        "191b37c8-0c43-4cb7-8602-4a89b5858fa0"
                    ]
                },
                {
                    "id": "2a7467fe-0653-4e95-b3aa-52ae065c5992",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_objective_lifting_cuts(m):\n        # 1. Compute Static Heads and Tails for Global Lower Bounds\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Standard Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            \n            # O(N^2) scan for max LB on this machine\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                current_sub = []\n                r_val = heads[sorted_ops[i]]\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n                \n        if not candidates: return\n        # Sort candidates by LB descending to find the bottleneck\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Target the most critical block\n        target_block = candidates[0]['ops']\n        global_lb_est = candidates[0]['lb']\n        \n        m.obj_lifting_cuts = pyo.ConstraintList()\n        m.obj_lifting_cuts.add(m.Cmax >= global_lb_est)\n    \n        # Helper to retrieve expression for \"u precedes v\"\n        def get_precedence_expr(u, v):\n            # Assumes u and v share a machine\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Generate Pairwise Objective Cuts\n        # Instead of lifting local Start times (Parents), we lift Cmax based on pair choice\n        pairs_data = []\n        n_blk = len(target_block)\n        for i in range(n_blk):\n            u = target_block[i]\n            for j in range(i + 1, n_blk):\n                v = target_block[j]\n                \n                # Calculate the minimal path cost through u and v in both orders\n                # If u -> v: Start(u) >= heads[u], End(v) <= Cmax - tails[v]\n                # Path: heads[u] + p[u] + p[v] + tails[v]\n                cost_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n                cost_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n                \n                # Metric: How tight is this conflict relative to the bottleneck?\n                metric = max(cost_uv, cost_vu)\n                \n                pairs_data.append({\n                    'u': u, 'v': v,\n                    'uv': cost_uv, 'vu': cost_vu,\n                    'metric': metric\n                })\n                \n        # Prioritize pairs that push the bound the most\n        pairs_data.sort(key=lambda x: x['metric'], reverse=True)\n        \n        CUT_LIMIT = 50\n        added = 0\n        \n        for data in pairs_data:\n            if added >= CUT_LIMIT: break\n            \n            # Filter: only add cuts if the pair is part of a \"tight\" path\n            if data['metric'] < 0.85 * global_lb_est:\n                continue\n                \n            u, v = data['u'], data['v']\n            L_uv = data['uv']\n            L_vu = data['vu']\n            \n            # Expression: 1 if u->v, 0 if v->u\n            y_expr = get_precedence_expr(u, v)\n            \n            # Constraint: Cmax must be >= the cost of the chosen direction\n            # Cmax >= L_uv * y + L_vu * (1 - y)\n            # This provides a convex combination lower bound on Cmax for fractional y\n            m.obj_lifting_cuts.add(\n                m.Cmax >= L_uv * y_expr + L_vu * (1 - y_expr)\n            )\n            added += 1\n    \n    add_objective_lifting_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_objective_lifting_cuts(m):\n    # 1. Compute Static Heads and Tails for Global Lower Bounds\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Standard Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        \n        # O(N^2) scan for max LB on this machine\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            current_sub = []\n            r_val = heads[sorted_ops[i]]\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n            \n    if not candidates: return\n    # Sort candidates by LB descending to find the bottleneck\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Target the most critical block\n    target_block = candidates[0]['ops']\n    global_lb_est = candidates[0]['lb']\n    \n    m.obj_lifting_cuts = pyo.ConstraintList()\n    m.obj_lifting_cuts.add(m.Cmax >= global_lb_est)\n\n    # Helper to retrieve expression for \"u precedes v\"\n    def get_precedence_expr(u, v):\n        # Assumes u and v share a machine\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Generate Pairwise Objective Cuts\n    # Instead of lifting local Start times (Parents), we lift Cmax based on pair choice\n    pairs_data = []\n    n_blk = len(target_block)\n    for i in range(n_blk):\n        u = target_block[i]\n        for j in range(i + 1, n_blk):\n            v = target_block[j]\n            \n            # Calculate the minimal path cost through u and v in both orders\n            # If u -> v: Start(u) >= heads[u], End(v) <= Cmax - tails[v]\n            # Path: heads[u] + p[u] + p[v] + tails[v]\n            cost_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n            cost_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n            \n            # Metric: How tight is this conflict relative to the bottleneck?\n            metric = max(cost_uv, cost_vu)\n            \n            pairs_data.append({\n                'u': u, 'v': v,\n                'uv': cost_uv, 'vu': cost_vu,\n                'metric': metric\n            })\n            \n    # Prioritize pairs that push the bound the most\n    pairs_data.sort(key=lambda x: x['metric'], reverse=True)\n    \n    CUT_LIMIT = 50\n    added = 0\n    \n    for data in pairs_data:\n        if added >= CUT_LIMIT: break\n        \n        # Filter: only add cuts if the pair is part of a \"tight\" path\n        if data['metric'] < 0.85 * global_lb_est:\n            continue\n            \n        u, v = data['u'], data['v']\n        L_uv = data['uv']\n        L_vu = data['vu']\n        \n        # Expression: 1 if u->v, 0 if v->u\n        y_expr = get_precedence_expr(u, v)\n        \n        # Constraint: Cmax must be >= the cost of the chosen direction\n        # Cmax >= L_uv * y + L_vu * (1 - y)\n        # This provides a convex combination lower bound on Cmax for fractional y\n        m.obj_lifting_cuts.add(\n            m.Cmax >= L_uv * y_expr + L_vu * (1 - y_expr)\n        )\n        added += 1\n\nadd_objective_lifting_cuts(model)",
                        "idea": "We introduce **Conflict-Aware Objective Lifting**, a complementary strategy that directly links the global makespan ($C_{max}$) to the binary precedence decisions in the critical block. Unlike Parents 1 and 2, which focus on feasibility (metric lifting of start times) or hull approximation (span variables), this approach quantifies the inevitable 'cost' of specific pairwise orderings ($L_{u \\to v} = r_u + p_u + p_v + q_v$) using static heads/tails. We scan the bottleneck for pairs with high conflict costs and impose cuts ($C_{max} \\ge L_{u \\to v} y_{uv} + L_{v \\to u} (1-y_{uv})$) that force the objective bound to rise immediately with fractional or suboptimal discrete choices. This tightens the LP relaxation's lower bound on the objective function itself, accelerating pruning by exposing the true penalties of local sequencing decisions."
                    },
                    "fitness": 14.202132054222849,
                    "solver_reports": [
                        {
                            "gap": 19.1398,
                            "total_time": 14.23,
                            "explored_nodes": 1,
                            "simplex_iterations": 29835,
                            "explored_time": 14.19,
                            "work_units": 10.05
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.43,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.39,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 9.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 13.36,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 13.34,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.3583,
                            "total_time": 10.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 32144,
                            "explored_time": 10.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.1765,
                            "total_time": 13.48,
                            "explored_nodes": 6543,
                            "simplex_iterations": 169587,
                            "explored_time": 13.46,
                            "work_units": 10.01
                        },
                        {
                            "gap": 41.0882,
                            "total_time": 18.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 28110,
                            "explored_time": 18.92,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.59,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "15672d5b-ca14-4b2d-aa51-eb221a77d9c6",
                        "1a191370-45de-41ef-b02e-cb4aa65d81c8"
                    ]
                },
                {
                    "id": "33db60c3-d72b-496a-8b0d-e9c5dc91eef0",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_inter_machine_delay_cuts(m):\n        # 1. Map operations to their job-predecessors (previous machine step)\n        prev_op = {}\n        for (j, k) in m.O:\n            if k > 0:\n                prev_op[(j, k)] = (j, k-1)\n    \n        # 2. Compute Static Timing (Heads/Tails) for Critical Block Detection\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 3. Identify Critical Blocks (reuse efficient Carlier logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k] \n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            p_vals = [m.p[op] for op in sorted_ops]\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Find sub-segment maximizing Carlier Bound\n            for u in range(n_ops):\n                current_p = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    current_p += p_vals[v]\n                    q_v = tails[sorted_ops[v]]\n                    lb = r_u + current_p + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # Target top blocks\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n        m.inter_machine_cuts = pyo.ConstraintList()\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_BUDGET = 200\n        cuts_added = 0\n        WINDOW = 5\n    \n        # 4. Apply Inter-Machine Delay Propagation Cuts\n        for target in targets:\n            ops = target['ops'] # Sorted by static release time\n            if len(ops) < 3: continue\n            \n            # Sliding window triplets (i -> k -> j)\n            for idx_i in range(len(ops)):\n                i = ops[idx_i]\n                # Only apply if 'i' has a predecessor to propagate delay from\n                if i not in prev_op: continue\n                p_prev = prev_op[i]\n                \n                limit_j = min(idx_i + WINDOW, len(ops))\n                for idx_j in range(idx_i + 1, limit_j):\n                    j = ops[idx_j]\n                    \n                    # Intermediate node k\n                    for idx_k in range(idx_i + 1, idx_j):\n                        k = ops[idx_k]\n                        \n                        # Logic: If sequence is i -> k -> j on this machine,\n                        # then j cannot start until i's *job predecessor* finishes,\n                        # plus processing of i and k.\n                        # S_j >= S_{prev(i)} + p_{prev(i)} + p_i + p_k\n                        \n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Cut: S_j + M*(2 - y_ik - y_kj) >= S_prev + p_prev + p_i + p_k\n                        lhs = m.S[j] + m.bigM * (2 - y_ik - y_kj)\n                        rhs = m.S[p_prev] + m.p[p_prev] + m.p[i] + m.p[k]\n                        \n                        m.inter_machine_cuts.add(lhs >= rhs)\n                        cuts_added += 1\n                        \n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n    \n    add_inter_machine_delay_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_inter_machine_delay_cuts(m):\n    # 1. Map operations to their job-predecessors (previous machine step)\n    prev_op = {}\n    for (j, k) in m.O:\n        if k > 0:\n            prev_op[(j, k)] = (j, k-1)\n\n    # 2. Compute Static Timing (Heads/Tails) for Critical Block Detection\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 3. Identify Critical Blocks (reuse efficient Carlier logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k] \n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        p_vals = [m.p[op] for op in sorted_ops]\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Find sub-segment maximizing Carlier Bound\n        for u in range(n_ops):\n            current_p = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                current_p += p_vals[v]\n                q_v = tails[sorted_ops[v]]\n                lb = r_u + current_p + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # Target top blocks\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n\n    m.inter_machine_cuts = pyo.ConstraintList()\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_BUDGET = 200\n    cuts_added = 0\n    WINDOW = 5\n\n    # 4. Apply Inter-Machine Delay Propagation Cuts\n    for target in targets:\n        ops = target['ops'] # Sorted by static release time\n        if len(ops) < 3: continue\n        \n        # Sliding window triplets (i -> k -> j)\n        for idx_i in range(len(ops)):\n            i = ops[idx_i]\n            # Only apply if 'i' has a predecessor to propagate delay from\n            if i not in prev_op: continue\n            p_prev = prev_op[i]\n            \n            limit_j = min(idx_i + WINDOW, len(ops))\n            for idx_j in range(idx_i + 1, limit_j):\n                j = ops[idx_j]\n                \n                # Intermediate node k\n                for idx_k in range(idx_i + 1, idx_j):\n                    k = ops[idx_k]\n                    \n                    # Logic: If sequence is i -> k -> j on this machine,\n                    # then j cannot start until i's *job predecessor* finishes,\n                    # plus processing of i and k.\n                    # S_j >= S_{prev(i)} + p_{prev(i)} + p_i + p_k\n                    \n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # Cut: S_j + M*(2 - y_ik - y_kj) >= S_prev + p_prev + p_i + p_k\n                    lhs = m.S[j] + m.bigM * (2 - y_ik - y_kj)\n                    rhs = m.S[p_prev] + m.p[p_prev] + m.p[i] + m.p[k]\n                    \n                    m.inter_machine_cuts.add(lhs >= rhs)\n                    cuts_added += 1\n                    \n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n        if cuts_added >= CUT_BUDGET: break\n\nadd_inter_machine_delay_cuts(model)",
                        "idea": "We introduce **Inter-Machine Delay Propagation**, a strategy that couples machine bottlenecks with job precedence delays. Unlike the parents, which analyze machines in isolation (using static release dates or intra-machine transitivity), this cut dynamically links the start time of an operation ($S_j$) to the *completion time* of a predecessor's previous job step ($C_{prev(i)}$). Specifically, for any triplet $i \\to k \\to j$ on a bottleneck, we enforce $S_j \\ge S_{prev(i)} + p_{prev(i)} + p_i + p_k$. This propagates accumulated delays from machine $M-1$ onto machine $M$, tightening the relaxation by strictly bounding sequences that ignore upstream lateness."
                    },
                    "fitness": 9.906866066464923,
                    "solver_reports": [
                        {
                            "total_time": 12.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 56098,
                            "explored_time": 12.04,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 17.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 67678,
                            "explored_time": 17.64,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 18.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 71222,
                            "explored_time": 18.53,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.17,
                            "explored_nodes": 2420,
                            "simplex_iterations": 366730,
                            "explored_time": 9.16,
                            "work_units": 10.03
                        },
                        {
                            "total_time": 18.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 69788,
                            "explored_time": 18.15,
                            "work_units": 10.0
                        },
                        {
                            "gap": 33.2352,
                            "total_time": 9.76,
                            "explored_nodes": 1483,
                            "simplex_iterations": 222770,
                            "explored_time": 9.75,
                            "work_units": 10.19
                        },
                        {
                            "total_time": 10.35,
                            "explored_nodes": 1135,
                            "simplex_iterations": 163778,
                            "explored_time": 10.33,
                            "work_units": 10.03
                        },
                        {
                            "total_time": 14.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 63283,
                            "explored_time": 14.77,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "dd001188-dbd3-4350-9c35-5cf076fe0fd4"
                    ]
                },
                {
                    "id": "1ace702a-dad0-4505-967a-0ccf3ba7e7f9",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_anchor_lift(m):\n        # 1. Compute Heads and Tails (Timing Logic from Parent 1)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier Logic from Parent 1)\n        # We scan for the single bottleneck block maximizing the Lower Bound (LB)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            \n            # O(N^2) scan for exact max LB on this machine\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                r_val = heads[sorted_ops[i]]\n                current_sub = []\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n        # Prioritize the tightest bottleneck\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        best_candidate = candidates[0]\n        \n        block = best_candidate['ops']\n        carlier_lb = best_candidate['lb']\n        \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        # 3. Global Bound (Synergy): Lift Cmax using the Carlier LB\n        m.hybrid_cuts.add(m.Cmax >= carlier_lb)\n        \n        # Helper for handling y[u,v] symmetry\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Twin-Anchor Mass Cuts (Structural Element from Parent 2)\n        # Apply 'Mass' logic to the identified Carlier block to squeeze Start Times and Cmax\n        r_min = min(heads[op] for op in block)\n        q_min = min(tails[op] for op in block)\n        \n        for u in block:\n            succ_mass = 0\n            pred_mass = 0\n            for v in block:\n                if u == v: continue\n                y_uv = get_y(u, v) # 1 if u -> v\n                y_vu = get_y(v, u) # 1 if v -> u\n                succ_mass += m.p[v] * y_uv\n                pred_mass += m.p[v] * y_vu\n            \n            # Forward Anchor: Push S[u] right by predecessors\n            m.hybrid_cuts.add(m.S[u] >= r_min + pred_mass)\n            \n            # Backward Anchor: Push Cmax by successors (Knapsack-style capacity)\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_mass + q_min)\n    \n        # 5. Overlap-Conditioned Metric Lifting (Conditional Element from Parent 1)\n        # Detect 'ambiguous' triplets where windows overlap and enforce metric lifting\n        # This tightens the binary variables used in the Mass cuts above\n        cut_count = 0\n        MAX_LIFTS = 50\n        \n        for i in range(len(block)):\n            u = block[i]\n            s_u, e_u = heads[u], carlier_lb - tails[u]\n            \n            for j in range(len(block)):\n                if i == j: continue\n                v = block[j]\n                s_v, e_v = heads[v], carlier_lb - tails[v]\n                \n                # Check for significant overlap between u and v\n                if max(s_u, s_v) < min(e_u, e_v):\n                    for k in range(len(block)):\n                        if k == i or k == j: continue\n                        w = block[k]\n                        s_w, e_w = heads[w], carlier_lb - tails[w]\n                        \n                        # Triple Overlap: Dense ambiguity zone\n                        if max(s_u, s_v, s_w) < min(e_u, e_v, e_w):\n                            y_uv = get_y(u, v)\n                            y_uw = get_y(u, w)\n                            y_wv = get_y(w, v)\n                            \n                            # Triangle Transitivity\n                            m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n                            \n                            # Metric Lifting: S[v] accounts for w if u->w->v\n                            m.hybrid_cuts.add(\n                                m.S[v] >= m.S[u] + m.p[u] + \n                                m.p[w] * (y_uw + y_wv - 1) - \n                                m.bigM * (1 - y_uv)\n                            )\n                            cut_count += 2\n                            if cut_count >= MAX_LIFTS: break\n            if cut_count >= MAX_LIFTS: break\n    \n    add_hybrid_anchor_lift(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_anchor_lift(m):\n    # 1. Compute Heads and Tails (Timing Logic from Parent 1)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier Logic from Parent 1)\n    # We scan for the single bottleneck block maximizing the Lower Bound (LB)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        \n        # O(N^2) scan for exact max LB on this machine\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            r_val = heads[sorted_ops[i]]\n            current_sub = []\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n    # Prioritize the tightest bottleneck\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    best_candidate = candidates[0]\n    \n    block = best_candidate['ops']\n    carlier_lb = best_candidate['lb']\n    \n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    # 3. Global Bound (Synergy): Lift Cmax using the Carlier LB\n    m.hybrid_cuts.add(m.Cmax >= carlier_lb)\n    \n    # Helper for handling y[u,v] symmetry\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Twin-Anchor Mass Cuts (Structural Element from Parent 2)\n    # Apply 'Mass' logic to the identified Carlier block to squeeze Start Times and Cmax\n    r_min = min(heads[op] for op in block)\n    q_min = min(tails[op] for op in block)\n    \n    for u in block:\n        succ_mass = 0\n        pred_mass = 0\n        for v in block:\n            if u == v: continue\n            y_uv = get_y(u, v) # 1 if u -> v\n            y_vu = get_y(v, u) # 1 if v -> u\n            succ_mass += m.p[v] * y_uv\n            pred_mass += m.p[v] * y_vu\n        \n        # Forward Anchor: Push S[u] right by predecessors\n        m.hybrid_cuts.add(m.S[u] >= r_min + pred_mass)\n        \n        # Backward Anchor: Push Cmax by successors (Knapsack-style capacity)\n        m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_mass + q_min)\n\n    # 5. Overlap-Conditioned Metric Lifting (Conditional Element from Parent 1)\n    # Detect 'ambiguous' triplets where windows overlap and enforce metric lifting\n    # This tightens the binary variables used in the Mass cuts above\n    cut_count = 0\n    MAX_LIFTS = 50\n    \n    for i in range(len(block)):\n        u = block[i]\n        s_u, e_u = heads[u], carlier_lb - tails[u]\n        \n        for j in range(len(block)):\n            if i == j: continue\n            v = block[j]\n            s_v, e_v = heads[v], carlier_lb - tails[v]\n            \n            # Check for significant overlap between u and v\n            if max(s_u, s_v) < min(e_u, e_v):\n                for k in range(len(block)):\n                    if k == i or k == j: continue\n                    w = block[k]\n                    s_w, e_w = heads[w], carlier_lb - tails[w]\n                    \n                    # Triple Overlap: Dense ambiguity zone\n                    if max(s_u, s_v, s_w) < min(e_u, e_v, e_w):\n                        y_uv = get_y(u, v)\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        \n                        # Triangle Transitivity\n                        m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n                        \n                        # Metric Lifting: S[v] accounts for w if u->w->v\n                        m.hybrid_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[w] * (y_uw + y_wv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        cut_count += 2\n                        if cut_count >= MAX_LIFTS: break\n        if cut_count >= MAX_LIFTS: break\n\nadd_hybrid_anchor_lift(model)",
                        "idea": "We construct 'Carlier-Regulated Twin-Anchor Cuts with Metric Lifting'. This strategy identifies the single most critical bottleneck block using Parent 1's rigorous Carlier LB scan. On this critical subset, we impose Parent 2's Twin-Anchor cuts, which bound both operation start times ($S_u$) and the global makespan ($C_{max}$) using the aggregated 'mass' of predecessor and successor processing times. To reinforce these aggregations, we detect 'ambiguous' triplets within the block (where Carlier-derived time windows strictly overlap, Parent 1 logic) and inject local Metric Lifting cuts. This hybrid strengthens the global capacity bounds of Parent 2 by resolving local sequencing ambiguities identified by Parent 1."
                    },
                    "fitness": 17.883337329775134,
                    "solver_reports": [
                        {
                            "total_time": 8.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 24709,
                            "explored_time": 8.25,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 21402,
                            "explored_time": 9.05,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 9.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 22623,
                            "explored_time": 9.09,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.2271,
                            "total_time": 11.96,
                            "explored_nodes": 53,
                            "simplex_iterations": 48251,
                            "explored_time": 11.95,
                            "work_units": 10.3
                        },
                        {
                            "total_time": 10.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 19599,
                            "explored_time": 10.18,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.201,
                            "total_time": 11.3,
                            "explored_nodes": 143,
                            "simplex_iterations": 71569,
                            "explored_time": 11.29,
                            "work_units": 13.16
                        },
                        {
                            "gap": 39.7698,
                            "total_time": 11.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 37553,
                            "explored_time": 11.79,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.43,
                            "explored_nodes": 1,
                            "simplex_iterations": 24072,
                            "explored_time": 10.37,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "15672d5b-ca14-4b2d-aa51-eb221a77d9c6",
                        "8ec448b0-d163-4217-ad6e-b98a040191bd"
                    ]
                },
                {
                    "id": "bf5cd65f-b6da-4332-bd61-2a840b3a7927",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_symmetric_overlap_mass_cuts(m):\n        \"\"\"\n        Hybrid Strategy: Symmetric Mass & Overlap-Metric Lifting\n        Combines Parent 1's Symmetric Mass Flow logic with Parent 2's Overlap-Conditioned Metric Lifting.\n        1. Identifies the critical machine block and sets a global Carlier lower bound on Cmax.\n        2. Applies Symmetric Mass Cuts (Forward & Backward) to all ops in the block to tighten the convex hull.\n        3. Scans for 'ambiguous' triplets (overlapping time windows) and enforces Transitivity and Metric Lifting\n           to resolve fractional ordering variables in the dense schedule core.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # 1. Timing Precomputation (Heads & Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            r_best = 0\n            q_best = 0\n            \n            # O(N^2) scan for max single-machine lower bound\n            for i in range(n):\n                p_sum = 0\n                current_r = heads[sorted_ops[i]]\n                min_q = float('inf')\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    \n                    lb = current_r + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n                        r_best = current_r\n                        q_best = min_q\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, 'ops': best_sub, 'r': r_best, 'q': q_best\n                })\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Best bottleneck parameters\n        global_lb = candidates[0]['lb']\n        block = candidates[0]['ops']\n        r_block = candidates[0]['r']\n        q_block = candidates[0]['q']\n        \n        m.hybrid_cuts = pyo.ConstraintList()\n        # Global Cut\n        m.hybrid_cuts.add(m.Cmax >= global_lb)\n    \n        # 3. Helpers and Time Windows\n        def get_y(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # Windows defined by global lower bound: [Head, LB - Tail]\n        windows = {}\n        for op in block:\n            windows[op] = (heads[op], global_lb - tails[op])\n    \n        CUT_BUDGET = 200\n        added = 0\n        \n        # 4. Symmetric Mass Flow Cuts (Parent 1)\n        # Apply to all ops in the critical block to anchor S and Cmax\n        for u in block:\n            lhs_fwd = 0\n            lhs_bwd = 0\n            for v in block:\n                if u == v: continue\n                y_vu = get_y(v, u)\n                y_uv = get_y(u, v)\n                # Sum processing times of all dynamic predecessors/successors\n                lhs_fwd += m.p[v] * y_vu\n                lhs_bwd += m.p[v] * y_uv \n            \n            # Forward Mass: S_u >= r_min + sum(p_v if v->u)\n            m.hybrid_cuts.add(m.S[u] >= r_block + lhs_fwd)\n            # Backward Mass: Cmax >= S_u + p_u + sum(p_v if u->v) + q_min\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + lhs_bwd + q_block)\n            added += 2\n    \n        # 5. Overlap-Conditioned Triplet Cuts (Parent 2)\n        # Identify triplets with overlapping windows -> Ambiguous ordering\n        triplets = []\n        for i in range(len(block)):\n            u = block[i]\n            for j in range(len(block)):\n                if i == j: continue\n                v = block[j]\n                for k in range(len(block)):\n                    if k == i or k == j: continue\n                    w = block[k]\n                    \n                    # Check intersection of windows\n                    s_common = max(windows[u][0], windows[v][0], windows[w][0])\n                    e_common = min(windows[u][1], windows[v][1], windows[w][1])\n                    \n                    if s_common < e_common:\n                        triplets.append((u, w, v)) # Ordered u -> w -> v for metric lifting check\n    \n        # Prioritize triplets by intermediate duration (maximal lifting impact)\n        triplets.sort(key=lambda x: m.p[x[1]], reverse=True)\n        \n        for (u, w, v) in triplets:\n            if added >= CUT_BUDGET: break\n            \n            y_uw = get_y(u, w)\n            y_wv = get_y(w, v)\n            y_uv = get_y(u, v)\n            \n            # A. Triangle Transitivity: y_uw + y_wv - 1 <= y_uv\n            m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n            added += 1\n            if added >= CUT_BUDGET: break\n    \n            # B. Metric Lifting: S_v >= S_u + p_u + p_w(y_uw + y_wv - 1)\n            # Only valid if y_uv=1, else relaxed by BigM\n            m.hybrid_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + m.p[w] * (y_uw + y_wv - 1) - m.bigM * (1 - y_uv)\n            )\n            added += 1\n    \n    add_symmetric_overlap_mass_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_symmetric_overlap_mass_cuts(m):\n    \"\"\"\n    Hybrid Strategy: Symmetric Mass & Overlap-Metric Lifting\n    Combines Parent 1's Symmetric Mass Flow logic with Parent 2's Overlap-Conditioned Metric Lifting.\n    1. Identifies the critical machine block and sets a global Carlier lower bound on Cmax.\n    2. Applies Symmetric Mass Cuts (Forward & Backward) to all ops in the block to tighten the convex hull.\n    3. Scans for 'ambiguous' triplets (overlapping time windows) and enforces Transitivity and Metric Lifting\n       to resolve fractional ordering variables in the dense schedule core.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # 1. Timing Precomputation (Heads & Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        r_best = 0\n        q_best = 0\n        \n        # O(N^2) scan for max single-machine lower bound\n        for i in range(n):\n            p_sum = 0\n            current_r = heads[sorted_ops[i]]\n            min_q = float('inf')\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                \n                lb = current_r + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n                    r_best = current_r\n                    q_best = min_q\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, 'ops': best_sub, 'r': r_best, 'q': q_best\n            })\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Best bottleneck parameters\n    global_lb = candidates[0]['lb']\n    block = candidates[0]['ops']\n    r_block = candidates[0]['r']\n    q_block = candidates[0]['q']\n    \n    m.hybrid_cuts = pyo.ConstraintList()\n    # Global Cut\n    m.hybrid_cuts.add(m.Cmax >= global_lb)\n\n    # 3. Helpers and Time Windows\n    def get_y(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # Windows defined by global lower bound: [Head, LB - Tail]\n    windows = {}\n    for op in block:\n        windows[op] = (heads[op], global_lb - tails[op])\n\n    CUT_BUDGET = 200\n    added = 0\n    \n    # 4. Symmetric Mass Flow Cuts (Parent 1)\n    # Apply to all ops in the critical block to anchor S and Cmax\n    for u in block:\n        lhs_fwd = 0\n        lhs_bwd = 0\n        for v in block:\n            if u == v: continue\n            y_vu = get_y(v, u)\n            y_uv = get_y(u, v)\n            # Sum processing times of all dynamic predecessors/successors\n            lhs_fwd += m.p[v] * y_vu\n            lhs_bwd += m.p[v] * y_uv \n        \n        # Forward Mass: S_u >= r_min + sum(p_v if v->u)\n        m.hybrid_cuts.add(m.S[u] >= r_block + lhs_fwd)\n        # Backward Mass: Cmax >= S_u + p_u + sum(p_v if u->v) + q_min\n        m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + lhs_bwd + q_block)\n        added += 2\n\n    # 5. Overlap-Conditioned Triplet Cuts (Parent 2)\n    # Identify triplets with overlapping windows -> Ambiguous ordering\n    triplets = []\n    for i in range(len(block)):\n        u = block[i]\n        for j in range(len(block)):\n            if i == j: continue\n            v = block[j]\n            for k in range(len(block)):\n                if k == i or k == j: continue\n                w = block[k]\n                \n                # Check intersection of windows\n                s_common = max(windows[u][0], windows[v][0], windows[w][0])\n                e_common = min(windows[u][1], windows[v][1], windows[w][1])\n                \n                if s_common < e_common:\n                    triplets.append((u, w, v)) # Ordered u -> w -> v for metric lifting check\n\n    # Prioritize triplets by intermediate duration (maximal lifting impact)\n    triplets.sort(key=lambda x: m.p[x[1]], reverse=True)\n    \n    for (u, w, v) in triplets:\n        if added >= CUT_BUDGET: break\n        \n        y_uw = get_y(u, w)\n        y_wv = get_y(w, v)\n        y_uv = get_y(u, v)\n        \n        # A. Triangle Transitivity: y_uw + y_wv - 1 <= y_uv\n        m.hybrid_cuts.add(y_uw + y_wv - y_uv <= 1)\n        added += 1\n        if added >= CUT_BUDGET: break\n\n        # B. Metric Lifting: S_v >= S_u + p_u + p_w(y_uw + y_wv - 1)\n        # Only valid if y_uv=1, else relaxed by BigM\n        m.hybrid_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + m.p[w] * (y_uw + y_wv - 1) - m.bigM * (1 - y_uv)\n        )\n        added += 1\n\nadd_symmetric_overlap_mass_cuts(model)",
                        "idea": "We introduce **Symmetric Mass & Overlap-Metric Lifting**, a hybrid strategy that creates a rigorous envelope for the critical path. First, it enforces a global **Carlier Lower Bound** on the makespan. Second, it applies **Symmetric Mass Flow Cuts** (from Parent 1) to every operation in the critical block, anchoring start times and the makespan to the block's release and tail times via dynamic predecessor sums ($S_u \\ge r + \\sum p_v y_{vu}$). Third, it refines this using **Overlap-Conditioned Triplet Cuts** (from Parent 2): for triplets with overlapping time windows (ambiguous ordering), it enforces triangle transitivity and adds **Metric Lifting** constraints ($S_v \\ge S_u + p_u + p_w(y_{uw}+y_{wv}-1)$) to tightly couple binary patterns with continuous variables in the densest part of the schedule."
                    },
                    "fitness": 16.695428288655602,
                    "solver_reports": [
                        {
                            "total_time": 11.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 23702,
                            "explored_time": 11.21,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 25897,
                            "explored_time": 9.77,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 23181,
                            "explored_time": 10.15,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.4071,
                            "total_time": 10.56,
                            "explored_nodes": 1,
                            "simplex_iterations": 33319,
                            "explored_time": 10.53,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 20826,
                            "explored_time": 9.49,
                            "work_units": 10.0
                        },
                        {
                            "gap": 22.4969,
                            "total_time": 12.18,
                            "explored_nodes": 171,
                            "simplex_iterations": 80942,
                            "explored_time": 12.15,
                            "work_units": 12.42
                        },
                        {
                            "gap": 42.3677,
                            "total_time": 10.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 30601,
                            "explored_time": 10.68,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 27516,
                            "explored_time": 9.75,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "eb996d32-feb6-444d-990a-d39823c6e0f0",
                        "15672d5b-ca14-4b2d-aa51-eb221a77d9c6"
                    ]
                },
                {
                    "id": "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_dynamic_horizon_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Machine-wise)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        # Identify bottleneck blocks maximizing r_min + sum(p) + q_min\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads) for Carlier logic\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Scan for the tightest sub-segment on this machine\n            best_lb = -1\n            best_sub = []\n            \n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Bounds and Filtering\n        # Sort candidates by LB tightness\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.dynamic_carlier_cuts = pyo.ConstraintList()\n        m.dynamic_carlier_cuts.add(m.Cmax >= global_max)\n    \n        # Filter: Keep blocks within 90% of global max (Parent 1 Strategy)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n        # 4. Dynamic Window Cuts (Hybrid Logic)\n        # Combine Multi-block targeting (P1) with Overlap-based Windowing (P2)\n        CUT_BUDGET = 200\n        cuts_added = 0\n        \n        def get_y(u, v):\n            # Determine correct order for the set Pair\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # Iterate through the most critical blocks\n        for target in targets[:3]:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            # Ops are already sorted by release time (heads)\n            for i in range(n_sub):\n                op_i = ops[i]\n                \n                # Dynamic Horizon: derived from Parent 2's overlap logic.\n                # We iterate j only as long as j's start is before i's necessary completion.\n                # This creates a data-driven window size based on slack.\n                horizon_limit = global_max - tails[op_i]\n                \n                for j in range(i + 1, n_sub):\n                    op_j = ops[j]\n                    \n                    # Dynamic Break: If j starts too late to overlap i, stop scanning.\n                    # (Since list is sorted by heads, all subsequent j will also fail)\n                    if heads[op_j] >= horizon_limit:\n                        break\n                    \n                    # Check for intermediate k inside this dynamic window\n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refinement: k must also overlap j significantly to form a clique\n                        if heads[op_j] >= global_max - tails[op_k]:\n                            continue\n    \n                        # Apply Cuts on Triplets (i, k, j)\n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # (A) Triangle Transitivity: Prevent cycles i->k->j->i\n                        m.dynamic_carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.dynamic_carlier_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_dynamic_horizon_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_dynamic_horizon_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Machine-wise)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    # Identify bottleneck blocks maximizing r_min + sum(p) + q_min\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads) for Carlier logic\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Scan for the tightest sub-segment on this machine\n        best_lb = -1\n        best_sub = []\n        \n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Bounds and Filtering\n    # Sort candidates by LB tightness\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.dynamic_carlier_cuts = pyo.ConstraintList()\n    m.dynamic_carlier_cuts.add(m.Cmax >= global_max)\n\n    # Filter: Keep blocks within 90% of global max (Parent 1 Strategy)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n\n    # 4. Dynamic Window Cuts (Hybrid Logic)\n    # Combine Multi-block targeting (P1) with Overlap-based Windowing (P2)\n    CUT_BUDGET = 200\n    cuts_added = 0\n    \n    def get_y(u, v):\n        # Determine correct order for the set Pair\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # Iterate through the most critical blocks\n    for target in targets[:3]:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        # Ops are already sorted by release time (heads)\n        for i in range(n_sub):\n            op_i = ops[i]\n            \n            # Dynamic Horizon: derived from Parent 2's overlap logic.\n            # We iterate j only as long as j's start is before i's necessary completion.\n            # This creates a data-driven window size based on slack.\n            horizon_limit = global_max - tails[op_i]\n            \n            for j in range(i + 1, n_sub):\n                op_j = ops[j]\n                \n                # Dynamic Break: If j starts too late to overlap i, stop scanning.\n                # (Since list is sorted by heads, all subsequent j will also fail)\n                if heads[op_j] >= horizon_limit:\n                    break\n                \n                # Check for intermediate k inside this dynamic window\n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refinement: k must also overlap j significantly to form a clique\n                    if heads[op_j] >= global_max - tails[op_k]:\n                        continue\n\n                    # Apply Cuts on Triplets (i, k, j)\n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # (A) Triangle Transitivity: Prevent cycles i->k->j->i\n                    m.dynamic_carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.dynamic_carlier_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_dynamic_horizon_carlier_cuts(model)",
                        "idea": "We introduce **Dynamic Horizon Transitivity**, a hybrid strategy that identifies multiple Carlier-critical blocks (adopting Parent 1's multi-block focus) but replaces fixed-size sliding windows with **LB-derived overlap horizons** (from Parent 2). By filtering triplets $(i, k, j)$ where the release of $j$ falls strictly before the latest-start-time of $i$ (calculated via the global Carlier LB), we dynamically size the constraint window to the local congestion density. This applies metric lifting and transitivity cuts exactly where the ordering is ambiguous in the relaxation, avoiding overhead on clearly separated operations."
                    },
                    "fitness": 21.904413757155574,
                    "solver_reports": [
                        {
                            "gap": 27.6881,
                            "total_time": 13.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 32594,
                            "explored_time": 13.65,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 11.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 38442,
                            "explored_time": 11.2,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 32907,
                            "explored_time": 10.69,
                            "work_units": 10.0
                        },
                        {
                            "gap": 12.3741,
                            "total_time": 11.0,
                            "explored_nodes": 87,
                            "simplex_iterations": 50655,
                            "explored_time": 10.98,
                            "work_units": 10.21
                        },
                        {
                            "total_time": 11.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 34085,
                            "explored_time": 11.82,
                            "work_units": 10.0
                        },
                        {
                            "gap": 4.0671,
                            "total_time": 12.07,
                            "explored_nodes": 3068,
                            "simplex_iterations": 154879,
                            "explored_time": 12.07,
                            "work_units": 10.14
                        },
                        {
                            "gap": 28.5714,
                            "total_time": 12.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 47274,
                            "explored_time": 12.06,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.5145,
                            "total_time": 14.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 38295,
                            "explored_time": 14.39,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "15672d5b-ca14-4b2d-aa51-eb221a77d9c6"
                    ]
                },
                {
                    "id": "8458d8bf-85a4-44b2-86e9-e78257074e86",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_symmetric_carlier_metric_cuts(m):\n        import pyomo.environ as pyo\n        \n        # 1. Precompute Timing (Heads/Tails)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Block (Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release times\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Find sub-segment maximizing LB = r_min + sum(p) + q_min\n            best_lb = -1\n            best_sub = []\n            best_q = 0\n            \n            for i in range(n):\n                p_sum = 0\n                curr_q_min = float('inf')\n                r_val = heads[sorted_ops[i]]\n                current_sub = []\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    current_sub.append(op)\n                    p_sum += m.p[op]\n                    if tails[op] < curr_q_min: curr_q_min = tails[op]\n                    \n                    lb = r_val + p_sum + curr_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n                        best_q = curr_q_min\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_sub, 'q_min': best_q})\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Apply Global Cut\n        carlier_lb = candidates[0]['lb']\n        m.sym_carlier_cuts = pyo.ConstraintList()\n        m.sym_carlier_cuts.add(m.Cmax >= carlier_lb)\n    \n        # 3. Hybrid Cuts: Backward Mass (P2) + Metric Lifting (P1)\n        target = candidates[0]\n        block = target['ops']\n        q_min_block = target['q_min']\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_LIMIT = 200\n        count = 0\n        \n        # A. Backward Mass Flow Cuts (from Parent 2)\n        # Links Cmax to S_u + p_u via the sum of dynamic successors in the block\n        # Effective for bounding the 'end' of the schedule relative to internal ops\n        for u in block:\n            rhs = m.S[u] + m.p[u] + q_min_block\n            succ_sum = 0\n            for v in block:\n                if u == v: continue\n                succ_sum += m.p[v] * get_y(u, v)\n            m.sym_carlier_cuts.add(m.Cmax >= rhs + succ_sum)\n            count += 1\n            if count >= CUT_LIMIT: break\n            \n        if count < CUT_LIMIT:\n            # B. Overlap-Conditioned Metric Lifting (from Parent 1)\n            # Resolves ambiguity in 'dense' triplets (overlapping time windows)\n            for i in range(len(block)):\n                u = block[i]\n                for j in range(len(block)):\n                    if i == j: continue\n                    v = block[j]\n                    \n                    # Define windows [Start, End] based on Carlier LB\n                    s_u, e_u = heads[u], carlier_lb - tails[u]\n                    s_v, e_v = heads[v], carlier_lb - tails[v]\n                    \n                    for k in range(len(block)):\n                        if k == i or k == j: continue\n                        w = block[k]\n                        \n                        s_w, e_w = heads[w], carlier_lb - tails[w]\n                        \n                        # If windows of u, v, w overlap significantly, ordering is loose\n                        if max(s_u, s_v, s_w) < min(e_u, e_v, e_w):\n                            y_uv = get_y(u, v)\n                            y_uw = get_y(u, w)\n                            y_wv = get_y(w, v)\n                            \n                            # Metric Lifting: S_v >= S_u + p_u + p_w (if u->w->v)\n                            m.sym_carlier_cuts.add(\n                                m.S[v] >= m.S[u] + m.p[u] + \n                                m.p[w] * (y_uw + y_wv - 1) - \n                                m.bigM * (1 - y_uv)\n                            )\n                            \n                            # Triangle Transitivity\n                            m.sym_carlier_cuts.add(y_uw + y_wv - y_uv <= 1)\n                            \n                            count += 2\n                            if count >= CUT_LIMIT: return\n    \n    add_symmetric_carlier_metric_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_symmetric_carlier_metric_cuts(m):\n    import pyomo.environ as pyo\n    \n    # 1. Precompute Timing (Heads/Tails)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Block (Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release times\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Find sub-segment maximizing LB = r_min + sum(p) + q_min\n        best_lb = -1\n        best_sub = []\n        best_q = 0\n        \n        for i in range(n):\n            p_sum = 0\n            curr_q_min = float('inf')\n            r_val = heads[sorted_ops[i]]\n            current_sub = []\n            for j in range(i, n):\n                op = sorted_ops[j]\n                current_sub.append(op)\n                p_sum += m.p[op]\n                if tails[op] < curr_q_min: curr_q_min = tails[op]\n                \n                lb = r_val + p_sum + curr_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n                    best_q = curr_q_min\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_sub, 'q_min': best_q})\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Apply Global Cut\n    carlier_lb = candidates[0]['lb']\n    m.sym_carlier_cuts = pyo.ConstraintList()\n    m.sym_carlier_cuts.add(m.Cmax >= carlier_lb)\n\n    # 3. Hybrid Cuts: Backward Mass (P2) + Metric Lifting (P1)\n    target = candidates[0]\n    block = target['ops']\n    q_min_block = target['q_min']\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_LIMIT = 200\n    count = 0\n    \n    # A. Backward Mass Flow Cuts (from Parent 2)\n    # Links Cmax to S_u + p_u via the sum of dynamic successors in the block\n    # Effective for bounding the 'end' of the schedule relative to internal ops\n    for u in block:\n        rhs = m.S[u] + m.p[u] + q_min_block\n        succ_sum = 0\n        for v in block:\n            if u == v: continue\n            succ_sum += m.p[v] * get_y(u, v)\n        m.sym_carlier_cuts.add(m.Cmax >= rhs + succ_sum)\n        count += 1\n        if count >= CUT_LIMIT: break\n        \n    if count < CUT_LIMIT:\n        # B. Overlap-Conditioned Metric Lifting (from Parent 1)\n        # Resolves ambiguity in 'dense' triplets (overlapping time windows)\n        for i in range(len(block)):\n            u = block[i]\n            for j in range(len(block)):\n                if i == j: continue\n                v = block[j]\n                \n                # Define windows [Start, End] based on Carlier LB\n                s_u, e_u = heads[u], carlier_lb - tails[u]\n                s_v, e_v = heads[v], carlier_lb - tails[v]\n                \n                for k in range(len(block)):\n                    if k == i or k == j: continue\n                    w = block[k]\n                    \n                    s_w, e_w = heads[w], carlier_lb - tails[w]\n                    \n                    # If windows of u, v, w overlap significantly, ordering is loose\n                    if max(s_u, s_v, s_w) < min(e_u, e_v, e_w):\n                        y_uv = get_y(u, v)\n                        y_uw = get_y(u, w)\n                        y_wv = get_y(w, v)\n                        \n                        # Metric Lifting: S_v >= S_u + p_u + p_w (if u->w->v)\n                        m.sym_carlier_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + \n                            m.p[w] * (y_uw + y_wv - 1) - \n                            m.bigM * (1 - y_uv)\n                        )\n                        \n                        # Triangle Transitivity\n                        m.sym_carlier_cuts.add(y_uw + y_wv - y_uv <= 1)\n                        \n                        count += 2\n                        if count >= CUT_LIMIT: return\n\nadd_symmetric_carlier_metric_cuts(model)",
                        "idea": "We combine Parent 2's **Backward Mass Flow** logic with Parent 1's **Overlap-Conditioned Metric Lifting** to tighten the critical path from both global and local perspectives. After identifying the bottleneck block via Carlier bounds, we first apply Backward Mass cuts ($C_{max} \\ge S_u + p_u + \\sum p_v y_{uv} + q_{min}$), which tightly bind the objective to the dynamic position of every operation in the block. Simultaneously, we use Parent 1's overlap detection to find 'ambiguous' triplets and enforce Metric Lifting ($S_v \\ge S_u + p_u + p_w(y_{uw} + y_{wv} - 1)$), resolving internal sequencing slack that the global mass cuts might miss. This creates a pincer effect: Mass Flow constrains the envelope, and Metric Lifting solidifies the structure within."
                    },
                    "fitness": 18.176616200198158,
                    "solver_reports": [
                        {
                            "total_time": 9.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 37292,
                            "explored_time": 9.1,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.1082,
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 38358,
                            "explored_time": 12.26,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 34482,
                            "explored_time": 10.4,
                            "work_units": 10.0
                        },
                        {
                            "gap": 25.8361,
                            "total_time": 12.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 44320,
                            "explored_time": 12.97,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 33438,
                            "explored_time": 9.19,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.0765,
                            "total_time": 10.17,
                            "explored_nodes": 171,
                            "simplex_iterations": 72255,
                            "explored_time": 10.16,
                            "work_units": 11.51
                        },
                        {
                            "gap": 38.5719,
                            "total_time": 11.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 37090,
                            "explored_time": 11.62,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 35528,
                            "explored_time": 9.49,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "15672d5b-ca14-4b2d-aa51-eb221a77d9c6",
                        "eb996d32-feb6-444d-990a-d39823c6e0f0"
                    ]
                },
                {
                    "id": "8e0a138b-7a0c-46cc-b55a-73114b804c7e",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_mass_metric_fusion_cuts(m):\n        \"\"\"\n        Hybrid Strategy: Symmetric Mass-Metric Fusion\n        Combines 'Symmetric Mass Flow' (Parent 1) and 'Metric Lifting' (Parent 2).\n        1. Identifies Critical Blocks via Carlier Bound.\n        2. Applies Forward/Backward Mass Lifting to anchor operations to block boundaries (r_min/q_min).\n        3. Applies Windowed Metric Lifting to enforce triangular delay consistency (S_j >= S_i + p_i + p_k) within the block.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Timing (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to access binary variables safely\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.mass_metric_cuts = pyo.ConstraintList()\n    \n        # 3. Detect Critical Blocks (Carlier)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            r_best = 0\n            q_best = 0\n            \n            # Scan contiguous sub-segments for max LB\n            for i in range(n):\n                p_sum = 0\n                current_r = heads[sorted_ops[i]]\n                current_q_min = float('inf')\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < current_q_min: current_q_min = tails[op]\n                    \n                    lb = current_r + p_sum + current_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n                        r_best = current_r\n                        q_best = current_q_min\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, \n                    'ops': best_sub, \n                    'r': r_best, \n                    'q': q_best\n                })\n    \n        if not candidates: return\n    \n        # 4. Apply Cuts to Top Blocks\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.mass_metric_cuts.add(m.Cmax >= global_max)\n    \n        # Target blocks within 95% of the bottleneck LB\n        targets = [c for c in candidates if c['lb'] >= 0.95 * global_max]\n        CUT_BUDGET = 200\n        cuts_added = 0\n    \n        for target in targets:\n            block = target['ops']\n            r_min = target['r']\n            q_min = target['q']\n            if len(block) < 2: continue\n    \n            # A. Forward & Backward Mass Lifting (Global Envelope for Block)\n            # Forces Start and Cmax to account for aggregate predecessors/successors within the block\n            for u in block:\n                fwd_mass = 0\n                bwd_mass = 0\n                for v in block:\n                    if u == v: continue\n                    y_vu = get_y(v, u)\n                    y_uv = get_y(u, v)\n                    fwd_mass += m.p[v] * y_vu\n                    bwd_mass += m.p[v] * y_uv\n                \n                m.mass_metric_cuts.add(m.S[u] >= r_min + fwd_mass)\n                m.mass_metric_cuts.add(m.Cmax >= m.S[u] + m.p[u] + bwd_mass + q_min)\n                cuts_added += 2\n            \n            if cuts_added >= CUT_BUDGET: break\n    \n            # B. Windowed Metric Lifting (Internal Skeleton for Block)\n            # Tightens triangular paths i -> k -> j inside the block\n            WINDOW = 6\n            n_blk = len(block)\n            for i_idx in range(n_blk):\n                i = block[i_idx]\n                limit = min(i_idx + WINDOW, n_blk)\n                for j_idx in range(i_idx + 1, limit):\n                    j = block[j_idx]\n                    \n                    for k_idx in range(i_idx + 1, j_idx):\n                        k = block[k_idx]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # Metric Lifting: S_j >= S_i + p_i + p_k if k is between i and j\n                        # Relaxed by BigM if i does not precede j\n                        m.mass_metric_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + m.p[k] * (y_ik + y_kj - 1) \n                            - m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 1\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n                \n            if cuts_added >= CUT_BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_mass_metric_fusion_cuts(m):\n    \"\"\"\n    Hybrid Strategy: Symmetric Mass-Metric Fusion\n    Combines 'Symmetric Mass Flow' (Parent 1) and 'Metric Lifting' (Parent 2).\n    1. Identifies Critical Blocks via Carlier Bound.\n    2. Applies Forward/Backward Mass Lifting to anchor operations to block boundaries (r_min/q_min).\n    3. Applies Windowed Metric Lifting to enforce triangular delay consistency (S_j >= S_i + p_i + p_k) within the block.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # 1. Precompute Timing (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to access binary variables safely\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.mass_metric_cuts = pyo.ConstraintList()\n\n    # 3. Detect Critical Blocks (Carlier)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        r_best = 0\n        q_best = 0\n        \n        # Scan contiguous sub-segments for max LB\n        for i in range(n):\n            p_sum = 0\n            current_r = heads[sorted_ops[i]]\n            current_q_min = float('inf')\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < current_q_min: current_q_min = tails[op]\n                \n                lb = current_r + p_sum + current_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n                    r_best = current_r\n                    q_best = current_q_min\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, \n                'ops': best_sub, \n                'r': r_best, \n                'q': q_best\n            })\n\n    if not candidates: return\n\n    # 4. Apply Cuts to Top Blocks\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.mass_metric_cuts.add(m.Cmax >= global_max)\n\n    # Target blocks within 95% of the bottleneck LB\n    targets = [c for c in candidates if c['lb'] >= 0.95 * global_max]\n    CUT_BUDGET = 200\n    cuts_added = 0\n\n    for target in targets:\n        block = target['ops']\n        r_min = target['r']\n        q_min = target['q']\n        if len(block) < 2: continue\n\n        # A. Forward & Backward Mass Lifting (Global Envelope for Block)\n        # Forces Start and Cmax to account for aggregate predecessors/successors within the block\n        for u in block:\n            fwd_mass = 0\n            bwd_mass = 0\n            for v in block:\n                if u == v: continue\n                y_vu = get_y(v, u)\n                y_uv = get_y(u, v)\n                fwd_mass += m.p[v] * y_vu\n                bwd_mass += m.p[v] * y_uv\n            \n            m.mass_metric_cuts.add(m.S[u] >= r_min + fwd_mass)\n            m.mass_metric_cuts.add(m.Cmax >= m.S[u] + m.p[u] + bwd_mass + q_min)\n            cuts_added += 2\n        \n        if cuts_added >= CUT_BUDGET: break\n\n        # B. Windowed Metric Lifting (Internal Skeleton for Block)\n        # Tightens triangular paths i -> k -> j inside the block\n        WINDOW = 6\n        n_blk = len(block)\n        for i_idx in range(n_blk):\n            i = block[i_idx]\n            limit = min(i_idx + WINDOW, n_blk)\n            for j_idx in range(i_idx + 1, limit):\n                j = block[j_idx]\n                \n                for k_idx in range(i_idx + 1, j_idx):\n                    k = block[k_idx]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # Metric Lifting: S_j >= S_i + p_i + p_k if k is between i and j\n                    # Relaxed by BigM if i does not precede j\n                    m.mass_metric_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + m.p[k] * (y_ik + y_kj - 1) \n                        - m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 1\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n            \n        if cuts_added >= CUT_BUDGET: break",
                        "idea": "We fuse **Symmetric Mass Lifting** (Parent 1) with **Windowed Metric Lifting** (Parent 2). On critical Carlier blocks, we first apply global mass constraints ($S_u \\ge r_{min} + \\sum p_v y_{vu}$ and $C_{max} \\ge S_u + p_u + \\dots$) to tighten the block's feasible time interval. Within these blocks, we simultaneously inject local metric lifting cuts ($S_j \\ge S_i + p_i + p_k(y_{ik}+y_{kj}-1)$) to enforce precise triangular processing logic. This dual-scope approach prevents the solver from satisfying aggregate mass constraints with valid $S$ variables that violate internal spacing, significantly strengthening the convex hull."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.16,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.82,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.67,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.61,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.55,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.54,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.32,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.62,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.61,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.79,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.82,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "eb996d32-feb6-444d-990a-d39823c6e0f0",
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86"
                    ]
                }
            ],
            21.904413757155574
        ],
        [
            [
                {
                    "id": "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_dynamic_horizon_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Machine-wise)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        # Identify bottleneck blocks maximizing r_min + sum(p) + q_min\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads) for Carlier logic\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Scan for the tightest sub-segment on this machine\n            best_lb = -1\n            best_sub = []\n            \n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n    \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Bounds and Filtering\n        # Sort candidates by LB tightness\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.dynamic_carlier_cuts = pyo.ConstraintList()\n        m.dynamic_carlier_cuts.add(m.Cmax >= global_max)\n    \n        # Filter: Keep blocks within 90% of global max (Parent 1 Strategy)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n        # 4. Dynamic Window Cuts (Hybrid Logic)\n        # Combine Multi-block targeting (P1) with Overlap-based Windowing (P2)\n        CUT_BUDGET = 200\n        cuts_added = 0\n        \n        def get_y(u, v):\n            # Determine correct order for the set Pair\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # Iterate through the most critical blocks\n        for target in targets[:3]:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            # Ops are already sorted by release time (heads)\n            for i in range(n_sub):\n                op_i = ops[i]\n                \n                # Dynamic Horizon: derived from Parent 2's overlap logic.\n                # We iterate j only as long as j's start is before i's necessary completion.\n                # This creates a data-driven window size based on slack.\n                horizon_limit = global_max - tails[op_i]\n                \n                for j in range(i + 1, n_sub):\n                    op_j = ops[j]\n                    \n                    # Dynamic Break: If j starts too late to overlap i, stop scanning.\n                    # (Since list is sorted by heads, all subsequent j will also fail)\n                    if heads[op_j] >= horizon_limit:\n                        break\n                    \n                    # Check for intermediate k inside this dynamic window\n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refinement: k must also overlap j significantly to form a clique\n                        if heads[op_j] >= global_max - tails[op_k]:\n                            continue\n    \n                        # Apply Cuts on Triplets (i, k, j)\n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # (A) Triangle Transitivity: Prevent cycles i->k->j->i\n                        m.dynamic_carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # (B) Metric Lifting: Tighten start times using binary path logic\n                        # S_j >= S_i + p_i + p_k if path i->k->j exists\n                        m.dynamic_carlier_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_dynamic_horizon_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_dynamic_horizon_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Machine-wise)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    # Identify bottleneck blocks maximizing r_min + sum(p) + q_min\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads) for Carlier logic\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Scan for the tightest sub-segment on this machine\n        best_lb = -1\n        best_sub = []\n        \n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Bounds and Filtering\n    # Sort candidates by LB tightness\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.dynamic_carlier_cuts = pyo.ConstraintList()\n    m.dynamic_carlier_cuts.add(m.Cmax >= global_max)\n\n    # Filter: Keep blocks within 90% of global max (Parent 1 Strategy)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n\n    # 4. Dynamic Window Cuts (Hybrid Logic)\n    # Combine Multi-block targeting (P1) with Overlap-based Windowing (P2)\n    CUT_BUDGET = 200\n    cuts_added = 0\n    \n    def get_y(u, v):\n        # Determine correct order for the set Pair\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # Iterate through the most critical blocks\n    for target in targets[:3]:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        # Ops are already sorted by release time (heads)\n        for i in range(n_sub):\n            op_i = ops[i]\n            \n            # Dynamic Horizon: derived from Parent 2's overlap logic.\n            # We iterate j only as long as j's start is before i's necessary completion.\n            # This creates a data-driven window size based on slack.\n            horizon_limit = global_max - tails[op_i]\n            \n            for j in range(i + 1, n_sub):\n                op_j = ops[j]\n                \n                # Dynamic Break: If j starts too late to overlap i, stop scanning.\n                # (Since list is sorted by heads, all subsequent j will also fail)\n                if heads[op_j] >= horizon_limit:\n                    break\n                \n                # Check for intermediate k inside this dynamic window\n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refinement: k must also overlap j significantly to form a clique\n                    if heads[op_j] >= global_max - tails[op_k]:\n                        continue\n\n                    # Apply Cuts on Triplets (i, k, j)\n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # (A) Triangle Transitivity: Prevent cycles i->k->j->i\n                    m.dynamic_carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # (B) Metric Lifting: Tighten start times using binary path logic\n                    # S_j >= S_i + p_i + p_k if path i->k->j exists\n                    m.dynamic_carlier_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_dynamic_horizon_carlier_cuts(model)",
                        "idea": "We introduce **Dynamic Horizon Transitivity**, a hybrid strategy that identifies multiple Carlier-critical blocks (adopting Parent 1's multi-block focus) but replaces fixed-size sliding windows with **LB-derived overlap horizons** (from Parent 2). By filtering triplets $(i, k, j)$ where the release of $j$ falls strictly before the latest-start-time of $i$ (calculated via the global Carlier LB), we dynamically size the constraint window to the local congestion density. This applies metric lifting and transitivity cuts exactly where the ordering is ambiguous in the relaxation, avoiding overhead on clearly separated operations."
                    },
                    "fitness": 21.904413757155574,
                    "solver_reports": [
                        {
                            "gap": 27.6881,
                            "total_time": 13.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 32594,
                            "explored_time": 13.65,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 11.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 38442,
                            "explored_time": 11.2,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 32907,
                            "explored_time": 10.69,
                            "work_units": 10.0
                        },
                        {
                            "gap": 12.3741,
                            "total_time": 11.0,
                            "explored_nodes": 87,
                            "simplex_iterations": 50655,
                            "explored_time": 10.98,
                            "work_units": 10.21
                        },
                        {
                            "total_time": 11.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 34085,
                            "explored_time": 11.82,
                            "work_units": 10.0
                        },
                        {
                            "gap": 4.0671,
                            "total_time": 12.07,
                            "explored_nodes": 3068,
                            "simplex_iterations": 154879,
                            "explored_time": 12.07,
                            "work_units": 10.14
                        },
                        {
                            "gap": 28.5714,
                            "total_time": 12.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 47274,
                            "explored_time": 12.06,
                            "work_units": 10.0
                        },
                        {
                            "gap": 21.5145,
                            "total_time": 14.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 38295,
                            "explored_time": 14.39,
                            "work_units": 10.01
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "15672d5b-ca14-4b2d-aa51-eb221a77d9c6"
                    ]
                },
                {
                    "id": "101328eb-f36a-4ac9-9863-144887bd3271",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_carlier_cuts(m):\n        # 1. Calculate Release (heads) and Delivery (tails) times\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Machine-wise Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        # Maximize r_min + sum(p) + q_min for contiguous blocks\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global LB Constraint and Filtering\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.hybrid_carlier = pyo.ConstraintList()\n        m.hybrid_carlier.add(m.Cmax >= global_max)\n    \n        # Select blocks close to global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Hybrid Cut Generation: Dynamic Horizon (P1) + Window Clamp (P2)\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 8 # Safety clamp from P2\n        cuts_added = 0\n        \n        for target in targets[:3]:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon (P1): Stop if j starts too late to affect i's critical path\n                # If heads[j] is large, j is likely after i; if too large, the order is fixed.\n                horizon_limit = global_max - tails[op_i]\n                \n                # Hybrid range: Enforce locality (P2) but respect dynamic bounds (P1)\n                end_j = min(i + WINDOW_SIZE, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # P1 Optimization: If j is too far, subsequent j's (sorted) are also too far\n                    if heads[op_j] >= horizon_limit:\n                        break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # P1 Refinement: Ensure k is relevant to j's tightness\n                        if heads[op_j] >= global_max - tails[op_k]:\n                            continue\n    \n                        # Generate Cuts\n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Transitivity\n                        m.hybrid_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Metric Lifting\n                        m.hybrid_carlier.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_hybrid_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_carlier_cuts(m):\n    # 1. Calculate Release (heads) and Delivery (tails) times\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Machine-wise Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    # Maximize r_min + sum(p) + q_min for contiguous blocks\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global LB Constraint and Filtering\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.hybrid_carlier = pyo.ConstraintList()\n    m.hybrid_carlier.add(m.Cmax >= global_max)\n\n    # Select blocks close to global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Hybrid Cut Generation: Dynamic Horizon (P1) + Window Clamp (P2)\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 8 # Safety clamp from P2\n    cuts_added = 0\n    \n    for target in targets[:3]:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon (P1): Stop if j starts too late to affect i's critical path\n            # If heads[j] is large, j is likely after i; if too large, the order is fixed.\n            horizon_limit = global_max - tails[op_i]\n            \n            # Hybrid range: Enforce locality (P2) but respect dynamic bounds (P1)\n            end_j = min(i + WINDOW_SIZE, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # P1 Optimization: If j is too far, subsequent j's (sorted) are also too far\n                if heads[op_j] >= horizon_limit:\n                    break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # P1 Refinement: Ensure k is relevant to j's tightness\n                    if heads[op_j] >= global_max - tails[op_k]:\n                        continue\n\n                    # Generate Cuts\n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Transitivity\n                    m.hybrid_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Metric Lifting\n                    m.hybrid_carlier.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_hybrid_carlier_cuts(model)",
                        "idea": "We introduce **Hybrid Adaptive Horizon Cuts**, integrating Parent 1's dynamic slack-based filtering with Parent 2's sliding window locality. The strategy first identifies Carlier-critical blocks (maximizing $r_{min} + \\sum p + q_{min}$) and enforces the global lower bound on $C_{max}$. Inside these blocks, we generate transitivity and metric lifting cuts for triplets $(i, k, j)$. A hybrid selection mechanism is used: we iterate $j$ within a fixed local window (from Parent 2) to manage complexity, but aggressively prune pairs where the release time of $j$ exceeds the slack allowed by the global lower bound (Dynamic Horizon from Parent 1). This ensures cuts target only the tightest, most ambiguous orderings."
                    },
                    "fitness": 22.19857710947803,
                    "solver_reports": [
                        {
                            "gap": 17.1079,
                            "total_time": 13.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 33374,
                            "explored_time": 13.68,
                            "work_units": 10.0
                        },
                        {
                            "gap": 24.3628,
                            "total_time": 10.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 34207,
                            "explored_time": 10.57,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 32336,
                            "explored_time": 9.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.3377,
                            "total_time": 13.94,
                            "explored_nodes": 59,
                            "simplex_iterations": 62449,
                            "explored_time": 13.92,
                            "work_units": 10.37
                        },
                        {
                            "total_time": 12.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 32656,
                            "explored_time": 12.22,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 12.17,
                            "explored_nodes": 201,
                            "simplex_iterations": 56875,
                            "explored_time": 12.16,
                            "work_units": 12.25
                        },
                        {
                            "gap": 26.5033,
                            "total_time": 12.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 48824,
                            "explored_time": 12.83,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.7736,
                            "total_time": 13.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 37863,
                            "explored_time": 13.89,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86"
                    ]
                },
                {
                    "id": "78e90a98-0c11-4951-adc9-ad3d6d1d1d76",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_multi_block_flow_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Heads (r) and Tails (q) for global bound estimation\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Blocks on All Machines using Carlier Logic\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Evaluate potential critical blocks\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads for O(N^2) scan to find tightest sub-segment\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            best_r = 0\n            best_q = 0\n            \n            # Maximize LB = r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                r_val = heads[sorted_ops[i]]\n                current_sub = []\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n                        best_r = r_val\n                        best_q = min_q\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, \n                    'ops': best_sub, \n                    'r_min': best_r, \n                    'q_min': best_q\n                })\n    \n        if not candidates: return\n        \n        # Sort blocks by LB to prioritize critical and near-critical paths\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # 3. Apply Symmetric Volume Cuts to Top Blocks\n        # Target blocks within 85% of global LB to prevent bottleneck shifting\n        global_max_lb = candidates[0]['lb']\n        threshold = 0.85 * global_max_lb\n        \n        m.flow_cuts = pyo.ConstraintList()\n        \n        # Helper: Returns expression (1 if v -> u else 0)\n        def get_prec_expr_vu(v, u):\n            # m.y index is always sorted (min, max)\n            if v < u:\n                return m.y[v[0], v[1], u[0], u[1]] # y[v,u]=1 => v->u\n            else:\n                return 1 - m.y[u[0], u[1], v[0], v[1]] # y[u,v]=1 => u->v => (1-y)=0. 1-y=1 => v->u.\n    \n        added_count = 0\n        CUT_LIMIT = 100\n        \n        for cand in candidates:\n            if cand['lb'] < threshold: break\n            if added_count >= CUT_LIMIT: break\n            \n            block = cand['ops']\n            r_min = cand['r_min']\n            q_min = cand['q_min']\n            \n            # For every operation in the critical/near-critical block, \n            # enforce that its Start Time respects the volume of dynamic predecessors/successors\n            for u in block:\n                # Forward Flow: S[u] >= r_min + Sum(p[v] for v in block if v precedes u)\n                pred_vol = 0\n                succ_vol = 0\n                \n                for v in block:\n                    if v == u: continue\n                    \n                    # Term: contributes p[v] to pred_vol if v -> u\n                    # Term: contributes p[v] to succ_vol if u -> v\n                    \n                    # Check if v precedes u\n                    is_v_pre_u = get_prec_expr_vu(v, u) \n                    # If v does not precede u (and u!=v), then u precedes v in the disjunctive clique\n                    is_u_pre_v = 1 - is_v_pre_u\n                    \n                    pred_vol += m.p[v] * is_v_pre_u\n                    succ_vol += m.p[v] * is_u_pre_v\n                \n                # Cut 1: Forward Displacement\n                # S[u] pushed right by volume of predecessors\n                m.flow_cuts.add(m.S[u] >= r_min + pred_vol)\n                \n                # Cut 2: Backward Displacement\n                # S[u] pushed left (bounded from top) by volume of successors\n                # Derived from: Cmax >= S[u] + p[u] + succ_vol + q_min\n                m.flow_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n                \n                added_count += 2\n                if added_count >= CUT_LIMIT: break\n    \n    add_multi_block_flow_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_multi_block_flow_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Heads (r) and Tails (q) for global bound estimation\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Blocks on All Machines using Carlier Logic\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Evaluate potential critical blocks\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads for O(N^2) scan to find tightest sub-segment\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        best_r = 0\n        best_q = 0\n        \n        # Maximize LB = r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            r_val = heads[sorted_ops[i]]\n            current_sub = []\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n                    best_r = r_val\n                    best_q = min_q\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, \n                'ops': best_sub, \n                'r_min': best_r, \n                'q_min': best_q\n            })\n\n    if not candidates: return\n    \n    # Sort blocks by LB to prioritize critical and near-critical paths\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # 3. Apply Symmetric Volume Cuts to Top Blocks\n    # Target blocks within 85% of global LB to prevent bottleneck shifting\n    global_max_lb = candidates[0]['lb']\n    threshold = 0.85 * global_max_lb\n    \n    m.flow_cuts = pyo.ConstraintList()\n    \n    # Helper: Returns expression (1 if v -> u else 0)\n    def get_prec_expr_vu(v, u):\n        # m.y index is always sorted (min, max)\n        if v < u:\n            return m.y[v[0], v[1], u[0], u[1]] # y[v,u]=1 => v->u\n        else:\n            return 1 - m.y[u[0], u[1], v[0], v[1]] # y[u,v]=1 => u->v => (1-y)=0. 1-y=1 => v->u.\n\n    added_count = 0\n    CUT_LIMIT = 100\n    \n    for cand in candidates:\n        if cand['lb'] < threshold: break\n        if added_count >= CUT_LIMIT: break\n        \n        block = cand['ops']\n        r_min = cand['r_min']\n        q_min = cand['q_min']\n        \n        # For every operation in the critical/near-critical block, \n        # enforce that its Start Time respects the volume of dynamic predecessors/successors\n        for u in block:\n            # Forward Flow: S[u] >= r_min + Sum(p[v] for v in block if v precedes u)\n            pred_vol = 0\n            succ_vol = 0\n            \n            for v in block:\n                if v == u: continue\n                \n                # Term: contributes p[v] to pred_vol if v -> u\n                # Term: contributes p[v] to succ_vol if u -> v\n                \n                # Check if v precedes u\n                is_v_pre_u = get_prec_expr_vu(v, u) \n                # If v does not precede u (and u!=v), then u precedes v in the disjunctive clique\n                is_u_pre_v = 1 - is_v_pre_u\n                \n                pred_vol += m.p[v] * is_v_pre_u\n                succ_vol += m.p[v] * is_u_pre_v\n            \n            # Cut 1: Forward Displacement\n            # S[u] pushed right by volume of predecessors\n            m.flow_cuts.add(m.S[u] >= r_min + pred_vol)\n            \n            # Cut 2: Backward Displacement\n            # S[u] pushed left (bounded from top) by volume of successors\n            # Derived from: Cmax >= S[u] + p[u] + succ_vol + q_min\n            m.flow_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n            \n            added_count += 2\n            if added_count >= CUT_LIMIT: break\n\nadd_multi_block_flow_cuts(model)",
                        "idea": "We introduce **Multi-Block Bi-Directional Flow Cuts**, a strategy that stabilizes the search by creating a tight 'time corridor' for operations in critical and near-critical blocks. Unlike Parent 1 (which lifts the global Cmax) and Parent 2 (which bounds the completion of the main bottleneck), this approach simultaneously constrains the **Start Times ($S_u$)** from both directions. It enforces **Forward Flow** ($S_u \\ge r_{min} + \\sum p_v y_{vu}$) and **Backward Flow** ($S_u \\le C_{max} - q_{min} - p_u - \\sum p_v y_{uv}$) across multiple active machine blocks. This symmetric tightening explicitly links binary sequence decisions to continuous time variables, preventing 'whack-a-mole' shifting of bottlenecks and improving the relaxation quality globally."
                    },
                    "fitness": 15.455218952261802,
                    "solver_reports": [
                        {
                            "total_time": 9.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 20950,
                            "explored_time": 9.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 22385,
                            "explored_time": 9.23,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 8.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 42179,
                            "explored_time": 8.55,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.7561,
                            "total_time": 12.36,
                            "explored_nodes": 85,
                            "simplex_iterations": 66616,
                            "explored_time": 12.34,
                            "work_units": 10.4
                        },
                        {
                            "gap": 93.3388,
                            "total_time": 9.56,
                            "explored_nodes": 1,
                            "simplex_iterations": 20971,
                            "explored_time": 9.49,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.0765,
                            "total_time": 10.23,
                            "explored_nodes": 114,
                            "simplex_iterations": 79799,
                            "explored_time": 10.22,
                            "work_units": 10.89
                        },
                        {
                            "gap": 45.4387,
                            "total_time": 10.42,
                            "explored_nodes": 1,
                            "simplex_iterations": 42457,
                            "explored_time": 10.37,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 26651,
                            "explored_time": 9.17,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "2a7467fe-0653-4e95-b3aa-52ae065c5992",
                        "8458d8bf-85a4-44b2-86e9-e78257074e86"
                    ]
                },
                {
                    "id": "3d1bebcf-5278-4df0-9c8d-4a6d298426b4",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_enhanced_objective_cuts(m):\n        # 1. Compute Static Heads and Tails\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Block on Machines\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Find the machine block with the highest 1|r_j|q_j lower bound\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads for Carlier-style check\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            \n            # O(N^2) scan for max LB of any subset on this machine\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                min_r = heads[sorted_ops[i]]\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    lb = min_r + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n            \n            candidates.append({'lb': best_lb, 'ops': ops})\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Focus on the most critical bottleneck\n        target = candidates[0]\n        target_ops = target['ops']\n        global_lb = target['lb']\n    \n        m.enhanced_obj_cuts = pyo.ConstraintList()\n        m.enhanced_obj_cuts.add(m.Cmax >= global_lb)\n    \n        # Helper to access binary variables direction-agnostically\n        def get_y_expr(u, v):\n            # Returns expression for y_{u->v}\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Generate Pairwise Cuts (Two-Sided)\n        # Links Cmax to y_uv with cost for both directions\n        pairs_data = []\n        n_blk = len(target_ops)\n        for i in range(n_blk):\n            u = target_ops[i]\n            for j in range(i + 1, n_blk):\n                v = target_ops[j]\n                cost_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n                cost_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n                metric = max(cost_uv, cost_vu)\n                \n                if metric >= 0.85 * global_lb:\n                    pairs_data.append({'u': u, 'v': v, 'uv': cost_uv, 'vu': cost_vu, 'metric': metric})\n        \n        pairs_data.sort(key=lambda x: x['metric'], reverse=True)\n        for d in pairs_data[:40]: # Limit number of cuts\n            expr = get_y_expr(d['u'], d['v'])\n            m.enhanced_obj_cuts.add(m.Cmax >= d['uv'] * expr + d['vu'] * (1 - expr))\n    \n        # 4. Generate Triplet Cuts (Sequence-Dependent)\n        # Targets specific high-cost sequences u -> m -> v\n        triplets_data = []\n        for i in range(n_blk):\n            u = target_ops[i]\n            for j in range(n_blk):\n                if i == j: continue\n                mid_op = target_ops[j]\n                for k in range(n_blk):\n                    if k == i or k == j: continue\n                    v = target_ops[k]\n                    \n                    # Valid Lower Bound if u -> mid -> v\n                    L_seq = heads[u] + m.p[u] + m.p[mid_op] + m.p[v] + tails[v]\n                    \n                    if L_seq >= 0.9 * global_lb:\n                        triplets_data.append({'u': u, 'm': mid_op, 'v': v, 'L': L_seq})\n        \n        triplets_data.sort(key=lambda x: x['L'], reverse=True)\n        for d in triplets_data[:40]:\n            y1 = get_y_expr(d['u'], d['m'])\n            y2 = get_y_expr(d['m'], d['v'])\n            # Cut: Cmax >= L_seq if y1=1 AND y2=1\n            # Formulated as: Cmax >= L_seq * (y1 + y2 - 1)\n            m.enhanced_obj_cuts.add(m.Cmax >= d['L'] * (y1 + y2 - 1))\n    \n    add_enhanced_objective_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_enhanced_objective_cuts(m):\n    # 1. Compute Static Heads and Tails\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Block on Machines\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Find the machine block with the highest 1|r_j|q_j lower bound\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads for Carlier-style check\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        \n        # O(N^2) scan for max LB of any subset on this machine\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            min_r = heads[sorted_ops[i]]\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                lb = min_r + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n        \n        candidates.append({'lb': best_lb, 'ops': ops})\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Focus on the most critical bottleneck\n    target = candidates[0]\n    target_ops = target['ops']\n    global_lb = target['lb']\n\n    m.enhanced_obj_cuts = pyo.ConstraintList()\n    m.enhanced_obj_cuts.add(m.Cmax >= global_lb)\n\n    # Helper to access binary variables direction-agnostically\n    def get_y_expr(u, v):\n        # Returns expression for y_{u->v}\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Generate Pairwise Cuts (Two-Sided)\n    # Links Cmax to y_uv with cost for both directions\n    pairs_data = []\n    n_blk = len(target_ops)\n    for i in range(n_blk):\n        u = target_ops[i]\n        for j in range(i + 1, n_blk):\n            v = target_ops[j]\n            cost_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n            cost_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n            metric = max(cost_uv, cost_vu)\n            \n            if metric >= 0.85 * global_lb:\n                pairs_data.append({'u': u, 'v': v, 'uv': cost_uv, 'vu': cost_vu, 'metric': metric})\n    \n    pairs_data.sort(key=lambda x: x['metric'], reverse=True)\n    for d in pairs_data[:40]: # Limit number of cuts\n        expr = get_y_expr(d['u'], d['v'])\n        m.enhanced_obj_cuts.add(m.Cmax >= d['uv'] * expr + d['vu'] * (1 - expr))\n\n    # 4. Generate Triplet Cuts (Sequence-Dependent)\n    # Targets specific high-cost sequences u -> m -> v\n    triplets_data = []\n    for i in range(n_blk):\n        u = target_ops[i]\n        for j in range(n_blk):\n            if i == j: continue\n            mid_op = target_ops[j]\n            for k in range(n_blk):\n                if k == i or k == j: continue\n                v = target_ops[k]\n                \n                # Valid Lower Bound if u -> mid -> v\n                L_seq = heads[u] + m.p[u] + m.p[mid_op] + m.p[v] + tails[v]\n                \n                if L_seq >= 0.9 * global_lb:\n                    triplets_data.append({'u': u, 'm': mid_op, 'v': v, 'L': L_seq})\n    \n    triplets_data.sort(key=lambda x: x['L'], reverse=True)\n    for d in triplets_data[:40]:\n        y1 = get_y_expr(d['u'], d['m'])\n        y2 = get_y_expr(d['m'], d['v'])\n        # Cut: Cmax >= L_seq if y1=1 AND y2=1\n        # Formulated as: Cmax >= L_seq * (y1 + y2 - 1)\n        m.enhanced_obj_cuts.add(m.Cmax >= d['L'] * (y1 + y2 - 1))\n\nadd_enhanced_objective_cuts(model)",
                        "idea": "We enhance Conflict-Aware Objective Lifting by introducing **Triplet Sequence Cuts**. While pairwise cuts ($u \\to v$) lift the makespan lower bound based on direct precedence, triplet cuts ($u \\to m \\to v$) capture the cumulative latency of intermediate operations in the critical block. We scan the bottleneck for high-cost 3-job sequences and impose cuts $C_{max} \\ge (r_u + p_u + p_m + p_v + q_v)(y_{um} + y_{mv} - 1)$. This tightens the relaxation by penalizing fractional or discrete orderings that force a longer minimal path through the machine, explicitly linking 3-step precedence chains to the objective function."
                    },
                    "fitness": 14.239600480934115,
                    "solver_reports": [
                        {
                            "gap": 19.1398,
                            "total_time": 14.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 29835,
                            "explored_time": 14.09,
                            "work_units": 10.05
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.56,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.52,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 9.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.87,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 13.66,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 13.65,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.3583,
                            "total_time": 10.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 32144,
                            "explored_time": 10.43,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.4605,
                            "total_time": 13.31,
                            "explored_nodes": 7551,
                            "simplex_iterations": 252051,
                            "explored_time": 13.29,
                            "work_units": 10.0
                        },
                        {
                            "gap": 29.9628,
                            "total_time": 12.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 31904,
                            "explored_time": 12.52,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.36,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "2a7467fe-0653-4e95-b3aa-52ae065c5992"
                    ]
                },
                {
                    "id": "037029f9-9069-467e-8d79-4de73f14f524",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_multi_block_mass_window_cuts(m):\n        import pyomo.environ as pyo\n        \n        # 1. Precompute Timing (Heads/Tails)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_ops = []\n            best_q = 0\n            \n            # Find sub-segment maximizing r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                curr_q_min = float('inf')\n                r_val = heads[sorted_ops[i]]\n                sub = []\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    sub.append(op)\n                    p_sum += m.p[op]\n                    if tails[op] < curr_q_min: curr_q_min = tails[op]\n                    \n                    lb = r_val + p_sum + curr_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_ops = list(sub)\n                        best_q = curr_q_min\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_ops, 'q_min': best_q})\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n    \n        # Target top blocks to handle shifting bottlenecks (Parent 1 Strategy)\n        # We take blocks within 85% of the global max to be robust\n        targets = [c for c in candidates if c['lb'] >= 0.85 * global_max][:3]\n    \n        m.hybrid_cuts = pyo.ConstraintList()\n        m.hybrid_cuts.add(m.Cmax >= global_max)\n    \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_BUDGET = 250\n        count = 0\n    \n        for target in targets:\n            block = target['ops']\n            q_min = target['q_min']\n            n_blk = len(block)\n            \n            # A. Backward Mass Flow (Parent 2 Strength)\n            # Links Cmax to start time of u + sum of dynamic successors\n            for u in block:\n                # Calculate mass of successors dynamically\n                succ_mass = sum(m.p[v] * get_y(u, v) for v in block if v != u)\n                m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_mass + q_min)\n                count += 1\n                if count >= CUT_BUDGET: break\n            \n            if count >= CUT_BUDGET: break\n    \n            # B. Sliding Window Transitivity (Parent 1 Efficiency)\n            # Tightens local precedence variables to support the Mass Flow cuts\n            # using a fixed window to avoid O(N^3) explosion\n            WINDOW = 6\n            for i_idx in range(n_blk):\n                i = block[i_idx]\n                for j_idx in range(i_idx + 1, min(i_idx + WINDOW, n_blk)):\n                    j = block[j_idx]\n                    \n                    # Intermediate k\n                    for k_idx in range(i_idx + 1, j_idx):\n                        k = block[k_idx]\n                        \n                        y_ij = get_y(i, j)\n                        y_ik = get_y(i, k)\n                        y_kj = get_y(k, j)\n                        \n                        # 1. Transitivity\n                        m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # 2. Metric Lifting\n                        # S_j >= S_i + p_i + p_k if i->k->j\n                        m.hybrid_cuts.add(\n                            m.S[j] >= m.S[i] + m.p[i] + \n                            m.p[k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        count += 2\n                        if count >= CUT_BUDGET: break\n                    if count >= CUT_BUDGET: break\n                if count >= CUT_BUDGET: break\n            if count >= CUT_BUDGET: break\n    \n    add_multi_block_mass_window_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_multi_block_mass_window_cuts(m):\n    import pyomo.environ as pyo\n    \n    # 1. Precompute Timing (Heads/Tails)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_ops = []\n        best_q = 0\n        \n        # Find sub-segment maximizing r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            curr_q_min = float('inf')\n            r_val = heads[sorted_ops[i]]\n            sub = []\n            for j in range(i, n):\n                op = sorted_ops[j]\n                sub.append(op)\n                p_sum += m.p[op]\n                if tails[op] < curr_q_min: curr_q_min = tails[op]\n                \n                lb = r_val + p_sum + curr_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_ops = list(sub)\n                    best_q = curr_q_min\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_ops, 'q_min': best_q})\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n\n    # Target top blocks to handle shifting bottlenecks (Parent 1 Strategy)\n    # We take blocks within 85% of the global max to be robust\n    targets = [c for c in candidates if c['lb'] >= 0.85 * global_max][:3]\n\n    m.hybrid_cuts = pyo.ConstraintList()\n    m.hybrid_cuts.add(m.Cmax >= global_max)\n\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_BUDGET = 250\n    count = 0\n\n    for target in targets:\n        block = target['ops']\n        q_min = target['q_min']\n        n_blk = len(block)\n        \n        # A. Backward Mass Flow (Parent 2 Strength)\n        # Links Cmax to start time of u + sum of dynamic successors\n        for u in block:\n            # Calculate mass of successors dynamically\n            succ_mass = sum(m.p[v] * get_y(u, v) for v in block if v != u)\n            m.hybrid_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_mass + q_min)\n            count += 1\n            if count >= CUT_BUDGET: break\n        \n        if count >= CUT_BUDGET: break\n\n        # B. Sliding Window Transitivity (Parent 1 Efficiency)\n        # Tightens local precedence variables to support the Mass Flow cuts\n        # using a fixed window to avoid O(N^3) explosion\n        WINDOW = 6\n        for i_idx in range(n_blk):\n            i = block[i_idx]\n            for j_idx in range(i_idx + 1, min(i_idx + WINDOW, n_blk)):\n                j = block[j_idx]\n                \n                # Intermediate k\n                for k_idx in range(i_idx + 1, j_idx):\n                    k = block[k_idx]\n                    \n                    y_ij = get_y(i, j)\n                    y_ik = get_y(i, k)\n                    y_kj = get_y(k, j)\n                    \n                    # 1. Transitivity\n                    m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # 2. Metric Lifting\n                    # S_j >= S_i + p_i + p_k if i->k->j\n                    m.hybrid_cuts.add(\n                        m.S[j] >= m.S[i] + m.p[i] + \n                        m.p[k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    count += 2\n                    if count >= CUT_BUDGET: break\n                if count >= CUT_BUDGET: break\n            if count >= CUT_BUDGET: break\n        if count >= CUT_BUDGET: break\n\nadd_multi_block_mass_window_cuts(model)",
                        "idea": "We introduce **Multi-Block Mass-Window Synergy**, combining Parent 2's high-fitness **Backward Mass Flow** cuts with Parent 1's robust **Sliding Window** strategy. While Parent 2 tightly bound $C_{max}$ using the dynamic sum of successors on the *single* critical block, this ignores shifting bottlenecks. We extend this by targeting the **top 3 competing blocks** (within 85% of global LB). On these blocks, we apply Backward Mass Flow ($C_{max} \\ge S_u + p_u + \\sum p_v y_{uv} + q_{min}$) to enforce global limits, supported by Sliding Window Transitivity ($y_{ik} + y_{kj} \\le 1 + y_{ij}$) and Metric Lifting. This synergy ensures that the binary variables driving the Mass Flow cuts are locally consistent, tightening the relaxation across multiple potential bottlenecks simultaneously without exploding model size."
                    },
                    "fitness": 15.253618864647562,
                    "solver_reports": [
                        {
                            "total_time": 10.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 37437,
                            "explored_time": 10.18,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 10.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 38446,
                            "explored_time": 10.54,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 35228,
                            "explored_time": 9.47,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.12,
                            "explored_nodes": 239,
                            "simplex_iterations": 79615,
                            "explored_time": 9.11,
                            "work_units": 10.08
                        },
                        {
                            "total_time": 9.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 36943,
                            "explored_time": 9.45,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5832,
                            "total_time": 10.87,
                            "explored_nodes": 171,
                            "simplex_iterations": 64271,
                            "explored_time": 10.86,
                            "work_units": 12.31
                        },
                        {
                            "gap": 40.4551,
                            "total_time": 10.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 39485,
                            "explored_time": 10.05,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 37383,
                            "explored_time": 9.31,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86",
                        "8458d8bf-85a4-44b2-86e9-e78257074e86"
                    ]
                },
                {
                    "id": "201a8e4a-ebb9-4376-a829-bb6bbaffdbb1",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_triplet_objective_cuts(m):\n        # 1. Precompute Static Heads (r) and Tails (q)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Standard Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads) for block analysis\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            \n            # O(N^2) scan for max LB (r_min + sum(p) + q_min)\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    \n                    lb = heads[sorted_ops[i]] + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j_idx+1]\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_lb = candidates[0]['lb']\n    \n        # 3. Apply Global LB Cut\n        m.hybrid_triplet_cuts = pyo.ConstraintList()\n        m.hybrid_triplet_cuts.add(m.Cmax >= global_lb)\n    \n        # Select critical blocks for intensive cut generation\n        targets = [c['ops'] for c in candidates if c['lb'] >= 0.9 * global_lb]\n    \n        # Helper for precedence variables: y_uv = 1 if u -> v\n        def get_y_expr(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Generate Hybrid Triplet Cuts\n        # Strategy: Use Parent 2's Dynamic Horizon loops to find tight triplets,\n        # then apply Parent 1's Objective Lifting logic to the triplet chain.\n        CUT_LIMIT = 100\n        added = 0\n        \n        for ops in targets:\n            if added >= CUT_LIMIT: break\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            # ops are sorted by heads\n            for i in range(n_sub):\n                u = ops[i]\n                # Dynamic Horizon (Parent 2): limit search based on global slack\n                horizon_limit = global_lb - tails[u]\n                \n                for j in range(i + 1, n_sub):\n                    w = ops[j]\n                    # Optimization: if w starts too late, it cannot overlap u in a critical way\n                    if heads[w] >= horizon_limit: \n                        break\n                    \n                    for k in range(i + 1, j):\n                        v = ops[k]\n                        \n                        # Filter: v must be able to bridge u and w\n                        if heads[w] >= global_lb - tails[v]:\n                            continue\n    \n                        # Triplet Cost: L_uvw = r_u + p_u + p_v + p_w + q_w\n                        # This extends Parent 1's pairwise cost to a 3-op chain\n                        L_uvw = heads[u] + m.p[u] + m.p[v] + m.p[w] + tails[w]\n                        \n                        # Only add if the chain is tight relative to the global bottleneck\n                        if L_uvw >= 0.9 * global_lb:\n                            y_uv = get_y_expr(u, v)\n                            y_vw = get_y_expr(v, w)\n                            y_uw = get_y_expr(u, w)\n                            \n                            # CUT A: Triplet Objective Lifting\n                            # If u->v and v->w, then Cmax must be >= L_uvw\n                            # Implies Cmax >= L_uvw * (y_uv + y_vw - 1)\n                            m.hybrid_triplet_cuts.add(\n                                m.Cmax >= L_uvw * (y_uv + y_vw - 1)\n                            )\n                            \n                            # CUT B: Transitivity (Structure from Parent 2)\n                            # Enforce logical consistency for the triplet\n                            m.hybrid_triplet_cuts.add(\n                                y_uv + y_vw - y_uw <= 1\n                            )\n                            \n                            added += 2\n                            if added >= CUT_LIMIT: break\n                    if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n    \n    add_hybrid_triplet_objective_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_triplet_objective_cuts(m):\n    # 1. Precompute Static Heads (r) and Tails (q)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Standard Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads) for block analysis\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        \n        # O(N^2) scan for max LB (r_min + sum(p) + q_min)\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                \n                lb = heads[sorted_ops[i]] + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j_idx+1]\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_lb = candidates[0]['lb']\n\n    # 3. Apply Global LB Cut\n    m.hybrid_triplet_cuts = pyo.ConstraintList()\n    m.hybrid_triplet_cuts.add(m.Cmax >= global_lb)\n\n    # Select critical blocks for intensive cut generation\n    targets = [c['ops'] for c in candidates if c['lb'] >= 0.9 * global_lb]\n\n    # Helper for precedence variables: y_uv = 1 if u -> v\n    def get_y_expr(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Generate Hybrid Triplet Cuts\n    # Strategy: Use Parent 2's Dynamic Horizon loops to find tight triplets,\n    # then apply Parent 1's Objective Lifting logic to the triplet chain.\n    CUT_LIMIT = 100\n    added = 0\n    \n    for ops in targets:\n        if added >= CUT_LIMIT: break\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        # ops are sorted by heads\n        for i in range(n_sub):\n            u = ops[i]\n            # Dynamic Horizon (Parent 2): limit search based on global slack\n            horizon_limit = global_lb - tails[u]\n            \n            for j in range(i + 1, n_sub):\n                w = ops[j]\n                # Optimization: if w starts too late, it cannot overlap u in a critical way\n                if heads[w] >= horizon_limit: \n                    break\n                \n                for k in range(i + 1, j):\n                    v = ops[k]\n                    \n                    # Filter: v must be able to bridge u and w\n                    if heads[w] >= global_lb - tails[v]:\n                        continue\n\n                    # Triplet Cost: L_uvw = r_u + p_u + p_v + p_w + q_w\n                    # This extends Parent 1's pairwise cost to a 3-op chain\n                    L_uvw = heads[u] + m.p[u] + m.p[v] + m.p[w] + tails[w]\n                    \n                    # Only add if the chain is tight relative to the global bottleneck\n                    if L_uvw >= 0.9 * global_lb:\n                        y_uv = get_y_expr(u, v)\n                        y_vw = get_y_expr(v, w)\n                        y_uw = get_y_expr(u, w)\n                        \n                        # CUT A: Triplet Objective Lifting\n                        # If u->v and v->w, then Cmax must be >= L_uvw\n                        # Implies Cmax >= L_uvw * (y_uv + y_vw - 1)\n                        m.hybrid_triplet_cuts.add(\n                            m.Cmax >= L_uvw * (y_uv + y_vw - 1)\n                        )\n                        \n                        # CUT B: Transitivity (Structure from Parent 2)\n                        # Enforce logical consistency for the triplet\n                        m.hybrid_triplet_cuts.add(\n                            y_uv + y_vw - y_uw <= 1\n                        )\n                        \n                        added += 2\n                        if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n            if added >= CUT_LIMIT: break\n\nadd_hybrid_triplet_objective_cuts(model)",
                        "idea": "We introduce **Triplet-Based Objective Lifting**, a hybrid strategy that combines the **Dynamic Horizon** filtering from Parent 2 with the **Cost-Based Lifting** philosophy of Parent 1. While Parent 2 used triplets for variable transitivity and local start-time lifting, and Parent 1 used pairs for global Cmax lifting, this approach identifies tight triplets $(u, v, w)$ within critical blocks and imposes a direct lower bound on the objective: $C_{max} \\ge (r_u + p_u + p_v + p_w + q_w) \\cdot (y_{uv} + y_{vw} - 1)$. This creates a stronger connection between binary sequencing decisions and the global makespan than pairwise cuts, utilizing the sum of three processing times to push the relaxation bound closer to the convex hull in the most ambiguous regions of the schedule."
                    },
                    "fitness": 14.1900871493206,
                    "solver_reports": [
                        {
                            "gap": 19.1398,
                            "total_time": 13.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 29835,
                            "explored_time": 13.94,
                            "work_units": 10.05
                        },
                        {
                            "gap": 90.6869,
                            "total_time": 10.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 36720,
                            "explored_time": 10.44,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.9117,
                            "total_time": 10.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 31511,
                            "explored_time": 9.97,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.5015,
                            "total_time": 13.01,
                            "explored_nodes": 143,
                            "simplex_iterations": 72683,
                            "explored_time": 13.0,
                            "work_units": 10.79
                        },
                        {
                            "gap": 93.3583,
                            "total_time": 10.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 32144,
                            "explored_time": 10.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.4,
                            "total_time": 13.02,
                            "explored_nodes": 9932,
                            "simplex_iterations": 303128,
                            "explored_time": 13.0,
                            "work_units": 10.0
                        },
                        {
                            "gap": 41.0882,
                            "total_time": 18.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 28111,
                            "explored_time": 18.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 90.8993,
                            "total_time": 10.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 37288,
                            "explored_time": 10.45,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "2a7467fe-0653-4e95-b3aa-52ae065c5992",
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3"
                    ]
                },
                {
                    "id": "685393b1-5e5f-43ed-84ad-b58f10275db2",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_predecessor_sigma_cuts(m):\n        # 1. Compute Static Heads (r) and Tails (q)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine to find Blocks\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Candidates)\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            # Use block-level metrics: min_r, sum_p, min_q\n            r_min = min(heads[o] for o in ops)\n            q_min = min(tails[o] for o in ops)\n            p_sum = sum(m.p[o] for o in ops)\n            lb = r_min + p_sum + q_min\n            candidates.append({'ops': ops, 'r_min': r_min, 'lb': lb})\n    \n        # Sort blocks by LB to focus on bottlenecks\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n        # 4. Generate Predecessor-Sigma Cuts\n        m.sigma_cuts = pyo.ConstraintList()\n        \n        # Limit to top 3 critical blocks to maintain efficiency\n        for cand in candidates[:3]:\n            ops = cand['ops']\n            r_min = cand['r_min']\n            \n            for u in ops:\n                # Construct expression for the sum of processing times of all v that precede u\n                pred_work = 0\n                for v in ops:\n                    if u == v: continue\n                    \n                    # Determine the binary term representing \"v precedes u\"\n                    # m.Pairs stores (j1, k1, j2, k2) where (j1,k1) < (j2,k2)\n                    # m.y[...] = 1 implies first component precedes second\n                    # m.y[...] = 0 implies second component precedes first\n                    if v < u:\n                        # Pair is (v, u). y[v, u] == 1 => v -> u\n                        is_pred = m.y[v[0], v[1], u[0], u[1]]\n                    else:\n                        # Pair is (u, v). y[u, v] == 0 => v -> u\n                        is_pred = 1 - m.y[u[0], u[1], v[0], v[1]]\n                    \n                    pred_work += m.p[v] * is_pred\n                \n                # Constraint: Cmax >= r_min(block) + p_u + q_u + Work(predecessors)\n                # Validity: The start time of u is at least the earliest release of the set\n                # plus the processing times of all jobs processed before u.\n                m.sigma_cuts.add(\n                    m.Cmax >= r_min + m.p[u] + tails[u] + pred_work\n                )\n    \n    add_predecessor_sigma_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_predecessor_sigma_cuts(m):\n    # 1. Compute Static Heads (r) and Tails (q)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine to find Blocks\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Candidates)\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        # Use block-level metrics: min_r, sum_p, min_q\n        r_min = min(heads[o] for o in ops)\n        q_min = min(tails[o] for o in ops)\n        p_sum = sum(m.p[o] for o in ops)\n        lb = r_min + p_sum + q_min\n        candidates.append({'ops': ops, 'r_min': r_min, 'lb': lb})\n\n    # Sort blocks by LB to focus on bottlenecks\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n\n    # 4. Generate Predecessor-Sigma Cuts\n    m.sigma_cuts = pyo.ConstraintList()\n    \n    # Limit to top 3 critical blocks to maintain efficiency\n    for cand in candidates[:3]:\n        ops = cand['ops']\n        r_min = cand['r_min']\n        \n        for u in ops:\n            # Construct expression for the sum of processing times of all v that precede u\n            pred_work = 0\n            for v in ops:\n                if u == v: continue\n                \n                # Determine the binary term representing \"v precedes u\"\n                # m.Pairs stores (j1, k1, j2, k2) where (j1,k1) < (j2,k2)\n                # m.y[...] = 1 implies first component precedes second\n                # m.y[...] = 0 implies second component precedes first\n                if v < u:\n                    # Pair is (v, u). y[v, u] == 1 => v -> u\n                    is_pred = m.y[v[0], v[1], u[0], u[1]]\n                else:\n                    # Pair is (u, v). y[u, v] == 0 => v -> u\n                    is_pred = 1 - m.y[u[0], u[1], v[0], v[1]]\n                \n                pred_work += m.p[v] * is_pred\n            \n            # Constraint: Cmax >= r_min(block) + p_u + q_u + Work(predecessors)\n            # Validity: The start time of u is at least the earliest release of the set\n            # plus the processing times of all jobs processed before u.\n            m.sigma_cuts.add(\n                m.Cmax >= r_min + m.p[u] + tails[u] + pred_work\n            )\n\nadd_predecessor_sigma_cuts(model)",
                        "idea": "We introduce **Predecessor-Sigma Lifting**, an aggregate constructive bound that generalizes pairwise conflict logic. Instead of examining single pairs, this strategy focuses on critical machine blocks and enforces that the makespan ($C_{max}$) must exceed the block's earliest release time ($r_{min}$) plus the tail of the specific operation ($u$) plus the sum of processing times of all other operations ($v$) sequenced before $u$ (via $\\sum p_v y_{vu}$). This creates a dense linear cut that 'lifts' the objective value in proportion to the volume of work pushed before $u$ by fractional binary variables, effectively approximating the cumulative resource constraint for the linear relaxation."
                    },
                    "fitness": 13.478447834963443,
                    "solver_reports": [
                        {
                            "total_time": 8.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 27611,
                            "explored_time": 8.05,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 30843,
                            "explored_time": 8.3,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.61,
                            "explored_nodes": 1,
                            "simplex_iterations": 27641,
                            "explored_time": 8.55,
                            "work_units": 10.0
                        },
                        {
                            "gap": 56.0156,
                            "total_time": 11.21,
                            "explored_nodes": 59,
                            "simplex_iterations": 100414,
                            "explored_time": 11.19,
                            "work_units": 10.45
                        },
                        {
                            "total_time": 7.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 27138,
                            "explored_time": 7.51,
                            "work_units": 10.0
                        },
                        {
                            "gap": 32.8441,
                            "total_time": 10.62,
                            "explored_nodes": 5405,
                            "simplex_iterations": 332138,
                            "explored_time": 10.6,
                            "work_units": 10.0
                        },
                        {
                            "gap": 45.9784,
                            "total_time": 13.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 32786,
                            "explored_time": 13.1,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 7.76,
                            "explored_nodes": 1,
                            "simplex_iterations": 30822,
                            "explored_time": 7.71,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "2a7467fe-0653-4e95-b3aa-52ae065c5992"
                    ]
                },
                {
                    "id": "92df15d4-85e9-44cb-a9fe-13b5e5ca1bde",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_symmetric_carlier_flow_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Timing Analysis (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Find the sub-segment maximizing Carlier Lower Bound\n            best_lb = -1\n            best_sub = []\n            min_r = 0\n            min_q = 0\n            \n            for i in range(n_ops):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]]\n                curr_q_min = float('inf')\n                for j in range(i, n_ops):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < curr_q_min: curr_q_min = tails[op]\n                    \n                    lb = r_val + p_sum + curr_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n                        min_r = r_val\n                        min_q = curr_q_min\n    \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, 'ops': best_sub, \n                    'min_r': min_r, 'min_q': min_q\n                })\n    \n        if not candidates: return\n        \n        # Select the most critical block globally\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        target = candidates[0]\n        block = target['ops']\n        min_r = target['min_r']\n        min_q = target['min_q']\n        carlier_lb = target['lb']\n    \n        m.sym_flow_cuts = pyo.ConstraintList()\n        m.sym_flow_cuts.add(m.Cmax >= carlier_lb)\n    \n        # Helper: resolve y indices\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_LIMIT = 200\n        count = 0\n    \n        # 3. Symmetric Mass Flow Cuts (P2 Backward + New Forward)\n        # Squeezes the block from both ends using sum of binary assignments\n        for u in block:\n            # (A) Forward Mass Flow: Link Start Time to Predecessors\n            # S_u >= min_release + sum(p_v * y_vu for v in block)\n            # Valid because all v preceding u on same machine must finish before u starts.\n            pred_sum = 0\n            for v in block:\n                if u == v: continue\n                pred_sum += m.p[v] * get_y(v, u) # v precedes u\n            m.sym_flow_cuts.add(m.S[u] >= min_r + pred_sum)\n            \n            # (B) Backward Mass Flow: Link Makespan to Successors (from P2)\n            # Cmax >= S_u + p_u + sum(p_v * y_uv for v in block) + min_tail\n            succ_sum = 0\n            for v in block:\n                if u == v: continue\n                succ_sum += m.p[v] * get_y(u, v) # u precedes v\n            m.sym_flow_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_sum + min_q)\n            \n            count += 2\n            if count >= CUT_LIMIT: break\n    \n        # 4. Metric Lifting on Ambiguous Triplets (P1/P2 Hybrid)\n        if count < CUT_LIMIT:\n            for i in range(len(block)):\n                u = block[i]\n                # Define valid start interval [s, e] based on global LB\n                s_u, e_u = heads[u], carlier_lb - tails[u]\n                \n                for j in range(len(block)):\n                    if i == j: continue\n                    v = block[j]\n                    s_v, e_v = heads[v], carlier_lb - tails[v]\n                    \n                    # P1/P2 Logic: Only lift if windows overlap (sequencing is ambiguous)\n                    if max(s_u, s_v) < min(e_u, e_v):\n                        for k in range(len(block)):\n                            if k == i or k == j: continue\n                            w = block[k]\n                            s_w, e_w = heads[w], carlier_lb - tails[w]\n                            \n                            # Strong Triplet Overlap\n                            if max(s_u, s_v, s_w) < min(e_u, e_v, e_w):\n                                y_uw = get_y(u, w)\n                                y_wv = get_y(w, v)\n                                y_uv = get_y(u, v)\n                                \n                                # Tighten path u->w->v: S_v >= S_u + p_u + p_w\n                                m.sym_flow_cuts.add(\n                                    m.S[v] >= m.S[u] + m.p[u] + \n                                    m.p[w] * (y_uw + y_wv - 1) - \n                                    m.bigM * (1 - y_uv)\n                                )\n                                count += 1\n                            if count >= CUT_LIMIT: break\n                    if count >= CUT_LIMIT: break\n                if count >= CUT_LIMIT: break\n\n    return model\n",
                        "added_cut": "def add_symmetric_carlier_flow_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Timing Analysis (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Find the sub-segment maximizing Carlier Lower Bound\n        best_lb = -1\n        best_sub = []\n        min_r = 0\n        min_q = 0\n        \n        for i in range(n_ops):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]]\n            curr_q_min = float('inf')\n            for j in range(i, n_ops):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < curr_q_min: curr_q_min = tails[op]\n                \n                lb = r_val + p_sum + curr_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n                    min_r = r_val\n                    min_q = curr_q_min\n\n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, 'ops': best_sub, \n                'min_r': min_r, 'min_q': min_q\n            })\n\n    if not candidates: return\n    \n    # Select the most critical block globally\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    target = candidates[0]\n    block = target['ops']\n    min_r = target['min_r']\n    min_q = target['min_q']\n    carlier_lb = target['lb']\n\n    m.sym_flow_cuts = pyo.ConstraintList()\n    m.sym_flow_cuts.add(m.Cmax >= carlier_lb)\n\n    # Helper: resolve y indices\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_LIMIT = 200\n    count = 0\n\n    # 3. Symmetric Mass Flow Cuts (P2 Backward + New Forward)\n    # Squeezes the block from both ends using sum of binary assignments\n    for u in block:\n        # (A) Forward Mass Flow: Link Start Time to Predecessors\n        # S_u >= min_release + sum(p_v * y_vu for v in block)\n        # Valid because all v preceding u on same machine must finish before u starts.\n        pred_sum = 0\n        for v in block:\n            if u == v: continue\n            pred_sum += m.p[v] * get_y(v, u) # v precedes u\n        m.sym_flow_cuts.add(m.S[u] >= min_r + pred_sum)\n        \n        # (B) Backward Mass Flow: Link Makespan to Successors (from P2)\n        # Cmax >= S_u + p_u + sum(p_v * y_uv for v in block) + min_tail\n        succ_sum = 0\n        for v in block:\n            if u == v: continue\n            succ_sum += m.p[v] * get_y(u, v) # u precedes v\n        m.sym_flow_cuts.add(m.Cmax >= m.S[u] + m.p[u] + succ_sum + min_q)\n        \n        count += 2\n        if count >= CUT_LIMIT: break\n\n    # 4. Metric Lifting on Ambiguous Triplets (P1/P2 Hybrid)\n    if count < CUT_LIMIT:\n        for i in range(len(block)):\n            u = block[i]\n            # Define valid start interval [s, e] based on global LB\n            s_u, e_u = heads[u], carlier_lb - tails[u]\n            \n            for j in range(len(block)):\n                if i == j: continue\n                v = block[j]\n                s_v, e_v = heads[v], carlier_lb - tails[v]\n                \n                # P1/P2 Logic: Only lift if windows overlap (sequencing is ambiguous)\n                if max(s_u, s_v) < min(e_u, e_v):\n                    for k in range(len(block)):\n                        if k == i or k == j: continue\n                        w = block[k]\n                        s_w, e_w = heads[w], carlier_lb - tails[w]\n                        \n                        # Strong Triplet Overlap\n                        if max(s_u, s_v, s_w) < min(e_u, e_v, e_w):\n                            y_uw = get_y(u, w)\n                            y_wv = get_y(w, v)\n                            y_uv = get_y(u, v)\n                            \n                            # Tighten path u->w->v: S_v >= S_u + p_u + p_w\n                            m.sym_flow_cuts.add(\n                                m.S[v] >= m.S[u] + m.p[u] + \n                                m.p[w] * (y_uw + y_wv - 1) - \n                                m.bigM * (1 - y_uv)\n                            )\n                            count += 1\n                        if count >= CUT_LIMIT: break\n                if count >= CUT_LIMIT: break\n            if count >= CUT_LIMIT: break",
                        "idea": "We introduce **Symmetric Carlier-Flow Cuts**, a holistic bounding strategy that minimizes joint violation by squeezing the critical block from both directions. It combines Parent 2's **Backward Mass Flow** (which tightly bounds $C_{max}$ based on operation successors) with a novel **Forward Mass Flow** (bounding start times $S_u$ using the sum of predecessors). This symmetric approach creates a stronger convex hull approximation for the disjunctive clique than Big-M constraints alone. We further refine this by integrating Parent 1's **Dynamic Horizon** logic to selectively apply Metric Lifting only to triplets with overlapping Carlier-derived time windows, ensuring computational effort is focused on ambiguous sequencings."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.15,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.37,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.3,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.35,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.34,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.78,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.72,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.07,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.06,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.7,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.01,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "8458d8bf-85a4-44b2-86e9-e78257074e86"
                    ]
                }
            ],
            22.19857710947803
        ],
        [
            [
                {
                    "id": "101328eb-f36a-4ac9-9863-144887bd3271",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_carlier_cuts(m):\n        # 1. Calculate Release (heads) and Delivery (tails) times\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Machine-wise Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        # Maximize r_min + sum(p) + q_min for contiguous blocks\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global LB Constraint and Filtering\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        \n        m.hybrid_carlier = pyo.ConstraintList()\n        m.hybrid_carlier.add(m.Cmax >= global_max)\n    \n        # Select blocks close to global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Hybrid Cut Generation: Dynamic Horizon (P1) + Window Clamp (P2)\n        CUT_BUDGET = 200\n        WINDOW_SIZE = 8 # Safety clamp from P2\n        cuts_added = 0\n        \n        for target in targets[:3]:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon (P1): Stop if j starts too late to affect i's critical path\n                # If heads[j] is large, j is likely after i; if too large, the order is fixed.\n                horizon_limit = global_max - tails[op_i]\n                \n                # Hybrid range: Enforce locality (P2) but respect dynamic bounds (P1)\n                end_j = min(i + WINDOW_SIZE, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # P1 Optimization: If j is too far, subsequent j's (sorted) are also too far\n                    if heads[op_j] >= horizon_limit:\n                        break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # P1 Refinement: Ensure k is relevant to j's tightness\n                        if heads[op_j] >= global_max - tails[op_k]:\n                            continue\n    \n                        # Generate Cuts\n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Transitivity\n                        m.hybrid_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Metric Lifting\n                        m.hybrid_carlier.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_hybrid_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_hybrid_carlier_cuts(m):\n    # 1. Calculate Release (heads) and Delivery (tails) times\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Machine-wise Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    # Maximize r_min + sum(p) + q_min for contiguous blocks\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global LB Constraint and Filtering\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    \n    m.hybrid_carlier = pyo.ConstraintList()\n    m.hybrid_carlier.add(m.Cmax >= global_max)\n\n    # Select blocks close to global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Hybrid Cut Generation: Dynamic Horizon (P1) + Window Clamp (P2)\n    CUT_BUDGET = 200\n    WINDOW_SIZE = 8 # Safety clamp from P2\n    cuts_added = 0\n    \n    for target in targets[:3]:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon (P1): Stop if j starts too late to affect i's critical path\n            # If heads[j] is large, j is likely after i; if too large, the order is fixed.\n            horizon_limit = global_max - tails[op_i]\n            \n            # Hybrid range: Enforce locality (P2) but respect dynamic bounds (P1)\n            end_j = min(i + WINDOW_SIZE, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # P1 Optimization: If j is too far, subsequent j's (sorted) are also too far\n                if heads[op_j] >= horizon_limit:\n                    break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # P1 Refinement: Ensure k is relevant to j's tightness\n                    if heads[op_j] >= global_max - tails[op_k]:\n                        continue\n\n                    # Generate Cuts\n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Transitivity\n                    m.hybrid_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Metric Lifting\n                    m.hybrid_carlier.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_hybrid_carlier_cuts(model)",
                        "idea": "We introduce **Hybrid Adaptive Horizon Cuts**, integrating Parent 1's dynamic slack-based filtering with Parent 2's sliding window locality. The strategy first identifies Carlier-critical blocks (maximizing $r_{min} + \\sum p + q_{min}$) and enforces the global lower bound on $C_{max}$. Inside these blocks, we generate transitivity and metric lifting cuts for triplets $(i, k, j)$. A hybrid selection mechanism is used: we iterate $j$ within a fixed local window (from Parent 2) to manage complexity, but aggressively prune pairs where the release time of $j$ exceeds the slack allowed by the global lower bound (Dynamic Horizon from Parent 1). This ensures cuts target only the tightest, most ambiguous orderings."
                    },
                    "fitness": 22.19857710947803,
                    "solver_reports": [
                        {
                            "gap": 17.1079,
                            "total_time": 13.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 33374,
                            "explored_time": 13.68,
                            "work_units": 10.0
                        },
                        {
                            "gap": 24.3628,
                            "total_time": 10.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 34207,
                            "explored_time": 10.57,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 32336,
                            "explored_time": 9.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 19.3377,
                            "total_time": 13.94,
                            "explored_nodes": 59,
                            "simplex_iterations": 62449,
                            "explored_time": 13.92,
                            "work_units": 10.37
                        },
                        {
                            "total_time": 12.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 32656,
                            "explored_time": 12.22,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 12.17,
                            "explored_nodes": 201,
                            "simplex_iterations": 56875,
                            "explored_time": 12.16,
                            "work_units": 12.25
                        },
                        {
                            "gap": 26.5033,
                            "total_time": 12.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 48824,
                            "explored_time": 12.83,
                            "work_units": 10.0
                        },
                        {
                            "gap": 27.7736,
                            "total_time": 13.94,
                            "explored_nodes": 1,
                            "simplex_iterations": 37863,
                            "explored_time": 13.89,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "6b0cd1d5-d4fa-431f-a101-57b5ec8d5c86"
                    ]
                },
                {
                    "id": "59dc35ff-3928-46da-b5c3-9e5b151d0099",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_selective_hybrid_cuts(m):\n        # 1. Heads/Tails Calculation\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Carlier blocks are sorted by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.selective_carlier = pyo.ConstraintList()\n        m.selective_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Selective Cut Generation\n        # Target top 5 blocks (expanded from P2's 3) for broader coverage\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        CUT_BUDGET = 200\n        WINDOW_SIZE = 12  # Expanded from P2 (8->12) due to selective filtering\n        cuts_added = 0\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for target in targets[:5]:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                horizon_limit = global_max - tails[op_i]\n                \n                # Sliding Window with Slack Check (P2 Logic)\n                end_j = min(i + WINDOW_SIZE, n_sub)\n                \n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic Horizon Filter (P1 Logic)\n                    if heads[op_j] >= horizon_limit:\n                        break\n                    \n                    # Collect valid intermediate operations\n                    potential_k = []\n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        # P1 Filter: Ensure k is relevant to j's tightness\n                        if heads[op_j] < global_max - tails[op_k]:\n                            potential_k.append(k)\n                    \n                    if not potential_k: continue\n    \n                    # SELECTION INNOVATION: Filter for High-Impact Intermediates\n                    # Sort k by processing time (descending) to maximize Lifting strength\n                    potential_k.sort(key=lambda idx: m.p[ops[idx]], reverse=True)\n                    \n                    # Only generate cuts for the top 2 strongest intermediates\n                    for k in potential_k[:2]:\n                        op_k = ops[k]\n                        \n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Transitivity: i->k->j implies i->j\n                        m.selective_carlier.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Metric Lifting: Tighten S_j lower bound using strong p_k\n                        m.selective_carlier.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        \n                        cuts_added += 2\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n    \n    add_selective_hybrid_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_selective_hybrid_cuts(m):\n    # 1. Heads/Tails Calculation\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Carlier blocks are sorted by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.selective_carlier = pyo.ConstraintList()\n    m.selective_carlier.add(m.Cmax >= global_max)\n\n    # 4. Selective Cut Generation\n    # Target top 5 blocks (expanded from P2's 3) for broader coverage\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    CUT_BUDGET = 200\n    WINDOW_SIZE = 12  # Expanded from P2 (8->12) due to selective filtering\n    cuts_added = 0\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for target in targets[:5]:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            horizon_limit = global_max - tails[op_i]\n            \n            # Sliding Window with Slack Check (P2 Logic)\n            end_j = min(i + WINDOW_SIZE, n_sub)\n            \n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic Horizon Filter (P1 Logic)\n                if heads[op_j] >= horizon_limit:\n                    break\n                \n                # Collect valid intermediate operations\n                potential_k = []\n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    # P1 Filter: Ensure k is relevant to j's tightness\n                    if heads[op_j] < global_max - tails[op_k]:\n                        potential_k.append(k)\n                \n                if not potential_k: continue\n\n                # SELECTION INNOVATION: Filter for High-Impact Intermediates\n                # Sort k by processing time (descending) to maximize Lifting strength\n                potential_k.sort(key=lambda idx: m.p[ops[idx]], reverse=True)\n                \n                # Only generate cuts for the top 2 strongest intermediates\n                for k in potential_k[:2]:\n                    op_k = ops[k]\n                    \n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Transitivity: i->k->j implies i->j\n                    m.selective_carlier.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Metric Lifting: Tighten S_j lower bound using strong p_k\n                    m.selective_carlier.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    \n                    cuts_added += 2\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break\n            if cuts_added >= CUT_BUDGET: break\n\nadd_selective_hybrid_cuts(model)",
                        "idea": "We introduce **Selective High-Impact Carlier Cuts**, refining Parent 2's hybrid logic by filtering intermediate operations ($k$) based on processing time intensity. Instead of generating cuts for every triplet within the window, we prioritize the top-2 $k$'s with the largest $p_k$. This maximizes the tightening effect of metric lifting ($S_j \\ge S_i + p_i + p_k$) while conserving the cut budget, enabling an expanded search window (size 12) and broader coverage of critical blocks (top 5 candidates)."
                    },
                    "fitness": 22.51366888632038,
                    "solver_reports": [
                        {
                            "gap": 17.0843,
                            "total_time": 13.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 33205,
                            "explored_time": 13.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.42,
                            "explored_nodes": 1,
                            "simplex_iterations": 33984,
                            "explored_time": 11.37,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 30578,
                            "explored_time": 9.95,
                            "work_units": 10.01
                        },
                        {
                            "gap": 16.3462,
                            "total_time": 13.47,
                            "explored_nodes": 59,
                            "simplex_iterations": 65296,
                            "explored_time": 13.46,
                            "work_units": 10.6
                        },
                        {
                            "total_time": 11.47,
                            "explored_nodes": 1,
                            "simplex_iterations": 30947,
                            "explored_time": 11.4,
                            "work_units": 10.0
                        },
                        {
                            "gap": 3.7565,
                            "total_time": 13.3,
                            "explored_nodes": 1953,
                            "simplex_iterations": 92094,
                            "explored_time": 13.3,
                            "work_units": 10.15
                        },
                        {
                            "gap": 26.1745,
                            "total_time": 11.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 48827,
                            "explored_time": 11.9,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 36859,
                            "explored_time": 9.59,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "92615402-5fb4-4e12-8e41-f682690b6c20",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_symmetric_flow_transitivity_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier-style Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort ops by head time for scan\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            best_r = 0\n            best_q = 0\n            \n            # Find sub-segment maximizing LB = r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                min_q = float('inf')\n                r_val = heads[sorted_ops[i]]\n                current_sub = []\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    if tails[op] < min_q: min_q = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n                        best_r = r_val\n                        best_q = min_q\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, \n                    'ops': best_sub, \n                    'r_min': best_r, \n                    'q_min': best_q\n                })\n    \n        if not candidates: return\n        \n        # Sort by LB descending and pick top targets\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        targets = [c for c in candidates if c['lb'] >= 0.85 * global_max][:3]\n    \n        m.sym_flow_cuts = pyo.ConstraintList()\n    \n        # Helper for y[u,v] = 1 if u -> v\n        def get_y_uv(u, v):\n            # m.y is indexed by (j1, k1, j2, k2) where tuple1 < tuple2\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        added = 0\n        CUT_LIMIT = 200\n    \n        for cand in targets:\n            if added >= CUT_LIMIT: break\n            \n            block = cand['ops']\n            r_min = cand['r_min']\n            q_min = cand['q_min']\n            \n            # A. Symmetric Flow Cuts (Parent 1)\n            # Tighten S[u] from both sides using volume of dynamic predecessors/successors\n            for u in block:\n                pred_vol = 0\n                succ_vol = 0\n                for v in block:\n                    if u == v: continue\n                    y_vu = get_y_uv(v, u) # 1 if v->u\n                    pred_vol += m.p[v] * y_vu\n                    succ_vol += m.p[v] * (1 - y_vu) # 1 if u->v\n                \n                # Forward Flow: S[u] >= r_min + sum(p_v * y_vu)\n                m.sym_flow_cuts.add(m.S[u] >= r_min + pred_vol)\n                \n                # Backward Flow: S[u] <= Cmax - q_min - p[u] - sum(p_v * y_uv)\n                m.sym_flow_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n                \n                added += 2\n                if added >= CUT_LIMIT: break\n            \n            # B. Windowed Transitivity (Parent 2)\n            # Enforce local consistency on y to strengthen the flow sums\n            WINDOW = 5\n            n_blk = len(block)\n            for i_idx in range(n_blk):\n                if added >= CUT_LIMIT: break\n                u = block[i_idx]\n                for j_idx in range(i_idx + 1, min(i_idx + WINDOW, n_blk)):\n                    w = block[j_idx]\n                    # Intermediate v\n                    for k_idx in range(i_idx + 1, j_idx):\n                        v = block[k_idx]\n                        # Triangle u -> v -> w implies y_uv + y_vw - y_uw <= 1\n                        y_uv = get_y_uv(u, v)\n                        y_vw = get_y_uv(v, w)\n                        y_uw = get_y_uv(u, w)\n                        m.sym_flow_cuts.add(y_uv + y_vw - y_uw <= 1)\n                        \n                        added += 1\n                        if added >= CUT_LIMIT: break\n                    if added >= CUT_LIMIT: break\n    \n    add_symmetric_flow_transitivity_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_symmetric_flow_transitivity_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier-style Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort ops by head time for scan\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        best_r = 0\n        best_q = 0\n        \n        # Find sub-segment maximizing LB = r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            min_q = float('inf')\n            r_val = heads[sorted_ops[i]]\n            current_sub = []\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                if tails[op] < min_q: min_q = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n                    best_r = r_val\n                    best_q = min_q\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, \n                'ops': best_sub, \n                'r_min': best_r, \n                'q_min': best_q\n            })\n\n    if not candidates: return\n    \n    # Sort by LB descending and pick top targets\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    targets = [c for c in candidates if c['lb'] >= 0.85 * global_max][:3]\n\n    m.sym_flow_cuts = pyo.ConstraintList()\n\n    # Helper for y[u,v] = 1 if u -> v\n    def get_y_uv(u, v):\n        # m.y is indexed by (j1, k1, j2, k2) where tuple1 < tuple2\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    added = 0\n    CUT_LIMIT = 200\n\n    for cand in targets:\n        if added >= CUT_LIMIT: break\n        \n        block = cand['ops']\n        r_min = cand['r_min']\n        q_min = cand['q_min']\n        \n        # A. Symmetric Flow Cuts (Parent 1)\n        # Tighten S[u] from both sides using volume of dynamic predecessors/successors\n        for u in block:\n            pred_vol = 0\n            succ_vol = 0\n            for v in block:\n                if u == v: continue\n                y_vu = get_y_uv(v, u) # 1 if v->u\n                pred_vol += m.p[v] * y_vu\n                succ_vol += m.p[v] * (1 - y_vu) # 1 if u->v\n            \n            # Forward Flow: S[u] >= r_min + sum(p_v * y_vu)\n            m.sym_flow_cuts.add(m.S[u] >= r_min + pred_vol)\n            \n            # Backward Flow: S[u] <= Cmax - q_min - p[u] - sum(p_v * y_uv)\n            m.sym_flow_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n            \n            added += 2\n            if added >= CUT_LIMIT: break\n        \n        # B. Windowed Transitivity (Parent 2)\n        # Enforce local consistency on y to strengthen the flow sums\n        WINDOW = 5\n        n_blk = len(block)\n        for i_idx in range(n_blk):\n            if added >= CUT_LIMIT: break\n            u = block[i_idx]\n            for j_idx in range(i_idx + 1, min(i_idx + WINDOW, n_blk)):\n                w = block[j_idx]\n                # Intermediate v\n                for k_idx in range(i_idx + 1, j_idx):\n                    v = block[k_idx]\n                    # Triangle u -> v -> w implies y_uv + y_vw - y_uw <= 1\n                    y_uv = get_y_uv(u, v)\n                    y_vw = get_y_uv(v, w)\n                    y_uw = get_y_uv(u, w)\n                    m.sym_flow_cuts.add(y_uv + y_vw - y_uw <= 1)\n                    \n                    added += 1\n                    if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n\nadd_symmetric_flow_transitivity_cuts(model)",
                        "idea": "We introduce **Symmetric Flow-Transitivity Cuts**, a hybrid strategy combining Parent 1's **Bi-Directional Flow** bounds with Parent 2's **Windowed Transitivity**. For the most critical blocks, we enforce strict time corridors on every operation: a **Forward Flow** bound ($S_u \\ge r_{min} + \\sum p_v y_{vu}$) and a **Backward Flow** bound ($S_u \\le C_{max} - q_{min} - p_u - \\sum p_v y_{uv}$). Crucially, we simultaneously apply **local transitivity constraints** ($y_{uv} + y_{vw} \\le 1 + y_{uw}$) on triples within these blocks. This synergy prevents the solver from satisfying the flow volume sums with inconsistent or cyclic binary values, yielding a significantly tighter relaxation for the bottleneck sequence."
                    },
                    "fitness": 16.922784794948818,
                    "solver_reports": [
                        {
                            "total_time": 9.57,
                            "explored_nodes": 1,
                            "simplex_iterations": 24715,
                            "explored_time": 9.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 15802,
                            "explored_time": 10.25,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.43,
                            "explored_nodes": 1,
                            "simplex_iterations": 38559,
                            "explored_time": 8.36,
                            "work_units": 10.0
                        },
                        {
                            "gap": 37.2923,
                            "total_time": 10.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 37388,
                            "explored_time": 10.84,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 26295,
                            "explored_time": 9.75,
                            "work_units": 10.0
                        },
                        {
                            "gap": 18.8875,
                            "total_time": 10.74,
                            "explored_nodes": 198,
                            "simplex_iterations": 67797,
                            "explored_time": 10.73,
                            "work_units": 10.27
                        },
                        {
                            "gap": 40.8477,
                            "total_time": 9.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 39644,
                            "explored_time": 9.56,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 23494,
                            "explored_time": 9.57,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "78e90a98-0c11-4951-adc9-ad3d6d1d1d76",
                        "037029f9-9069-467e-8d79-4de73f14f524"
                    ]
                },
                {
                    "id": "495deea1-afdd-4ad3-94d1-a2fdc00e66a9",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_triplet_path_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        # Forward pass for release times\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass for delivery times\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier-style bottleneck detection)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads to approximate natural flow\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            r_min = heads[sorted_ops[0]]\n            q_min = min(tails[op] for op in ops)\n            p_sum = sum(m.p[op] for op in ops)\n            lb = r_min + p_sum + q_min\n            candidates.append({'mid': mid, 'lb': lb, 'ops': sorted_ops})\n    \n        if not candidates: return\n        \n        # Sort blocks by tightness (Lower Bound)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_lb = candidates[0]['lb']\n        # Filter: only generate cuts for blocks and paths that threaten the Global LB\n        threshold = 0.85 * global_lb \n        \n        m.triplet_path_cuts = pyo.ConstraintList()\n    \n        # Helper to retrieve directed binary variable y[u,v] (1 if u->v)\n        def get_prec_expr(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        added = 0\n        CUT_LIMIT = 150\n        WINDOW = 7 # Look-ahead window for triplets\n    \n        # 3. Generate Sequence-Conditional Objective Cuts\n        for cand in candidates:\n            if cand['lb'] < threshold: break\n            ops = cand['ops']\n            n = len(ops)\n            if n < 3: continue\n            \n            for i in range(n):\n                op_i = ops[i]\n                # Heuristic pruning: if i starts very late, it's unlikely to head a critical chain\n                if heads[op_i] > global_lb * 0.7: continue\n    \n                for j_idx in range(i + 1, min(i + WINDOW, n)):\n                    op_j = ops[j_idx]\n                    \n                    for k_idx in range(j_idx + 1, min(j_idx + WINDOW, n)):\n                        op_k = ops[k_idx]\n                        \n                        # Evaluate the specific path latency: Head(i) -> i -> j -> k -> Tail(k)\n                        # This path exists only if y_ij=1 AND y_jk=1\n                        path_cost = heads[op_i] + m.p[op_i] + m.p[op_j] + m.p[op_k] + tails[op_k]\n                        \n                        # If this sequence forces Cmax higher than threshold, add the cut\n                        if path_cost > threshold:\n                            y_ij = get_prec_expr(op_i, op_j)\n                            y_jk = get_prec_expr(op_j, op_k)\n                            \n                            # Constraint: Cmax >= PathCost * (y_ij + y_jk - 1)\n                            # If y_ij=1 and y_jk=1, RHS = PathCost. Else RHS <= 0 (inactive).\n                            m.triplet_path_cuts.add(\n                                m.Cmax >= path_cost * (y_ij + y_jk - 1)\n                            )\n                            added += 1\n                            if added >= CUT_LIMIT: break\n                    if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n\n    return model\n",
                        "added_cut": "def add_critical_triplet_path_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    # Forward pass for release times\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass for delivery times\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier-style bottleneck detection)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads to approximate natural flow\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        r_min = heads[sorted_ops[0]]\n        q_min = min(tails[op] for op in ops)\n        p_sum = sum(m.p[op] for op in ops)\n        lb = r_min + p_sum + q_min\n        candidates.append({'mid': mid, 'lb': lb, 'ops': sorted_ops})\n\n    if not candidates: return\n    \n    # Sort blocks by tightness (Lower Bound)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_lb = candidates[0]['lb']\n    # Filter: only generate cuts for blocks and paths that threaten the Global LB\n    threshold = 0.85 * global_lb \n    \n    m.triplet_path_cuts = pyo.ConstraintList()\n\n    # Helper to retrieve directed binary variable y[u,v] (1 if u->v)\n    def get_prec_expr(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    added = 0\n    CUT_LIMIT = 150\n    WINDOW = 7 # Look-ahead window for triplets\n\n    # 3. Generate Sequence-Conditional Objective Cuts\n    for cand in candidates:\n        if cand['lb'] < threshold: break\n        ops = cand['ops']\n        n = len(ops)\n        if n < 3: continue\n        \n        for i in range(n):\n            op_i = ops[i]\n            # Heuristic pruning: if i starts very late, it's unlikely to head a critical chain\n            if heads[op_i] > global_lb * 0.7: continue\n\n            for j_idx in range(i + 1, min(i + WINDOW, n)):\n                op_j = ops[j_idx]\n                \n                for k_idx in range(j_idx + 1, min(j_idx + WINDOW, n)):\n                    op_k = ops[k_idx]\n                    \n                    # Evaluate the specific path latency: Head(i) -> i -> j -> k -> Tail(k)\n                    # This path exists only if y_ij=1 AND y_jk=1\n                    path_cost = heads[op_i] + m.p[op_i] + m.p[op_j] + m.p[op_k] + tails[op_k]\n                    \n                    # If this sequence forces Cmax higher than threshold, add the cut\n                    if path_cost > threshold:\n                        y_ij = get_prec_expr(op_i, op_j)\n                        y_jk = get_prec_expr(op_j, op_k)\n                        \n                        # Constraint: Cmax >= PathCost * (y_ij + y_jk - 1)\n                        # If y_ij=1 and y_jk=1, RHS = PathCost. Else RHS <= 0 (inactive).\n                        m.triplet_path_cuts.add(\n                            m.Cmax >= path_cost * (y_ij + y_jk - 1)\n                        )\n                        added += 1\n                        if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n            if added >= CUT_LIMIT: break",
                        "idea": "We introduce **Critical Triplet Path Cuts**, a strategy that directly links binary sequence decisions to the global objective ($C_{max}$) without relying on intermediate Start Time variables. Unlike Parent 1 (which bounds $S_u$ via flow volume) and Parent 2 (which enforces logical transitivity), this approach evaluates the mandatory 'Path Cost' (Head $i$ + $p_i$ + $p_j$ + $p_k$ + Tail $k$) of specific triplets $(i, j, k)$ within critical blocks. If a sequence $i \\to j \\to k$ implies a makespan exceeding a threshold, we enforce $C_{max} \\ge \\text{Cost} \\cdot (y_{ij} + y_{jk} - 1)$. This creates a 'Cost Oracle' that penalizes high-latency local orderings directly in the objective function, guiding the solver away from sub-optimal branches by raising their relaxation bounds immediately."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.11,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 16.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 16.13,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.76,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.17,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.16,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.25,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 13.04,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 13.03,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.8,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.79,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "78e90a98-0c11-4951-adc9-ad3d6d1d1d76",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "04fb62fa-3123-40a3-b0d0-6f58f5588574",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_multi_scale_machine_flow_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Scan all sub-windows (subsets) on every machine to find critical sections\n        # We look for nested blocks where LB = r_min + sum(p) + q_min is high.\n        candidates = []\n        est_global_max = 0\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort operations by release time (head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Examine all contiguous sub-segments\n            for i in range(n_ops):\n                p_sum = 0\n                # Track min tail in the current window\n                # (For exactness we scan, or one could optimize, but N is small)\n                window_ops = []\n                current_min_q = float('inf')\n                \n                r_val = heads[sorted_ops[i]] # Min head is fixed at start due to sorting\n    \n                for j_idx in range(i, n_ops):\n                    op = sorted_ops[j_idx]\n                    window_ops.append(op)\n                    p_sum += m.p[op]\n                    if tails[op] < current_min_q:\n                        current_min_q = tails[op]\n                    \n                    lb = r_val + p_sum + current_min_q\n                    if lb > est_global_max:\n                        est_global_max = lb\n                    \n                    candidates.append({\n                        'lb': lb,\n                        'ops': list(window_ops),\n                        'r_min': r_val,\n                        'q_min': current_min_q\n                    })\n    \n        # 4. Filter and Apply Cuts\n        # We target the top critical windows. A threshold (e.g., 90% of max LB) ensures quality.\n        threshold = 0.90 * est_global_max\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n        # Limit the number of blocks processed to control model size\n        BLOCK_LIMIT = 20\n        added_blocks = 0\n        \n        m.multi_scale_cuts = pyo.ConstraintList()\n        \n        for cand in candidates:\n            if cand['lb'] < threshold: break\n            if added_blocks >= BLOCK_LIMIT: break\n            \n            block = cand['ops']\n            r_min = cand['r_min']\n            q_min = cand['q_min']\n            \n            # For each operation in this critical window, enforce flow bounds\n            for u in block:\n                lhs_fwd = 0\n                lhs_bwd = 0\n                \n                for v in block:\n                    if v == u: continue\n                    \n                    # Resolve binary variable for precedence v <-> u\n                    # The model stores y[j1,k1,j2,k2] where (j1,k1) < (j2,k2)\n                    if v < u:\n                        # y[v,u]=1 => v->u. We need v->u for fwd flow.\n                        is_v_pre_u = m.y[v[0], v[1], u[0], u[1]]\n                        # if y[v,u]=0 => u->v. We need u->v for bwd flow.\n                        is_u_pre_v = 1 - is_v_pre_u\n                    else:\n                        # y[u,v]=1 => u->v.\n                        is_u_pre_v = m.y[u[0], u[1], v[0], v[1]]\n                        is_v_pre_u = 1 - is_u_pre_v\n                    \n                    # Accumulate processing times based on sequence\n                    lhs_fwd += m.p[v] * is_v_pre_u\n                    lhs_bwd += m.p[v] * is_u_pre_v\n                \n                # Forward Cut: S[u] must be after the volume of predecessors + window start\n                m.multi_scale_cuts.add(m.S[u] >= r_min + lhs_fwd)\n                \n                # Backward Cut: Cmax must accommodate u, successors, and window tail\n                m.multi_scale_cuts.add(m.Cmax >= m.S[u] + m.p[u] + lhs_bwd + q_min)\n            \n            added_blocks += 1\n\n    return model\n",
                        "added_cut": "def add_multi_scale_machine_flow_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Scan all sub-windows (subsets) on every machine to find critical sections\n    # We look for nested blocks where LB = r_min + sum(p) + q_min is high.\n    candidates = []\n    est_global_max = 0\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort operations by release time (head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Examine all contiguous sub-segments\n        for i in range(n_ops):\n            p_sum = 0\n            # Track min tail in the current window\n            # (For exactness we scan, or one could optimize, but N is small)\n            window_ops = []\n            current_min_q = float('inf')\n            \n            r_val = heads[sorted_ops[i]] # Min head is fixed at start due to sorting\n\n            for j_idx in range(i, n_ops):\n                op = sorted_ops[j_idx]\n                window_ops.append(op)\n                p_sum += m.p[op]\n                if tails[op] < current_min_q:\n                    current_min_q = tails[op]\n                \n                lb = r_val + p_sum + current_min_q\n                if lb > est_global_max:\n                    est_global_max = lb\n                \n                candidates.append({\n                    'lb': lb,\n                    'ops': list(window_ops),\n                    'r_min': r_val,\n                    'q_min': current_min_q\n                })\n\n    # 4. Filter and Apply Cuts\n    # We target the top critical windows. A threshold (e.g., 90% of max LB) ensures quality.\n    threshold = 0.90 * est_global_max\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n\n    # Limit the number of blocks processed to control model size\n    BLOCK_LIMIT = 20\n    added_blocks = 0\n    \n    m.multi_scale_cuts = pyo.ConstraintList()\n    \n    for cand in candidates:\n        if cand['lb'] < threshold: break\n        if added_blocks >= BLOCK_LIMIT: break\n        \n        block = cand['ops']\n        r_min = cand['r_min']\n        q_min = cand['q_min']\n        \n        # For each operation in this critical window, enforce flow bounds\n        for u in block:\n            lhs_fwd = 0\n            lhs_bwd = 0\n            \n            for v in block:\n                if v == u: continue\n                \n                # Resolve binary variable for precedence v <-> u\n                # The model stores y[j1,k1,j2,k2] where (j1,k1) < (j2,k2)\n                if v < u:\n                    # y[v,u]=1 => v->u. We need v->u for fwd flow.\n                    is_v_pre_u = m.y[v[0], v[1], u[0], u[1]]\n                    # if y[v,u]=0 => u->v. We need u->v for bwd flow.\n                    is_u_pre_v = 1 - is_v_pre_u\n                else:\n                    # y[u,v]=1 => u->v.\n                    is_u_pre_v = m.y[u[0], u[1], v[0], v[1]]\n                    is_v_pre_u = 1 - is_u_pre_v\n                \n                # Accumulate processing times based on sequence\n                lhs_fwd += m.p[v] * is_v_pre_u\n                lhs_bwd += m.p[v] * is_u_pre_v\n            \n            # Forward Cut: S[u] must be after the volume of predecessors + window start\n            m.multi_scale_cuts.add(m.S[u] >= r_min + lhs_fwd)\n            \n            # Backward Cut: Cmax must accommodate u, successors, and window tail\n            m.multi_scale_cuts.add(m.Cmax >= m.S[u] + m.p[u] + lhs_bwd + q_min)\n        \n        added_blocks += 1",
                        "idea": "We generalize the single-block strategy to **Multi-Scale Machine Flow Cuts**. Instead of generating cuts for only the single 'worst' bottleneck block per machine, this mutation scans all contiguous sub-segments (windows) of operations on every machine to identify multiple critical and near-critical sets. This approach captures 'nested' bottlenecks where a smaller subset of operations possesses a significantly higher release time ($r_{min}$) or tail ($q_{min}$) than the enclosing block. By imposing the symmetric flow constraints ($S_u \\ge r_{min} + \\dots$ and $C_{max} \\ge S_u + p_u + \\dots$) on these tighter sub-windows, we create a denser system of valid inequalities that restricts the feasible region for Start Times more effectively than a single global cut."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.17,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 16.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.96,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.16,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.1,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.09,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.18,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 13.06,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 13.05,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.84,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.87,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "78e90a98-0c11-4951-adc9-ad3d6d1d1d76"
                    ]
                },
                {
                    "id": "202e82ac-6511-4481-81da-85d4a18caad7",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_flow_lifting_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Timing (Heads/Tails) for Bounds\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        # Find blocks maximizing r_min + sum(p) + q_min\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads for Carlier scan\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            best_r = 0\n            best_q = 0\n            \n            # O(N^2) scan for tightest sub-segment\n            for i in range(n):\n                p_sum = 0\n                current_q_min = float('inf')\n                r_val = heads[sorted_ops[i]]\n                current_sub = []\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op] \n                    if tails[op] < current_q_min: current_q_min = tails[op]\n                    current_sub.append(op)\n                    \n                    lb = r_val + p_sum + current_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = list(current_sub)\n                        best_r = r_val\n                        best_q = current_q_min\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb, 'ops': best_sub, \n                    'r': best_r, 'q': best_q\n                })\n    \n        if not candidates: return\n        \n        # Sort and Filter (Parent 2 Threshold Strategy)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        # Keep only blocks within 90% of global Carlier LB\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        \n        m.hybrid_cuts = pyo.ConstraintList()\n        \n        # Helper: Returns expression for 1 if u -> v, else 0\n        def get_y_expr(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        added_count = 0\n        CUT_LIMIT = 150\n        \n        # 3. Apply Hybrid Cuts to Top Critical Blocks\n        for cand in targets[:3]: # Focus on top 3 bottlenecks\n            if added_count >= CUT_LIMIT: break\n            \n            block = cand['ops']\n            r_min = cand['r']\n            q_min = cand['q']\n            n_blk = len(block)\n            \n            # --- A. Symmetric Flow Cuts (from Parent 1) ---\n            # Creates a \"Time Corridor\": S[u] is bounded by the volume of predecessors/successors\n            # This stabilizes the continuous variables relative to the binary decisions.\n            for u in block:\n                pred_vol = 0\n                succ_vol = 0\n                for v in block:\n                    if u == v: continue\n                    y_vu = get_y_expr(v, u) # 1 if v -> u\n                    y_uv = 1 - y_vu         # 1 if u -> v\n                    \n                    pred_vol += m.p[v] * y_vu\n                    succ_vol += m.p[v] * y_uv\n                \n                # Forward Flow: S[u] >= r_min + Sum(p[v] | v->u)\n                m.hybrid_cuts.add(m.S[u] >= r_min + pred_vol)\n                \n                # Backward Flow: Cmax >= S[u] + p[u] + Sum(p[v] | u->v) + q_min\n                m.hybrid_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n                \n                added_count += 2\n            \n            # --- B. Metric Lifting Cuts (from Parent 2) ---\n            # \"Dynamic Horizon\": Enforce local transitivity on triplets within the block\n            # Only checks triplets that can conceivably overlap given the global LB.\n            for i in range(n_blk):\n                op_i = block[i]\n                limit = global_max - tails[op_i] # Parent 2's overlap logic\n                \n                for j in range(i + 1, n_blk):\n                    op_j = block[j]\n                    if heads[op_j] >= limit: break # Out of dynamic window\n                    \n                    for k in range(i + 1, j):\n                        op_k = block[k]\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n                        \n                        # If i -> k -> j, tighten S[j] relative to S[i]\n                        y_ij = get_y_expr(op_i, op_j)\n                        y_ik = get_y_expr(op_i, op_k)\n                        y_kj = get_y_expr(op_k, op_j)\n                        \n                        # Cut: S[j] >= S[i] + p[i] + p[k] * (y_ik + y_kj - 1) - M(1 - y_ij)\n                        m.hybrid_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                            m.p[op_k] * (y_ik + y_kj - 1) - \n                            m.bigM * (1 - y_ij)\n                        )\n                        added_count += 1\n                        if added_count >= CUT_LIMIT: break\n                    if added_count >= CUT_LIMIT: break\n                if added_count >= CUT_LIMIT: break\n\n    return model\n",
                        "added_cut": "def add_hybrid_flow_lifting_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Timing (Heads/Tails) for Bounds\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    # Find blocks maximizing r_min + sum(p) + q_min\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads for Carlier scan\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        best_r = 0\n        best_q = 0\n        \n        # O(N^2) scan for tightest sub-segment\n        for i in range(n):\n            p_sum = 0\n            current_q_min = float('inf')\n            r_val = heads[sorted_ops[i]]\n            current_sub = []\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op] \n                if tails[op] < current_q_min: current_q_min = tails[op]\n                current_sub.append(op)\n                \n                lb = r_val + p_sum + current_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = list(current_sub)\n                    best_r = r_val\n                    best_q = current_q_min\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb, 'ops': best_sub, \n                'r': best_r, 'q': best_q\n            })\n\n    if not candidates: return\n    \n    # Sort and Filter (Parent 2 Threshold Strategy)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    # Keep only blocks within 90% of global Carlier LB\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    \n    m.hybrid_cuts = pyo.ConstraintList()\n    \n    # Helper: Returns expression for 1 if u -> v, else 0\n    def get_y_expr(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    added_count = 0\n    CUT_LIMIT = 150\n    \n    # 3. Apply Hybrid Cuts to Top Critical Blocks\n    for cand in targets[:3]: # Focus on top 3 bottlenecks\n        if added_count >= CUT_LIMIT: break\n        \n        block = cand['ops']\n        r_min = cand['r']\n        q_min = cand['q']\n        n_blk = len(block)\n        \n        # --- A. Symmetric Flow Cuts (from Parent 1) ---\n        # Creates a \"Time Corridor\": S[u] is bounded by the volume of predecessors/successors\n        # This stabilizes the continuous variables relative to the binary decisions.\n        for u in block:\n            pred_vol = 0\n            succ_vol = 0\n            for v in block:\n                if u == v: continue\n                y_vu = get_y_expr(v, u) # 1 if v -> u\n                y_uv = 1 - y_vu         # 1 if u -> v\n                \n                pred_vol += m.p[v] * y_vu\n                succ_vol += m.p[v] * y_uv\n            \n            # Forward Flow: S[u] >= r_min + Sum(p[v] | v->u)\n            m.hybrid_cuts.add(m.S[u] >= r_min + pred_vol)\n            \n            # Backward Flow: Cmax >= S[u] + p[u] + Sum(p[v] | u->v) + q_min\n            m.hybrid_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n            \n            added_count += 2\n        \n        # --- B. Metric Lifting Cuts (from Parent 2) ---\n        # \"Dynamic Horizon\": Enforce local transitivity on triplets within the block\n        # Only checks triplets that can conceivably overlap given the global LB.\n        for i in range(n_blk):\n            op_i = block[i]\n            limit = global_max - tails[op_i] # Parent 2's overlap logic\n            \n            for j in range(i + 1, n_blk):\n                op_j = block[j]\n                if heads[op_j] >= limit: break # Out of dynamic window\n                \n                for k in range(i + 1, j):\n                    op_k = block[k]\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n                    \n                    # If i -> k -> j, tighten S[j] relative to S[i]\n                    y_ij = get_y_expr(op_i, op_j)\n                    y_ik = get_y_expr(op_i, op_k)\n                    y_kj = get_y_expr(op_k, op_j)\n                    \n                    # Cut: S[j] >= S[i] + p[i] + p[k] * (y_ik + y_kj - 1) - M(1 - y_ij)\n                    m.hybrid_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                        m.p[op_k] * (y_ik + y_kj - 1) - \n                        m.bigM * (1 - y_ij)\n                    )\n                    added_count += 1\n                    if added_count >= CUT_LIMIT: break\n                if added_count >= CUT_LIMIT: break\n            if added_count >= CUT_LIMIT: break",
                        "idea": "We introduce **Hybrid Flow-Lifting Cuts**, a strategy that combines the macro-stabilization of Parent 1's **Bi-Directional Flow Cuts** with the micro-tightening of Parent 2's **Dynamic Horizon Lifting**. The constraint first identifies critical Carlier blocks using Parent 2's stricter global-LB filtering. For these blocks, it applies (A) **Volume Bounds**: $S_u \\ge r_{min} + \\sum p_v y_{vu}$ and $S_u \\le C_{max} - q_{min} - p_u - \\sum p_v y_{uv}$, creating a tight global corridor for operation start times. It then applies (B) **Metric Lifting**: $S_j \\ge S_i + p_i + p_k(y_{ik} + y_{kj} - 1)$ on triplets $(i, k, j)$ filtered by Parent 2's dynamic horizon logic (checking if release/tail times allow overlap). This sandwiches the feasible region by constraining both the aggregate displacement of the block and the specific spacing of local sequences."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.22,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.86,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.3,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.91,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.89,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.2,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 13.0,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.99,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.8,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.71,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "78e90a98-0c11-4951-adc9-ad3d6d1d1d76",
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3"
                    ]
                },
                {
                    "id": "4cb7f99e-35a7-4fd6-892f-2e8c5d5d6272",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_dynamic_clique_mass_cuts(m):\n        import pyomo.environ as pyo\n        \n        # 1. Precompute Timing (Heads/Tails)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            \n            # Find tightest sub-segment maximizing r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                curr_q_min = float('inf')\n                r_val = heads[sorted_ops[i]]\n                for j in range(i, n):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < curr_q_min: curr_q_min = tails[op]\n                    lb = r_val + p_sum + curr_q_min\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n    \n        # Target top blocks (Parent 1/2 Strategy)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    \n        m.dynamic_mass_cuts = pyo.ConstraintList()\n        m.dynamic_mass_cuts.add(m.Cmax >= global_max)\n    \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_BUDGET = 250\n        count = 0\n    \n        for target in targets:\n            block = target['ops']\n            # Conservative tail for validity over the whole block\n            block_q_min = min(tails[op] for op in block)\n            n_blk = len(block)\n            \n            for i in range(n_blk):\n                u = block[i]\n                # Dynamic Horizon (Parent 2): Define window of operations v that can \n                # tightly overlap with u based on Global LB. \n                # If r_v >= global_max - q_u, v starts too late to constrain u tightly.\n                horizon_limit = global_max - tails[u]\n                \n                clique = []\n                for j in range(i + 1, n_blk):\n                    v = block[j]\n                    if heads[v] >= horizon_limit:\n                        break # Parent 2's dynamic break logic\n                    clique.append(v)\n                \n                if not clique: continue\n    \n                # A. Sparse Mass Flow (Parent 1 Idea on P2 Window)\n                # Apply Cmax bound summing p_v only for successors in the dynamic clique.\n                # This concentrates 'mass' pressure where ordering is ambiguous.\n                mass_expr = m.S[u] + m.p[u] + sum(m.p[v] * get_y(u, v) for v in clique) + block_q_min\n                m.dynamic_mass_cuts.add(m.Cmax >= mass_expr)\n                count += 1\n                if count >= CUT_BUDGET: break\n    \n                # B. Metric Lifting (Parent 2 Strength)\n                # Apply transitivity/lifting only on triplets within this tight clique\n                for v_idx, v in enumerate(clique):\n                    for k_idx in range(v_idx):\n                        k = clique[k_idx] # intermediate\n                        \n                        # Refined Overlap Check (P2): k must also overlap v\n                        if heads[v] >= global_max - tails[k]:\n                            continue\n                            \n                        y_uk = get_y(u, k)\n                        y_kv = get_y(k, v)\n                        y_uv = get_y(u, v)\n                        \n                        # Transitivity\n                        m.dynamic_mass_cuts.add(y_uk + y_kv - y_uv <= 1)\n                        \n                        # Lifting: S_v >= S_u + p_u + p_k (if u->k->v)\n                        m.dynamic_mass_cuts.add(\n                            m.S[v] >= m.S[u] + m.p[u] + m.p[k]*(y_uk + y_kv - 1) - m.bigM*(1 - y_uv)\n                        )\n                        count += 2\n                        if count >= CUT_BUDGET: break\n                    if count >= CUT_BUDGET: break\n                if count >= CUT_BUDGET: break\n            if count >= CUT_BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_dynamic_clique_mass_cuts(m):\n    import pyomo.environ as pyo\n    \n    # 1. Precompute Timing (Heads/Tails)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        \n        # Find tightest sub-segment maximizing r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            curr_q_min = float('inf')\n            r_val = heads[sorted_ops[i]]\n            for j in range(i, n):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < curr_q_min: curr_q_min = tails[op]\n                lb = r_val + p_sum + curr_q_min\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n\n    # Target top blocks (Parent 1/2 Strategy)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n\n    m.dynamic_mass_cuts = pyo.ConstraintList()\n    m.dynamic_mass_cuts.add(m.Cmax >= global_max)\n\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_BUDGET = 250\n    count = 0\n\n    for target in targets:\n        block = target['ops']\n        # Conservative tail for validity over the whole block\n        block_q_min = min(tails[op] for op in block)\n        n_blk = len(block)\n        \n        for i in range(n_blk):\n            u = block[i]\n            # Dynamic Horizon (Parent 2): Define window of operations v that can \n            # tightly overlap with u based on Global LB. \n            # If r_v >= global_max - q_u, v starts too late to constrain u tightly.\n            horizon_limit = global_max - tails[u]\n            \n            clique = []\n            for j in range(i + 1, n_blk):\n                v = block[j]\n                if heads[v] >= horizon_limit:\n                    break # Parent 2's dynamic break logic\n                clique.append(v)\n            \n            if not clique: continue\n\n            # A. Sparse Mass Flow (Parent 1 Idea on P2 Window)\n            # Apply Cmax bound summing p_v only for successors in the dynamic clique.\n            # This concentrates 'mass' pressure where ordering is ambiguous.\n            mass_expr = m.S[u] + m.p[u] + sum(m.p[v] * get_y(u, v) for v in clique) + block_q_min\n            m.dynamic_mass_cuts.add(m.Cmax >= mass_expr)\n            count += 1\n            if count >= CUT_BUDGET: break\n\n            # B. Metric Lifting (Parent 2 Strength)\n            # Apply transitivity/lifting only on triplets within this tight clique\n            for v_idx, v in enumerate(clique):\n                for k_idx in range(v_idx):\n                    k = clique[k_idx] # intermediate\n                    \n                    # Refined Overlap Check (P2): k must also overlap v\n                    if heads[v] >= global_max - tails[k]:\n                        continue\n                        \n                    y_uk = get_y(u, k)\n                    y_kv = get_y(k, v)\n                    y_uv = get_y(u, v)\n                    \n                    # Transitivity\n                    m.dynamic_mass_cuts.add(y_uk + y_kv - y_uv <= 1)\n                    \n                    # Lifting: S_v >= S_u + p_u + p_k (if u->k->v)\n                    m.dynamic_mass_cuts.add(\n                        m.S[v] >= m.S[u] + m.p[u] + m.p[k]*(y_uk + y_kv - 1) - m.bigM*(1 - y_uv)\n                    )\n                    count += 2\n                    if count >= CUT_BUDGET: break\n                if count >= CUT_BUDGET: break\n            if count >= CUT_BUDGET: break\n        if count >= CUT_BUDGET: break",
                        "idea": "We introduce **Dynamic Clique Mass Flow**, merging Parent 2's high-fitness **LB-based horizon filtering** with Parent 1's **Mass Flow** aggregation. While Parent 2 used global lower bounds to define 'overlap horizons' solely for transitivity cuts, it missed the direct objective tightening of Parent 1. This offspring identifies **dynamic cliques** of operations where the release time $r_j$ allows strict overlap with the latest finish of $i$ ($r_j < LB - q_i$). On these tight sub-windows, we apply (1) **Sparse Mass Flow** cuts ($C_{max} \\ge S_u + p_u + \\sum_{clique} p_v y_{uv} + q_{min}$) to bind the objective using only relevant variables, and (2) **Metric Lifting** on triplets to enforce local consistency. This synergy applies the strongest known bounds (Mass Flow) exactly where the schedule density is highest (Dynamic Horizon), avoiding model bloat from irrelevant pairs."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.02,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 16.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 16.1,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.41,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.38,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.37,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.33,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.84,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.83,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.72,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.01,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "037029f9-9069-467e-8d79-4de73f14f524",
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3"
                    ]
                }
            ],
            23.42775824076793
        ],
        [
            [
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "b7ca7772-8f72-46ac-b2d3-6de5a9f6a8ec",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_path_lifting_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Static Analysis: Heads (Release) and Tails (Delivery)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            # Iterate backwards for tails (work remaining after op)\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier-style)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Approximated flow order based on release times\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Find tightest sub-block\n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # Sort candidates by Lower Bound to target bottleneck machines\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_lb = candidates[0]['lb']\n        \n        # Filter: Process only near-critical blocks\n        targets = [c for c in candidates if c['lb'] >= 0.85 * global_lb]\n    \n        m.cp_lifting_cuts = pyo.ConstraintList()\n        CUT_BUDGET = 200\n        added_cuts = 0\n        tail_cuts_added = set()\n        \n        # Helper for directional variable access\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Generate Hybrid Cuts\n        for target in targets:\n            ops = target['ops']\n            n = len(ops)\n            if n < 3: continue\n            \n            # Iterate triplets (i -> ... -> j)\n            for i in range(n):\n                op_i = ops[i]\n                # Limit search window to avoid loose pairs\n                for j in range(i + 1, min(i + 8, n)):\n                    op_j = ops[j]\n                    \n                    # Identify potential intermediates k between i and j in sorted list\n                    intermediates = []\n                    for k in range(i + 1, j):\n                        intermediates.append(k)\n                    if not intermediates: continue\n    \n                    # SELECTION (Parent 2): Prioritize high-impact intermediates (large processing time)\n                    intermediates.sort(key=lambda idx: m.p[ops[idx]], reverse=True)\n                    \n                    # Process only the single strongest intermediate to maximize budget efficiency\n                    for k_idx in intermediates[:1]:\n                        op_k = ops[k_idx]\n                        \n                        y_ij = get_y(op_i, op_j)\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Cut A: Transitivity (Consistency)\n                        m.cp_lifting_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        # Cut B: Metric Lifting (Parent 2 Strength)\n                        # Tighten S_j lower bound using strong p_k if sequence is i->k->j\n                        m.cp_lifting_cuts.add(\n                            m.S[op_j] >= m.S[op_i] + m.p[op_i] + m.p[op_k] * (y_ik + y_kj - 1) \n                            - m.bigM * (1 - y_ij)\n                        )\n                        \n                        # Cut C: Tail Projection (Parent 1 Logic Integration)\n                        # Explicitly link the lifted S_j to Cmax. If S_j is pushed later by p_k,\n                        # Cmax must increase by remaining job work (tails). \n                        if op_j not in tail_cuts_added:\n                            m.cp_lifting_cuts.add(\n                                m.Cmax >= m.S[op_j] + m.p[op_j] + tails[op_j]\n                            )\n                            tail_cuts_added.add(op_j)\n                            added_cuts += 1\n                        \n                        added_cuts += 2\n                        if added_cuts >= CUT_BUDGET: break\n                    if added_cuts >= CUT_BUDGET: break\n                if added_cuts >= CUT_BUDGET: break\n            if added_cuts >= CUT_BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_critical_path_lifting_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Static Analysis: Heads (Release) and Tails (Delivery)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        # Iterate backwards for tails (work remaining after op)\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier-style)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Approximated flow order based on release times\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Find tightest sub-block\n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # Sort candidates by Lower Bound to target bottleneck machines\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_lb = candidates[0]['lb']\n    \n    # Filter: Process only near-critical blocks\n    targets = [c for c in candidates if c['lb'] >= 0.85 * global_lb]\n\n    m.cp_lifting_cuts = pyo.ConstraintList()\n    CUT_BUDGET = 200\n    added_cuts = 0\n    tail_cuts_added = set()\n    \n    # Helper for directional variable access\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Generate Hybrid Cuts\n    for target in targets:\n        ops = target['ops']\n        n = len(ops)\n        if n < 3: continue\n        \n        # Iterate triplets (i -> ... -> j)\n        for i in range(n):\n            op_i = ops[i]\n            # Limit search window to avoid loose pairs\n            for j in range(i + 1, min(i + 8, n)):\n                op_j = ops[j]\n                \n                # Identify potential intermediates k between i and j in sorted list\n                intermediates = []\n                for k in range(i + 1, j):\n                    intermediates.append(k)\n                if not intermediates: continue\n\n                # SELECTION (Parent 2): Prioritize high-impact intermediates (large processing time)\n                intermediates.sort(key=lambda idx: m.p[ops[idx]], reverse=True)\n                \n                # Process only the single strongest intermediate to maximize budget efficiency\n                for k_idx in intermediates[:1]:\n                    op_k = ops[k_idx]\n                    \n                    y_ij = get_y(op_i, op_j)\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Cut A: Transitivity (Consistency)\n                    m.cp_lifting_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    # Cut B: Metric Lifting (Parent 2 Strength)\n                    # Tighten S_j lower bound using strong p_k if sequence is i->k->j\n                    m.cp_lifting_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + m.p[op_k] * (y_ik + y_kj - 1) \n                        - m.bigM * (1 - y_ij)\n                    )\n                    \n                    # Cut C: Tail Projection (Parent 1 Logic Integration)\n                    # Explicitly link the lifted S_j to Cmax. If S_j is pushed later by p_k,\n                    # Cmax must increase by remaining job work (tails). \n                    if op_j not in tail_cuts_added:\n                        m.cp_lifting_cuts.add(\n                            m.Cmax >= m.S[op_j] + m.p[op_j] + tails[op_j]\n                        )\n                        tail_cuts_added.add(op_j)\n                        added_cuts += 1\n                    \n                    added_cuts += 2\n                    if added_cuts >= CUT_BUDGET: break\n                if added_cuts >= CUT_BUDGET: break\n            if added_cuts >= CUT_BUDGET: break\n        if added_cuts >= CUT_BUDGET: break",
                        "idea": "We introduce **Critical Path Lifting & Tail Projection Cuts**, a hybrid strategy that fuses Parent 2's 'Metric Lifting' with Parent 1's 'Tail Awareness'. By identifying critical blocks and selecting the highest-impact intermediate operations ($k$ with large $p_k$), we apply a lifting constraint that pushes the start time of downstream operations ($S_j$) when the sequence $i \\to k \\to j$ is active. Crucially, we augment this with explicit Tail Projection cuts ($C_{max} \\ge S_j + p_j + \\text{Tail}_j$) for these specific critical operations. This ensures that the local delay induced by the lifting immediately propagates to the global makespan variable, preventing the solver from relaxing $S_j$ without objective penalty."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.75,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.1,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.65,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.82,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.81,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.81,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.83,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.82,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.79,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.66,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "495deea1-afdd-4ad3-94d1-a2fdc00e66a9",
                        "59dc35ff-3928-46da-b5c3-9e5b151d0099"
                    ]
                },
                {
                    "id": "a33164cc-c345-4fee-97de-af9cfbf85f15",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_dynamic_triplet_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute static data (Heads/Tails) for efficient filtering\n        heads = {}\n        tails = {}\n        # Forward pass for release times\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass for delivery times\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads (earliest start) to approximate natural flow\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            r_min = heads[sorted_ops[0]]\n            q_min = min(tails[op] for op in ops)\n            p_sum = sum(m.p[op] for op in ops)\n            lb = r_min + p_sum + q_min\n            candidates.append({'mid': mid, 'lb': lb, 'ops': sorted_ops})\n    \n        if not candidates: return\n        \n        # Sort blocks by criticality\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_lb = candidates[0]['lb']\n        threshold = 0.85 * global_lb \n        \n        m.dynamic_triplet_cuts = pyo.ConstraintList()\n    \n        # Helper for directed precedence y[u,v]\n        def get_prec_expr(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        added = 0\n        CUT_LIMIT = 200\n        WINDOW = 6 \n    \n        # 3. Generate Dynamic Cuts\n        for cand in candidates:\n            if cand['lb'] < threshold: break\n            ops = cand['ops']\n            n = len(ops)\n            if n < 3: continue\n            \n            for i in range(n):\n                op_i = ops[i]\n                # Heuristic pruning\n                if heads[op_i] > global_lb * 0.7: continue\n    \n                for j_idx in range(i + 1, min(i + WINDOW, n)):\n                    op_j = ops[j_idx]\n                    \n                    for k_idx in range(j_idx + 1, min(j_idx + WINDOW, n)):\n                        op_k = ops[k_idx]\n                        \n                        # Check if static cost justifies the cut potential\n                        static_cost = heads[op_i] + m.p[op_i] + m.p[op_j] + m.p[op_k] + tails[op_k]\n                        \n                        if static_cost > threshold:\n                            y_ij = get_prec_expr(op_i, op_j)\n                            y_jk = get_prec_expr(op_j, op_k)\n                            \n                            # Dynamic Constraint Logic:\n                            # If i->j->k is active (y_ij=1, y_jk=1), then:\n                            # Cmax >= S[i] + p[i] + p[j] + p[k] + tails[k]\n                            # Implemented as big-M formulation:\n                            # Cmax + M*(2 - y_ij - y_jk) >= S[i] + path_adder\n                            \n                            path_adder = m.p[op_i] + m.p[op_j] + m.p[op_k] + tails[op_k]\n                            \n                            m.dynamic_triplet_cuts.add(\n                                m.Cmax + m.bigM * (2 - y_ij - y_jk) >= m.S[op_i] + path_adder\n                            )\n                            \n                            added += 1\n                            if added >= CUT_LIMIT: break\n                    if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n\n    return model\n",
                        "added_cut": "def add_dynamic_triplet_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute static data (Heads/Tails) for efficient filtering\n    heads = {}\n    tails = {}\n    # Forward pass for release times\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass for delivery times\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads (earliest start) to approximate natural flow\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        r_min = heads[sorted_ops[0]]\n        q_min = min(tails[op] for op in ops)\n        p_sum = sum(m.p[op] for op in ops)\n        lb = r_min + p_sum + q_min\n        candidates.append({'mid': mid, 'lb': lb, 'ops': sorted_ops})\n\n    if not candidates: return\n    \n    # Sort blocks by criticality\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_lb = candidates[0]['lb']\n    threshold = 0.85 * global_lb \n    \n    m.dynamic_triplet_cuts = pyo.ConstraintList()\n\n    # Helper for directed precedence y[u,v]\n    def get_prec_expr(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    added = 0\n    CUT_LIMIT = 200\n    WINDOW = 6 \n\n    # 3. Generate Dynamic Cuts\n    for cand in candidates:\n        if cand['lb'] < threshold: break\n        ops = cand['ops']\n        n = len(ops)\n        if n < 3: continue\n        \n        for i in range(n):\n            op_i = ops[i]\n            # Heuristic pruning\n            if heads[op_i] > global_lb * 0.7: continue\n\n            for j_idx in range(i + 1, min(i + WINDOW, n)):\n                op_j = ops[j_idx]\n                \n                for k_idx in range(j_idx + 1, min(j_idx + WINDOW, n)):\n                    op_k = ops[k_idx]\n                    \n                    # Check if static cost justifies the cut potential\n                    static_cost = heads[op_i] + m.p[op_i] + m.p[op_j] + m.p[op_k] + tails[op_k]\n                    \n                    if static_cost > threshold:\n                        y_ij = get_prec_expr(op_i, op_j)\n                        y_jk = get_prec_expr(op_j, op_k)\n                        \n                        # Dynamic Constraint Logic:\n                        # If i->j->k is active (y_ij=1, y_jk=1), then:\n                        # Cmax >= S[i] + p[i] + p[j] + p[k] + tails[k]\n                        # Implemented as big-M formulation:\n                        # Cmax + M*(2 - y_ij - y_jk) >= S[i] + path_adder\n                        \n                        path_adder = m.p[op_i] + m.p[op_j] + m.p[op_k] + tails[op_k]\n                        \n                        m.dynamic_triplet_cuts.add(\n                            m.Cmax + m.bigM * (2 - y_ij - y_jk) >= m.S[op_i] + path_adder\n                        )\n                        \n                        added += 1\n                        if added >= CUT_LIMIT: break\n                if added >= CUT_LIMIT: break\n            if added >= CUT_LIMIT: break",
                        "idea": "We evolve the static triplet strategy into **Dynamic Start-Time Triplet Cuts**. Instead of relying on a static lower bound head (release time), which assumes no upstream delays, this mutation anchors the cut to the decision variable S[i]. The constraint Cmax + M(2 - y_ij - y_jk) >= S[i] + p_i + p_j + p_k + q_k enforces that if the machine sequence i -> j -> k is chosen, the global makespan must accommodate the *actual* start time of i (which may be pushed later by cross-machine conflicts) plus the mandatory processing and tail times. This creates a tighter, delay-sensitive bound that propagates scheduling latencies directly to the objective function."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.16,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.5,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.54,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.48,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 17.46,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 17.45,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.18,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.82,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.81,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.89,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.86,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.11,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "495deea1-afdd-4ad3-94d1-a2fdc00e66a9"
                    ]
                },
                {
                    "id": "34f6310d-3f8f-4960-80f5-1d26b10302e4",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_flow_metric_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Timing (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier-style)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by earliest start (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]]\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx] # op is v in the subset\n                    p_sum += m.p[op]\n                    q_val = tails[op]\n                    lb = r_val + p_sum + q_val\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j_idx+1]\n            \n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint from top LB\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.hybrid_cuts = pyo.ConstraintList()\n        m.hybrid_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Generation\n        # Use Parent 2's density scoring to identify bottlenecks\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            # Precompute block stats for Flow Cuts (Parent 1 logic)\n            r_min = min(heads[op] for op in ops)\n            q_min = min(tails[op] for op in ops)\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                limit = global_max - tails[op_i]\n                \n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        # Pruning: if j cannot fit after k in global timeline\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Impact Density Score: processing mass / time spread\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j),\n                            'block': ops,\n                            'r_min': r_min,\n                            'q_min': q_min,\n                            'score': score\n                        })\n    \n        # 5. Apply Hybrid Cuts\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            # Helper to get variable representing u -> v\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        ops_with_flow_cuts = set()\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Metric Lifting & Transitivity (from Parent 2)\n            # Enforce tight path i -> k -> j if binary vars match\n            m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n            m.hybrid_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n            \n            # (B) Pivot-Anchored Flow Bounds (from Parent 1)\n            # Apply heavy flow cuts only to the pivot 'k' of high-score triplets\n            # This anchors the bottleneck operation 'k' against the volume of the entire block\n            if op_k not in ops_with_flow_cuts:\n                if cuts_added + 2 > CUT_BUDGET: break\n                \n                block = t['block']\n                r_min = t['r_min']\n                q_min = t['q_min']\n                \n                # Forward Flow: S[k] >= r_min + sum(p_v * y_vk)\n                pred_vol = 0\n                for v in block:\n                    if v == op_k: continue\n                    pred_vol += m.p[v] * get_y(v, op_k)\n                m.hybrid_cuts.add(m.S[op_k] >= r_min + pred_vol)\n                \n                # Backward Flow: S[k] <= Cmax - q_min - p[k] - sum(p_v * y_kv)\n                succ_vol = 0\n                for v in block:\n                    if v == op_k: continue\n                    succ_vol += m.p[v] * get_y(op_k, v)\n                m.hybrid_cuts.add(m.S[op_k] <= m.Cmax - q_min - m.p[op_k] - succ_vol)\n                \n                ops_with_flow_cuts.add(op_k)\n                cuts_added += 2\n\n    return model\n",
                        "added_cut": "def add_hybrid_flow_metric_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Timing (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier-style)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by earliest start (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]]\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx] # op is v in the subset\n                p_sum += m.p[op]\n                q_val = tails[op]\n                lb = r_val + p_sum + q_val\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j_idx+1]\n        \n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint from top LB\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.hybrid_cuts = pyo.ConstraintList()\n    m.hybrid_cuts.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Generation\n    # Use Parent 2's density scoring to identify bottlenecks\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        # Precompute block stats for Flow Cuts (Parent 1 logic)\n        r_min = min(heads[op] for op in ops)\n        q_min = min(tails[op] for op in ops)\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            limit = global_max - tails[op_i]\n            \n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    # Pruning: if j cannot fit after k in global timeline\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Impact Density Score: processing mass / time spread\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j),\n                        'block': ops,\n                        'r_min': r_min,\n                        'q_min': q_min,\n                        'score': score\n                    })\n\n    # 5. Apply Hybrid Cuts\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        # Helper to get variable representing u -> v\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    ops_with_flow_cuts = set()\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Metric Lifting & Transitivity (from Parent 2)\n        # Enforce tight path i -> k -> j if binary vars match\n        m.hybrid_cuts.add(y_ik + y_kj - y_ij <= 1)\n        m.hybrid_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n        \n        # (B) Pivot-Anchored Flow Bounds (from Parent 1)\n        # Apply heavy flow cuts only to the pivot 'k' of high-score triplets\n        # This anchors the bottleneck operation 'k' against the volume of the entire block\n        if op_k not in ops_with_flow_cuts:\n            if cuts_added + 2 > CUT_BUDGET: break\n            \n            block = t['block']\n            r_min = t['r_min']\n            q_min = t['q_min']\n            \n            # Forward Flow: S[k] >= r_min + sum(p_v * y_vk)\n            pred_vol = 0\n            for v in block:\n                if v == op_k: continue\n                pred_vol += m.p[v] * get_y(v, op_k)\n            m.hybrid_cuts.add(m.S[op_k] >= r_min + pred_vol)\n            \n            # Backward Flow: S[k] <= Cmax - q_min - p[k] - sum(p_v * y_kv)\n            succ_vol = 0\n            for v in block:\n                if v == op_k: continue\n                succ_vol += m.p[v] * get_y(op_k, v)\n            m.hybrid_cuts.add(m.S[op_k] <= m.Cmax - q_min - m.p[op_k] - succ_vol)\n            \n            ops_with_flow_cuts.add(op_k)\n            cuts_added += 2",
                        "idea": "We introduce **Hybrid Flow-Metric Cuts**, fusing Parent 2's **impact-density scoring** for triplet selection with Parent 1's **Symmetric Flow** bounds. We first identify critical blocks and generate high-impact triplets $(i, k, j)$ based on processing density. For these triplets, we apply **Metric Lifting** to enforce tight spacing ($S_j \\ge S_i + p_i + p_k$) conditioned on transitivity. Crucially, we also anchor the **pivot operation** $k$ using **Symmetric Flow bounds** derived from the entire critical block ($S_k \\ge r_{min} + \\sum p_v y_{vk}$). This selectively reinforces the relaxation at the most congested nodes using both local sequence and global volume information, avoiding the expense of applying flow cuts to all nodes."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.87,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.45,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.59,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.03,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.02,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.11,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.04,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.76,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.75,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.03,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.28,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.24,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "92615402-5fb4-4e12-8e41-f682690b6c20",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "d9042eff-e107-4461-8553-b2865eb1acbb",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_sequence_deviation_cuts(m):\n        import pyomo.environ as pyo\n    \n        # Pre-process: Map (job, machine_id) -> operation_index k\n        mach_to_k = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            mach_to_k[(j, mid)] = k\n    \n        # Helper: Construct expression for \"Job j1 precedes Job j2 on Machine\"\n        # Returns an expression that evaluates to 1 if j1 -> j2, else 0.\n        def get_precedence_expr(j1, k1, j2, k2):\n            if (j1, k1) < (j2, k2):\n                return m.y[j1, k1, j2, k2]\n            else:\n                return 1 - m.y[j2, k2, j1, k1]\n    \n        candidates = []\n        job_list = sorted(list(m.J))\n    \n        # Iterate unique pairs of jobs to find coupled machine sequences\n        for i in range(len(job_list)):\n            u = job_list[i]\n            # Get ordered machines for job u\n            u_ops_k = sorted([k for k in m.K if (u, k) in m.O])\n            u_machs = [m.mach[u, k] for k in u_ops_k]\n            \n            for j in range(i + 1, len(job_list)):\n                v = job_list[j]\n                v_ops_k = sorted([k for k in m.K if (v, k) in m.O])\n                v_machs = [m.mach[v, k] for k in v_ops_k]\n                \n                # Identify common machines appearing in the same relative order\n                common_machs = set(u_machs) & set(v_machs)\n                if len(common_machs) < 2:\n                    continue\n    \n                # Filter sequences to common machines only\n                u_common_seq = [mid for mid in u_machs if mid in common_machs]\n                v_common_seq = [mid for mid in v_machs if mid in common_machs]\n                \n                # Check adjacent pairs in u's sequence\n                for idx in range(len(u_common_seq) - 1):\n                    m1 = u_common_seq[idx]\n                    m2 = u_common_seq[idx+1]\n                    \n                    try:\n                        v_idx1 = v_common_seq.index(m1)\n                        v_idx2 = v_common_seq.index(m2)\n                    except ValueError:\n                        continue\n    \n                    # If both jobs visit m1 then m2\n                    if v_idx1 < v_idx2:\n                        k_u1, k_u2 = mach_to_k[u, m1], mach_to_k[u, m2]\n                        k_v1, k_v2 = mach_to_k[v, m1], mach_to_k[v, m2]\n                        \n                        # Penalty on job u if u->v on m1 but v->u on m2 (Crossing)\n                        # Logic: If v is sandwiched or forces a wait, u is delayed by v's processing.\n                        pen_u = m.p[v, k_v1] + m.p[v, k_v2]\n                        candidates.append({\n                            'target_job': u, 'interfering_job': v,\n                            'ops_target': (k_u1, k_u2), 'ops_inter': (k_v1, k_v2),\n                            'score': pen_u\n                        })\n                        \n                        # Penalty on job v if v->u on m1 but u->v on m2\n                        pen_v = m.p[u, k_u1] + m.p[u, k_u2]\n                        candidates.append({\n                            'target_job': v, 'interfering_job': u,\n                            'ops_target': (k_v1, k_v2), 'ops_inter': (k_u1, k_u2),\n                            'score': pen_v\n                        })\n    \n        # Prioritize cuts with largest potential delay impact\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        \n        m.seq_deviation_cuts = pyo.ConstraintList()\n        BUDGET = 200\n        added_count = 0\n        \n        for c in candidates:\n            if added_count >= BUDGET: break\n                \n            u, v = c['target_job'], c['interfering_job']\n            k_u1, k_u2 = c['ops_target']\n            k_v1, k_v2 = c['ops_inter']\n            penalty = c['score']\n            \n            # y_m1 = 1 if u->v on m1, y_m2 = 1 if u->v on m2.\n            # Crossing condition (u->v on m1 AND v->u on m2) => y_m1=1, y_m2=0 => (y_m1 - y_m2) = 1\n            expr_m1 = get_precedence_expr(u, k_u1, v, k_v1)\n            expr_m2 = get_precedence_expr(u, k_u2, v, k_v2)\n            \n            # Constraint: S[u2] >= S[u1] + p[u1] + penalty * (is_crossing)\n            m.seq_deviation_cuts.add(\n                m.S[u, k_u2] >= m.S[u, k_u1] + m.p[u, k_u1] + \n                penalty * (expr_m1 - expr_m2)\n            )\n            added_count += 1\n\n    return model\n",
                        "added_cut": "def add_sequence_deviation_cuts(m):\n    import pyomo.environ as pyo\n\n    # Pre-process: Map (job, machine_id) -> operation_index k\n    mach_to_k = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        mach_to_k[(j, mid)] = k\n\n    # Helper: Construct expression for \"Job j1 precedes Job j2 on Machine\"\n    # Returns an expression that evaluates to 1 if j1 -> j2, else 0.\n    def get_precedence_expr(j1, k1, j2, k2):\n        if (j1, k1) < (j2, k2):\n            return m.y[j1, k1, j2, k2]\n        else:\n            return 1 - m.y[j2, k2, j1, k1]\n\n    candidates = []\n    job_list = sorted(list(m.J))\n\n    # Iterate unique pairs of jobs to find coupled machine sequences\n    for i in range(len(job_list)):\n        u = job_list[i]\n        # Get ordered machines for job u\n        u_ops_k = sorted([k for k in m.K if (u, k) in m.O])\n        u_machs = [m.mach[u, k] for k in u_ops_k]\n        \n        for j in range(i + 1, len(job_list)):\n            v = job_list[j]\n            v_ops_k = sorted([k for k in m.K if (v, k) in m.O])\n            v_machs = [m.mach[v, k] for k in v_ops_k]\n            \n            # Identify common machines appearing in the same relative order\n            common_machs = set(u_machs) & set(v_machs)\n            if len(common_machs) < 2:\n                continue\n\n            # Filter sequences to common machines only\n            u_common_seq = [mid for mid in u_machs if mid in common_machs]\n            v_common_seq = [mid for mid in v_machs if mid in common_machs]\n            \n            # Check adjacent pairs in u's sequence\n            for idx in range(len(u_common_seq) - 1):\n                m1 = u_common_seq[idx]\n                m2 = u_common_seq[idx+1]\n                \n                try:\n                    v_idx1 = v_common_seq.index(m1)\n                    v_idx2 = v_common_seq.index(m2)\n                except ValueError:\n                    continue\n\n                # If both jobs visit m1 then m2\n                if v_idx1 < v_idx2:\n                    k_u1, k_u2 = mach_to_k[u, m1], mach_to_k[u, m2]\n                    k_v1, k_v2 = mach_to_k[v, m1], mach_to_k[v, m2]\n                    \n                    # Penalty on job u if u->v on m1 but v->u on m2 (Crossing)\n                    # Logic: If v is sandwiched or forces a wait, u is delayed by v's processing.\n                    pen_u = m.p[v, k_v1] + m.p[v, k_v2]\n                    candidates.append({\n                        'target_job': u, 'interfering_job': v,\n                        'ops_target': (k_u1, k_u2), 'ops_inter': (k_v1, k_v2),\n                        'score': pen_u\n                    })\n                    \n                    # Penalty on job v if v->u on m1 but u->v on m2\n                    pen_v = m.p[u, k_u1] + m.p[u, k_u2]\n                    candidates.append({\n                        'target_job': v, 'interfering_job': u,\n                        'ops_target': (k_v1, k_v2), 'ops_inter': (k_u1, k_u2),\n                        'score': pen_v\n                    })\n\n    # Prioritize cuts with largest potential delay impact\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    m.seq_deviation_cuts = pyo.ConstraintList()\n    BUDGET = 200\n    added_count = 0\n    \n    for c in candidates:\n        if added_count >= BUDGET: break\n            \n        u, v = c['target_job'], c['interfering_job']\n        k_u1, k_u2 = c['ops_target']\n        k_v1, k_v2 = c['ops_inter']\n        penalty = c['score']\n        \n        # y_m1 = 1 if u->v on m1, y_m2 = 1 if u->v on m2.\n        # Crossing condition (u->v on m1 AND v->u on m2) => y_m1=1, y_m2=0 => (y_m1 - y_m2) = 1\n        expr_m1 = get_precedence_expr(u, k_u1, v, k_v1)\n        expr_m2 = get_precedence_expr(u, k_u2, v, k_v2)\n        \n        # Constraint: S[u2] >= S[u1] + p[u1] + penalty * (is_crossing)\n        m.seq_deviation_cuts.add(\n            m.S[u, k_u2] >= m.S[u, k_u1] + m.p[u, k_u1] + \n            penalty * (expr_m1 - expr_m2)\n        )\n        added_count += 1",
                        "idea": "We introduce **Cross-Machine Sequence Deviation Cuts**. Unlike Parent 1 (local triplets) and Parent 2 (single-machine flow), this strategy enforces **consistency of job orderings across coupled machines**. By detecting pairs of jobs that visit two machines $(m_1, m_2)$ in the same relative order, we identify 'sequence crossings' (e.g., Job A precedes B on $m_1$ but follows B on $m_2$). Such a crossing physically mandates a delay equal to the sum of the interfering operations' processing times ($p_{B,1} + p_{B,2}$). We lift the standard job-precedence constraint ($S_{next} \\ge S_{prev} + p_{prev}$) by adding this dynamic penalty term, activated by the difference in binary variables $(y_{m1} - y_{m2})$. This links independent disjunctive decisions, penalizing inconsistent flow-shop-like orderings without adding auxiliary variables."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.22,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.17,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 14.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 14.88,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.36,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.3,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.4,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.39,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.09,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.84,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.83,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.51,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.36,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                        "04fb62fa-3123-40a3-b0d0-6f58f5588574"
                    ]
                },
                {
                    "id": "f750fd32-1299-4d74-b76d-9fe44f54adb5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_impact_scored_carlier_cuts(m):\n        # 1. Heads/Tails Calculation (EST/LST Estimation)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort operations by estimated release time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Calculate Carlier Lower Bound for subsets\n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint: Cmax Lower Bound\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.impact_carlier = pyo.ConstraintList()\n        m.impact_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Hybrid Triplet Generation & Scoring\n        # Use Parent 1's broader search parameters (Top 5 blocks, Window 12)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:5]\n        triplets = []\n        WINDOW = 12\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                limit_j = global_max - tails[op_i]\n                \n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic Horizon Filter (P1/P2)\n                    if heads[op_j] >= limit_j: break\n                    \n                    # Find potential intermediates k\n                    valid_ks = []\n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        # Prune k if it makes the path i->k->j impossible w.r.t global_max\n                        if heads[op_j] < global_max - tails[op_k]:\n                            valid_ks.append(k)\n                    \n                    if not valid_ks: continue\n    \n                    # HYBRID SELECTION: Combine P1's High-p filtering with P2's Density Scoring\n                    # First, sort k by processing time (descending) to maximize Lifting strength (P1)\n                    valid_ks.sort(key=lambda idx: m.p[ops[idx]], reverse=True)\n                    \n                    # Take top 3 strongest intermediates (Expanded from P1's 2 to feed P2's scorer)\n                    for k_idx in valid_ks[:3]:\n                        op_k = ops[k_idx]\n                        \n                        # Calculate Score: Impact Density (P2)\n                        # (Mass of operations) / (Time spread)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j),\n                            'score': score\n                        })\n    \n        # 5. Apply Cuts Globally (Budgeted via Score)\n        # Sort all candidates by density score (P2 logic)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Transitivity: i->k and k->j implies i->j must be consistent\n            m.impact_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting: If i->k->j, force S_j significantly later\n            # Using the large p[op_k] selected by the filter maximizes the push on S[op_j]\n            m.impact_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n\n    return model\n",
                        "added_cut": "def add_impact_scored_carlier_cuts(m):\n    # 1. Heads/Tails Calculation (EST/LST Estimation)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort operations by estimated release time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Calculate Carlier Lower Bound for subsets\n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint: Cmax Lower Bound\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.impact_carlier = pyo.ConstraintList()\n    m.impact_carlier.add(m.Cmax >= global_max)\n\n    # 4. Hybrid Triplet Generation & Scoring\n    # Use Parent 1's broader search parameters (Top 5 blocks, Window 12)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:5]\n    triplets = []\n    WINDOW = 12\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            limit_j = global_max - tails[op_i]\n            \n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic Horizon Filter (P1/P2)\n                if heads[op_j] >= limit_j: break\n                \n                # Find potential intermediates k\n                valid_ks = []\n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    # Prune k if it makes the path i->k->j impossible w.r.t global_max\n                    if heads[op_j] < global_max - tails[op_k]:\n                        valid_ks.append(k)\n                \n                if not valid_ks: continue\n\n                # HYBRID SELECTION: Combine P1's High-p filtering with P2's Density Scoring\n                # First, sort k by processing time (descending) to maximize Lifting strength (P1)\n                valid_ks.sort(key=lambda idx: m.p[ops[idx]], reverse=True)\n                \n                # Take top 3 strongest intermediates (Expanded from P1's 2 to feed P2's scorer)\n                for k_idx in valid_ks[:3]:\n                    op_k = ops[k_idx]\n                    \n                    # Calculate Score: Impact Density (P2)\n                    # (Mass of operations) / (Time spread)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j),\n                        'score': score\n                    })\n\n    # 5. Apply Cuts Globally (Budgeted via Score)\n    # Sort all candidates by density score (P2 logic)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Transitivity: i->k and k->j implies i->j must be consistent\n        m.impact_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting: If i->k->j, force S_j significantly later\n        # Using the large p[op_k] selected by the filter maximizes the push on S[op_j]\n        m.impact_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2",
                        "idea": "We introduce **Impact-Scored High-Value Carlier Cuts**, a hybrid strategy that combines the **global impact density scoring** of Parent 2 with the **selective high-processing-time filtering** and **expanded search window** of Parent 1. By filtering intermediate operations ($k$) to prioritize only those with the largest $p_k$ (Parent 1) *before* scoring them with Parent 2's density metric (Mass/Spread), we ensure the limited cut budget targets triplets that provide the strongest numerical lifting (via large $p_k$) within the most congested time windows. This allows us to safely expand the search window (size 12) to capture longer-range dependencies without diluting the pool with weak cuts."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.22,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.17,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.31,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.79,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.19,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.18,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.99,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.61,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.6,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.82,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.48,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "59dc35ff-3928-46da-b5c3-9e5b151d0099",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "f707a138-582c-4e6a-8a35-5778089657fa",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_slack_based_carlier_cuts(m):\n        \"\"\"\n        Adds cuts based on 'Slack-Based Critical Triplet Prioritization'.\n        Identifies triplets (i, k, j) on the same machine that form tight paths \n        relative to the global lower bound (Heads + Processing + Tails).\n        Prioritizes cuts that constrain the most critical bottlenecks.\n        \"\"\"\n        # 1. Calculate Static Heads and Tails\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n                \n        # Estimate Global Lower Bound (LB) for filtering\n        lb_max = max(heads[j, m.K.last()] + m.p[j, m.K.last()] for j in m.J)\n        \n        # 2. Collect and Score Triplets (i, k, j)\n        triplets = []\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n            \n        WINDOW = 12\n        for mid, ops in mach_ops.items():\n            # Sort ops by release time to form a topological window\n            ops_sorted = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(ops_sorted)\n            \n            for u in range(n_ops):\n                op_i = ops_sorted[u]\n                # Look ahead in window\n                for v in range(u + 2, min(u + WINDOW, n_ops)):\n                    op_j = ops_sorted[v]\n                    \n                    # Check intermediates k\n                    for w in range(u + 1, v):\n                        op_k = ops_sorted[w]\n                        \n                        # Calculate Path Slack Score\n                        # A high score means this sequence i->k->j is potentially a critical path\n                        path_score = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n                        \n                        # Filter: Only keep triplets that are close to the critical path\n                        if path_score >= 0.85 * lb_max:\n                            triplets.append({\n                                'i': op_i, 'k': op_k, 'j': op_j,\n                                'score': path_score,\n                                'p_k': m.p[op_k]\n                            })\n    \n        # 3. Global Prioritization\n        # Sort first by Tightness (Score), then by Impact (p_k)\n        triplets.sort(key=lambda x: (x['score'], x['p_k']), reverse=True)\n        \n        # 4. Add Constraints\n        m.slack_carlier = pyo.ConstraintList()\n        CUT_BUDGET = 200\n        added = 0\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for t in triplets:\n            if added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['i'], t['k'], t['j']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Transitivity: if i->k and k->j, then i->j MUST be true\n            m.slack_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting: S_j >= S_i + p_i + p_k (if intermediate)\n            # If y_ik=1 and y_kj=1, term is 1 -> Bound tightens by p_k\n            # If y_ij=0, BigM relaxes the constraint\n            m.slack_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            added += 2\n    \n    add_slack_based_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_slack_based_carlier_cuts(m):\n    \"\"\"\n    Adds cuts based on 'Slack-Based Critical Triplet Prioritization'.\n    Identifies triplets (i, k, j) on the same machine that form tight paths \n    relative to the global lower bound (Heads + Processing + Tails).\n    Prioritizes cuts that constrain the most critical bottlenecks.\n    \"\"\"\n    # 1. Calculate Static Heads and Tails\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n            \n    # Estimate Global Lower Bound (LB) for filtering\n    lb_max = max(heads[j, m.K.last()] + m.p[j, m.K.last()] for j in m.J)\n    \n    # 2. Collect and Score Triplets (i, k, j)\n    triplets = []\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n        \n    WINDOW = 12\n    for mid, ops in mach_ops.items():\n        # Sort ops by release time to form a topological window\n        ops_sorted = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(ops_sorted)\n        \n        for u in range(n_ops):\n            op_i = ops_sorted[u]\n            # Look ahead in window\n            for v in range(u + 2, min(u + WINDOW, n_ops)):\n                op_j = ops_sorted[v]\n                \n                # Check intermediates k\n                for w in range(u + 1, v):\n                    op_k = ops_sorted[w]\n                    \n                    # Calculate Path Slack Score\n                    # A high score means this sequence i->k->j is potentially a critical path\n                    path_score = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n                    \n                    # Filter: Only keep triplets that are close to the critical path\n                    if path_score >= 0.85 * lb_max:\n                        triplets.append({\n                            'i': op_i, 'k': op_k, 'j': op_j,\n                            'score': path_score,\n                            'p_k': m.p[op_k]\n                        })\n\n    # 3. Global Prioritization\n    # Sort first by Tightness (Score), then by Impact (p_k)\n    triplets.sort(key=lambda x: (x['score'], x['p_k']), reverse=True)\n    \n    # 4. Add Constraints\n    m.slack_carlier = pyo.ConstraintList()\n    CUT_BUDGET = 200\n    added = 0\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for t in triplets:\n        if added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['i'], t['k'], t['j']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Transitivity: if i->k and k->j, then i->j MUST be true\n        m.slack_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting: S_j >= S_i + p_i + p_k (if intermediate)\n        # If y_ik=1 and y_kj=1, term is 1 -> Bound tightens by p_k\n        # If y_ij=0, BigM relaxes the constraint\n        m.slack_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        added += 2\n\nadd_slack_based_carlier_cuts(model)",
                        "idea": "We introduce **Slack-Based Critical Triplet Prioritization**. While the original cut filtered intermediates solely by processing time ($p_k$), this mutation calculates the **Total Path Length** ($r_i + p_i + p_k + p_j + q_j$) for every triplet $(i, k, j)$ within machine blocks. It then globally sorts all triplets from all machines and selects the top candidates that are closest to the global lower bound. This ensures the limited cut budget targets the true bottlenecks of the schedule, enforcing transitivity ($y_{ik} \\land y_{kj} \\implies y_{ij}$) and metric lifting ($S_j \\ge S_i + p_i + p_k$) exactly where they are most likely to increase the makespan lower bound."
                    },
                    "fitness": 9.883434461225772,
                    "solver_reports": [
                        {
                            "total_time": 12.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 76698,
                            "explored_time": 12.24,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 16.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 64930,
                            "explored_time": 16.19,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.92,
                            "explored_nodes": 1,
                            "simplex_iterations": 47534,
                            "explored_time": 12.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.82,
                            "explored_nodes": 2206,
                            "simplex_iterations": 301744,
                            "explored_time": 9.81,
                            "work_units": 10.07
                        },
                        {
                            "total_time": 12.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 55471,
                            "explored_time": 12.63,
                            "work_units": 10.0
                        },
                        {
                            "gap": 34.1821,
                            "total_time": 10.32,
                            "explored_nodes": 8889,
                            "simplex_iterations": 375554,
                            "explored_time": 10.3,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.3,
                            "explored_nodes": 872,
                            "simplex_iterations": 156957,
                            "explored_time": 9.28,
                            "work_units": 10.01
                        },
                        {
                            "gap": 95.2045,
                            "total_time": 13.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 60993,
                            "explored_time": 13.15,
                            "work_units": 10.06
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "59dc35ff-3928-46da-b5c3-9e5b151d0099"
                    ]
                },
                {
                    "id": "f3636ebd-c26c-4f1c-8b32-e829da09ba41",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_prioritized_symmetric_flow_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Heads (r) and Tails (q)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier Logic)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by earliest release time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            best_r = 0\n            best_q = 0\n            \n            # Find sub-segment maximizing LB = r_min + sum(p) + q_min\n            for i in range(n):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]] # r_min for this window\n                current_min_q = float('inf')\n                \n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    if tails[op] < current_min_q:\n                        current_min_q = tails[op]\n                    \n                    lb = r_val + p_sum + current_min_q\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j_idx+1]\n                        best_r = r_val\n                        best_q = current_min_q\n            \n            if best_lb > 0:\n                candidates.append({\n                    'lb': best_lb,\n                    'ops': best_sub,\n                    'r': best_r,\n                    'q': best_q\n                })\n    \n        if not candidates: return\n    \n        # 3. Global Constraint: Lift Cmax lower bound\n        # Sort candidates by LB to prioritize the bottleneck\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.hybrid_cuts = pyo.ConstraintList()\n        m.hybrid_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Apply Symmetric Flow Cuts to Top Critical Blocks\n        # Focus budget on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        # Limit to top 3 blocks to allow dense cuts within budget\n        targets = targets[:3]\n    \n        def get_y(u, v):\n            # Returns expression for \"u precedes v\"\n            # m.y is indexed (j1, k1, j2, k2) where tuple1 < tuple2\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        cuts_added = 0\n        CUT_BUDGET = 200\n    \n        for block in targets:\n            ops = block['ops']\n            r_min = block['r']\n            q_min = block['q']\n            \n            # A. Symmetric Flow Bounds\n            # Tightens S[u] using the volume of all dynamic predecessors/successors in the block\n            # This is Big-M free and tighter than pairwise lifting for cliques\n            for u in ops:\n                if cuts_added >= CUT_BUDGET: break\n                \n                pred_vol = 0\n                succ_vol = 0\n                for v in ops:\n                    if u == v: continue\n                    y_vu = get_y(v, u) # 1 if v->u\n                    pred_vol += m.p[v] * y_vu\n                    succ_vol += m.p[v] * (1 - y_vu) # 1 if u->v\n                \n                # Forward: Start >= Earliest Release + Predecessors Volume\n                m.hybrid_cuts.add(m.S[u] >= r_min + pred_vol)\n                \n                # Backward: Start <= Latest Finish - Self - Successors Volume\n                m.hybrid_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n                \n                cuts_added += 2\n            \n            # B. Windowed Transitivity\n            # Enforces consistency of y variables to support the flow sums\n            WINDOW = 6\n            n_blk = len(ops)\n            for i in range(n_blk):\n                if cuts_added >= CUT_BUDGET: break\n                u = ops[i]\n                for j in range(i+1, min(i+WINDOW, n_blk)):\n                    w = ops[j]\n                    for k in range(i+1, j):\n                        v = ops[k]\n                        # If u->v and v->w then u->w\n                        # y_uv + y_vw - y_uw <= 1\n                        y_uv = get_y(u, v)\n                        y_vw = get_y(v, w)\n                        y_uw = get_y(u, w)\n                        m.hybrid_cuts.add(y_uv + y_vw - y_uw <= 1)\n                        \n                        cuts_added += 1\n                        if cuts_added >= CUT_BUDGET: break\n                    if cuts_added >= CUT_BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_prioritized_symmetric_flow_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Heads (r) and Tails (q)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier Logic)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by earliest release time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        best_r = 0\n        best_q = 0\n        \n        # Find sub-segment maximizing LB = r_min + sum(p) + q_min\n        for i in range(n):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]] # r_min for this window\n            current_min_q = float('inf')\n            \n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                if tails[op] < current_min_q:\n                    current_min_q = tails[op]\n                \n                lb = r_val + p_sum + current_min_q\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j_idx+1]\n                    best_r = r_val\n                    best_q = current_min_q\n        \n        if best_lb > 0:\n            candidates.append({\n                'lb': best_lb,\n                'ops': best_sub,\n                'r': best_r,\n                'q': best_q\n            })\n\n    if not candidates: return\n\n    # 3. Global Constraint: Lift Cmax lower bound\n    # Sort candidates by LB to prioritize the bottleneck\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.hybrid_cuts = pyo.ConstraintList()\n    m.hybrid_cuts.add(m.Cmax >= global_max)\n\n    # 4. Apply Symmetric Flow Cuts to Top Critical Blocks\n    # Focus budget on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    # Limit to top 3 blocks to allow dense cuts within budget\n    targets = targets[:3]\n\n    def get_y(u, v):\n        # Returns expression for \"u precedes v\"\n        # m.y is indexed (j1, k1, j2, k2) where tuple1 < tuple2\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    cuts_added = 0\n    CUT_BUDGET = 200\n\n    for block in targets:\n        ops = block['ops']\n        r_min = block['r']\n        q_min = block['q']\n        \n        # A. Symmetric Flow Bounds\n        # Tightens S[u] using the volume of all dynamic predecessors/successors in the block\n        # This is Big-M free and tighter than pairwise lifting for cliques\n        for u in ops:\n            if cuts_added >= CUT_BUDGET: break\n            \n            pred_vol = 0\n            succ_vol = 0\n            for v in ops:\n                if u == v: continue\n                y_vu = get_y(v, u) # 1 if v->u\n                pred_vol += m.p[v] * y_vu\n                succ_vol += m.p[v] * (1 - y_vu) # 1 if u->v\n            \n            # Forward: Start >= Earliest Release + Predecessors Volume\n            m.hybrid_cuts.add(m.S[u] >= r_min + pred_vol)\n            \n            # Backward: Start <= Latest Finish - Self - Successors Volume\n            m.hybrid_cuts.add(m.S[u] <= m.Cmax - q_min - m.p[u] - succ_vol)\n            \n            cuts_added += 2\n        \n        # B. Windowed Transitivity\n        # Enforces consistency of y variables to support the flow sums\n        WINDOW = 6\n        n_blk = len(ops)\n        for i in range(n_blk):\n            if cuts_added >= CUT_BUDGET: break\n            u = ops[i]\n            for j in range(i+1, min(i+WINDOW, n_blk)):\n                w = ops[j]\n                for k in range(i+1, j):\n                    v = ops[k]\n                    # If u->v and v->w then u->w\n                    # y_uv + y_vw - y_uw <= 1\n                    y_uv = get_y(u, v)\n                    y_vw = get_y(v, w)\n                    y_uw = get_y(u, w)\n                    m.hybrid_cuts.add(y_uv + y_vw - y_uw <= 1)\n                    \n                    cuts_added += 1\n                    if cuts_added >= CUT_BUDGET: break\n                if cuts_added >= CUT_BUDGET: break",
                        "idea": "We introduce **Prioritized Symmetric Flow Cuts**, a hybrid strategy that leverages the robust bottleneck detection of Parent 2 to deploy the high-strength flow bounds of Parent 1. First, we identify and sort critical machine blocks based on their Carlier Lower Bounds, immediately enforcing a global cut ($C_{max} \\ge LB_{max}$). Then, specifically for the top-ranked blocks, we apply **Symmetric Flow** constraints: a Forward Flow bound ($S_u \\ge r_{min} + \\sum p_v y_{vu}$) and a Backward Flow bound ($S_u \\le C_{max} - q_{min} - p_u - \\sum p_v y_{uv}$), reinforced by local transitivity. This approach uses the scoring logic to focus the dense, Big-M-free flow cuts exactly where the schedule is most congested, creating a tight polyhedral approximation of the critical path."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.97,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 14.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 14.88,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.67,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.0,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.99,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.03,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.98,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.54,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.53,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.04,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.67,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.63,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "92615402-5fb4-4e12-8e41-f682690b6c20",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                }
            ],
            23.42775824076793
        ],
        [
            [
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "cc0fbfc9-9a75-4a90-bf75-97bf90812b9d",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_flow_enhanced_scored_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Timing (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads) for Carlier check\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB\n            for u in range(n):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                r_min = min(heads[op] for op in best_sub)\n                q_min = min(tails[op] for op in best_sub)\n                candidates.append({\n                    'lb': best_lb, \n                    'ops': best_sub,\n                    'r_min': r_min,\n                    'q_min': q_min\n                })\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.flow_scored_cuts = pyo.ConstraintList()\n        m.flow_scored_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Generation\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n        # Identify the absolute critical block to restrict expensive flow cuts\n        critical_block_ops = set(candidates[0]['ops']) if candidates else set()\n        \n        triplets = []\n        WINDOW = 8\n        \n        for target in targets:\n            ops = target['ops']\n            block_r = target['r_min']\n            block_q = target['q_min']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                limit = global_max - tails[op_i]\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Density Score (Parent 2)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j),\n                            'score': score,\n                            'block': ops,\n                            'r_min': block_r,\n                            'q_min': block_q\n                        })\n    \n        # 5. Apply Cuts (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            # 1 if u precedes v\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        flow_cuts_added = set()\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Metric Lifting & Transitivity (Parent 2 Core)\n            # Enforce tight local spacing i->k->j\n            m.flow_scored_cuts.add(y_ik + y_kj - y_ij <= 1)\n            m.flow_scored_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n            \n            # (B) Selective Flow Bounds (Parent 1 Optimization)\n            # Only apply heavy flow cuts to pivots in the *absolute critical block*\n            if op_k in critical_block_ops and op_k not in flow_cuts_added:\n                if cuts_added + 2 > CUT_BUDGET: break\n                \n                block = t['block']\n                r_min = t['r_min']\n                q_min = t['q_min']\n                \n                # Forward Flow: S[k] >= r_min + sum(p_v * y_vk)\n                pred_vol = sum(m.p[v] * get_y(v, op_k) for v in block if v != op_k)\n                m.flow_scored_cuts.add(m.S[op_k] >= r_min + pred_vol)\n                \n                # Backward Flow: S[k] <= Cmax - q_min - p[k] - sum(p_v * y_kv)\n                succ_vol = sum(m.p[v] * get_y(op_k, v) for v in block if v != op_k)\n                m.flow_scored_cuts.add(m.S[op_k] <= m.Cmax - q_min - m.p[op_k] - succ_vol)\n                \n                flow_cuts_added.add(op_k)\n                cuts_added += 2\n\n    return model\n",
                        "added_cut": "def add_flow_enhanced_scored_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Timing (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads) for Carlier check\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB\n        for u in range(n):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            r_min = min(heads[op] for op in best_sub)\n            q_min = min(tails[op] for op in best_sub)\n            candidates.append({\n                'lb': best_lb, \n                'ops': best_sub,\n                'r_min': r_min,\n                'q_min': q_min\n            })\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.flow_scored_cuts = pyo.ConstraintList()\n    m.flow_scored_cuts.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Generation\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max]\n    # Identify the absolute critical block to restrict expensive flow cuts\n    critical_block_ops = set(candidates[0]['ops']) if candidates else set()\n    \n    triplets = []\n    WINDOW = 8\n    \n    for target in targets:\n        ops = target['ops']\n        block_r = target['r_min']\n        block_q = target['q_min']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            limit = global_max - tails[op_i]\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Density Score (Parent 2)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j),\n                        'score': score,\n                        'block': ops,\n                        'r_min': block_r,\n                        'q_min': block_q\n                    })\n\n    # 5. Apply Cuts (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        # 1 if u precedes v\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    flow_cuts_added = set()\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Metric Lifting & Transitivity (Parent 2 Core)\n        # Enforce tight local spacing i->k->j\n        m.flow_scored_cuts.add(y_ik + y_kj - y_ij <= 1)\n        m.flow_scored_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n        \n        # (B) Selective Flow Bounds (Parent 1 Optimization)\n        # Only apply heavy flow cuts to pivots in the *absolute critical block*\n        if op_k in critical_block_ops and op_k not in flow_cuts_added:\n            if cuts_added + 2 > CUT_BUDGET: break\n            \n            block = t['block']\n            r_min = t['r_min']\n            q_min = t['q_min']\n            \n            # Forward Flow: S[k] >= r_min + sum(p_v * y_vk)\n            pred_vol = sum(m.p[v] * get_y(v, op_k) for v in block if v != op_k)\n            m.flow_scored_cuts.add(m.S[op_k] >= r_min + pred_vol)\n            \n            # Backward Flow: S[k] <= Cmax - q_min - p[k] - sum(p_v * y_kv)\n            succ_vol = sum(m.p[v] * get_y(op_k, v) for v in block if v != op_k)\n            m.flow_scored_cuts.add(m.S[op_k] <= m.Cmax - q_min - m.p[op_k] - succ_vol)\n            \n            flow_cuts_added.add(op_k)\n            cuts_added += 2",
                        "idea": "We construct **Flow-Enhanced Scored Cuts** by fusing the high-fitness *Metric Lifting* from Parent 2 with a targeted application of Parent 1's *Symmetric Flow Bounds*. Triples are selected via impact-density scoring (processing mass/time spread) to apply tight spacing ($S_j \\ge S_i + p_i + p_k$) and transitivity. To maximize budget efficiency, we apply the expensive Input/Output Flow Cuts ($S_k \\ge r_{min} + \\sum p_v y_{vk}$) *only* to operations within the **global bottleneck block**. This ensures the relaxation is maximally tightened on the critical path without diluting the cut budget for other areas."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.98,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.11,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.07,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.96,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.9,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.82,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.81,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.49,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 11.39,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 11.39,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 18.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 18.48,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.06,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "34f6310d-3f8f-4960-80f5-1d26b10302e4",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "099bbce3-a01d-4cd5-8475-73d89245d1f7",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_scored_tail_lifting_cuts(m):\n        # 1. Heads (Release) and Tails (Delivery) Analysis\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (approximated topological order)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Calculate Carlier Lower Bound for sub-blocks to find criticality\n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Filtering Candidates (Parent 1 Logic)\n        # Sort by LB and focus on blocks near the global critical path\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_lb = candidates[0]['lb']\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_lb]\n    \n        # 4. Triplet Collection & Scoring (Parent 1 Logic)\n        triplets = []\n        WINDOW = 8\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Restrict search window for efficiency\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Identify intermediates k\n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-4: spread = 1e-4\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Hybrid Cut Generation\n        # Use Parent 1's scoring to prioritize, but include Parent 2's Tail Projection\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        m.scored_lifting_cuts = pyo.ConstraintList()\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        tail_cuts_added = set() # Avoid redundant tail projections\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Transitivity (Consistency)\n            m.scored_lifting_cuts.add(y_ik + y_kj - y_ij <= 1)\n            cuts_added += 1\n            \n            # (B) Metric Lifting\n            # If i->k->j, lift S_j by p_k\n            m.scored_lifting_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 1\n            \n            # (C) Tail Projection (Parent 2 Enhancement)\n            # If S_j is pushed, force Cmax to respect it immediately\n            if op_j not in tail_cuts_added:\n                m.scored_lifting_cuts.add(\n                    m.Cmax >= m.S[op_j] + m.p[op_j] + tails[op_j]\n                )\n                tail_cuts_added.add(op_j)\n                cuts_added += 1\n\n    return model\n",
                        "added_cut": "def add_scored_tail_lifting_cuts(m):\n    # 1. Heads (Release) and Tails (Delivery) Analysis\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (approximated topological order)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Calculate Carlier Lower Bound for sub-blocks to find criticality\n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Filtering Candidates (Parent 1 Logic)\n    # Sort by LB and focus on blocks near the global critical path\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_lb = candidates[0]['lb']\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_lb]\n\n    # 4. Triplet Collection & Scoring (Parent 1 Logic)\n    triplets = []\n    WINDOW = 8\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Restrict search window for efficiency\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Identify intermediates k\n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-4: spread = 1e-4\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Hybrid Cut Generation\n    # Use Parent 1's scoring to prioritize, but include Parent 2's Tail Projection\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    m.scored_lifting_cuts = pyo.ConstraintList()\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    tail_cuts_added = set() # Avoid redundant tail projections\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Transitivity (Consistency)\n        m.scored_lifting_cuts.add(y_ik + y_kj - y_ij <= 1)\n        cuts_added += 1\n        \n        # (B) Metric Lifting\n        # If i->k->j, lift S_j by p_k\n        m.scored_lifting_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 1\n        \n        # (C) Tail Projection (Parent 2 Enhancement)\n        # If S_j is pushed, force Cmax to respect it immediately\n        if op_j not in tail_cuts_added:\n            m.scored_lifting_cuts.add(\n                m.Cmax >= m.S[op_j] + m.p[op_j] + tails[op_j]\n            )\n            tail_cuts_added.add(op_j)\n            cuts_added += 1",
                        "idea": "We propose **Scored Impact Lifting with Tail Projection**. This hybrid strategy utilizes Parent 1's **Impact Density Scoring** to identify the most ambiguous, high-congestion triplets $(i, k, j)$ where the ratio of processing mass to time spread is maximized. For these top-ranked triplets, we apply a strengthened cut suite: (1) **Triangle Transitivity** to resolve precedence ambiguity, (2) **Metric Lifting** to tighten start times based on intermediate processing $p_k$, and importantly (3) **Tail Projection** (from Parent 2) which explicitly links the lifted $S_j$ to the global makespan $C_{max}$ via the job's tail. This combination ensures that local tightenings on critical blocks immediately propagate to the objective function."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.25,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 16.0,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.95,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.14,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.1,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.08,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.18,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.96,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.95,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.67,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.59,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                        "b7ca7772-8f72-46ac-b2d3-6de5a9f6a8ec"
                    ]
                },
                {
                    "id": "c26f9990-6a08-4503-94a5-d3744c2b47ca",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_internal_block_volume_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Static Analysis: Heads for heuristic sorting\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Identify high-volume blocks to target bottleneck machines\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            # Sort by Earliest Release (Heuristic Topological Order)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            vol = sum(m.p[op] for op in ops)\n            candidates.append({'mid': mid, 'ops': sorted_ops, 'vol': vol})\n    \n        # Process only the most loaded blocks\n        candidates.sort(key=lambda x: x['vol'], reverse=True)\n        targets = candidates[:5]\n    \n        m.block_volume_cuts = pyo.ConstraintList()\n        CUT_BUDGET = 200\n        added_cuts = 0\n    \n        # Helper to access y variables in correct direction\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 3. Generate Internal Block Volume Cuts\n        for block in targets:\n            ops = block['ops']\n            block_M = block['vol'] # Safe local Big-M (total block duration)\n            n = len(ops)\n            \n            # Identify \"Anchor Pairs\" (u, v) that span the block\n            # u from the start region, v from the end region\n            pairs = []\n            for i in range(min(3, n-2)):\n                for j in range(max(i+2, n-3), n):\n                    u = ops[i]\n                    v = ops[j]\n                    # Heuristic: prioritize pairs enclosing large static volume\n                    static_vol = sum(m.p[ops[k]] for k in range(i+1, j))\n                    pairs.append((u, v, static_vol))\n            \n            # Sort pairs by enclosed volume to maximize cut impact\n            pairs.sort(key=lambda x: x[2], reverse=True)\n            \n            for (u, v, _) in pairs[:3]:\n                if added_cuts >= CUT_BUDGET: break\n                \n                y_uv = get_y(u, v)\n                \n                # Calculate Dynamic Volume of intermediates\n                # We iterate ALL other operations k in the block. \n                # The term (y_uk + y_kv - 1) equals 1 IF u -> k -> v, and <= 0 otherwise.\n                # This creates a \"Relative Density\" term that counts exactly the jobs \n                # dynamically sequenced between u and v.\n                intermediates = [op for op in ops if op != u and op != v]\n                \n                vol_expr = 0\n                for k_op in intermediates:\n                    term = get_y(u, k_op) + get_y(k_op, v) - 1\n                    vol_expr += m.p[k_op] * term\n                    \n                # Cut: The time interval (S_v - S_u) must be large enough to contain \n                # p_u plus the processing times of all jobs sequenced between u and v.\n                # We use block_M to relax the cut if u does not precede v.\n                m.block_volume_cuts.add(\n                    m.S[v] >= m.S[u] + m.p[u] + vol_expr - block_M * (1 - y_uv)\n                )\n                added_cuts += 1\n            \n            if added_cuts >= CUT_BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_internal_block_volume_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Static Analysis: Heads for heuristic sorting\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Identify high-volume blocks to target bottleneck machines\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        # Sort by Earliest Release (Heuristic Topological Order)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        vol = sum(m.p[op] for op in ops)\n        candidates.append({'mid': mid, 'ops': sorted_ops, 'vol': vol})\n\n    # Process only the most loaded blocks\n    candidates.sort(key=lambda x: x['vol'], reverse=True)\n    targets = candidates[:5]\n\n    m.block_volume_cuts = pyo.ConstraintList()\n    CUT_BUDGET = 200\n    added_cuts = 0\n\n    # Helper to access y variables in correct direction\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 3. Generate Internal Block Volume Cuts\n    for block in targets:\n        ops = block['ops']\n        block_M = block['vol'] # Safe local Big-M (total block duration)\n        n = len(ops)\n        \n        # Identify \"Anchor Pairs\" (u, v) that span the block\n        # u from the start region, v from the end region\n        pairs = []\n        for i in range(min(3, n-2)):\n            for j in range(max(i+2, n-3), n):\n                u = ops[i]\n                v = ops[j]\n                # Heuristic: prioritize pairs enclosing large static volume\n                static_vol = sum(m.p[ops[k]] for k in range(i+1, j))\n                pairs.append((u, v, static_vol))\n        \n        # Sort pairs by enclosed volume to maximize cut impact\n        pairs.sort(key=lambda x: x[2], reverse=True)\n        \n        for (u, v, _) in pairs[:3]:\n            if added_cuts >= CUT_BUDGET: break\n            \n            y_uv = get_y(u, v)\n            \n            # Calculate Dynamic Volume of intermediates\n            # We iterate ALL other operations k in the block. \n            # The term (y_uk + y_kv - 1) equals 1 IF u -> k -> v, and <= 0 otherwise.\n            # This creates a \"Relative Density\" term that counts exactly the jobs \n            # dynamically sequenced between u and v.\n            intermediates = [op for op in ops if op != u and op != v]\n            \n            vol_expr = 0\n            for k_op in intermediates:\n                term = get_y(u, k_op) + get_y(k_op, v) - 1\n                vol_expr += m.p[k_op] * term\n                \n            # Cut: The time interval (S_v - S_u) must be large enough to contain \n            # p_u plus the processing times of all jobs sequenced between u and v.\n            # We use block_M to relax the cut if u does not precede v.\n            m.block_volume_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + vol_expr - block_M * (1 - y_uv)\n            )\n            added_cuts += 1\n        \n        if added_cuts >= CUT_BUDGET: break",
                        "idea": "We introduce **Internal Block Volume Cuts**, a strategy that complements the pairwise lifting of Parent 1 and the static flow bounds of Parent 2. Instead of focusing on single intermediates or fixed release windows, this approach selects dynamic 'anchor pairs' $(u, v)$ within critical blocks and enforces a **relative density constraint**. The cut ensures that the time difference $S_v - S_u$ is sufficient to cover the processing of $u$ plus the sum of all operations $k$ that are dynamically sequenced between them (captured by the term $\\sum p_k(y_{uk} + y_{kv} - 1)$). This sums the 'volume' of the cluster directly into the precedence relation, creating a tight, shift-invariant bound that accommodates dynamic reordering."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.05,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.39,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.43,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.52,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.51,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.28,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.22,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.72,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.09,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.93,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "b7ca7772-8f72-46ac-b2d3-6de5a9f6a8ec",
                        "f3636ebd-c26c-4f1c-8b32-e829da09ba41"
                    ]
                },
                {
                    "id": "2b11cf59-e1f4-4363-a89c-649efa5c6ccd",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_lifted_sequence_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Static Analysis: Compute Heads (release) and Tails (delivery)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine to find critical blocks\n        machine_ops = {}\n        for (j, k) in m.O:\n            mach = m.mach[j, k]\n            if mach not in machine_ops: machine_ops[mach] = []\n            machine_ops[mach].append((j, k))\n    \n        candidates = []\n        for mach, ops in machine_ops.items():\n            if not ops: continue\n            # Sort operations by release time (heads) as a heuristic for topological order\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Find sub-blocks with highest energetic lower bound\n            best_lb = -1\n            best_block = []\n            for i in range(n):\n                p_sum = 0\n                for j in range(i, n):\n                    op_j = sorted_ops[j]\n                    p_sum += m.p[op_j]\n                    lb = heads[sorted_ops[i]] + p_sum + tails[op_j]\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_block = sorted_ops[i : j+1]\n            if best_lb > 0:\n                candidates.append({'lb': best_lb, 'ops': best_block})\n    \n        # Sort blocks by criticality (LB)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # 3. Apply Lifting Cuts\n        m.lifted_cuts = pyo.ConstraintList()\n        BUDGET = 150\n        cut_count = 0\n        \n        def get_y(u, v):\n            # Return y[u,v] correctly indexed\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # Process top critical blocks\n        for block in candidates[:5]:\n            ops = block['ops']\n            n_ops = len(ops)\n            if n_ops < 3: continue\n    \n            # Iterate over start (i) and end (j) of sub-sequences\n            for i in range(n_ops):\n                op_i = ops[i]\n                # Look ahead in the block\n                for j in range(i + 2, min(i + 10, n_ops)):\n                    op_j = ops[j]\n                    \n                    # Identify potential intermediates (k) between i and j\n                    intermediates = ops[i+1 : j]\n                    \n                    # Select top intermediates by processing time to maximize lifting impact\n                    # This effectively sums multiple 'Cut B' terms from the parent logic\n                    k_selection = sorted(intermediates, key=lambda x: m.p[x], reverse=True)[:5]\n                    \n                    if not k_selection: continue\n                    \n                    y_ij = get_y(op_i, op_j)\n                    \n                    # Aggregate Lifting Term: Sum of p_k for all k confirmed between i and j\n                    # If y_ik=1 and y_kj=1, then (y_ik + y_kj - 1) = 1, adding p_k to the mandatory delay\n                    lift_term = 0\n                    for op_k in k_selection:\n                        y_ik = get_y(op_i, op_k)\n                        y_kj = get_y(op_k, op_j)\n                        \n                        # Enforce Transitivity to strengthen the relaxation\n                        m.lifted_cuts.add(y_ik + y_kj - y_ij <= 1)\n                        \n                        lift_term += m.p[op_k] * (y_ik + y_kj - 1)\n                    \n                    # Lifted Constraint: S_j >= S_i + p_i + Sum(p_k * active_k) - M*(1-y_ij)\n                    # This tightens the minimal gap between i and j dynamically based on intermediate decisions\n                    m.lifted_cuts.add(\n                        m.S[op_j] >= m.S[op_i] + m.p[op_i] + lift_term - m.bigM * (1 - y_ij)\n                    )\n                    \n                    # Tail Projection: Link S_j delay to Cmax\n                    m.lifted_cuts.add(m.Cmax >= m.S[op_j] + m.p[op_j] + tails[op_j])\n                    \n                    cut_count += 1\n                    if cut_count >= BUDGET: break\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_lifted_sequence_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Static Analysis: Compute Heads (release) and Tails (delivery)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine to find critical blocks\n    machine_ops = {}\n    for (j, k) in m.O:\n        mach = m.mach[j, k]\n        if mach not in machine_ops: machine_ops[mach] = []\n        machine_ops[mach].append((j, k))\n\n    candidates = []\n    for mach, ops in machine_ops.items():\n        if not ops: continue\n        # Sort operations by release time (heads) as a heuristic for topological order\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Find sub-blocks with highest energetic lower bound\n        best_lb = -1\n        best_block = []\n        for i in range(n):\n            p_sum = 0\n            for j in range(i, n):\n                op_j = sorted_ops[j]\n                p_sum += m.p[op_j]\n                lb = heads[sorted_ops[i]] + p_sum + tails[op_j]\n                if lb > best_lb:\n                    best_lb = lb\n                    best_block = sorted_ops[i : j+1]\n        if best_lb > 0:\n            candidates.append({'lb': best_lb, 'ops': best_block})\n\n    # Sort blocks by criticality (LB)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # 3. Apply Lifting Cuts\n    m.lifted_cuts = pyo.ConstraintList()\n    BUDGET = 150\n    cut_count = 0\n    \n    def get_y(u, v):\n        # Return y[u,v] correctly indexed\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # Process top critical blocks\n    for block in candidates[:5]:\n        ops = block['ops']\n        n_ops = len(ops)\n        if n_ops < 3: continue\n\n        # Iterate over start (i) and end (j) of sub-sequences\n        for i in range(n_ops):\n            op_i = ops[i]\n            # Look ahead in the block\n            for j in range(i + 2, min(i + 10, n_ops)):\n                op_j = ops[j]\n                \n                # Identify potential intermediates (k) between i and j\n                intermediates = ops[i+1 : j]\n                \n                # Select top intermediates by processing time to maximize lifting impact\n                # This effectively sums multiple 'Cut B' terms from the parent logic\n                k_selection = sorted(intermediates, key=lambda x: m.p[x], reverse=True)[:5]\n                \n                if not k_selection: continue\n                \n                y_ij = get_y(op_i, op_j)\n                \n                # Aggregate Lifting Term: Sum of p_k for all k confirmed between i and j\n                # If y_ik=1 and y_kj=1, then (y_ik + y_kj - 1) = 1, adding p_k to the mandatory delay\n                lift_term = 0\n                for op_k in k_selection:\n                    y_ik = get_y(op_i, op_k)\n                    y_kj = get_y(op_k, op_j)\n                    \n                    # Enforce Transitivity to strengthen the relaxation\n                    m.lifted_cuts.add(y_ik + y_kj - y_ij <= 1)\n                    \n                    lift_term += m.p[op_k] * (y_ik + y_kj - 1)\n                \n                # Lifted Constraint: S_j >= S_i + p_i + Sum(p_k * active_k) - M*(1-y_ij)\n                # This tightens the minimal gap between i and j dynamically based on intermediate decisions\n                m.lifted_cuts.add(\n                    m.S[op_j] >= m.S[op_i] + m.p[op_i] + lift_term - m.bigM * (1 - y_ij)\n                )\n                \n                # Tail Projection: Link S_j delay to Cmax\n                m.lifted_cuts.add(m.Cmax >= m.S[op_j] + m.p[op_j] + tails[op_j])\n                \n                cut_count += 1\n                if cut_count >= BUDGET: break\n            if cut_count >= BUDGET: break\n        if cut_count >= BUDGET: break",
                        "idea": "We perform **Aggregated Intermediate Lifting** on the critical path. Unlike the original cut which considered only a single intermediate operation $k$ per triplet, this mutation identifies a start-end pair $(i, j)$ in a critical block and sums the processing times of the top $N$ intermediate operations $k$ that satisfy the sequence $i \\to k \\to j$. The lifting term $\\sum p_k(y_{ik} + y_{kj} - 1)$ exploits the superadditivity of processing times on a single machine: if multiple $k$ are sequenced between $i$ and $j$, their times must cumulatively delay $S_j$. Transitivity cuts are added to enforce logical consistency, and Tail Projection ensures these local delays propagate to the global makespan ($C_{max}$). This creates a much tighter feasible region for the linear relaxation."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.22,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.77,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.22,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.17,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.78,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.77,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.43,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.31,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 11.72,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 11.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.02,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.78,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "b7ca7772-8f72-46ac-b2d3-6de5a9f6a8ec"
                    ]
                },
                {
                    "id": "8aba996b-d3b6-4325-b362-2def7ccead4f",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_density_anchored_deviation_cuts(m):\n        \"\"\"\n        Hybridizes Parent 1's Critical Block Flow Bounds with Parent 2's Sequence Deviation logic.\n        Identifies bottleneck 'pivot' operations using impact density, then applies:\n        1. Vertical Flow Bounds: Anchors pivot start time using the volume of the block.\n        2. Horizontal Deviation Cuts: Penalizes sequence inversions between the pivot and block neighbors across machines.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # --- 1. Precompute Timing (Heads/Tails) ---\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # --- 2. Critical Block Detection ---\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads (earliest start)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            best_lb = -1\n            best_block = []\n            best_pivot = None\n            \n            # Identify Carlier-style block with max lower bound\n            for i in range(n):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]]\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    q_val = tails[op]\n                    lb = r_val + p_sum + q_val\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_block = sorted_ops[i : j_idx+1]\n                        # Heuristic: pivot is the last op in block (sink)\n                        best_pivot = op\n            \n            if best_lb > 0 and len(best_block) >= 2:\n                candidates.append({\n                    'lb': best_lb, \n                    'block': best_block, \n                    'pivot': best_pivot,\n                    'mid': mid\n                })\n    \n        # Sort candidates by tightness (descending LB)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Helper for Y variables (u -> v)\n        def get_y_expr(u, v):\n            if (u[0], u[1]) < (v[0], v[1]):\n                 return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                 return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # Helper for Precedence Expression (returns 1 if u->v, 0 if v->u)\n        def get_prec_val(u, v):\n            j1, k1 = u\n            j2, k2 = v\n            if (j1, k1) < (j2, k2):\n                 return m.y[j1, k1, j2, k2]\n            else:\n                 return 1 - m.y[j2, k2, j1, k1]\n    \n        m.density_deviation_cuts = pyo.ConstraintList()\n        \n        # Process top blocks\n        CUT_BUDGET = 100\n        added = 0\n        \n        for cand in candidates[:15]: # Focus on tightest blocks\n            if added >= CUT_BUDGET: break\n            \n            block = cand['block']\n            pivot = cand['pivot']\n            pivot_job = pivot[0]\n            pivot_idx = pivot[1]\n            \n            # --- A. Pivot-Anchored Flow Bound (Vertical) ---\n            # S_pivot >= r_min + sum(p_v * y_v_pivot)\n            r_min = min(heads[op] for op in block)\n            flow_sum = 0\n            for op in block:\n                if op == pivot: continue\n                # We need y_op_pivot (op -> pivot)\n                # If op < pivot, y is y[op, pivot]. If op > pivot, y is 1-y[pivot, op].\n                # This is exactly what get_y_expr(op, pivot) returns.\n                flow_sum += m.p[op] * get_y_expr(op, pivot)\n            \n            m.density_deviation_cuts.add(m.S[pivot] >= r_min + flow_sum)\n            added += 1\n            \n            # --- B. Sequence Deviation Cuts (Horizontal) ---\n            # Check pivot against other ops in block for cross-machine inconsistencies\n            for op in block:\n                if op == pivot: continue\n                if added >= CUT_BUDGET: break\n                \n                neighbor_job = op[0]\n                \n                # Reconstruct machine sequences for pivot and neighbor jobs\n                # Filter by existence in O to avoid errors\n                p_seq = sorted([(k, m.mach[pivot_job, k]) for k in m.K if (pivot_job, k) in m.O], key=lambda x: x[0])\n                n_seq = sorted([(k, m.mach[neighbor_job, k]) for k in m.K if (neighbor_job, k) in m.O], key=lambda x: x[0])\n                \n                curr_mid = cand['mid']\n                \n                # Find common machines\n                common_mids = set([x[1] for x in p_seq]) & set([x[1] for x in n_seq])\n                common_mids.discard(curr_mid)\n                \n                for other_mid in common_mids:\n                    # Get operation indices on the other machine\n                    p_prev_info = next(x for x in p_seq if x[1] == other_mid)\n                    n_prev_info = next(x for x in n_seq if x[1] == other_mid)\n                    \n                    # Apply only if 'other_mid' is a predecessor machine for the PIVOT\n                    # (To strengthen the pivot's incoming precedence)\n                    if p_prev_info[0] < pivot_idx:\n                        u_curr = pivot\n                        u_prev = (pivot_job, p_prev_info[0])\n                        v_curr = op\n                        v_prev = (neighbor_job, n_prev_info[0])\n                        \n                        # Logic: If u->v on Prev but v->u on Curr (Crossing),\n                        # u is delayed by v's processing on both machines.\n                        # Crossing Condition: prec_prev=1 (u->v), prec_curr=0 (v->u)\n                        prec_prev = get_prec_val(u_prev, v_prev)\n                        prec_curr = get_prec_val(u_curr, v_curr)\n                        \n                        # Lift Term\n                        penalty = m.p[v_curr] + m.p[v_prev]\n                        \n                        # S[u_curr] >= S[u_prev] + p[u_prev] + penalty * (prec_prev - prec_curr)\n                        # If crossing (1 - 0 = 1), penalty is added.\n                        m.density_deviation_cuts.add(\n                            m.S[u_curr] >= m.S[u_prev] + m.p[u_prev] + \n                            penalty * (prec_prev - prec_curr)\n                        )\n                        added += 1\n\n    return model\n",
                        "added_cut": "def add_density_anchored_deviation_cuts(m):\n    \"\"\"\n    Hybridizes Parent 1's Critical Block Flow Bounds with Parent 2's Sequence Deviation logic.\n    Identifies bottleneck 'pivot' operations using impact density, then applies:\n    1. Vertical Flow Bounds: Anchors pivot start time using the volume of the block.\n    2. Horizontal Deviation Cuts: Penalizes sequence inversions between the pivot and block neighbors across machines.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # --- 1. Precompute Timing (Heads/Tails) ---\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # --- 2. Critical Block Detection ---\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads (earliest start)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        best_lb = -1\n        best_block = []\n        best_pivot = None\n        \n        # Identify Carlier-style block with max lower bound\n        for i in range(n):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]]\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                q_val = tails[op]\n                lb = r_val + p_sum + q_val\n                if lb > best_lb:\n                    best_lb = lb\n                    best_block = sorted_ops[i : j_idx+1]\n                    # Heuristic: pivot is the last op in block (sink)\n                    best_pivot = op\n        \n        if best_lb > 0 and len(best_block) >= 2:\n            candidates.append({\n                'lb': best_lb, \n                'block': best_block, \n                'pivot': best_pivot,\n                'mid': mid\n            })\n\n    # Sort candidates by tightness (descending LB)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Helper for Y variables (u -> v)\n    def get_y_expr(u, v):\n        if (u[0], u[1]) < (v[0], v[1]):\n             return m.y[u[0], u[1], v[0], v[1]]\n        else:\n             return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # Helper for Precedence Expression (returns 1 if u->v, 0 if v->u)\n    def get_prec_val(u, v):\n        j1, k1 = u\n        j2, k2 = v\n        if (j1, k1) < (j2, k2):\n             return m.y[j1, k1, j2, k2]\n        else:\n             return 1 - m.y[j2, k2, j1, k1]\n\n    m.density_deviation_cuts = pyo.ConstraintList()\n    \n    # Process top blocks\n    CUT_BUDGET = 100\n    added = 0\n    \n    for cand in candidates[:15]: # Focus on tightest blocks\n        if added >= CUT_BUDGET: break\n        \n        block = cand['block']\n        pivot = cand['pivot']\n        pivot_job = pivot[0]\n        pivot_idx = pivot[1]\n        \n        # --- A. Pivot-Anchored Flow Bound (Vertical) ---\n        # S_pivot >= r_min + sum(p_v * y_v_pivot)\n        r_min = min(heads[op] for op in block)\n        flow_sum = 0\n        for op in block:\n            if op == pivot: continue\n            # We need y_op_pivot (op -> pivot)\n            # If op < pivot, y is y[op, pivot]. If op > pivot, y is 1-y[pivot, op].\n            # This is exactly what get_y_expr(op, pivot) returns.\n            flow_sum += m.p[op] * get_y_expr(op, pivot)\n        \n        m.density_deviation_cuts.add(m.S[pivot] >= r_min + flow_sum)\n        added += 1\n        \n        # --- B. Sequence Deviation Cuts (Horizontal) ---\n        # Check pivot against other ops in block for cross-machine inconsistencies\n        for op in block:\n            if op == pivot: continue\n            if added >= CUT_BUDGET: break\n            \n            neighbor_job = op[0]\n            \n            # Reconstruct machine sequences for pivot and neighbor jobs\n            # Filter by existence in O to avoid errors\n            p_seq = sorted([(k, m.mach[pivot_job, k]) for k in m.K if (pivot_job, k) in m.O], key=lambda x: x[0])\n            n_seq = sorted([(k, m.mach[neighbor_job, k]) for k in m.K if (neighbor_job, k) in m.O], key=lambda x: x[0])\n            \n            curr_mid = cand['mid']\n            \n            # Find common machines\n            common_mids = set([x[1] for x in p_seq]) & set([x[1] for x in n_seq])\n            common_mids.discard(curr_mid)\n            \n            for other_mid in common_mids:\n                # Get operation indices on the other machine\n                p_prev_info = next(x for x in p_seq if x[1] == other_mid)\n                n_prev_info = next(x for x in n_seq if x[1] == other_mid)\n                \n                # Apply only if 'other_mid' is a predecessor machine for the PIVOT\n                # (To strengthen the pivot's incoming precedence)\n                if p_prev_info[0] < pivot_idx:\n                    u_curr = pivot\n                    u_prev = (pivot_job, p_prev_info[0])\n                    v_curr = op\n                    v_prev = (neighbor_job, n_prev_info[0])\n                    \n                    # Logic: If u->v on Prev but v->u on Curr (Crossing),\n                    # u is delayed by v's processing on both machines.\n                    # Crossing Condition: prec_prev=1 (u->v), prec_curr=0 (v->u)\n                    prec_prev = get_prec_val(u_prev, v_prev)\n                    prec_curr = get_prec_val(u_curr, v_curr)\n                    \n                    # Lift Term\n                    penalty = m.p[v_curr] + m.p[v_prev]\n                    \n                    # S[u_curr] >= S[u_prev] + p[u_prev] + penalty * (prec_prev - prec_curr)\n                    # If crossing (1 - 0 = 1), penalty is added.\n                    m.density_deviation_cuts.add(\n                        m.S[u_curr] >= m.S[u_prev] + m.p[u_prev] + \n                        penalty * (prec_prev - prec_curr)\n                    )\n                    added += 1",
                        "idea": "We fuse Parent 1's **Critical Block Detection** with Parent 2's **Sequence Deviation** logic to create **Density-Anchored Deviation Cuts**. By identifying high-density blocks on specific machines (Parent 1), we pinpoint bottleneck 'pivot' operations. We then strengthen the bounds for these pivots in two dimensions simultaneously: (1) **Vertically**, by enforcing Symmetric Flow Bounds ($S_k \\ge r_{min} + \\sum p_v y_{vk}$) that anchor the pivot against the local machine volume, and (2) **Horizontally**, by applying Sequence Deviation cuts to the pivot and its block neighbors, penalizing cross-machine order inversions ($S_{u,curr} \\ge S_{u,prev} + p_{u,prev} + (p_{v,curr}+p_{v,prev})(y_{uv}^{prev}-y_{uv}^{curr})$). This hybrid approach focuses the solver's effort on the most congested sub-problems, linking machine capacity limits with job transitivity constraints."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.86,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.37,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.72,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.72,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.71,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.04,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.86,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.85,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.84,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.13,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "34f6310d-3f8f-4960-80f5-1d26b10302e4",
                        "d9042eff-e107-4461-8553-b2865eb1acbb"
                    ]
                },
                {
                    "id": "424f28a0-86ef-4ac3-8294-75211b873dbc",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_hybrid_critical_crossing_tail_cuts(m):\n        import pyomo.environ as pyo\n    \n        # --- 1. Tail Analysis (Inherited from Parent 1) ---\n        # Precompute work remaining after each operation\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # --- 2. Critical Machine Detection (Inherited from Parent 1) ---\n        # Identify bottleneck machines to filter high-impact cuts\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Estimate Lower Bound (Release + Load + Delivery) for each machine\n        critical_machs = set()\n        if mach_ops:\n            mach_stats = []\n            for mid, ops in mach_ops.items():\n                min_r = min(sum(m.p[j, x] for x in range(k)) for (j, k) in ops)\n                min_q = min(tails[j, k] for (j, k) in ops)\n                load = sum(m.p[op] for op in ops)\n                mach_stats.append((mid, min_r + load + min_q))\n            \n            if mach_stats:\n                mach_stats.sort(key=lambda x: x[1], reverse=True)\n                global_lb = mach_stats[0][1]\n                # Filter: Machines with LB >= 85% of global LB\n                critical_machs = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n    \n        # --- 3. Sequence Deviation & Tail Projection (Hybrid Logic) ---\n        mach_to_k = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            mach_to_k[(j, mid)] = k\n    \n        def get_y_expr(j1, k1, j2, k2):\n            # Returns expression for 1 if j1 precedes j2, else 0\n            if (j1, k1) < (j2, k2):\n                return m.y[j1, k1, j2, k2]\n            else:\n                return 1 - m.y[j2, k2, j1, k1]\n    \n        candidates = []\n        job_list = sorted(list(m.J))\n    \n        # Iterate job pairs to find cross-machine sequence deviations\n        for i in range(len(job_list)):\n            u = job_list[i]\n            u_seq = [m.mach[u, k] for k in sorted([k for k in m.K if (u, k) in m.O])]\n    \n            for j in range(i + 1, len(job_list)):\n                v = job_list[j]\n                v_seq = [m.mach[v, k] for k in sorted([k for k in m.K if (v, k) in m.O])]\n    \n                common = set(u_seq) & set(v_seq)\n                if len(common) < 2: continue\n                # Optimization: Only generate cuts if a Critical Machine is involved\n                if not (common & critical_machs): continue\n    \n                u_sub = [mid for mid in u_seq if mid in common]\n                v_sub = [mid for mid in v_seq if mid in common]\n    \n                # Check adjacent common machines for crossing patterns\n                for idx in range(len(u_sub) - 1):\n                    m1 = u_sub[idx]\n                    m2 = u_sub[idx+1]\n    \n                    try:\n                        v_idx1 = v_sub.index(m1)\n                        v_idx2 = v_sub.index(m2)\n                    except ValueError: continue\n    \n                    # If both jobs visit m1 then m2\n                    if v_idx1 < v_idx2:\n                        kt1, kt2 = mach_to_k[u, m1], mach_to_k[u, m2]\n                        ki1, ki2 = mach_to_k[v, m1], mach_to_k[v, m2]\n    \n                        # Penalty if crossing occurs (sum of interfering processing times)\n                        pen = m.p[v, ki1] + m.p[v, ki2]\n                        \n                        score = pen\n                        if m1 in critical_machs: score *= 1.2\n                        if m2 in critical_machs: score *= 1.2\n    \n                        candidates.append({'u': u, 'v': v, 'kt': (kt1, kt2), 'ki': (ki1, ki2), 'pen': pen, 'score': score})\n                        \n                        # Symmetric case\n                        pen_v = m.p[u, kt1] + m.p[u, kt2]\n                        score_v = pen_v\n                        if m1 in critical_machs: score_v *= 1.2\n                        if m2 in critical_machs: score_v *= 1.2\n                        candidates.append({'u': v, 'v': u, 'kt': (ki1, ki2), 'ki': (kt1, kt2), 'pen': pen_v, 'score': score_v})\n    \n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        m.hybrid_tail_cuts = pyo.ConstraintList()\n        BUDGET = 200\n        added = 0\n    \n        for c in candidates:\n            if added >= BUDGET: break\n            u, v = c['u'], c['v']\n            kt1, kt2 = c['kt']\n            ki1, ki2 = c['ki']\n    \n            # Crossing Term: (u->v on m1) - (u->v on m2)\n            # Equals 1 if u->v on m1 AND v->u on m2 (Crossing)\n            cross_expr = get_y_expr(u, kt1, v, ki1) - get_y_expr(u, kt2, v, ki2)\n    \n            # Hybrid Cut: Cmax >= S_u_m1 + p_u_m1 + Penalty*Cross + p_u_m2 + Tail_u_m2\n            # This projects the local crossing delay directly to the global Cmax\n            m.hybrid_tail_cuts.add(\n                m.Cmax >= m.S[u, kt1] + m.p[u, kt1] + \n                c['pen'] * cross_expr + \n                m.p[u, kt2] + tails[u, kt2]\n            )\n            added += 1\n\n    return model\n",
                        "added_cut": "def add_hybrid_critical_crossing_tail_cuts(m):\n    import pyomo.environ as pyo\n\n    # --- 1. Tail Analysis (Inherited from Parent 1) ---\n    # Precompute work remaining after each operation\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # --- 2. Critical Machine Detection (Inherited from Parent 1) ---\n    # Identify bottleneck machines to filter high-impact cuts\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Estimate Lower Bound (Release + Load + Delivery) for each machine\n    critical_machs = set()\n    if mach_ops:\n        mach_stats = []\n        for mid, ops in mach_ops.items():\n            min_r = min(sum(m.p[j, x] for x in range(k)) for (j, k) in ops)\n            min_q = min(tails[j, k] for (j, k) in ops)\n            load = sum(m.p[op] for op in ops)\n            mach_stats.append((mid, min_r + load + min_q))\n        \n        if mach_stats:\n            mach_stats.sort(key=lambda x: x[1], reverse=True)\n            global_lb = mach_stats[0][1]\n            # Filter: Machines with LB >= 85% of global LB\n            critical_machs = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n\n    # --- 3. Sequence Deviation & Tail Projection (Hybrid Logic) ---\n    mach_to_k = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        mach_to_k[(j, mid)] = k\n\n    def get_y_expr(j1, k1, j2, k2):\n        # Returns expression for 1 if j1 precedes j2, else 0\n        if (j1, k1) < (j2, k2):\n            return m.y[j1, k1, j2, k2]\n        else:\n            return 1 - m.y[j2, k2, j1, k1]\n\n    candidates = []\n    job_list = sorted(list(m.J))\n\n    # Iterate job pairs to find cross-machine sequence deviations\n    for i in range(len(job_list)):\n        u = job_list[i]\n        u_seq = [m.mach[u, k] for k in sorted([k for k in m.K if (u, k) in m.O])]\n\n        for j in range(i + 1, len(job_list)):\n            v = job_list[j]\n            v_seq = [m.mach[v, k] for k in sorted([k for k in m.K if (v, k) in m.O])]\n\n            common = set(u_seq) & set(v_seq)\n            if len(common) < 2: continue\n            # Optimization: Only generate cuts if a Critical Machine is involved\n            if not (common & critical_machs): continue\n\n            u_sub = [mid for mid in u_seq if mid in common]\n            v_sub = [mid for mid in v_seq if mid in common]\n\n            # Check adjacent common machines for crossing patterns\n            for idx in range(len(u_sub) - 1):\n                m1 = u_sub[idx]\n                m2 = u_sub[idx+1]\n\n                try:\n                    v_idx1 = v_sub.index(m1)\n                    v_idx2 = v_sub.index(m2)\n                except ValueError: continue\n\n                # If both jobs visit m1 then m2\n                if v_idx1 < v_idx2:\n                    kt1, kt2 = mach_to_k[u, m1], mach_to_k[u, m2]\n                    ki1, ki2 = mach_to_k[v, m1], mach_to_k[v, m2]\n\n                    # Penalty if crossing occurs (sum of interfering processing times)\n                    pen = m.p[v, ki1] + m.p[v, ki2]\n                    \n                    score = pen\n                    if m1 in critical_machs: score *= 1.2\n                    if m2 in critical_machs: score *= 1.2\n\n                    candidates.append({'u': u, 'v': v, 'kt': (kt1, kt2), 'ki': (ki1, ki2), 'pen': pen, 'score': score})\n                    \n                    # Symmetric case\n                    pen_v = m.p[u, kt1] + m.p[u, kt2]\n                    score_v = pen_v\n                    if m1 in critical_machs: score_v *= 1.2\n                    if m2 in critical_machs: score_v *= 1.2\n                    candidates.append({'u': v, 'v': u, 'kt': (ki1, ki2), 'ki': (kt1, kt2), 'pen': pen_v, 'score': score_v})\n\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    m.hybrid_tail_cuts = pyo.ConstraintList()\n    BUDGET = 200\n    added = 0\n\n    for c in candidates:\n        if added >= BUDGET: break\n        u, v = c['u'], c['v']\n        kt1, kt2 = c['kt']\n        ki1, ki2 = c['ki']\n\n        # Crossing Term: (u->v on m1) - (u->v on m2)\n        # Equals 1 if u->v on m1 AND v->u on m2 (Crossing)\n        cross_expr = get_y_expr(u, kt1, v, ki1) - get_y_expr(u, kt2, v, ki2)\n\n        # Hybrid Cut: Cmax >= S_u_m1 + p_u_m1 + Penalty*Cross + p_u_m2 + Tail_u_m2\n        # This projects the local crossing delay directly to the global Cmax\n        m.hybrid_tail_cuts.add(\n            m.Cmax >= m.S[u, kt1] + m.p[u, kt1] + \n            c['pen'] * cross_expr + \n            m.p[u, kt2] + tails[u, kt2]\n        )\n        added += 1",
                        "idea": "We introduce **Critical Cross-Machine Tail Cuts**, which fuse Parent 2's sequence deviation logic with Parent 1's critical path and tail projection concepts. The strategy identifies pairs of jobs traversing two machines ($m_1, m_2$) in the same relative order. If a 'crossing' occurs (jobs swap order between machines), a delay penalty is calculated based on the interfering job's processing times (from Parent 2). Crucially, instead of applying this delay locally, we project it globally to the makespan ($C_{max}$) using the target job's **Tail** (processing time of all subsequent operations, from Parent 1). This bypasses intermediate variables, tightening the lower bound on $C_{max}$ directly from the start time at $m_1$. To maintain efficiency, cuts are filtered to involve only **Critical Machines** identified via release/delivery bound analysis."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.23,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.19,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.44,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.74,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.86,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.85,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.4,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.76,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.75,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.22,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.2,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.4,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "b7ca7772-8f72-46ac-b2d3-6de5a9f6a8ec",
                        "d9042eff-e107-4461-8553-b2865eb1acbb"
                    ]
                },
                {
                    "id": "7feec2a9-c7f4-48c6-b3a2-73f12bf4ec30",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_machine_workload_funnel_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Static Heads and Tails\n        heads = {}\n        tails = {}\n        # Forward pass: Earliest Start Times\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass: Work Remaining (Tails)\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Detect High-Impact Machine Blocks (Bottleneck Detection)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by heads (approximate flow order)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Find tightest sub-block using Carlier's Lower Bound\n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # Sort candidates to focus on the most critical bottlenecks first\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        # Select top blocks to apply dense cuts without exploding model size\n        targets = candidates[:4] \n    \n        m.workload_funnel = pyo.ConstraintList()\n        \n        # Helper to retrieve the correct binary variable for \"u precedes v\"\n        # m.y is indexed by pairs (j1,k1,j2,k2) where (j1,k1) < (j2,k2)\n        def get_precedence_var(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        added_cuts = 0\n        CUT_BUDGET = 200\n    \n        for target in targets:\n            ops = target['ops']\n            # Determine the static bounds for the entire block\n            min_head = min(heads[op] for op in ops)\n            min_tail = min(tails[op] for op in ops)\n            \n            # Apply cuts to operations in the block\n            # This creates a 'funnel' effect: pushing S_u from the left and Cmax from the right\n            for op_u in ops:\n                if added_cuts >= CUT_BUDGET: break\n                \n                # (A) Input-Sum Cut: Aggregated Predecessor Workload\n                # S_u must be >= earliest release + sum of processing times of all predecessors\n                input_workload = 0\n                for op_v in ops:\n                    if op_v == op_u: continue\n                    # Term: p_v * 1 if v precedes u, else 0\n                    y_vu = get_precedence_var(op_v, op_u)\n                    input_workload += m.p[op_v] * y_vu\n                \n                m.workload_funnel.add(\n                    m.S[op_u] >= min_head + input_workload\n                )\n                added_cuts += 1\n                \n                if added_cuts >= CUT_BUDGET: break\n    \n                # (B) Output-Sum Cut: Aggregated Successor Workload\n                # Cmax must be >= S_u + p_u + sum of processing times of all successors + min tail\n                output_workload = 0\n                for op_v in ops:\n                    if op_v == op_u: continue\n                    # Term: p_v * 1 if u precedes v, else 0\n                    y_uv = get_precedence_var(op_u, op_v)\n                    output_workload += m.p[op_v] * y_uv\n                \n                m.workload_funnel.add(\n                    m.Cmax >= m.S[op_u] + m.p[op_u] + output_workload + min_tail\n                )\n                added_cuts += 1\n    \n    add_machine_workload_funnel_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_machine_workload_funnel_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Static Heads and Tails\n    heads = {}\n    tails = {}\n    # Forward pass: Earliest Start Times\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass: Work Remaining (Tails)\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Detect High-Impact Machine Blocks (Bottleneck Detection)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by heads (approximate flow order)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Find tightest sub-block using Carlier's Lower Bound\n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # Sort candidates to focus on the most critical bottlenecks first\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    # Select top blocks to apply dense cuts without exploding model size\n    targets = candidates[:4] \n\n    m.workload_funnel = pyo.ConstraintList()\n    \n    # Helper to retrieve the correct binary variable for \"u precedes v\"\n    # m.y is indexed by pairs (j1,k1,j2,k2) where (j1,k1) < (j2,k2)\n    def get_precedence_var(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    added_cuts = 0\n    CUT_BUDGET = 200\n\n    for target in targets:\n        ops = target['ops']\n        # Determine the static bounds for the entire block\n        min_head = min(heads[op] for op in ops)\n        min_tail = min(tails[op] for op in ops)\n        \n        # Apply cuts to operations in the block\n        # This creates a 'funnel' effect: pushing S_u from the left and Cmax from the right\n        for op_u in ops:\n            if added_cuts >= CUT_BUDGET: break\n            \n            # (A) Input-Sum Cut: Aggregated Predecessor Workload\n            # S_u must be >= earliest release + sum of processing times of all predecessors\n            input_workload = 0\n            for op_v in ops:\n                if op_v == op_u: continue\n                # Term: p_v * 1 if v precedes u, else 0\n                y_vu = get_precedence_var(op_v, op_u)\n                input_workload += m.p[op_v] * y_vu\n            \n            m.workload_funnel.add(\n                m.S[op_u] >= min_head + input_workload\n            )\n            added_cuts += 1\n            \n            if added_cuts >= CUT_BUDGET: break\n\n            # (B) Output-Sum Cut: Aggregated Successor Workload\n            # Cmax must be >= S_u + p_u + sum of processing times of all successors + min tail\n            output_workload = 0\n            for op_v in ops:\n                if op_v == op_u: continue\n                # Term: p_v * 1 if u precedes v, else 0\n                y_uv = get_precedence_var(op_u, op_v)\n                output_workload += m.p[op_v] * y_uv\n            \n            m.workload_funnel.add(\n                m.Cmax >= m.S[op_u] + m.p[op_u] + output_workload + min_tail\n            )\n            added_cuts += 1\n\nadd_machine_workload_funnel_cuts(model)",
                        "idea": "We introduce **Machine Workload Funnel Cuts**, a dense constraint strategy that complements the sparse triplet cuts of the parents. While the parents refine local sequencing (e.g., $i \\to k \\to j$) using transitivity, this method aggregates the total processing mass of a critical block. For each operation $u$ in a bottleneck, we impose two bounds: (1) an **Input-Sum Cut** ensuring $S_u$ reflects the minimum block release plus the aggregated processing times of all identified predecessors, and (2) an **Output-Sum Cut** ensuring $C_{max}$ accounts for $u$'s completion plus the sum of all successors' work and the block's minimal tail. This effectively 'funnels' the disjunctive binary decisions into continuous global time bounds, forcing the LP relaxation to respect the machine's total capacity."
                    },
                    "fitness": 16.293877180601747,
                    "solver_reports": [
                        {
                            "total_time": 6.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 28844,
                            "explored_time": 6.12,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.14,
                            "explored_nodes": 1,
                            "simplex_iterations": 17982,
                            "explored_time": 7.09,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.22,
                            "explored_nodes": 1,
                            "simplex_iterations": 35942,
                            "explored_time": 7.16,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.3413,
                            "total_time": 11.94,
                            "explored_nodes": 115,
                            "simplex_iterations": 58071,
                            "explored_time": 11.93,
                            "work_units": 11.31
                        },
                        {
                            "total_time": 6.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 32785,
                            "explored_time": 6.46,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.4375,
                            "total_time": 12.82,
                            "explored_nodes": 115,
                            "simplex_iterations": 61827,
                            "explored_time": 12.81,
                            "work_units": 12.78
                        },
                        {
                            "total_time": 8.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 35688,
                            "explored_time": 8.02,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 27895,
                            "explored_time": 5.94,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "b7ca7772-8f72-46ac-b2d3-6de5a9f6a8ec",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                }
            ],
            23.42775824076793
        ],
        [
            [
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "87111a8b-df25-431a-99f8-dc4c65f8e7e1",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_multi_stage_workload_funnels(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Heads and Tails\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier-style)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by earliest start (heads) to approximate flow\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            best_lb = -1\n            best_sub = []\n            \n            # Find tightest sub-block [u...v]\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0 and len(best_sub) > 1:\n                candidates.append({'lb': best_lb, 'ops': best_sub})\n    \n        # Prioritize bottlenecks with highest lower bound\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        targets = candidates[:4] # Focus on top 4 critical blocks\n    \n        if not targets: return\n    \n        m.multi_stage_funnels = pyo.ConstraintList()\n        \n        # --- Helpers ---\n        # Retrieve binary variable for \"op_a precedes op_b\"\n        def get_prec_var(a, b):\n            if a < b:\n                if (a[0], a[1], b[0], b[1]) in m.Pairs:\n                    return m.y[a[0], a[1], b[0], b[1]]\n            else:\n                if (b[0], b[1], a[0], a[1]) in m.Pairs:\n                    return 1 - m.y[b[0], b[1], a[0], a[1]]\n            return 0\n    \n        # Check for previous machine interaction between two ops\n        def get_prev_ops(a, b):\n            # a, b are (j, k) tuples. Check k-1.\n            if a[1] == 0 or b[1] == 0: return None\n            a_prev = (a[0], a[1]-1)\n            b_prev = (b[0], b[1]-1)\n            # Must exist and be on the same machine\n            if a_prev in m.O and b_prev in m.O:\n                if m.mach[a_prev] == m.mach[b_prev]:\n                    return (a_prev, b_prev)\n            return None\n    \n        CUT_BUDGET = 300\n        added_cuts = 0\n    \n        for target in targets:\n            ops = target['ops']\n            min_head = min(heads[op] for op in ops)\n            min_tail = min(tails[op] for op in ops)\n    \n            # --- A. Intra-Machine Funnel Cuts (Parent 1) ---\n            # Bound S_u and Cmax using aggregated block workload\n            for u in ops:\n                if added_cuts >= CUT_BUDGET: break\n                \n                # Input-Sum: S_u >= min_head + sum(p_v * y_vu)\n                input_work = 0\n                for v in ops:\n                    if u == v: continue\n                    input_work += m.p[v] * get_prec_var(v, u)\n                \n                m.multi_stage_funnels.add(m.S[u] >= min_head + input_work)\n                added_cuts += 1\n                \n                if added_cuts >= CUT_BUDGET: break\n    \n                # Output-Sum: Cmax >= S_u + p_u + sum(p_v * y_uv) + min_tail\n                output_work = 0\n                for v in ops:\n                    if u == v: continue\n                    output_work += m.p[v] * get_prec_var(u, v)\n                \n                m.multi_stage_funnels.add(\n                    m.Cmax >= m.S[u] + m.p[u] + output_work + min_tail\n                )\n                added_cuts += 1\n    \n            # --- B. Inter-Machine Deviation Cuts (Parent 2 Idea Applied Locally) ---\n            # Strengthen the binary variables inside the funnel by penalizing crossings\n            for i in range(len(ops)):\n                for j in range(i+1, len(ops)):\n                    if added_cuts >= CUT_BUDGET: break\n                    \n                    u = ops[i]\n                    v = ops[j]\n                    prevs = get_prev_ops(u, v)\n                    \n                    if prevs:\n                        u_prev, v_prev = prevs\n                        \n                        # alpha_prev = 1 if u_prev -> v_prev\n                        # alpha_curr = 1 if u -> v\n                        alpha_prev = get_prec_var(u_prev, v_prev)\n                        alpha_curr = get_prec_var(u, v)\n                        \n                        # Cut 1: Bound S_u if u crossed (prev: u->v, curr: v->u)\n                        # Lift: p[v] + p[v_prev]\n                        penalty_u = m.p[v] + m.p[v_prev]\n                        m.multi_stage_funnels.add(\n                            m.S[u] >= m.S[u_prev] + m.p[u_prev] + \n                            penalty_u * (alpha_prev - alpha_curr)\n                        )\n                        added_cuts += 1\n    \n                        # Cut 2: Bound S_v if v crossed (prev: v->u, curr: u->v)\n                        # Lift: p[u] + p[u_prev]\n                        # term: (curr: u->v => alpha_curr=1) - (prev: u->v => alpha_prev=1)\n                        # We want condition: prev v->u (alpha_prev=0) AND curr u->v (alpha_curr=1)\n                        # So term is (alpha_curr - alpha_prev)\n                        penalty_v = m.p[u] + m.p[u_prev]\n                        m.multi_stage_funnels.add(\n                            m.S[v] >= m.S[v_prev] + m.p[v_prev] + \n                            penalty_v * (alpha_curr - alpha_prev)\n                        )\n                        added_cuts += 1\n\n    return model\n",
                        "added_cut": "def add_multi_stage_workload_funnels(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Heads and Tails\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier-style)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by earliest start (heads) to approximate flow\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        best_lb = -1\n        best_sub = []\n        \n        # Find tightest sub-block [u...v]\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0 and len(best_sub) > 1:\n            candidates.append({'lb': best_lb, 'ops': best_sub})\n\n    # Prioritize bottlenecks with highest lower bound\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    targets = candidates[:4] # Focus on top 4 critical blocks\n\n    if not targets: return\n\n    m.multi_stage_funnels = pyo.ConstraintList()\n    \n    # --- Helpers ---\n    # Retrieve binary variable for \"op_a precedes op_b\"\n    def get_prec_var(a, b):\n        if a < b:\n            if (a[0], a[1], b[0], b[1]) in m.Pairs:\n                return m.y[a[0], a[1], b[0], b[1]]\n        else:\n            if (b[0], b[1], a[0], a[1]) in m.Pairs:\n                return 1 - m.y[b[0], b[1], a[0], a[1]]\n        return 0\n\n    # Check for previous machine interaction between two ops\n    def get_prev_ops(a, b):\n        # a, b are (j, k) tuples. Check k-1.\n        if a[1] == 0 or b[1] == 0: return None\n        a_prev = (a[0], a[1]-1)\n        b_prev = (b[0], b[1]-1)\n        # Must exist and be on the same machine\n        if a_prev in m.O and b_prev in m.O:\n            if m.mach[a_prev] == m.mach[b_prev]:\n                return (a_prev, b_prev)\n        return None\n\n    CUT_BUDGET = 300\n    added_cuts = 0\n\n    for target in targets:\n        ops = target['ops']\n        min_head = min(heads[op] for op in ops)\n        min_tail = min(tails[op] for op in ops)\n\n        # --- A. Intra-Machine Funnel Cuts (Parent 1) ---\n        # Bound S_u and Cmax using aggregated block workload\n        for u in ops:\n            if added_cuts >= CUT_BUDGET: break\n            \n            # Input-Sum: S_u >= min_head + sum(p_v * y_vu)\n            input_work = 0\n            for v in ops:\n                if u == v: continue\n                input_work += m.p[v] * get_prec_var(v, u)\n            \n            m.multi_stage_funnels.add(m.S[u] >= min_head + input_work)\n            added_cuts += 1\n            \n            if added_cuts >= CUT_BUDGET: break\n\n            # Output-Sum: Cmax >= S_u + p_u + sum(p_v * y_uv) + min_tail\n            output_work = 0\n            for v in ops:\n                if u == v: continue\n                output_work += m.p[v] * get_prec_var(u, v)\n            \n            m.multi_stage_funnels.add(\n                m.Cmax >= m.S[u] + m.p[u] + output_work + min_tail\n            )\n            added_cuts += 1\n\n        # --- B. Inter-Machine Deviation Cuts (Parent 2 Idea Applied Locally) ---\n        # Strengthen the binary variables inside the funnel by penalizing crossings\n        for i in range(len(ops)):\n            for j in range(i+1, len(ops)):\n                if added_cuts >= CUT_BUDGET: break\n                \n                u = ops[i]\n                v = ops[j]\n                prevs = get_prev_ops(u, v)\n                \n                if prevs:\n                    u_prev, v_prev = prevs\n                    \n                    # alpha_prev = 1 if u_prev -> v_prev\n                    # alpha_curr = 1 if u -> v\n                    alpha_prev = get_prec_var(u_prev, v_prev)\n                    alpha_curr = get_prec_var(u, v)\n                    \n                    # Cut 1: Bound S_u if u crossed (prev: u->v, curr: v->u)\n                    # Lift: p[v] + p[v_prev]\n                    penalty_u = m.p[v] + m.p[v_prev]\n                    m.multi_stage_funnels.add(\n                        m.S[u] >= m.S[u_prev] + m.p[u_prev] + \n                        penalty_u * (alpha_prev - alpha_curr)\n                    )\n                    added_cuts += 1\n\n                    # Cut 2: Bound S_v if v crossed (prev: v->u, curr: u->v)\n                    # Lift: p[u] + p[u_prev]\n                    # term: (curr: u->v => alpha_curr=1) - (prev: u->v => alpha_prev=1)\n                    # We want condition: prev v->u (alpha_prev=0) AND curr u->v (alpha_curr=1)\n                    # So term is (alpha_curr - alpha_prev)\n                    penalty_v = m.p[u] + m.p[u_prev]\n                    m.multi_stage_funnels.add(\n                        m.S[v] >= m.S[v_prev] + m.p[v_prev] + \n                        penalty_v * (alpha_curr - alpha_prev)\n                    )\n                    added_cuts += 1",
                        "idea": "We construct **Multi-Stage Workload Funnels** by integrating Parent 1's dense capacity bounds with Parent 2's deviation logic. We first identify critical bottleneck blocks and apply Input/Output-Sum cuts (Parent 1) to 'funnel' the aggregate processing mass into tight global time bounds ($S_u$ and $C_{max}$). We then reinforce these blocks by adding pairwise Deviation Cuts (Parent 2) specifically between operations in the block. These deviation cuts penalize sequence inversions ($u \\to v$ previously, $v \\to u$ currently) by lifting the start time lower bound using the inverted job's processing time. This synergy tightens the binary precedence variables governing the block, which in turn strengthens the aggregated workload bounds, effectively coupling local machine sequencing decisions with global capacity constraints."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.66,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.07,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.33,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.83,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.82,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.86,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.8,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 11.59,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 11.58,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.52,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.5,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.77,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "7feec2a9-c7f4-48c6-b3a2-73f12bf4ec30",
                        "8aba996b-d3b6-4325-b362-2def7ccead4f"
                    ]
                },
                {
                    "id": "aebfde51-8fea-4c46-9945-639e1e3188bc",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_block_span_elasticity_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute static Heads (Release) and Tails (Tail) times\n        heads = {}\n        tails = {}\n        # Forward pass\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify bottleneck blocks using Carlier's logic\n        candidates = []\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            # Sort by earliest release time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            # Find the sub-sequence with maximum theoretical Lower Bound\n            for i in range(n_ops):\n                p_sum = 0\n                r_i = heads[sorted_ops[i]]\n                for j in range(i, n_ops):\n                    op_j = sorted_ops[j]\n                    p_sum += m.p[op_j]\n                    q_j = tails[op_j]\n                    lb = r_i + p_sum + q_j\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n            \n            if best_sub and len(best_sub) >= 3:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        # Sort candidates to prioritize most critical blocks\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        m.block_span_cuts = pyo.ConstraintList()\n        \n        # Helper to access binary precedence variables safely\n        def get_y(op_a, op_b):\n            # Returns expression for \"a precedes b\"\n            # m.y is indexed by (j1, k1, j2, k2) where tuple(a) < tuple(b)\n            if op_a < op_b:\n                return m.y[op_a[0], op_a[1], op_b[0], op_b[1]]\n            else:\n                return 1 - m.y[op_b[0], op_b[1], op_a[0], op_a[1]]\n    \n        added = 0\n        # 4. Add Elastic Span Cuts for top bottlenecks\n        for cand in candidates[:6]:  # Limit to top blocks to maintain sparsity\n            ops = cand['ops']\n            # Identify potential endpoints: u (start) and v (end)\n            u = min(ops, key=lambda x: heads[x])\n            v = min(ops, key=lambda x: tails[x])\n            \n            if u == v: continue\n            \n            # Construct RHS: p_u + sum of p_w for all w strictly between u and v\n            rhs_expr = m.p[u]\n            for w in ops:\n                if w == u or w == v: continue\n                \n                # Logic: If u -> w -> v, then y_uw=1 and y_wv=1 => term is p_w * (1).\n                # If w is not between, term <= 0 (making constraint looser/valid).\n                # (y_uw + y_wv - 1) is a valid linear lower bound for AND(y_uw, y_wv)\n                y_uw = get_y(u, w)\n                y_wv = get_y(w, v)\n                \n                rhs_expr += m.p[w] * (y_uw + y_wv - 1)\n            \n            # Constraint: The span S_v - S_u must accommodate u and all intermediate operations\n            m.block_span_cuts.add(m.S[v] - m.S[u] >= rhs_expr)\n            added += 1\n\n    return model\n",
                        "added_cut": "def add_block_span_elasticity_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute static Heads (Release) and Tails (Tail) times\n    heads = {}\n    tails = {}\n    # Forward pass\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify bottleneck blocks using Carlier's logic\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        # Sort by earliest release time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        # Find the sub-sequence with maximum theoretical Lower Bound\n        for i in range(n_ops):\n            p_sum = 0\n            r_i = heads[sorted_ops[i]]\n            for j in range(i, n_ops):\n                op_j = sorted_ops[j]\n                p_sum += m.p[op_j]\n                q_j = tails[op_j]\n                lb = r_i + p_sum + q_j\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n        \n        if best_sub and len(best_sub) >= 3:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    # Sort candidates to prioritize most critical blocks\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    m.block_span_cuts = pyo.ConstraintList()\n    \n    # Helper to access binary precedence variables safely\n    def get_y(op_a, op_b):\n        # Returns expression for \"a precedes b\"\n        # m.y is indexed by (j1, k1, j2, k2) where tuple(a) < tuple(b)\n        if op_a < op_b:\n            return m.y[op_a[0], op_a[1], op_b[0], op_b[1]]\n        else:\n            return 1 - m.y[op_b[0], op_b[1], op_a[0], op_a[1]]\n\n    added = 0\n    # 4. Add Elastic Span Cuts for top bottlenecks\n    for cand in candidates[:6]:  # Limit to top blocks to maintain sparsity\n        ops = cand['ops']\n        # Identify potential endpoints: u (start) and v (end)\n        u = min(ops, key=lambda x: heads[x])\n        v = min(ops, key=lambda x: tails[x])\n        \n        if u == v: continue\n        \n        # Construct RHS: p_u + sum of p_w for all w strictly between u and v\n        rhs_expr = m.p[u]\n        for w in ops:\n            if w == u or w == v: continue\n            \n            # Logic: If u -> w -> v, then y_uw=1 and y_wv=1 => term is p_w * (1).\n            # If w is not between, term <= 0 (making constraint looser/valid).\n            # (y_uw + y_wv - 1) is a valid linear lower bound for AND(y_uw, y_wv)\n            y_uw = get_y(u, w)\n            y_wv = get_y(w, v)\n            \n            rhs_expr += m.p[w] * (y_uw + y_wv - 1)\n        \n        # Constraint: The span S_v - S_u must accommodate u and all intermediate operations\n        m.block_span_cuts.add(m.S[v] - m.S[u] >= rhs_expr)\n        added += 1",
                        "idea": "We introduce **Block Span Elasticity Cuts**. Unlike the previous 'Funnel' cuts that anchor decisions to global static bounds (release/tail times), this strategy focuses on the **relative compression** within a machine block. For the most critical bottlenecks, we identify the likely first ($u$) and last ($v$) operations. We then impose a constraint ensuring the time span $S_v - S_u$ is at least $p_u$ plus the sum of processing times of all other operations $w$, conditional on $w$ being sequenced between $u$ and $v$. The condition is linearized as $(y_{uw} + y_{wv} - 1)$, which acts as a valid lower bound for the logical AND. This forces the solver to expand the continuous time interval if it chooses to sequence operations between the endpoints, thereby strengthening the link between the binary precedence decisions and the continuous start variables."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.4,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 14.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 14.86,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.47,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.4,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.74,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.73,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.67,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.6,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.09,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.09,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 18.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 18.51,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.73,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "7feec2a9-c7f4-48c6-b3a2-73f12bf4ec30"
                    ]
                },
                {
                    "id": "9841a198-e999-43df-85b4-51db0eb91283",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_lifted_path_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Heads and Tails for Carlier bounds\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Machine Blocks and Generate Interval Candidates\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        global_max_lb = 0\n        \n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            # Sort operations by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Scan all sub-intervals [u, v]\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    \n                    # Track Global Carlier Lower Bound\n                    lb = r_u + p_sum + q_v\n                    if lb > global_max_lb:\n                        global_max_lb = lb\n                    \n                    # Select intervals with at least one intermediate for lifting\n                    if v > u + 1:\n                        # Score by density: Total Processing / Time Spread\n                        spread = max(1, heads[op_v] - heads[sorted_ops[u]])\n                        candidates.append({\n                            'i': sorted_ops[u],\n                            'j': op_v,\n                            'intermediates': sorted_ops[u+1 : v],\n                            'score': p_sum / spread\n                        })\n    \n        # 3. Apply Global Lower Bound\n        m.lifted_cuts = pyo.ConstraintList()\n        m.lifted_cuts.add(m.Cmax >= global_max_lb)\n    \n        # 4. Apply Aggregated Path Cuts (Budgeted)\n        # Prioritize most congested intervals\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y_expr(u, v):\n            # Helper to access y variables regardless of index order\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n        added = 0\n        BUDGET = 100\n        \n        for c in candidates:\n            if added >= BUDGET: break\n            \n            op_i = c['i']\n            op_j = c['j']\n            intermediates = c['intermediates']\n            \n            # Aggregated Lifting Term: sum(p_k * (y_ik + y_kj - 1))\n            # This term activates (adds p_k) only if k is sequenced between i and j.\n            term_sum = sum(\n                m.p[op_k] * (get_y_expr(op_i, op_k) + get_y_expr(op_k, op_j) - 1)\n                for op_k in intermediates\n            )\n            \n            y_ij = get_y_expr(op_i, op_j)\n            \n            # Constraint: S_j >= S_i + p_i + Sum(p_k if k in path) - M(1 - y_ij)\n            m.lifted_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + term_sum - m.bigM * (1 - y_ij)\n            )\n            added += 1\n    \n    add_lifted_path_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_lifted_path_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Heads and Tails for Carlier bounds\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Machine Blocks and Generate Interval Candidates\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    global_max_lb = 0\n    \n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        # Sort operations by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Scan all sub-intervals [u, v]\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                \n                # Track Global Carlier Lower Bound\n                lb = r_u + p_sum + q_v\n                if lb > global_max_lb:\n                    global_max_lb = lb\n                \n                # Select intervals with at least one intermediate for lifting\n                if v > u + 1:\n                    # Score by density: Total Processing / Time Spread\n                    spread = max(1, heads[op_v] - heads[sorted_ops[u]])\n                    candidates.append({\n                        'i': sorted_ops[u],\n                        'j': op_v,\n                        'intermediates': sorted_ops[u+1 : v],\n                        'score': p_sum / spread\n                    })\n\n    # 3. Apply Global Lower Bound\n    m.lifted_cuts = pyo.ConstraintList()\n    m.lifted_cuts.add(m.Cmax >= global_max_lb)\n\n    # 4. Apply Aggregated Path Cuts (Budgeted)\n    # Prioritize most congested intervals\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y_expr(u, v):\n        # Helper to access y variables regardless of index order\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n    added = 0\n    BUDGET = 100\n    \n    for c in candidates:\n        if added >= BUDGET: break\n        \n        op_i = c['i']\n        op_j = c['j']\n        intermediates = c['intermediates']\n        \n        # Aggregated Lifting Term: sum(p_k * (y_ik + y_kj - 1))\n        # This term activates (adds p_k) only if k is sequenced between i and j.\n        term_sum = sum(\n            m.p[op_k] * (get_y_expr(op_i, op_k) + get_y_expr(op_k, op_j) - 1)\n            for op_k in intermediates\n        )\n        \n        y_ij = get_y_expr(op_i, op_j)\n        \n        # Constraint: S_j >= S_i + p_i + Sum(p_k if k in path) - M(1 - y_ij)\n        m.lifted_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + term_sum - m.bigM * (1 - y_ij)\n        )\n        added += 1\n\nadd_lifted_path_cuts(model)",
                        "idea": "We apply **Aggregated Path Lifting** to evolve the pairwise triplet cuts. Instead of generating weak individual cuts for each intermediate node $k$ in a triplet $(i, k, j)$, we identify dense critical windows $[i, j]$ and enforce a single, tightened inequality that aggregates the processing times of *all* intermediate operations $K_{ij}$: $S_j \\ge S_i + p_i + \\sum_{k \\in K_{ij}} p_k(y_{ik} + y_{kj} - 1) - M(1-y_{ij})$. This captures the cumulative displacement of the entire substructure when $i$ precedes $j$, utilizing superadditivity to significantly constrain the feasible region within the budget."
                    },
                    "fitness": 21.91288473816205,
                    "solver_reports": [
                        {
                            "gap": 16.681,
                            "total_time": 13.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 35876,
                            "explored_time": 13.59,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.9455,
                            "total_time": 14.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 35831,
                            "explored_time": 14.45,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.35,
                            "explored_nodes": 1,
                            "simplex_iterations": 35631,
                            "explored_time": 10.3,
                            "work_units": 10.0
                        },
                        {
                            "gap": 17.1053,
                            "total_time": 13.73,
                            "explored_nodes": 59,
                            "simplex_iterations": 60183,
                            "explored_time": 13.72,
                            "work_units": 10.14
                        },
                        {
                            "total_time": 10.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 32881,
                            "explored_time": 10.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 3.881,
                            "total_time": 11.89,
                            "explored_nodes": 3925,
                            "simplex_iterations": 196943,
                            "explored_time": 11.88,
                            "work_units": 10.36
                        },
                        {
                            "gap": 29.6125,
                            "total_time": 11.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 48132,
                            "explored_time": 11.15,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 37630,
                            "explored_time": 11.93,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "96a1c877-22bc-4bf3-b826-d95500cf67bd",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_global_volume_tail_cuts(m):\n        import pyomo.environ as pyo\n    \n        # --- 1. Tail Analysis (Inherited from Parent 2) ---\n        # Calculate remaining work (tails) for each operation\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # --- 2. Critical Machine Detection (Inherited from Parent 2) ---\n        # Identify bottleneck machines to filter high-impact cuts\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        critical_machs = set()\n        if mach_ops:\n            mach_stats = []\n            for mid, ops in mach_ops.items():\n                # Lower Bound = Min Release + Load + Min Tail\n                min_r = min(sum(m.p[j, x] for x in range(k)) for (j, k) in ops)\n                min_q = min(tails[j, k] for (j, k) in ops)\n                load = sum(m.p[op] for op in ops)\n                mach_stats.append((mid, min_r + load + min_q))\n            \n            if mach_stats:\n                mach_stats.sort(key=lambda x: x[1], reverse=True)\n                global_lb = mach_stats[0][1]\n                # Filter: Machines with LB >= 85% of global LB\n                critical_machs = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n    \n        # --- 3. Block Analysis & Cut Generation (Inherited from Parent 1) ---\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        candidates = []\n        for mid in critical_machs:\n            ops = mach_ops[mid]\n            if len(ops) < 3: continue\n            # Heuristic sort by earliest start\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            vol = sum(m.p[op] for op in ops)\n            candidates.append({'mid': mid, 'ops': sorted_ops, 'vol': vol})\n    \n        # Target highest load blocks\n        candidates.sort(key=lambda x: x['vol'], reverse=True)\n        \n        m.global_volume_tail_cuts = pyo.ConstraintList()\n        CUT_BUDGET = 200\n        added_cuts = 0\n        big_M = m.bigM\n    \n        def get_y(u, v):\n            # Helper to access y variables regardless of (j, k) order\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for block in candidates[:10]:\n            ops = block['ops']\n            n = len(ops)\n            \n            # Identify pairs (u, v) enclosing significant static volume\n            pairs = []\n            for i in range(n-1):\n                for j in range(i+1, n):\n                    u = ops[i]\n                    v = ops[j]\n                    static_vol = sum(m.p[ops[x]] for x in range(i+1, j))\n                    if static_vol > 0:\n                        pairs.append((u, v, static_vol))\n            \n            # Sort pairs to prioritize larger blocks\n            pairs.sort(key=lambda x: x[2], reverse=True)\n    \n            for (u, v, _) in pairs[:5]:\n                if added_cuts >= CUT_BUDGET: break\n                \n                y_uv = get_y(u, v)\n                \n                # Calculate Dynamic Volume of intermediates (Logic from Parent 1)\n                # Sum of p_k for all k where u -> k -> v is active\n                intermediates = [op for op in ops if op != u and op != v]\n                if not intermediates: continue\n    \n                vol_expr = 0\n                for k_op in intermediates:\n                    # term = 1 if u -> k -> v, else <= 0\n                    term = get_y(u, k_op) + get_y(k_op, v) - 1\n                    vol_expr += m.p[k_op] * term\n    \n                # Combined Cut: Lift local volume to global Cmax (Logic from Parent 2)\n                # If u -> v, Cmax >= Start_u + Duration_u + Volume_Intermediates + Duration_v + Tail_v\n                # This bypasses S_v variable to tighten Cmax directly.\n                m.global_volume_tail_cuts.add(\n                    m.Cmax >= m.S[u] + m.p[u] + \n                              vol_expr + \n                              m.p[v] + tails[v] - \n                              big_M * (1 - y_uv)\n                )\n                added_cuts += 1\n                \n            if added_cuts >= CUT_BUDGET: break\n\n    return model\n",
                        "added_cut": "def add_global_volume_tail_cuts(m):\n    import pyomo.environ as pyo\n\n    # --- 1. Tail Analysis (Inherited from Parent 2) ---\n    # Calculate remaining work (tails) for each operation\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # --- 2. Critical Machine Detection (Inherited from Parent 2) ---\n    # Identify bottleneck machines to filter high-impact cuts\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    critical_machs = set()\n    if mach_ops:\n        mach_stats = []\n        for mid, ops in mach_ops.items():\n            # Lower Bound = Min Release + Load + Min Tail\n            min_r = min(sum(m.p[j, x] for x in range(k)) for (j, k) in ops)\n            min_q = min(tails[j, k] for (j, k) in ops)\n            load = sum(m.p[op] for op in ops)\n            mach_stats.append((mid, min_r + load + min_q))\n        \n        if mach_stats:\n            mach_stats.sort(key=lambda x: x[1], reverse=True)\n            global_lb = mach_stats[0][1]\n            # Filter: Machines with LB >= 85% of global LB\n            critical_machs = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n\n    # --- 3. Block Analysis & Cut Generation (Inherited from Parent 1) ---\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    candidates = []\n    for mid in critical_machs:\n        ops = mach_ops[mid]\n        if len(ops) < 3: continue\n        # Heuristic sort by earliest start\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        vol = sum(m.p[op] for op in ops)\n        candidates.append({'mid': mid, 'ops': sorted_ops, 'vol': vol})\n\n    # Target highest load blocks\n    candidates.sort(key=lambda x: x['vol'], reverse=True)\n    \n    m.global_volume_tail_cuts = pyo.ConstraintList()\n    CUT_BUDGET = 200\n    added_cuts = 0\n    big_M = m.bigM\n\n    def get_y(u, v):\n        # Helper to access y variables regardless of (j, k) order\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for block in candidates[:10]:\n        ops = block['ops']\n        n = len(ops)\n        \n        # Identify pairs (u, v) enclosing significant static volume\n        pairs = []\n        for i in range(n-1):\n            for j in range(i+1, n):\n                u = ops[i]\n                v = ops[j]\n                static_vol = sum(m.p[ops[x]] for x in range(i+1, j))\n                if static_vol > 0:\n                    pairs.append((u, v, static_vol))\n        \n        # Sort pairs to prioritize larger blocks\n        pairs.sort(key=lambda x: x[2], reverse=True)\n\n        for (u, v, _) in pairs[:5]:\n            if added_cuts >= CUT_BUDGET: break\n            \n            y_uv = get_y(u, v)\n            \n            # Calculate Dynamic Volume of intermediates (Logic from Parent 1)\n            # Sum of p_k for all k where u -> k -> v is active\n            intermediates = [op for op in ops if op != u and op != v]\n            if not intermediates: continue\n\n            vol_expr = 0\n            for k_op in intermediates:\n                # term = 1 if u -> k -> v, else <= 0\n                term = get_y(u, k_op) + get_y(k_op, v) - 1\n                vol_expr += m.p[k_op] * term\n\n            # Combined Cut: Lift local volume to global Cmax (Logic from Parent 2)\n            # If u -> v, Cmax >= Start_u + Duration_u + Volume_Intermediates + Duration_v + Tail_v\n            # This bypasses S_v variable to tighten Cmax directly.\n            m.global_volume_tail_cuts.add(\n                m.Cmax >= m.S[u] + m.p[u] + \n                          vol_expr + \n                          m.p[v] + tails[v] - \n                          big_M * (1 - y_uv)\n            )\n            added_cuts += 1\n            \n        if added_cuts >= CUT_BUDGET: break",
                        "idea": "We introduce **Global Volume-Tail Cuts**, which synthesize the local density logic of Parent 1 with the global projection of Parent 2. Instead of merely enforcing spacing between two operations $u$ and $v$ on a machine (Parent 1), this strategy lifts that spacing constraint directly to the makespan ($C_{max}$) by incorporating the **Tail** of the downstream operation $v$ (Parent 2). The cut asserts that if $u$ precedes $v$ on a critical machine, $C_{max}$ must accommodate the start of $u$, the processing of $u$ and $v$, the processing of all dynamically intermediate jobs (the 'Volume'), and the subsequent work remaining after $v$. This creates a powerful global bound that tightens the relaxation by bridging local sequencing decisions with objective value requirements."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.22,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.2,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.19,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.68,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.67,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.12,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.72,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.17,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.76,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "c26f9990-6a08-4503-94a5-d3744c2b47ca",
                        "424f28a0-86ef-4ac3-8294-75211b873dbc"
                    ]
                },
                {
                    "id": "b4ae9e44-273e-40f1-b813-a256d0829380",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_pairwise_objective_lifting_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Static Heads (Earliest Start) and Tails (Work Remaining)\n        heads = {}\n        tails = {}\n        \n        # Forward pass: Heads\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        # Backward pass: Tails\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Estimate Global Static Lower Bound (Critical Path)\n        # This filters out non-critical pairs that don't threaten the makespan\n        global_lb = 0\n        for o in m.O:\n            val = heads[o] + m.p[o] + tails[o]\n            if val > global_lb:\n                global_lb = val\n    \n        # 3. Identify and Score Critical Pairs\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        \n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            \n            # Iterate all unique pairs on the machine\n            for i, u in enumerate(ops):\n                for v in ops[i+1:]:\n                    # Calculate Carlier 1-Machine Bounds for the pair {u, v}\n                    \n                    # Case A: Sequence u -> v\n                    # Must finish at least: head(u) + p(u) + p(v) + tail(v)\n                    lb_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n                    \n                    # Case B: Sequence v -> u\n                    # Must finish at least: head(v) + p(v) + p(u) + tail(u)\n                    lb_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n                    \n                    # Metric: \"Lift Potential\"\n                    # We only care if at least one direction pushes the objective high.\n                    mx = max(lb_uv, lb_vu)\n                    \n                    # Filter: Keep only pairs close to or exceeding the global bottleneck\n                    if mx > 0.85 * global_lb:\n                        candidates.append({\n                            'u': u, \n                            'v': v, \n                            'lb_uv': lb_uv, \n                            'lb_vu': lb_vu, \n                            'score': mx\n                        })\n    \n        # Sort candidates to prioritize the most restrictive constraints\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        \n        # 4. Apply Cuts\n        m.objective_lifting = pyo.ConstraintList()\n        added = 0\n        BUDGET = 200\n        \n        for c in candidates:\n            if added >= BUDGET: break\n            \n            u, v = c['u'], c['v']\n            \n            # Retrieve the correct binary variable from the model\n            # Model stores y for (j1, k1, j2, k2) where tuple1 < tuple2\n            if u < v:\n                # y[u, v] = 1 implies u -> v\n                y_expr = m.y[u[0], u[1], v[0], v[1]]\n                # If y=1, LB is lb_uv. If y=0, LB is lb_vu.\n                rhs = c['lb_vu'] + (c['lb_uv'] - c['lb_vu']) * y_expr\n            else:\n                # y[v, u] = 1 implies v -> u\n                y_expr = m.y[v[0], v[1], u[0], u[1]]\n                # If y=1, LB is lb_vu. If y=0, LB is lb_uv.\n                rhs = c['lb_uv'] + (c['lb_vu'] - c['lb_uv']) * y_expr\n                \n            m.objective_lifting.add(m.Cmax >= rhs)\n            added += 1\n    \n    add_pairwise_objective_lifting_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_pairwise_objective_lifting_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Static Heads (Earliest Start) and Tails (Work Remaining)\n    heads = {}\n    tails = {}\n    \n    # Forward pass: Heads\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    # Backward pass: Tails\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Estimate Global Static Lower Bound (Critical Path)\n    # This filters out non-critical pairs that don't threaten the makespan\n    global_lb = 0\n    for o in m.O:\n        val = heads[o] + m.p[o] + tails[o]\n        if val > global_lb:\n            global_lb = val\n\n    # 3. Identify and Score Critical Pairs\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    \n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        \n        # Iterate all unique pairs on the machine\n        for i, u in enumerate(ops):\n            for v in ops[i+1:]:\n                # Calculate Carlier 1-Machine Bounds for the pair {u, v}\n                \n                # Case A: Sequence u -> v\n                # Must finish at least: head(u) + p(u) + p(v) + tail(v)\n                lb_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n                \n                # Case B: Sequence v -> u\n                # Must finish at least: head(v) + p(v) + p(u) + tail(u)\n                lb_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n                \n                # Metric: \"Lift Potential\"\n                # We only care if at least one direction pushes the objective high.\n                mx = max(lb_uv, lb_vu)\n                \n                # Filter: Keep only pairs close to or exceeding the global bottleneck\n                if mx > 0.85 * global_lb:\n                    candidates.append({\n                        'u': u, \n                        'v': v, \n                        'lb_uv': lb_uv, \n                        'lb_vu': lb_vu, \n                        'score': mx\n                    })\n\n    # Sort candidates to prioritize the most restrictive constraints\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    # 4. Apply Cuts\n    m.objective_lifting = pyo.ConstraintList()\n    added = 0\n    BUDGET = 200\n    \n    for c in candidates:\n        if added >= BUDGET: break\n        \n        u, v = c['u'], c['v']\n        \n        # Retrieve the correct binary variable from the model\n        # Model stores y for (j1, k1, j2, k2) where tuple1 < tuple2\n        if u < v:\n            # y[u, v] = 1 implies u -> v\n            y_expr = m.y[u[0], u[1], v[0], v[1]]\n            # If y=1, LB is lb_uv. If y=0, LB is lb_vu.\n            rhs = c['lb_vu'] + (c['lb_uv'] - c['lb_vu']) * y_expr\n        else:\n            # y[v, u] = 1 implies v -> u\n            y_expr = m.y[v[0], v[1], u[0], u[1]]\n            # If y=1, LB is lb_vu. If y=0, LB is lb_uv.\n            rhs = c['lb_uv'] + (c['lb_vu'] - c['lb_uv']) * y_expr\n            \n        m.objective_lifting.add(m.Cmax >= rhs)\n        added += 1\n\nadd_pairwise_objective_lifting_cuts(model)",
                        "idea": "We introduce **Pairwise Objective-Lifting Cuts** to complement the parents by directly linking binary sequencing decisions to the global objective ($C_{max}$). While Parent 1 aggregates workloads into start time variables and Parent 2 enforces local triplet consistency, this strategy pre-calculates the unavoidable makespan ($Head + P_u + P_v + Tail$) for both orientations of critical pairs. It then imposes a conditional lower bound on $C_{max}$ that varies linearly with the precedence variable $y_{uv}$. This creates a V-shaped cut on the relaxation surface, penalizing fractional ambiguity in high-impact sequencing decisions and forcing the LP dual bound closer to the true integer makespan."
                    },
                    "fitness": 14.151518915860482,
                    "solver_reports": [
                        {
                            "gap": 56.745,
                            "total_time": 15.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 57385,
                            "explored_time": 15.0,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 17.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 58528,
                            "explored_time": 17.54,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 16.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 58897,
                            "explored_time": 16.68,
                            "work_units": 10.0
                        },
                        {
                            "gap": 47.8008,
                            "total_time": 10.58,
                            "explored_nodes": 618,
                            "simplex_iterations": 178677,
                            "explored_time": 10.57,
                            "work_units": 10.13
                        },
                        {
                            "total_time": 18.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 79213,
                            "explored_time": 18.22,
                            "work_units": 10.0
                        },
                        {
                            "gap": 33.8746,
                            "total_time": 11.95,
                            "explored_nodes": 5749,
                            "simplex_iterations": 369009,
                            "explored_time": 11.93,
                            "work_units": 10.0
                        },
                        {
                            "gap": 43.4501,
                            "total_time": 15.86,
                            "explored_nodes": 115,
                            "simplex_iterations": 88724,
                            "explored_time": 15.84,
                            "work_units": 10.8
                        },
                        {
                            "total_time": 13.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 62765,
                            "explored_time": 13.78,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "7feec2a9-c7f4-48c6-b3a2-73f12bf4ec30",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "1f863c3c-34f6-4ffc-ab71-df5f90da0e79",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_block_tail_flow_cuts(m):\n        \"\"\"\n        Combines Parent 1's Critical Block structure with Parent 2's Global Tail Projection and Crossing logic.\n        1. Filters for 'Critical Machines' using Parent 2's LB criteria (Release + Load + Tail).\n        2. Identifies 'Carlier Blocks' on these machines (Parent 1).\n        3. Adds 'Tail-Anchored Flow Cuts': Bounds Cmax using block volume and pivot tail.\n        4. Adds 'Crossing-Tail Cuts': Bounds Cmax using sequence deviations between block members and previous machines.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # --- 1. Precompute Timing (Heads & Tails) ---\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # --- 2. Identify Critical Machines (Hybrid Filter) ---\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Calculate 1-machine LB for each machine to find bottlenecks\n        mach_stats = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            min_r = min(heads[op] for op in ops)\n            sum_p = sum(m.p[op] for op in ops)\n            min_q = min(tails[op] for op in ops)\n            mach_stats.append((mid, min_r + sum_p + min_q))\n        \n        if not mach_stats: return\n    \n        # Filter: Focus on machines within 85% of the max lower bound\n        mach_stats.sort(key=lambda x: x[1], reverse=True)\n        global_lb = mach_stats[0][1]\n        critical_mids = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n    \n        # Helper: Get binary variable for u -> v (handles ordering)\n        def get_y(u, v):\n            # Assumes u != v\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.critical_block_tail_cuts = pyo.ConstraintList()\n        CUT_BUDGET = 100\n        added = 0\n    \n        # --- 3. Generate Cuts on Critical Machines ---\n        for mid in critical_mids:\n            if added >= CUT_BUDGET: break\n            ops = mach_ops[mid]\n            # Sort by earliest start time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # --- Find Critical Block (P1 Logic) ---\n            best_block_lb = -1\n            block = []\n            pivot = None\n    \n            # Identify block [i...j] with max LB\n            for i in range(n):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]]\n                for j_idx in range(i, n):\n                    op = sorted_ops[j_idx]\n                    p_sum += m.p[op]\n                    q_val = tails[op]\n                    current_lb = r_val + p_sum + q_val\n                    \n                    if current_lb > best_block_lb:\n                        best_block_lb = current_lb\n                        block = sorted_ops[i : j_idx+1]\n                        pivot = op # Pivot is the sink of the block\n    \n            if not block or len(block) < 2: continue\n    \n            # --- Cut A: Tail-Anchored Flow Bound ---\n            # Projects machine capacity congestion to Cmax\n            r_min = min(heads[op] for op in block)\n            flow_expr = 0\n            for op in block:\n                if op == pivot: continue\n                # Sum processing of all ops that END UP preceding pivot\n                flow_expr += m.p[op] * get_y(op, pivot)\n            \n            m.critical_block_tail_cuts.add(\n                m.Cmax >= r_min + flow_expr + m.p[pivot] + tails[pivot]\n            )\n            added += 1\n    \n            # --- Cut B: Crossing-Tail Cuts for Block Members ---\n            # If block members crossed on a previous machine, apply P2 penalty\n            for op_u in block:\n                if added >= CUT_BUDGET: break\n                if op_u == pivot: continue\n                \n                # Check relation against pivot\n                op_v = pivot \n                \n                # Retrieve machine sequences\n                u_job, v_job = op_u[0], op_v[0]\n                if u_job == v_job: continue # Should not happen in block but safety check\n                \n                u_seq = sorted([(k, m.mach[u_job, k]) for k in m.K if (u_job, k) in m.O], key=lambda x: x[0])\n                v_seq = sorted([(k, m.mach[v_job, k]) for k in m.K if (v_job, k) in m.O], key=lambda x: x[0])\n                \n                u_mid_k = {mm: kk for kk, mm in u_seq}\n                v_mid_k = {mm: kk for kk, mm in v_seq}\n                \n                # Find common previous machines\n                common_mids = set(u_mid_k.keys()) & set(v_mid_k.keys()) - {mid}\n                \n                for pm in common_mids:\n                    # Check if pm is actually previous\n                    if u_mid_k[pm] < op_u[1] and v_mid_k[pm] < op_v[1]:\n                        u_prev = (u_job, u_mid_k[pm])\n                        v_prev = (v_job, v_mid_k[pm])\n                        \n                        # Crossing Logic: u->v on Prev, v->u on Curr\n                        y_prev = get_y(u_prev, v_prev)\n                        y_curr = get_y(op_u, op_v)\n                        \n                        # Approximate interference penalty\n                        penalty = m.p[op_v] + m.p[v_prev]\n                        \n                        # Cmax >= S_u_prev + p_u_prev + Penalty*(Crossing) + p_u_curr + Tail_u_curr\n                        # Lifts the delay from the previous machine crossing directly to Cmax\n                        m.critical_block_tail_cuts.add(\n                            m.Cmax >= m.S[u_prev] + m.p[u_prev] + \n                            penalty * (y_prev - y_curr) + \n                            m.p[op_u] + tails[op_u]\n                        )\n                        added += 1\n                        break # Only add one crossing cut per op to save budget\n\n    return model\n",
                        "added_cut": "def add_critical_block_tail_flow_cuts(m):\n    \"\"\"\n    Combines Parent 1's Critical Block structure with Parent 2's Global Tail Projection and Crossing logic.\n    1. Filters for 'Critical Machines' using Parent 2's LB criteria (Release + Load + Tail).\n    2. Identifies 'Carlier Blocks' on these machines (Parent 1).\n    3. Adds 'Tail-Anchored Flow Cuts': Bounds Cmax using block volume and pivot tail.\n    4. Adds 'Crossing-Tail Cuts': Bounds Cmax using sequence deviations between block members and previous machines.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # --- 1. Precompute Timing (Heads & Tails) ---\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # --- 2. Identify Critical Machines (Hybrid Filter) ---\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Calculate 1-machine LB for each machine to find bottlenecks\n    mach_stats = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        min_r = min(heads[op] for op in ops)\n        sum_p = sum(m.p[op] for op in ops)\n        min_q = min(tails[op] for op in ops)\n        mach_stats.append((mid, min_r + sum_p + min_q))\n    \n    if not mach_stats: return\n\n    # Filter: Focus on machines within 85% of the max lower bound\n    mach_stats.sort(key=lambda x: x[1], reverse=True)\n    global_lb = mach_stats[0][1]\n    critical_mids = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n\n    # Helper: Get binary variable for u -> v (handles ordering)\n    def get_y(u, v):\n        # Assumes u != v\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.critical_block_tail_cuts = pyo.ConstraintList()\n    CUT_BUDGET = 100\n    added = 0\n\n    # --- 3. Generate Cuts on Critical Machines ---\n    for mid in critical_mids:\n        if added >= CUT_BUDGET: break\n        ops = mach_ops[mid]\n        # Sort by earliest start time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # --- Find Critical Block (P1 Logic) ---\n        best_block_lb = -1\n        block = []\n        pivot = None\n\n        # Identify block [i...j] with max LB\n        for i in range(n):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]]\n            for j_idx in range(i, n):\n                op = sorted_ops[j_idx]\n                p_sum += m.p[op]\n                q_val = tails[op]\n                current_lb = r_val + p_sum + q_val\n                \n                if current_lb > best_block_lb:\n                    best_block_lb = current_lb\n                    block = sorted_ops[i : j_idx+1]\n                    pivot = op # Pivot is the sink of the block\n\n        if not block or len(block) < 2: continue\n\n        # --- Cut A: Tail-Anchored Flow Bound ---\n        # Projects machine capacity congestion to Cmax\n        r_min = min(heads[op] for op in block)\n        flow_expr = 0\n        for op in block:\n            if op == pivot: continue\n            # Sum processing of all ops that END UP preceding pivot\n            flow_expr += m.p[op] * get_y(op, pivot)\n        \n        m.critical_block_tail_cuts.add(\n            m.Cmax >= r_min + flow_expr + m.p[pivot] + tails[pivot]\n        )\n        added += 1\n\n        # --- Cut B: Crossing-Tail Cuts for Block Members ---\n        # If block members crossed on a previous machine, apply P2 penalty\n        for op_u in block:\n            if added >= CUT_BUDGET: break\n            if op_u == pivot: continue\n            \n            # Check relation against pivot\n            op_v = pivot \n            \n            # Retrieve machine sequences\n            u_job, v_job = op_u[0], op_v[0]\n            if u_job == v_job: continue # Should not happen in block but safety check\n            \n            u_seq = sorted([(k, m.mach[u_job, k]) for k in m.K if (u_job, k) in m.O], key=lambda x: x[0])\n            v_seq = sorted([(k, m.mach[v_job, k]) for k in m.K if (v_job, k) in m.O], key=lambda x: x[0])\n            \n            u_mid_k = {mm: kk for kk, mm in u_seq}\n            v_mid_k = {mm: kk for kk, mm in v_seq}\n            \n            # Find common previous machines\n            common_mids = set(u_mid_k.keys()) & set(v_mid_k.keys()) - {mid}\n            \n            for pm in common_mids:\n                # Check if pm is actually previous\n                if u_mid_k[pm] < op_u[1] and v_mid_k[pm] < op_v[1]:\n                    u_prev = (u_job, u_mid_k[pm])\n                    v_prev = (v_job, v_mid_k[pm])\n                    \n                    # Crossing Logic: u->v on Prev, v->u on Curr\n                    y_prev = get_y(u_prev, v_prev)\n                    y_curr = get_y(op_u, op_v)\n                    \n                    # Approximate interference penalty\n                    penalty = m.p[op_v] + m.p[v_prev]\n                    \n                    # Cmax >= S_u_prev + p_u_prev + Penalty*(Crossing) + p_u_curr + Tail_u_curr\n                    # Lifts the delay from the previous machine crossing directly to Cmax\n                    m.critical_block_tail_cuts.add(\n                        m.Cmax >= m.S[u_prev] + m.p[u_prev] + \n                        penalty * (y_prev - y_curr) + \n                        m.p[op_u] + tails[op_u]\n                    )\n                    added += 1\n                    break # Only add one crossing cut per op to save budget",
                        "idea": "We introduce 'Critical Block Tail-Flow Cuts', a hybrid strategy that fuses Parent 1's vertical capacity blocks with Parent 2's global tail projection. By identifying critical blocks on bottleneck machines (Parent 1), we enforce a strengthened bound on the pivot operation's start time using the volume of its predecessors ($S_{pivot} \\ge r_{min} + \\sum p_j y_{jk}$), but crucially, we project this directly to the makespan ($C_{max}$) using the pivot's tail ($q_{pivot}$). Additionally, for block members that interact on previous machines, we incorporate Parent 2's crossing penalties ($y^{prev} - y^{curr}$) to lift sequence delays to $C_{max}$. This dual approach simultaneously tightens resource capacity bounds and penalizes infeasible sequence swaps."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.87,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.32,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.28,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.58,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.53,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.07,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.06,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.71,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.92,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.91,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.85,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.15,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "8aba996b-d3b6-4325-b362-2def7ccead4f",
                        "424f28a0-86ef-4ac3-8294-75211b873dbc"
                    ]
                },
                {
                    "id": "5bc84b2b-8efb-4479-9116-aec028a5bdb9",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_aggregate_congestion_cuts(m):\n        \"\"\"\n        Adds 'Aggregate Congestion Cuts' (ACC) to the model.\n        ACC enforces a lower bound on the sum of start times for clusters of operations on a single machine.\n        It relies on the relaxation that even if all operations in a cluster were released at the cluster's \n        earliest release time (r_min), their combined start times must allow for processing sequences (SPT logic).\n        This lifts the 'volume' of the variables, repairing weak Big-M behavior in dense schedules.\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # 1. Precompute static earliest start times (heads)\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.aggregate_congestion_cuts = pyo.ConstraintList()\n        \n        # Sliding window sizes for clustering\n        # Larger windows capture broader congestion; smaller capture local bottlenecks.\n        WINDOW_SIZES = [3, 4, 5, 6]\n    \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            \n            # Sort operations by release time (head) to identify time-localized clusters\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            for w in WINDOW_SIZES:\n                if n_ops < w: continue\n                \n                for i in range(n_ops - w + 1):\n                    block = sorted_ops[i : i+w]\n                    \n                    # --- Derivation of the Cut ---\n                    # We want a lower bound on sum(S_op) for op in block.\n                    # Relaxation: Assume all ops are ready at r_min = min(heads).\n                    # On a single machine, sum(S) is minimized by Shortest Processing Time (SPT) order.\n                    \n                    r_min = min(heads[op] for op in block)\n                    \n                    # Sort processing times for SPT calculation\n                    p_vals = sorted([pyo.value(m.p[op]) for op in block])\n                    \n                    # Calculate Minimum Internal Waiting Time (Interaction Cost)\n                    # For w jobs starting at t=0, sorted by p, the sum of start times is:\n                    # 0 + p_0 + (p_0 + p_1) + ... = sum_{k=0 to w-1} (w - 1 - k) * p_k\n                    interaction_cost = sum((w - 1 - k) * p_vals[k] for k in range(w))\n                    \n                    # The aggregate bound\n                    # If all start at r_min, sum(S) >= w * r_min + interaction_cost\n                    rhs_val = w * r_min + interaction_cost\n                    \n                    # Filter: Only add if this bound is stronger than the trivial sum of heads\n                    # (Trivial: S_j >= head_j, so sum(S) >= sum(heads))\n                    trivial_bound = sum(heads[op] for op in block)\n                    \n                    if rhs_val > trivial_bound + 1e-4:\n                        lhs_expr = sum(m.S[op] for op in block)\n                        m.aggregate_congestion_cuts.add(lhs_expr >= rhs_val)\n\n    return model\n",
                        "added_cut": "def add_aggregate_congestion_cuts(m):\n    \"\"\"\n    Adds 'Aggregate Congestion Cuts' (ACC) to the model.\n    ACC enforces a lower bound on the sum of start times for clusters of operations on a single machine.\n    It relies on the relaxation that even if all operations in a cluster were released at the cluster's \n    earliest release time (r_min), their combined start times must allow for processing sequences (SPT logic).\n    This lifts the 'volume' of the variables, repairing weak Big-M behavior in dense schedules.\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # 1. Precompute static earliest start times (heads)\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.aggregate_congestion_cuts = pyo.ConstraintList()\n    \n    # Sliding window sizes for clustering\n    # Larger windows capture broader congestion; smaller capture local bottlenecks.\n    WINDOW_SIZES = [3, 4, 5, 6]\n\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        \n        # Sort operations by release time (head) to identify time-localized clusters\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        for w in WINDOW_SIZES:\n            if n_ops < w: continue\n            \n            for i in range(n_ops - w + 1):\n                block = sorted_ops[i : i+w]\n                \n                # --- Derivation of the Cut ---\n                # We want a lower bound on sum(S_op) for op in block.\n                # Relaxation: Assume all ops are ready at r_min = min(heads).\n                # On a single machine, sum(S) is minimized by Shortest Processing Time (SPT) order.\n                \n                r_min = min(heads[op] for op in block)\n                \n                # Sort processing times for SPT calculation\n                p_vals = sorted([pyo.value(m.p[op]) for op in block])\n                \n                # Calculate Minimum Internal Waiting Time (Interaction Cost)\n                # For w jobs starting at t=0, sorted by p, the sum of start times is:\n                # 0 + p_0 + (p_0 + p_1) + ... = sum_{k=0 to w-1} (w - 1 - k) * p_k\n                interaction_cost = sum((w - 1 - k) * p_vals[k] for k in range(w))\n                \n                # The aggregate bound\n                # If all start at r_min, sum(S) >= w * r_min + interaction_cost\n                rhs_val = w * r_min + interaction_cost\n                \n                # Filter: Only add if this bound is stronger than the trivial sum of heads\n                # (Trivial: S_j >= head_j, so sum(S) >= sum(heads))\n                trivial_bound = sum(heads[op] for op in block)\n                \n                if rhs_val > trivial_bound + 1e-4:\n                    lhs_expr = sum(m.S[op] for op in block)\n                    m.aggregate_congestion_cuts.add(lhs_expr >= rhs_val)",
                        "idea": "We introduce **Aggregate Congestion Cuts (ACC)**, an exploratory mutation that shifts focus from individual pivot anchoring (Parent 1) to **cluster-based volumetric bounds**. By identifying operation clusters on each machine and relaxing their constraints to a single-machine problem with simultaneous release, ACC derives a valid lower bound on the **sum of start times** using Shortest Processing Time (SPT) logic. This effectively cuts off weak Big-M solutions where multiple operations in a high-density block are artificially scheduled too early, forcing the solver to acknowledge the unavoidable 'latency mass' generated by resource contention."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.13,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.84,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.8,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.05,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.01,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.05,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.04,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.09,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.04,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.24,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.23,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.6,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.19,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.15,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "8aba996b-d3b6-4325-b362-2def7ccead4f"
                    ]
                }
            ],
            23.42775824076793
        ],
        [
            [
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "9a5899e1-a817-4e71-98b6-df4fe00147ca",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_machine_workload_accumulation_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Heads (Earliest Start) and Tails (Work Remaining)\n        heads = {}\n        tails = {}\n        \n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Machines (Bottleneck Detection)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        machine_lbs = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Lower Bound = Min Release + Total Load + Min Tail\n            min_head = min(heads[op] for op in ops)\n            min_tail = min(tails[op] for op in ops)\n            total_p = sum(m.p[op] for op in ops)\n            machine_lbs.append((mid, min_head + total_p + min_tail))\n        \n        if not machine_lbs: return\n        machine_lbs.sort(key=lambda x: x[1], reverse=True)\n        global_lb = machine_lbs[0][1]\n        \n        # Filter: Focus on machines with LB >= 85% of global bottleneck\n        critical_mids = [mid for mid, lb in machine_lbs if lb >= 0.85 * global_lb]\n    \n        # 3. Helper to access precedence variables y_uv\n        def get_y(u, v):\n            # Returns expression for \"u precedes v\"\n            # Model stores y for pair (a, b) where a < b\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Generate Pivot-Based Workload Accumulation Cuts\n        m.workload_accumulation = pyo.ConstraintList()\n        cuts_added = 0\n        BUDGET = 200\n    \n        for mid in critical_mids:\n            ops = mach_ops[mid]\n            if len(ops) < 2: continue\n            \n            min_head_mach = min(heads[op] for op in ops)\n            min_tail_mach = min(tails[op] for op in ops)\n            \n            # Iterate through operations to serve as \"Pivots\"\n            # We prioritize all, as the solver will leverage the most binding ones.\n            for k_op in ops:\n                if cuts_added >= BUDGET: break\n                \n                # --- Cut A: Input Accumulation (Start Time Bound) ---\n                # The start time of pivot k must be >= the machine's earliest availability\n                # PLUS the sum of processing times of all operations scheduled BEFORE k.\n                # This is a Big-M-free structural bound on S[k].\n                lhs_input = m.S[k_op]\n                rhs_input = min_head_mach + sum(m.p[j] * get_y(j, k_op) for j in ops if j != k_op)\n                \n                m.workload_accumulation.add(lhs_input >= rhs_input)\n                cuts_added += 1\n                \n                if cuts_added >= BUDGET: break\n    \n                # --- Cut B: Output Accumulation (Makespan Bound) ---\n                # The global Cmax must be >= the start of k + p[k] + \n                # processing times of all operations scheduled AFTER k + minimum tail.\n                # This links the pivot's specific position to the global objective.\n                lhs_output = m.Cmax\n                rhs_output = m.S[k_op] + m.p[k_op] + \\\n                             sum(m.p[j] * get_y(k_op, j) for j in ops if j != k_op) + \\\n                             min_tail_mach\n                \n                m.workload_accumulation.add(lhs_output >= rhs_output)\n                cuts_added += 1\n    \n    add_machine_workload_accumulation_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_machine_workload_accumulation_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Heads (Earliest Start) and Tails (Work Remaining)\n    heads = {}\n    tails = {}\n    \n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Machines (Bottleneck Detection)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    machine_lbs = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Lower Bound = Min Release + Total Load + Min Tail\n        min_head = min(heads[op] for op in ops)\n        min_tail = min(tails[op] for op in ops)\n        total_p = sum(m.p[op] for op in ops)\n        machine_lbs.append((mid, min_head + total_p + min_tail))\n    \n    if not machine_lbs: return\n    machine_lbs.sort(key=lambda x: x[1], reverse=True)\n    global_lb = machine_lbs[0][1]\n    \n    # Filter: Focus on machines with LB >= 85% of global bottleneck\n    critical_mids = [mid for mid, lb in machine_lbs if lb >= 0.85 * global_lb]\n\n    # 3. Helper to access precedence variables y_uv\n    def get_y(u, v):\n        # Returns expression for \"u precedes v\"\n        # Model stores y for pair (a, b) where a < b\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Generate Pivot-Based Workload Accumulation Cuts\n    m.workload_accumulation = pyo.ConstraintList()\n    cuts_added = 0\n    BUDGET = 200\n\n    for mid in critical_mids:\n        ops = mach_ops[mid]\n        if len(ops) < 2: continue\n        \n        min_head_mach = min(heads[op] for op in ops)\n        min_tail_mach = min(tails[op] for op in ops)\n        \n        # Iterate through operations to serve as \"Pivots\"\n        # We prioritize all, as the solver will leverage the most binding ones.\n        for k_op in ops:\n            if cuts_added >= BUDGET: break\n            \n            # --- Cut A: Input Accumulation (Start Time Bound) ---\n            # The start time of pivot k must be >= the machine's earliest availability\n            # PLUS the sum of processing times of all operations scheduled BEFORE k.\n            # This is a Big-M-free structural bound on S[k].\n            lhs_input = m.S[k_op]\n            rhs_input = min_head_mach + sum(m.p[j] * get_y(j, k_op) for j in ops if j != k_op)\n            \n            m.workload_accumulation.add(lhs_input >= rhs_input)\n            cuts_added += 1\n            \n            if cuts_added >= BUDGET: break\n\n            # --- Cut B: Output Accumulation (Makespan Bound) ---\n            # The global Cmax must be >= the start of k + p[k] + \n            # processing times of all operations scheduled AFTER k + minimum tail.\n            # This links the pivot's specific position to the global objective.\n            lhs_output = m.Cmax\n            rhs_output = m.S[k_op] + m.p[k_op] + \\\n                         sum(m.p[j] * get_y(k_op, j) for j in ops if j != k_op) + \\\n                         min_tail_mach\n            \n            m.workload_accumulation.add(lhs_output >= rhs_output)\n            cuts_added += 1\n\nadd_machine_workload_accumulation_cuts(model)",
                        "idea": "We introduce **Pivot-Based Workload Accumulation Cuts**, which partition the machine schedule around a specific 'pivot' operation $k$. Unlike Parent 1 (pairwise lifting) and Parent 2 (block volume lifting), this strategy focuses on bounding the **Start Time ($S_k$)** and the global **Makespan ($C_{max}$)** by summing the processing times of *all* predecessors or successors on the machine. \n\nBy asserting that $S_k \\ge \\min(Heads) + \\sum_{j \\ne k} p_j y_{jk}$, we create a **Big-M-free** valid inequality that forces the continuous start-time variable to respect the aggregate volume of binary sequencing decisions. This tightens the relaxation for $S_k$, which is the crucial 'glue' linking different machines via job-precedence constraints, effectively complementing the objective-focused cuts of the parents."
                    },
                    "fitness": 15.544356030039152,
                    "solver_reports": [
                        {
                            "total_time": 6.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 27382,
                            "explored_time": 6.02,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 28180,
                            "explored_time": 6.19,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.57,
                            "explored_nodes": 1,
                            "simplex_iterations": 33565,
                            "explored_time": 6.51,
                            "work_units": 10.0
                        },
                        {
                            "gap": 28.9832,
                            "total_time": 11.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 36295,
                            "explored_time": 11.43,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 6.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 34324,
                            "explored_time": 6.7,
                            "work_units": 10.0
                        },
                        {
                            "gap": 26.4516,
                            "total_time": 9.89,
                            "explored_nodes": 168,
                            "simplex_iterations": 81018,
                            "explored_time": 9.88,
                            "work_units": 10.14
                        },
                        {
                            "total_time": 6.6,
                            "explored_nodes": 1,
                            "simplex_iterations": 23414,
                            "explored_time": 6.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 19824,
                            "explored_time": 9.73,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "b4ae9e44-273e-40f1-b813-a256d0829380",
                        "96a1c877-22bc-4bf3-b826-d95500cf67bd"
                    ]
                },
                {
                    "id": "fbcc126d-c302-4e66-ae73-9ccd80214d44",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_path_consistency_lifting_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Heads (Earliest Start) and Tails (Work Remaining)\n        heads = {}\n        tails = {}\n        \n        # Forward pass: Heads\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        # Backward pass: Tails\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # Calculate Global LB for filtering weak cuts\n        global_lb = 0\n        for o in m.O:\n            val = heads[o] + m.p[o] + tails[o]\n            if val > global_lb:\n                global_lb = val\n    \n        # 2. Map Job Flows: j -> list of (index, machine_id)\n        job_flow = {j: [] for j in m.J}\n        for (j, k) in m.O:\n            job_flow[j].append((k, m.mach[j, k]))\n        for j in m.J:\n            job_flow[j].sort(key=lambda x: x[0])\n    \n        candidates = []\n    \n        # 3. Identify Divergent Path Candidates\n        # Look for pairs of jobs (j, i) that traverse the same two machines M1 -> M2\n        for j in m.J:\n            flow = job_flow[j]\n            # Iterate adjacent operations in job j (M1 -> M2)\n            for idx in range(len(flow) - 1):\n                j_k1, m1 = flow[idx]\n                j_k2, m2 = flow[idx+1]\n                \n                # Identify other jobs i that also traverse M1 then M2\n                for i in m.J:\n                    if i == j: continue\n                    \n                    # Find operation indices for job i on m1 and m2\n                    i_k1 = -1\n                    i_k2 = -1\n                    found_m1 = False\n                    \n                    # Check flow of job i\n                    for (k, mach) in job_flow[i]:\n                        if mach == m1:\n                            i_k1 = k\n                            found_m1 = True\n                        elif mach == m2 and found_m1: # Ensure M2 comes after M1 for i\n                            i_k2 = k\n                            break\n                    \n                    if i_k1 != -1 and i_k2 != -1:\n                        # Found parallel flow: j and i both go M1 -> ... -> M2\n                        \n                        # Calculate the Penalty if they cross\n                        # Crossing: j->i on M1 but i->j on M2\n                        # This forces the path: Start_j(M1) -> End_j(M1) -> Start_i(M1) \n                        # ... -> End_i(M1) -> ... -> Start_i(M2) -> End_i(M2) -> Start_j(M2)\n                        # The delay injected into Job j's stream is roughly i's processing time.\n                        penalty = m.p[i, i_k1] + m.p[i, i_k2]\n                        \n                        # Base Lower Bound for Job j (assuming no crossing)\n                        # Head(M1) + Processing(M1) + Processing(M2) + Tail(M2)\n                        base_lb = heads[j, j_k1] + m.p[j, j_k1] + m.p[j, j_k2] + tails[j, j_k2]\n                        \n                        # If potential bound is significant, add to candidates\n                        if base_lb + penalty > 0.85 * global_lb:\n                            candidates.append({\n                                'j': j, 'j_k1': j_k1, 'j_k2': j_k2,\n                                'i': i, 'i_k1': i_k1, 'i_k2': i_k2,\n                                'base': base_lb,\n                                'penalty': penalty,\n                                'score': base_lb + penalty\n                            })\n    \n        # Sort by impact score\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n        # 4. Apply Path-Consistency Cuts\n        m.path_consistency_cuts = pyo.ConstraintList()\n        added = 0\n        BUDGET = 200\n        \n        def get_prec_var(u_job, u_k, v_job, v_k):\n            # Returns expression for variable y representing \"u precedes v\"\n            # Model convention: y indices are sorted (lexicographically or by value)\n            if (u_job, u_k) < (v_job, v_k):\n                return m.y[u_job, u_k, v_job, v_k]\n            else:\n                return 1 - m.y[v_job, v_k, u_job, u_k]\n    \n        for c in candidates:\n            if added >= BUDGET: break\n            \n            # y1: j -> i on M1\n            y1 = get_prec_var(c['j'], c['j_k1'], c['i'], c['i_k1'])\n            # y2: j -> i on M2\n            y2 = get_prec_var(c['j'], c['j_k2'], c['i'], c['i_k2'])\n            \n            # Crossing condition logic:\n            # We want to penalize if y1=1 (j->i) AND y2=0 (i->j).\n            # The expression (y1 - y2) captures this: \n            # If aligned (1,1) or (0,0) -> 0. \n            # If crossed (1,0) -> 1. \n            # If anti-crossed (0,1) -> -1 (loosens bound, safe for valid inequality).\n            \n            m.path_consistency_cuts.add(\n                m.Cmax >= c['base'] + c['penalty'] * (y1 - y2)\n            )\n            added += 1\n    \n    add_path_consistency_lifting_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_path_consistency_lifting_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Heads (Earliest Start) and Tails (Work Remaining)\n    heads = {}\n    tails = {}\n    \n    # Forward pass: Heads\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    # Backward pass: Tails\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # Calculate Global LB for filtering weak cuts\n    global_lb = 0\n    for o in m.O:\n        val = heads[o] + m.p[o] + tails[o]\n        if val > global_lb:\n            global_lb = val\n\n    # 2. Map Job Flows: j -> list of (index, machine_id)\n    job_flow = {j: [] for j in m.J}\n    for (j, k) in m.O:\n        job_flow[j].append((k, m.mach[j, k]))\n    for j in m.J:\n        job_flow[j].sort(key=lambda x: x[0])\n\n    candidates = []\n\n    # 3. Identify Divergent Path Candidates\n    # Look for pairs of jobs (j, i) that traverse the same two machines M1 -> M2\n    for j in m.J:\n        flow = job_flow[j]\n        # Iterate adjacent operations in job j (M1 -> M2)\n        for idx in range(len(flow) - 1):\n            j_k1, m1 = flow[idx]\n            j_k2, m2 = flow[idx+1]\n            \n            # Identify other jobs i that also traverse M1 then M2\n            for i in m.J:\n                if i == j: continue\n                \n                # Find operation indices for job i on m1 and m2\n                i_k1 = -1\n                i_k2 = -1\n                found_m1 = False\n                \n                # Check flow of job i\n                for (k, mach) in job_flow[i]:\n                    if mach == m1:\n                        i_k1 = k\n                        found_m1 = True\n                    elif mach == m2 and found_m1: # Ensure M2 comes after M1 for i\n                        i_k2 = k\n                        break\n                \n                if i_k1 != -1 and i_k2 != -1:\n                    # Found parallel flow: j and i both go M1 -> ... -> M2\n                    \n                    # Calculate the Penalty if they cross\n                    # Crossing: j->i on M1 but i->j on M2\n                    # This forces the path: Start_j(M1) -> End_j(M1) -> Start_i(M1) \n                    # ... -> End_i(M1) -> ... -> Start_i(M2) -> End_i(M2) -> Start_j(M2)\n                    # The delay injected into Job j's stream is roughly i's processing time.\n                    penalty = m.p[i, i_k1] + m.p[i, i_k2]\n                    \n                    # Base Lower Bound for Job j (assuming no crossing)\n                    # Head(M1) + Processing(M1) + Processing(M2) + Tail(M2)\n                    base_lb = heads[j, j_k1] + m.p[j, j_k1] + m.p[j, j_k2] + tails[j, j_k2]\n                    \n                    # If potential bound is significant, add to candidates\n                    if base_lb + penalty > 0.85 * global_lb:\n                        candidates.append({\n                            'j': j, 'j_k1': j_k1, 'j_k2': j_k2,\n                            'i': i, 'i_k1': i_k1, 'i_k2': i_k2,\n                            'base': base_lb,\n                            'penalty': penalty,\n                            'score': base_lb + penalty\n                        })\n\n    # Sort by impact score\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n\n    # 4. Apply Path-Consistency Cuts\n    m.path_consistency_cuts = pyo.ConstraintList()\n    added = 0\n    BUDGET = 200\n    \n    def get_prec_var(u_job, u_k, v_job, v_k):\n        # Returns expression for variable y representing \"u precedes v\"\n        # Model convention: y indices are sorted (lexicographically or by value)\n        if (u_job, u_k) < (v_job, v_k):\n            return m.y[u_job, u_k, v_job, v_k]\n        else:\n            return 1 - m.y[v_job, v_k, u_job, u_k]\n\n    for c in candidates:\n        if added >= BUDGET: break\n        \n        # y1: j -> i on M1\n        y1 = get_prec_var(c['j'], c['j_k1'], c['i'], c['i_k1'])\n        # y2: j -> i on M2\n        y2 = get_prec_var(c['j'], c['j_k2'], c['i'], c['i_k2'])\n        \n        # Crossing condition logic:\n        # We want to penalize if y1=1 (j->i) AND y2=0 (i->j).\n        # The expression (y1 - y2) captures this: \n        # If aligned (1,1) or (0,0) -> 0. \n        # If crossed (1,0) -> 1. \n        # If anti-crossed (0,1) -> -1 (loosens bound, safe for valid inequality).\n        \n        m.path_consistency_cuts.add(\n            m.Cmax >= c['base'] + c['penalty'] * (y1 - y2)\n        )\n        added += 1\n\nadd_path_consistency_lifting_cuts(model)",
                        "idea": "We introduce **Path-Consistency Lifting Cuts**, which complement the machine-centric parents by enforcing **multi-machine flow consistency**. Unlike Parent 1 (pairwise machine bounds) and Parent 2 (block flow bounds), this strategy targets the **interaction between job paths**. It identifies pairs of jobs that traverse the same sequence of machines ($M_A \to M_B$) and calculates the unavoidable delay induced if their processing order is swapped between these machines (a 'crossing'). We then lift the static lower bound of the primary job by this delay penalty, conditional on the sequence discrepancy ($y_{M_A} - y_{M_B}$). This tightens the relaxation by penalizing expensive flow inconsistencies that single-machine cuts cannot detect."
                    },
                    "fitness": 12.452230796565866,
                    "solver_reports": [
                        {
                            "gap": 95.8604,
                            "total_time": 13.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 34095,
                            "explored_time": 13.02,
                            "work_units": 10.0
                        },
                        {
                            "gap": 96.5857,
                            "total_time": 15.93,
                            "explored_nodes": 1,
                            "simplex_iterations": 27467,
                            "explored_time": 15.9,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 17.28,
                            "explored_nodes": 1,
                            "simplex_iterations": 60073,
                            "explored_time": 17.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 44.683,
                            "total_time": 11.88,
                            "explored_nodes": 596,
                            "simplex_iterations": 133547,
                            "explored_time": 11.87,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 17.77,
                            "explored_nodes": 1,
                            "simplex_iterations": 59512,
                            "explored_time": 17.7,
                            "work_units": 10.0
                        },
                        {
                            "gap": 31.5425,
                            "total_time": 11.43,
                            "explored_nodes": 4517,
                            "simplex_iterations": 288153,
                            "explored_time": 11.42,
                            "work_units": 10.0
                        },
                        {
                            "gap": 42.5812,
                            "total_time": 13.31,
                            "explored_nodes": 87,
                            "simplex_iterations": 83734,
                            "explored_time": 13.29,
                            "work_units": 10.08
                        },
                        {
                            "total_time": 16.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 61604,
                            "explored_time": 16.26,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Complement",
                    "parents_id": [
                        "b4ae9e44-273e-40f1-b813-a256d0829380",
                        "1f863c3c-34f6-4ffc-ab71-df5f90da0e79"
                    ]
                },
                {
                    "id": "c45276c9-c276-4691-a682-d1874fae51be",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_elastic_objective_block_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Heads (Earliest Start) and Tails (Work Remaining)\n        heads = {}\n        tails = {}\n        \n        # Forward pass\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        # Backward pass\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # Global Lower Bound estimate for filtering candidates\n        global_lb = 0\n        for o in m.O:\n            val = heads[o] + m.p[o] + tails[o]\n            if val > global_lb: global_lb = val\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n    \n        # 3. Identify Critical Blocks and Endpoints (from Parent 2 logic)\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            \n            # Sort operations by Earliest Start Time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Sliding window to find dense sub-sequences (Blocks)\n            for i in range(n):\n                for j in range(i + 2, n): # At least 3 operations\n                    sub = sorted_ops[i : j+1]\n                    \n                    # Identify endpoints: u (start) and v (bottleneck end)\n                    u = sub[0]\n                    v = max(sub, key=lambda x: tails[x])\n                    \n                    if u == v: continue\n    \n                    # Calculate Static Block Bound\n                    p_sum = sum(m.p[w] for w in sub)\n                    static_lb = heads[u] + p_sum + tails[v]\n                    \n                    # Filter: Only consider blocks that threaten the global makespan\n                    if static_lb > 0.85 * global_lb:\n                        candidates.append({\n                            'u': u, 'v': v, 'sub': sub,\n                            'static_lb': static_lb\n                        })\n    \n        # Sort candidates by tightness to prioritize strongest cuts\n        candidates.sort(key=lambda x: x['static_lb'], reverse=True)\n    \n        # 4. Add Elastic Objective Cuts\n        m.elastic_obj_cuts = pyo.ConstraintList()\n        seen_pairs = set()\n        added = 0\n        \n        # Helper to retrieve or construct precedence variable y_{o1,o2}\n        def get_y(o1, o2):\n            if o1 < o2:\n                return m.y[o1[0], o1[1], o2[0], o2[1]]\n            else:\n                return 1 - m.y[o2[0], o2[1], o1[0], o1[1]]\n    \n        for cand in candidates:\n            if added >= 100: break\n            \n            u, v = cand['u'], cand['v']\n            if (u, v) in seen_pairs: continue\n            seen_pairs.add((u, v))\n            \n            sub = cand['sub']\n            \n            # -- Cut A: Forward Direction (u -> v) --\n            # Base: Head(u) + P(u) + P(v) + Tail(v)\n            base_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n            lift_uv = 0\n            \n            # Dynamic term: sum(P(w)) if w is sequenced between u and v\n            # The term (y_uw + y_wv - 1) is 1 if u->w->v, else <= 0.\n            for w in sub:\n                if w == u or w == v: continue\n                lift_uv += m.p[w] * (get_y(u, w) + get_y(w, v) - 1)\n                \n            # Constraint: Cmax >= Base + Lift. \n            # Enforced only if u -> v (y_uv=1) using Big-M.\n            y_uv = get_y(u, v)\n            m.elastic_obj_cuts.add(\n                m.Cmax >= base_uv + lift_uv - m.bigM * (1 - y_uv)\n            )\n            \n            # -- Cut B: Reverse Direction (v -> u) --\n            # Base: Head(v) + P(v) + P(u) + Tail(u)\n            base_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n            lift_vu = 0\n            \n            for w in sub:\n                if w == u or w == v: continue\n                lift_vu += m.p[w] * (get_y(v, w) + get_y(w, u) - 1)\n                \n            # Enforced only if v -> u (y_uv=0).\n            m.elastic_obj_cuts.add(\n                m.Cmax >= base_vu + lift_vu - m.bigM * y_uv\n            )\n            \n            added += 2\n\n    return model\n",
                        "added_cut": "def add_elastic_objective_block_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Heads (Earliest Start) and Tails (Work Remaining)\n    heads = {}\n    tails = {}\n    \n    # Forward pass\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    # Backward pass\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # Global Lower Bound estimate for filtering candidates\n    global_lb = 0\n    for o in m.O:\n        val = heads[o] + m.p[o] + tails[o]\n        if val > global_lb: global_lb = val\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n\n    # 3. Identify Critical Blocks and Endpoints (from Parent 2 logic)\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        \n        # Sort operations by Earliest Start Time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Sliding window to find dense sub-sequences (Blocks)\n        for i in range(n):\n            for j in range(i + 2, n): # At least 3 operations\n                sub = sorted_ops[i : j+1]\n                \n                # Identify endpoints: u (start) and v (bottleneck end)\n                u = sub[0]\n                v = max(sub, key=lambda x: tails[x])\n                \n                if u == v: continue\n\n                # Calculate Static Block Bound\n                p_sum = sum(m.p[w] for w in sub)\n                static_lb = heads[u] + p_sum + tails[v]\n                \n                # Filter: Only consider blocks that threaten the global makespan\n                if static_lb > 0.85 * global_lb:\n                    candidates.append({\n                        'u': u, 'v': v, 'sub': sub,\n                        'static_lb': static_lb\n                    })\n\n    # Sort candidates by tightness to prioritize strongest cuts\n    candidates.sort(key=lambda x: x['static_lb'], reverse=True)\n\n    # 4. Add Elastic Objective Cuts\n    m.elastic_obj_cuts = pyo.ConstraintList()\n    seen_pairs = set()\n    added = 0\n    \n    # Helper to retrieve or construct precedence variable y_{o1,o2}\n    def get_y(o1, o2):\n        if o1 < o2:\n            return m.y[o1[0], o1[1], o2[0], o2[1]]\n        else:\n            return 1 - m.y[o2[0], o2[1], o1[0], o1[1]]\n\n    for cand in candidates:\n        if added >= 100: break\n        \n        u, v = cand['u'], cand['v']\n        if (u, v) in seen_pairs: continue\n        seen_pairs.add((u, v))\n        \n        sub = cand['sub']\n        \n        # -- Cut A: Forward Direction (u -> v) --\n        # Base: Head(u) + P(u) + P(v) + Tail(v)\n        base_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n        lift_uv = 0\n        \n        # Dynamic term: sum(P(w)) if w is sequenced between u and v\n        # The term (y_uw + y_wv - 1) is 1 if u->w->v, else <= 0.\n        for w in sub:\n            if w == u or w == v: continue\n            lift_uv += m.p[w] * (get_y(u, w) + get_y(w, v) - 1)\n            \n        # Constraint: Cmax >= Base + Lift. \n        # Enforced only if u -> v (y_uv=1) using Big-M.\n        y_uv = get_y(u, v)\n        m.elastic_obj_cuts.add(\n            m.Cmax >= base_uv + lift_uv - m.bigM * (1 - y_uv)\n        )\n        \n        # -- Cut B: Reverse Direction (v -> u) --\n        # Base: Head(v) + P(v) + P(u) + Tail(u)\n        base_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n        lift_vu = 0\n        \n        for w in sub:\n            if w == u or w == v: continue\n            lift_vu += m.p[w] * (get_y(v, w) + get_y(w, u) - 1)\n            \n        # Enforced only if v -> u (y_uv=0).\n        m.elastic_obj_cuts.add(\n            m.Cmax >= base_vu + lift_vu - m.bigM * y_uv\n        )\n        \n        added += 2",
                        "idea": "We introduce **Elastic Objective-Block Cuts**, a hybrid of pairwise objective lifting and block span elasticity. We identify critical machine blocks (Parent 2) but, instead of constraining local start times, we impose global lower bounds on $C_{max}$ (Parent 1). For the block endpoints $u$ and $v$, we formulate two conditional constraints: one assuming $u \\to v$ and one assuming $v \\to u$. Each constraint calculates the makespan lower bound as the sum of fixed Head/Tail times and the processing times of all intermediate operations $w$, dynamically activated by the term $(y_{uw} + y_{wv} - 1)$. This captures the 'elastic' processing load within the block and lifts the relaxation surface closer to the convex hull for both possible orientations of the bottleneck."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.44,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.4,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.11,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.23,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.22,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.68,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 11.64,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 11.63,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.02,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.82,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "b4ae9e44-273e-40f1-b813-a256d0829380",
                        "aebfde51-8fea-4c46-9945-639e1e3188bc"
                    ]
                },
                {
                    "id": "bc6cb50d-3d85-4b20-9c7f-53aaeca904be",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_triplet_lifted_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Heads and Tails\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Global Critical Path Lower Bound\n        global_lb = max(heads[o] + m.p[o] + tails[o] for o in m.O)\n    \n        # 3. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper to get sequence variable for u -> v\n        def get_y_expr(u, v):\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        m.triplet_lifting = pyo.ConstraintList()\n        candidates = []\n    \n        # 4. Generate Lifted Cuts\n        for mid, ops in mach_ops.items():\n            n_ops = len(ops)\n            if n_ops < 2: continue\n    \n            for i in range(n_ops):\n                u = ops[i]\n                for j in range(i + 1, n_ops):\n                    v = ops[j]\n    \n                    # Calculate base 1-machine bounds for u->v and v->u\n                    # LB(u->v) = r_u + p_u + p_v + q_v\n                    lb_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n                    lb_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n    \n                    # Determine critical direction\n                    if lb_uv >= lb_vu:\n                        primary, sec = u, v\n                        base_lb, weak_lb = lb_uv, lb_vu\n                        y_ref = get_y_expr(u, v) # 1 if u->v\n                    else:\n                        primary, sec = v, u\n                        base_lb, weak_lb = lb_vu, lb_uv\n                        y_ref = get_y_expr(v, u) # 1 if v->u\n                    \n                    # Filter: Only tighten if the pair is near critical path\n                    if base_lb < 0.85 * global_lb:\n                        continue\n    \n                    # LIFTING STEP: Intermediate Node Intervention\n                    # If u->v, check for any k such that u->k->v is implied.\n                    # Valid cut: Cmax >= WeakLB + (BaseLB - WeakLB)*y_uv \n                    #                  + Sum [p_k * (y_uk + y_kv - 1)]\n                    lift_term = 0\n                    for k in ops:\n                        if k == u or k == v: continue\n                        # Term: (y_uk + y_kv - 1). \n                        # Equals 1 iff u->k AND k->v. Otherwise <= 0.\n                        y_uk = get_y_expr(primary, k)\n                        y_kv = get_y_expr(k, sec)\n                        lift_term += m.p[k] * (y_uk + y_kv - 1)\n    \n                    candidates.append((base_lb, weak_lb, y_ref, lift_term))\n    \n        # Sort by criticality and add top cuts\n        candidates.sort(key=lambda x: x[0], reverse=True)\n        BUDGET = 200\n        for c in candidates[:BUDGET]:\n            base_lb, weak_lb, y_ref, lift_term = c\n            # Cut: Cmax >= LB_weak + (LB_base - LB_weak) * y_uv + Lifting\n            rhs = weak_lb + (base_lb - weak_lb) * y_ref + lift_term\n            m.triplet_lifting.add(m.Cmax >= rhs)\n\n    return model\n",
                        "added_cut": "def add_triplet_lifted_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Heads and Tails\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Global Critical Path Lower Bound\n    global_lb = max(heads[o] + m.p[o] + tails[o] for o in m.O)\n\n    # 3. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper to get sequence variable for u -> v\n    def get_y_expr(u, v):\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    m.triplet_lifting = pyo.ConstraintList()\n    candidates = []\n\n    # 4. Generate Lifted Cuts\n    for mid, ops in mach_ops.items():\n        n_ops = len(ops)\n        if n_ops < 2: continue\n\n        for i in range(n_ops):\n            u = ops[i]\n            for j in range(i + 1, n_ops):\n                v = ops[j]\n\n                # Calculate base 1-machine bounds for u->v and v->u\n                # LB(u->v) = r_u + p_u + p_v + q_v\n                lb_uv = heads[u] + m.p[u] + m.p[v] + tails[v]\n                lb_vu = heads[v] + m.p[v] + m.p[u] + tails[u]\n\n                # Determine critical direction\n                if lb_uv >= lb_vu:\n                    primary, sec = u, v\n                    base_lb, weak_lb = lb_uv, lb_vu\n                    y_ref = get_y_expr(u, v) # 1 if u->v\n                else:\n                    primary, sec = v, u\n                    base_lb, weak_lb = lb_vu, lb_uv\n                    y_ref = get_y_expr(v, u) # 1 if v->u\n                \n                # Filter: Only tighten if the pair is near critical path\n                if base_lb < 0.85 * global_lb:\n                    continue\n\n                # LIFTING STEP: Intermediate Node Intervention\n                # If u->v, check for any k such that u->k->v is implied.\n                # Valid cut: Cmax >= WeakLB + (BaseLB - WeakLB)*y_uv \n                #                  + Sum [p_k * (y_uk + y_kv - 1)]\n                lift_term = 0\n                for k in ops:\n                    if k == u or k == v: continue\n                    # Term: (y_uk + y_kv - 1). \n                    # Equals 1 iff u->k AND k->v. Otherwise <= 0.\n                    y_uk = get_y_expr(primary, k)\n                    y_kv = get_y_expr(k, sec)\n                    lift_term += m.p[k] * (y_uk + y_kv - 1)\n\n                candidates.append((base_lb, weak_lb, y_ref, lift_term))\n\n    # Sort by criticality and add top cuts\n    candidates.sort(key=lambda x: x[0], reverse=True)\n    BUDGET = 200\n    for c in candidates[:BUDGET]:\n        base_lb, weak_lb, y_ref, lift_term = c\n        # Cut: Cmax >= LB_weak + (LB_base - LB_weak) * y_uv + Lifting\n        rhs = weak_lb + (base_lb - weak_lb) * y_ref + lift_term\n        m.triplet_lifting.add(m.Cmax >= rhs)",
                        "idea": "We implement **Triplet-Based Objective Lifting**, which strengthens the pairwise cuts by incorporating the processing times of intermediate operations. Standard pairwise cuts approximate the makespan lower bound as $Head(u) + p_u + p_v + Tail(v)$ when $u \\to v$. We lift this bound by observing that if any third job $k$ is sequenced between $u$ and $v$ (i.e., $u \\to k \\to v$), the makespan must effectively increase by $p_k$. This is formulated using the valid term $\\sum p_k(y_{uk} + y_{kv} - 1)$, which activates strictly when the triangular precedence holds, thereby penalizing fractional cycles and tightening the relaxation surface for dense machines."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.66,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.62,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.88,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.11,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.15,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.14,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.45,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.39,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.96,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.99,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.86,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "b4ae9e44-273e-40f1-b813-a256d0829380"
                    ]
                },
                {
                    "id": "ae40837c-8108-4aa4-b014-b93fb864c365",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_density_driven_conditional_tail_cuts(m):\n        # 1. Static Timing Analysis (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += pyo.value(m.p[j, k])\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += pyo.value(m.p[j, k])\n                \n        # Retrieve Big-M value for disjunctive logic\n        M_val = pyo.value(m.bigM)\n    \n        # 2. Critical Block Detection (Structure from Parent 1)\n        # We group operations by machine to find congested intervals\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = pyo.value(m.mach[j, k])\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        MAX_WIN = 5\n    \n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            # Sort by Earliest Start Time\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            # Sliding Window to find dense sub-problems\n            for i in range(n_ops):\n                for w in range(2, MAX_WIN + 1):\n                    if i + w > n_ops: break\n                    sub = sorted_ops[i : i+w]\n                    \n                    # Impact Density Score (Numerical feature from Parent 1)\n                    # Preference for high processing mass in small time windows\n                    t_start = min(heads[o] for o in sub)\n                    t_end = max(heads[o] for o in sub)\n                    spread = t_end - t_start\n                    if spread < 1e-4: spread = 1e-4\n                    \n                    workload = sum(pyo.value(m.p[o]) for o in sub)\n                    score = workload / spread\n                    \n                    candidates.append({'sub': sub, 'score': score})\n    \n        # Sort candidates by Density Score to prioritize the most ambiguous blocks\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n        # 3. Generate Hybrid Cuts\n        # Hybrid Concept: Apply Conditional Objective Lifting (Parent 2 logic)\n        # but strictly within high-density blocks (Parent 1 selection)\n        # and using dynamic Start vars (Parent 1) instead of static heads.\n        \n        m.density_tail_cuts = pyo.ConstraintList()\n        seen_pairs = set()\n        cuts_added = 0\n        BUDGET = 200\n        \n        def get_y_expr(u, v):\n            # Returns expression for y[u, v] = 1\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for cand in candidates:\n            if cuts_added >= BUDGET: break\n            sub = cand['sub']\n            \n            for u in sub:\n                for v in sub:\n                    if u == v: continue\n                    \n                    # Calculate Lift Potential:\n                    # If u -> v, the \"path to end\" for u increases from tails[u]\n                    # to (p[v] + tails[v]). We only add cuts where this provides a lift.\n                    p_v_val = pyo.value(m.p[v])\n                    if p_v_val + tails[v] > tails[u]:\n                        \n                        if (u, v) in seen_pairs: continue\n                        seen_pairs.add((u, v))\n                        \n                        # Constraint Construction:\n                        # Cmax >= S[u] + p[u] + p[v] + tail[v] - M * (1 - y_uv)\n                        # This links S[u] (dynamic) directly to Cmax via the decision variable.\n                        y_uv = get_y_expr(u, v)\n                        \n                        lhs = m.Cmax\n                        rhs = m.S[u] + m.p[u] + m.p[v] + tails[v] - M_val * (1 - y_uv)\n                        \n                        m.density_tail_cuts.add(lhs >= rhs)\n                        \n                        cuts_added += 1\n                        if cuts_added >= BUDGET: break\n                if cuts_added >= BUDGET: break\n    \n    add_density_driven_conditional_tail_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_density_driven_conditional_tail_cuts(m):\n    # 1. Static Timing Analysis (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += pyo.value(m.p[j, k])\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += pyo.value(m.p[j, k])\n            \n    # Retrieve Big-M value for disjunctive logic\n    M_val = pyo.value(m.bigM)\n\n    # 2. Critical Block Detection (Structure from Parent 1)\n    # We group operations by machine to find congested intervals\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = pyo.value(m.mach[j, k])\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    MAX_WIN = 5\n\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        # Sort by Earliest Start Time\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        # Sliding Window to find dense sub-problems\n        for i in range(n_ops):\n            for w in range(2, MAX_WIN + 1):\n                if i + w > n_ops: break\n                sub = sorted_ops[i : i+w]\n                \n                # Impact Density Score (Numerical feature from Parent 1)\n                # Preference for high processing mass in small time windows\n                t_start = min(heads[o] for o in sub)\n                t_end = max(heads[o] for o in sub)\n                spread = t_end - t_start\n                if spread < 1e-4: spread = 1e-4\n                \n                workload = sum(pyo.value(m.p[o]) for o in sub)\n                score = workload / spread\n                \n                candidates.append({'sub': sub, 'score': score})\n\n    # Sort candidates by Density Score to prioritize the most ambiguous blocks\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n\n    # 3. Generate Hybrid Cuts\n    # Hybrid Concept: Apply Conditional Objective Lifting (Parent 2 logic)\n    # but strictly within high-density blocks (Parent 1 selection)\n    # and using dynamic Start vars (Parent 1) instead of static heads.\n    \n    m.density_tail_cuts = pyo.ConstraintList()\n    seen_pairs = set()\n    cuts_added = 0\n    BUDGET = 200\n    \n    def get_y_expr(u, v):\n        # Returns expression for y[u, v] = 1\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for cand in candidates:\n        if cuts_added >= BUDGET: break\n        sub = cand['sub']\n        \n        for u in sub:\n            for v in sub:\n                if u == v: continue\n                \n                # Calculate Lift Potential:\n                # If u -> v, the \"path to end\" for u increases from tails[u]\n                # to (p[v] + tails[v]). We only add cuts where this provides a lift.\n                p_v_val = pyo.value(m.p[v])\n                if p_v_val + tails[v] > tails[u]:\n                    \n                    if (u, v) in seen_pairs: continue\n                    seen_pairs.add((u, v))\n                    \n                    # Constraint Construction:\n                    # Cmax >= S[u] + p[u] + p[v] + tail[v] - M * (1 - y_uv)\n                    # This links S[u] (dynamic) directly to Cmax via the decision variable.\n                    y_uv = get_y_expr(u, v)\n                    \n                    lhs = m.Cmax\n                    rhs = m.S[u] + m.p[u] + m.p[v] + tails[v] - M_val * (1 - y_uv)\n                    \n                    m.density_tail_cuts.add(lhs >= rhs)\n                    \n                    cuts_added += 1\n                    if cuts_added >= BUDGET: break\n            if cuts_added >= BUDGET: break\n\nadd_density_driven_conditional_tail_cuts(model)",
                        "idea": "We introduce **Density-Driven Conditional Tail Cuts**, a hybrid strategy that leverages Parent 1's **impact density scoring** to identify congested machine blocks and Parent 2's **objective lifting** concept. Unlike Parent 2, which relies on static heads, this method dynamically links operation start times ($S_u$) to the Makespan ($C_{max}$) via binary sequencing decisions. Specifically, for critical pairs $(u, v)$ within high-density blocks where $v$ is a 'critical follower' (i.e., its processing plus tail exceeds $u$'s tail), we enforce a conditional lower bound on $C_{max}$. This tightens the relaxation by propagating delays in $S_u$ directly to the global objective whenever the sequence $u \\to v$ is active."
                    },
                    "fitness": 14.566136484527846,
                    "solver_reports": [
                        {
                            "gap": 56.7312,
                            "total_time": 15.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 53934,
                            "explored_time": 15.6,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 16.3,
                            "explored_nodes": 1,
                            "simplex_iterations": 81588,
                            "explored_time": 16.25,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 14.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 63974,
                            "explored_time": 14.48,
                            "work_units": 10.0
                        },
                        {
                            "gap": 44.4006,
                            "total_time": 14.42,
                            "explored_nodes": 143,
                            "simplex_iterations": 91786,
                            "explored_time": 14.4,
                            "work_units": 11.58
                        },
                        {
                            "total_time": 16.95,
                            "explored_nodes": 1,
                            "simplex_iterations": 63629,
                            "explored_time": 16.89,
                            "work_units": 10.0
                        },
                        {
                            "gap": 31.8031,
                            "total_time": 12.25,
                            "explored_nodes": 4361,
                            "simplex_iterations": 322207,
                            "explored_time": 12.23,
                            "work_units": 10.0
                        },
                        {
                            "gap": 42.0167,
                            "total_time": 15.5,
                            "explored_nodes": 115,
                            "simplex_iterations": 47276,
                            "explored_time": 15.49,
                            "work_units": 12.63
                        },
                        {
                            "total_time": 15.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 55399,
                            "explored_time": 15.2,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                        "b4ae9e44-273e-40f1-b813-a256d0829380"
                    ]
                },
                {
                    "id": "456a3439-9d6e-481e-bde6-2483c5d4a957",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_worst_case_triplet_lifting(m):\n        import itertools\n    \n        # 1. Static Heads/Tails Calculation\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine & Global LB Estimate\n        mach_ops = {}\n        global_lb = 0\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n        \n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            r_min = min(heads[o] for o in ops)\n            q_min = min(tails[o] for o in ops)\n            p_sum = sum(m.p[o] for o in ops)\n            global_lb = max(global_lb, r_min + p_sum + q_min)\n    \n        # 3. Generate Worst-Case Permutation Cuts\n        potential_cuts = []\n        \n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            # Focus on heavy operations where ordering matters most\n            top_ops = sorted(ops, key=lambda x: m.p[x], reverse=True)[:8]\n            \n            # Evaluate all permutations of triplets\n            for triplet in itertools.combinations(top_ops, 3):\n                for seq in itertools.permutations(triplet):\n                    u, v, w = seq\n                    # If u->v->w, then Cmax >= r_u + p_u + p_v + p_w + q_w\n                    lb_seq = heads[u] + m.p[u] + m.p[v] + m.p[w] + tails[w]\n                    \n                    # Only penalize sequences that are worse than the baseline approximation\n                    if lb_seq > global_lb * 1.02:\n                        potential_cuts.append({'lb': lb_seq, 'seq': (u, v, w)})\n    \n        # 4. Apply Cuts (Budgeted)\n        # Sort by LB descending: effectively cutting off the \"worst\" local choices first\n        potential_cuts.sort(key=lambda x: x['lb'], reverse=True)\n        \n        m.triplet_lifting = pyo.ConstraintList()\n        added = 0\n        BUDGET = 200\n        \n        def get_y(a, b):\n            # Retrieve y[a,b] accounting for set ordering\n            if a < b: return m.y[a[0], a[1], b[0], b[1]]\n            else:     return 1 - m.y[b[0], b[1], a[0], a[1]]\n    \n        for cut in potential_cuts:\n            if added >= BUDGET: break\n            u, v, w = cut['seq']\n            limit = cut['lb']\n            y_uv = get_y(u, v)\n            y_vw = get_y(v, w)\n            \n            # Conditional Lower Bound on Cmax\n            # If y_uv=1 and y_vw=1 (sequence u->v->w), then Cmax >= limit\n            m.triplet_lifting.add(\n                m.Cmax >= limit - m.bigM * (2 - y_uv - y_vw)\n            )\n            added += 1\n\n    return model\n",
                        "added_cut": "def add_worst_case_triplet_lifting(m):\n    import itertools\n\n    # 1. Static Heads/Tails Calculation\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine & Global LB Estimate\n    mach_ops = {}\n    global_lb = 0\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n    \n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        r_min = min(heads[o] for o in ops)\n        q_min = min(tails[o] for o in ops)\n        p_sum = sum(m.p[o] for o in ops)\n        global_lb = max(global_lb, r_min + p_sum + q_min)\n\n    # 3. Generate Worst-Case Permutation Cuts\n    potential_cuts = []\n    \n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        # Focus on heavy operations where ordering matters most\n        top_ops = sorted(ops, key=lambda x: m.p[x], reverse=True)[:8]\n        \n        # Evaluate all permutations of triplets\n        for triplet in itertools.combinations(top_ops, 3):\n            for seq in itertools.permutations(triplet):\n                u, v, w = seq\n                # If u->v->w, then Cmax >= r_u + p_u + p_v + p_w + q_w\n                lb_seq = heads[u] + m.p[u] + m.p[v] + m.p[w] + tails[w]\n                \n                # Only penalize sequences that are worse than the baseline approximation\n                if lb_seq > global_lb * 1.02:\n                    potential_cuts.append({'lb': lb_seq, 'seq': (u, v, w)})\n\n    # 4. Apply Cuts (Budgeted)\n    # Sort by LB descending: effectively cutting off the \"worst\" local choices first\n    potential_cuts.sort(key=lambda x: x['lb'], reverse=True)\n    \n    m.triplet_lifting = pyo.ConstraintList()\n    added = 0\n    BUDGET = 200\n    \n    def get_y(a, b):\n        # Retrieve y[a,b] accounting for set ordering\n        if a < b: return m.y[a[0], a[1], b[0], b[1]]\n        else:     return 1 - m.y[b[0], b[1], a[0], a[1]]\n\n    for cut in potential_cuts:\n        if added >= BUDGET: break\n        u, v, w = cut['seq']\n        limit = cut['lb']\n        y_uv = get_y(u, v)\n        y_vw = get_y(v, w)\n        \n        # Conditional Lower Bound on Cmax\n        # If y_uv=1 and y_vw=1 (sequence u->v->w), then Cmax >= limit\n        m.triplet_lifting.add(\n            m.Cmax >= limit - m.bigM * (2 - y_uv - y_vw)\n        )\n        added += 1",
                        "idea": "We introduce **Worst-Case Triplet Lifting**, an exploratory strategy that directly links local binary decisions to the global objective lower bound. Unlike the parent's approach which tightens start time variables ($S_j$) based on precedence, this method evaluates the makespan impact of specific operation permutations (e.g., $i \\to j \\to k$) on critical machines. By identifying and penalizing 'worst-case' local sequences that yield bounds significantly higher than the global relaxation, we add conditional cuts ($C_{max} \\ge LB_{seq} - M(2 - y_{ij} - y_{jk})$) that forcefully raise the objective value if the solver explores these suboptimal branches, thereby accelerating tree pruning."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.02,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.48,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.44,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.2,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.15,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.98,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.96,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.39,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.34,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.73,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.72,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.23,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.2,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.27,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.24,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Exploratory",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "7569795d-d98f-4074-82fa-5983072024f0",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_cluster_volume_cuts(m):\n        \"\"\"\n        Adds 'Critical Cluster Volume Cuts' (CCVC) to the model.\n        Integrates Parent 1's volumetric SPT bounds with Parent 2's Critical Machine detection.\n        1. Identifies bottleneck machines using Carlier's 1-machine bound (Release + P + Tail).\n        2. On these machines, identifies clusters using sliding windows.\n        3. Enforces a lower bound on sum(S_j) (Congestion Cut).\n        4. Projects this congestion to Cmax using tail data (Tail-Volume Cut).\n        \"\"\"\n        import pyomo.environ as pyo\n    \n        # --- 1. Precompute Static Heads and Tails ---\n        heads = {}\n        tails = {}\n        # Forward pass for heads (est)\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass for tails (q)\n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # --- 2. Identify Critical Machines (Parent 2 Logic) ---\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        mach_stats = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Carlier's 1-machine bound: min_r + sum_p + min_q\n            min_r = min(heads[op] for op in ops)\n            sum_p = sum(m.p[op] for op in ops)\n            min_q = min(tails[op] for op in ops)\n            mach_stats.append((mid, min_r + sum_p + min_q))\n        \n        if not mach_stats: return\n    \n        # Filter: Keep machines within 85% of the max lower bound\n        mach_stats.sort(key=lambda x: x[1], reverse=True)\n        global_lb = mach_stats[0][1]\n        critical_mids = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n    \n        m.critical_cluster_volume_cuts = pyo.ConstraintList()\n        WINDOW_SIZES = [3, 4, 5, 6]\n    \n        # --- 3. Generate Cuts on Critical Machines ---\n        for mid in critical_mids:\n            ops = mach_ops[mid]\n            # Sort by Earliest Release (Head) to find time-localized clusters\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n    \n            for w in WINDOW_SIZES:\n                if n_ops < w: continue\n                \n                for i in range(n_ops - w + 1):\n                    block = sorted_ops[i : i+w]\n                    \n                    # -- Calculate ACC Metrics (Parent 1) --\n                    r_min = min(heads[op] for op in block)\n                    # Processing times sorted for SPT calculation\n                    p_vals = sorted([pyo.value(m.p[op]) for op in block])\n                    \n                    # Interaction Cost: sum of unavoidable waiting times in SPT order\n                    interaction_cost = sum((w - 1 - k) * p_vals[k] for k in range(w))\n                    \n                    # Valid lower bound on sum(S) for this block\n                    acc_lb = w * r_min + interaction_cost\n                    \n                    # Filter redundant cuts (if bound is trivial)\n                    trivial_bound = sum(heads[op] for op in block)\n                    if acc_lb <= trivial_bound + 1e-4:\n                        continue\n    \n                    # -- Metric 1: Add Volumetric Start Time Cut --\n                    # Forces variables S to respect the congestion mass\n                    lhs_S = sum(m.S[op] for op in block)\n                    m.critical_cluster_volume_cuts.add(lhs_S >= acc_lb)\n    \n                    # -- Metric 2: Add Tail-Projected Makespan Bound --\n                    # Uses the relation: Cmax >= S_j + p_j + q_j\n                    # Summed over block: w * Cmax >= sum(S) + sum(p) + sum(q)\n                    # Substituting sum(S) >= acc_lb yields a scalar bound, but keeping\n                    # lhs_S in the constraint strengthens the relaxation by linking variables.\n                    sum_p_block = sum(p_vals)\n                    sum_q_block = sum(tails[op] for op in block)\n                    \n                    m.critical_cluster_volume_cuts.add(\n                        w * m.Cmax >= lhs_S + sum_p_block + sum_q_block\n                    )\n\n    return model\n",
                        "added_cut": "def add_critical_cluster_volume_cuts(m):\n    \"\"\"\n    Adds 'Critical Cluster Volume Cuts' (CCVC) to the model.\n    Integrates Parent 1's volumetric SPT bounds with Parent 2's Critical Machine detection.\n    1. Identifies bottleneck machines using Carlier's 1-machine bound (Release + P + Tail).\n    2. On these machines, identifies clusters using sliding windows.\n    3. Enforces a lower bound on sum(S_j) (Congestion Cut).\n    4. Projects this congestion to Cmax using tail data (Tail-Volume Cut).\n    \"\"\"\n    import pyomo.environ as pyo\n\n    # --- 1. Precompute Static Heads and Tails ---\n    heads = {}\n    tails = {}\n    # Forward pass for heads (est)\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass for tails (q)\n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # --- 2. Identify Critical Machines (Parent 2 Logic) ---\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    mach_stats = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Carlier's 1-machine bound: min_r + sum_p + min_q\n        min_r = min(heads[op] for op in ops)\n        sum_p = sum(m.p[op] for op in ops)\n        min_q = min(tails[op] for op in ops)\n        mach_stats.append((mid, min_r + sum_p + min_q))\n    \n    if not mach_stats: return\n\n    # Filter: Keep machines within 85% of the max lower bound\n    mach_stats.sort(key=lambda x: x[1], reverse=True)\n    global_lb = mach_stats[0][1]\n    critical_mids = {mid for mid, lb in mach_stats if lb >= 0.85 * global_lb}\n\n    m.critical_cluster_volume_cuts = pyo.ConstraintList()\n    WINDOW_SIZES = [3, 4, 5, 6]\n\n    # --- 3. Generate Cuts on Critical Machines ---\n    for mid in critical_mids:\n        ops = mach_ops[mid]\n        # Sort by Earliest Release (Head) to find time-localized clusters\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n\n        for w in WINDOW_SIZES:\n            if n_ops < w: continue\n            \n            for i in range(n_ops - w + 1):\n                block = sorted_ops[i : i+w]\n                \n                # -- Calculate ACC Metrics (Parent 1) --\n                r_min = min(heads[op] for op in block)\n                # Processing times sorted for SPT calculation\n                p_vals = sorted([pyo.value(m.p[op]) for op in block])\n                \n                # Interaction Cost: sum of unavoidable waiting times in SPT order\n                interaction_cost = sum((w - 1 - k) * p_vals[k] for k in range(w))\n                \n                # Valid lower bound on sum(S) for this block\n                acc_lb = w * r_min + interaction_cost\n                \n                # Filter redundant cuts (if bound is trivial)\n                trivial_bound = sum(heads[op] for op in block)\n                if acc_lb <= trivial_bound + 1e-4:\n                    continue\n\n                # -- Metric 1: Add Volumetric Start Time Cut --\n                # Forces variables S to respect the congestion mass\n                lhs_S = sum(m.S[op] for op in block)\n                m.critical_cluster_volume_cuts.add(lhs_S >= acc_lb)\n\n                # -- Metric 2: Add Tail-Projected Makespan Bound --\n                # Uses the relation: Cmax >= S_j + p_j + q_j\n                # Summed over block: w * Cmax >= sum(S) + sum(p) + sum(q)\n                # Substituting sum(S) >= acc_lb yields a scalar bound, but keeping\n                # lhs_S in the constraint strengthens the relaxation by linking variables.\n                sum_p_block = sum(p_vals)\n                sum_q_block = sum(tails[op] for op in block)\n                \n                m.critical_cluster_volume_cuts.add(\n                    w * m.Cmax >= lhs_S + sum_p_block + sum_q_block\n                )",
                        "idea": "We introduce 'Critical Cluster Volume Cuts' (CCVC). This method filters for bottleneck machines using Parent 2's load-tail metrics, then applies Parent 1's aggregate congestion logic to valid operation clusters. Specifically, for each window of operations on a critical machine, we enforce a valid lower bound on the sum of start times based on relaxed SPT scheduling. We further strengthen this by projecting the cluster's aggregate latency (start volume + processing + tails) directly onto the makespan (Cmax), ensuring the objective function reflects the unavoidable congestion of the most critical resources."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.86,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.26,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.22,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.25,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.21,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 18.12,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 18.1,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 14.31,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.07,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.06,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.31,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 15.69,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 15.65,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "5bc84b2b-8efb-4479-9116-aec028a5bdb9",
                        "1f863c3c-34f6-4ffc-ab71-df5f90da0e79"
                    ]
                }
            ],
            23.42775824076793
        ],
        [
            [
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "adae8cdf-ef3d-4130-bde0-3829d04e5408",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_dense_triplet_dynamic_cuts(m):\n        import itertools\n        import pyomo.environ as pyo\n    \n        # 1. Precompute Static Data (Heads/Tails/Values)\n        # Using numeric values for filtering allows fast pre-solve checks.\n        p_val = {index: pyo.value(m.p[index]) for index in m.O}\n        \n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += p_val[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += p_val[j, k]\n    \n        # 2. Identify High-Density Machine Blocks\n        # Uses Parent 2's density logic to find congested intervals.\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = pyo.value(m.mach[j, k])\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n            \n        candidates = []\n        MAX_WIN = 6  # Look for contention in windows of ~6 operations\n        \n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            # Sort ops by earliest start time (est)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            \n            # Sliding window analysis\n            for i in range(len(sorted_ops)):\n                sub = sorted_ops[i : i+MAX_WIN]\n                if len(sub) < 3: continue\n                \n                t_min = min(heads[o] for o in sub)\n                t_max = max(heads[o] for o in sub)\n                span = max(1e-4, t_max - t_min)\n                work = sum(p_val[o] for o in sub)\n                \n                # Score by density (workload per unit time)\n                candidates.append({'block': sub, 'score': work/span})\n                \n        # Prioritize the most congested blocks\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        \n        # 3. Generate Dynamic Triplet Cuts\n        m.dense_triplet_cuts = pyo.ConstraintList()\n        cuts_added = 0\n        BUDGET = 200\n        seen_triplets = set()\n        \n        def get_y_expr(a, b):\n            # Helper to get the expression for binary decision \"a precedes b\"\n            if a < b: return m.y[a[0], a[1], b[0], b[1]]\n            else:     return 1 - m.y[b[0], b[1], a[0], a[1]]\n    \n        for cand in candidates:\n            if cuts_added >= BUDGET: break\n            block = cand['block']\n            possible_cuts = []\n            \n            # Analyze permutations of triplets (u, v, w) within the block\n            for u, v, w in itertools.permutations(block, 3):\n                # Calculate \"Lift Gain\":\n                # If sequence u->v->w is chosen, the new tail for u effectively becomes (p_v + p_w + tail_w).\n                # We add a cut only if this is strictly greater than u's static tail.\n                gain = (p_val[v] + p_val[w] + tails[w]) - tails[u]\n                \n                if gain > 0:\n                    possible_cuts.append(((u, v, w), gain))\n            \n            # Sort by gain to prioritize cuts that push the bound the most\n            possible_cuts.sort(key=lambda x: x[1], reverse=True)\n            \n            for (u, v, w), gain in possible_cuts:\n                if cuts_added >= BUDGET: break\n                if (u, v, w) in seen_triplets: continue\n                \n                seen_triplets.add((u, v, w))\n                \n                # Cut: Cmax >= S[u] + p[u] + p[v] + p[w] + tail[w] - M * (2 - y_uv - y_vw)\n                # This links the continuous start variable S[u] to Cmax via the triplet sequence.\n                \n                y_uv = get_y_expr(u, v)\n                y_vw = get_y_expr(v, w)\n                bound_val = p_val[u] + p_val[v] + p_val[w] + tails[w]\n                \n                m.dense_triplet_cuts.add(\n                    m.Cmax >= m.S[u] + bound_val - m.bigM * (2 - y_uv - y_vw)\n                )\n                cuts_added += 1\n\n    return model\n",
                        "added_cut": "def add_dense_triplet_dynamic_cuts(m):\n    import itertools\n    import pyomo.environ as pyo\n\n    # 1. Precompute Static Data (Heads/Tails/Values)\n    # Using numeric values for filtering allows fast pre-solve checks.\n    p_val = {index: pyo.value(m.p[index]) for index in m.O}\n    \n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += p_val[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += p_val[j, k]\n\n    # 2. Identify High-Density Machine Blocks\n    # Uses Parent 2's density logic to find congested intervals.\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = pyo.value(m.mach[j, k])\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n        \n    candidates = []\n    MAX_WIN = 6  # Look for contention in windows of ~6 operations\n    \n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        # Sort ops by earliest start time (est)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        \n        # Sliding window analysis\n        for i in range(len(sorted_ops)):\n            sub = sorted_ops[i : i+MAX_WIN]\n            if len(sub) < 3: continue\n            \n            t_min = min(heads[o] for o in sub)\n            t_max = max(heads[o] for o in sub)\n            span = max(1e-4, t_max - t_min)\n            work = sum(p_val[o] for o in sub)\n            \n            # Score by density (workload per unit time)\n            candidates.append({'block': sub, 'score': work/span})\n            \n    # Prioritize the most congested blocks\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    # 3. Generate Dynamic Triplet Cuts\n    m.dense_triplet_cuts = pyo.ConstraintList()\n    cuts_added = 0\n    BUDGET = 200\n    seen_triplets = set()\n    \n    def get_y_expr(a, b):\n        # Helper to get the expression for binary decision \"a precedes b\"\n        if a < b: return m.y[a[0], a[1], b[0], b[1]]\n        else:     return 1 - m.y[b[0], b[1], a[0], a[1]]\n\n    for cand in candidates:\n        if cuts_added >= BUDGET: break\n        block = cand['block']\n        possible_cuts = []\n        \n        # Analyze permutations of triplets (u, v, w) within the block\n        for u, v, w in itertools.permutations(block, 3):\n            # Calculate \"Lift Gain\":\n            # If sequence u->v->w is chosen, the new tail for u effectively becomes (p_v + p_w + tail_w).\n            # We add a cut only if this is strictly greater than u's static tail.\n            gain = (p_val[v] + p_val[w] + tails[w]) - tails[u]\n            \n            if gain > 0:\n                possible_cuts.append(((u, v, w), gain))\n        \n        # Sort by gain to prioritize cuts that push the bound the most\n        possible_cuts.sort(key=lambda x: x[1], reverse=True)\n        \n        for (u, v, w), gain in possible_cuts:\n            if cuts_added >= BUDGET: break\n            if (u, v, w) in seen_triplets: continue\n            \n            seen_triplets.add((u, v, w))\n            \n            # Cut: Cmax >= S[u] + p[u] + p[v] + p[w] + tail[w] - M * (2 - y_uv - y_vw)\n            # This links the continuous start variable S[u] to Cmax via the triplet sequence.\n            \n            y_uv = get_y_expr(u, v)\n            y_vw = get_y_expr(v, w)\n            bound_val = p_val[u] + p_val[v] + p_val[w] + tails[w]\n            \n            m.dense_triplet_cuts.add(\n                m.Cmax >= m.S[u] + bound_val - m.bigM * (2 - y_uv - y_vw)\n            )\n            cuts_added += 1",
                        "idea": "We introduce **Density-Aware Dynamic Triplet Cuts**, which fuses Parent 1's triplet structure with Parent 2's density-based dynamic lifting. By identifying high-contention machine blocks, this method selects specific operation triplets ($u \\to v \\to w$) thatif activewould impose a delay significantly larger than $u$'s baseline static tail. The constraint $C_{max} \\ge S_u + p_u + p_v + p_w + \\text{tail}_w - M(2 - y_{uv} - y_{vw})$ dynamically couples the start time variable $S_u$ to the global objective, propagating the impact of local sequencing decisions deeper into the search tree than standard pairwise disjunctions."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 13.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 13.1,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 16.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 16.02,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.12,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.06,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.09,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.07,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 14.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.96,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.86,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.85,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 19.82,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 19.8,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.83,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "456a3439-9d6e-481e-bde6-2483c5d4a957",
                        "ae40837c-8108-4aa4-b014-b93fb864c365"
                    ]
                },
                {
                    "id": "b663f2b6-3965-4859-9c5d-e17a3b94a0d8",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_block_path_aggregation_cuts(m):\n        # 1. Static Timing Analysis (Est/Lft) for Critical Block detection\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Blocks (Sequences with high Carlier Bound)\n        blocks = []\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            # Sort ops by release time (Head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(sorted_ops)\n            \n            # Identify sub-segments u..v with high Lower Bound\n            for u in range(n):\n                p_sum = 0\n                min_r = heads[sorted_ops[u]]\n                for v in range(u, n):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    if v - u + 1 >= 3:\n                        min_q = min(tails[sorted_ops[k]] for k in range(u, v+1))\n                        lb = min_r + p_sum + min_q\n                        blocks.append({\n                            'mid': mid,\n                            'ops': sorted_ops[u : v+1],\n                            'lb': lb\n                        })\n    \n        # Sort blocks by LB to prioritize critical bottlenecks\n        blocks.sort(key=lambda x: x['lb'], reverse=True)\n    \n        # 4. Generate Aggregated Path Cuts\n        m.block_path_cuts = pyo.ConstraintList()\n        \n        def get_y(u, v):\n            # Helper to access y variables respecting index order\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        CUT_BUDGET = 100\n        added_count = 0\n        seen_endpoints = set()\n    \n        for block in blocks:\n            if added_count >= CUT_BUDGET: break\n            \n            ops = block['ops']\n            op_i = ops[0]   # Predicted First operation in block\n            op_j = ops[-1]  # Predicted Last operation in block\n            \n            # Avoid duplicate cuts for the same pair\n            if (op_i, op_j) in seen_endpoints: continue\n            seen_endpoints.add((op_i, op_j))\n    \n            # Build the aggregated lifting term:\n            # Sum of p_k for all intermediates k that are sequenced between i and j\n            term_sum = 0\n            intermediates = ops[1:-1]\n            y_ij = get_y(op_i, op_j)\n            \n            for op_k in intermediates:\n                y_ik = get_y(op_i, op_k)\n                y_kj = get_y(op_k, op_j)\n                \n                # This term activates (+1) only if i->k and k->j\n                term_sum += m.p[op_k] * (y_ik + y_kj - 1)\n                \n                # Enforce triangle transitivity locally to support the lifting\n                m.block_path_cuts.add(y_ik + y_kj - y_ij <= 1)\n    \n            # Calculate a tight local Big-M (sum of processing times on this machine)\n            local_M = sum(m.p[o] for o in mach_ops[block['mid']])\n    \n            # Add the Aggregated Block Path Constraint:\n            # If i precedes j (y_ij=1), then S_j >= S_i + p_i + sum(p_k for k in between)\n            m.block_path_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + term_sum - local_M * (1 - y_ij)\n            )\n            added_count += 1\n\n    return model\n",
                        "added_cut": "def add_block_path_aggregation_cuts(m):\n    # 1. Static Timing Analysis (Est/Lft) for Critical Block detection\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Blocks (Sequences with high Carlier Bound)\n    blocks = []\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        # Sort ops by release time (Head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(sorted_ops)\n        \n        # Identify sub-segments u..v with high Lower Bound\n        for u in range(n):\n            p_sum = 0\n            min_r = heads[sorted_ops[u]]\n            for v in range(u, n):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                if v - u + 1 >= 3:\n                    min_q = min(tails[sorted_ops[k]] for k in range(u, v+1))\n                    lb = min_r + p_sum + min_q\n                    blocks.append({\n                        'mid': mid,\n                        'ops': sorted_ops[u : v+1],\n                        'lb': lb\n                    })\n\n    # Sort blocks by LB to prioritize critical bottlenecks\n    blocks.sort(key=lambda x: x['lb'], reverse=True)\n\n    # 4. Generate Aggregated Path Cuts\n    m.block_path_cuts = pyo.ConstraintList()\n    \n    def get_y(u, v):\n        # Helper to access y variables respecting index order\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    CUT_BUDGET = 100\n    added_count = 0\n    seen_endpoints = set()\n\n    for block in blocks:\n        if added_count >= CUT_BUDGET: break\n        \n        ops = block['ops']\n        op_i = ops[0]   # Predicted First operation in block\n        op_j = ops[-1]  # Predicted Last operation in block\n        \n        # Avoid duplicate cuts for the same pair\n        if (op_i, op_j) in seen_endpoints: continue\n        seen_endpoints.add((op_i, op_j))\n\n        # Build the aggregated lifting term:\n        # Sum of p_k for all intermediates k that are sequenced between i and j\n        term_sum = 0\n        intermediates = ops[1:-1]\n        y_ij = get_y(op_i, op_j)\n        \n        for op_k in intermediates:\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # This term activates (+1) only if i->k and k->j\n            term_sum += m.p[op_k] * (y_ik + y_kj - 1)\n            \n            # Enforce triangle transitivity locally to support the lifting\n            m.block_path_cuts.add(y_ik + y_kj - y_ij <= 1)\n\n        # Calculate a tight local Big-M (sum of processing times on this machine)\n        local_M = sum(m.p[o] for o in mach_ops[block['mid']])\n\n        # Add the Aggregated Block Path Constraint:\n        # If i precedes j (y_ij=1), then S_j >= S_i + p_i + sum(p_k for k in between)\n        m.block_path_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + term_sum - local_M * (1 - y_ij)\n        )\n        added_count += 1",
                        "idea": "We introduce **Block-Wide Path Aggregation Cuts** as a generalization of the individual triplet cuts. Instead of generating separate lifting constraints for every triplet, we identify entire critical blocks (high Carlier bound subsequences) and enforce a single, aggregated lifting constraint between the block's head ($i$) and tail ($j$). This constraint sets the minimum distance $S_j - S_i$ to include not only $p_i$, but the sum of processing times of *all* intermediate operations $k$ in the block verified by transitivity ($y_{ik} \\land y_{kj}$). This creates a much denser and stronger lower bound on the critical path segments while reducing the number of redundant constraints."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.44,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.4,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.49,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.44,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.47,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.41,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.53,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.52,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.71,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.33,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 20.02,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 20.0,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.93,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "242809ef-1b25-4c45-a4bf-814a3ea73440",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_density_scored_lifting(m):\n        import pyomo.environ as pyo\n    \n        # 1. Static Timing Analysis (Heads/Tails)\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper for precedence variable y_uv (1 if u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        candidates = []\n        \n        # 3. Candidate Generation and Scoring\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            \n            # Sort operations by earliest start (Heads) to hypothesize precedence direction\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            for i in range(n_ops):\n                u = sorted_ops[i]\n                for j in range(i + 1, n_ops):\n                    v = sorted_ops[j]\n                    \n                    # Identify all other operations k on the same machine\n                    intermediates = []\n                    p_sum_k = 0\n                    for k in ops:\n                        if k == u or k == v: continue\n                        intermediates.append(k)\n                        p_sum_k += m.p[k]\n                    \n                    if not intermediates: continue\n    \n                    # Hybrid Scoring: Density = Total Processing Mass / Time Spread\n                    # Combines Parent 1's impact scoring with Parent 2's multi-node scope.\n                    spread = heads[v] - heads[u]\n                    if spread < 1.0: spread = 1.0\n                    \n                    # High density implies a \"tight fit\" where cuts are most effective\n                    density = (m.p[u] + m.p[v] + p_sum_k) / spread\n                    \n                    candidates.append({\n                        'pair': (u, v),\n                        'k_list': intermediates,\n                        'score': density\n                    })\n    \n        # 4. Add Top Cuts (Budgeted)\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        m.density_lifting = pyo.ConstraintList()\n        \n        budget = 200\n        added = 0\n        \n        for cand in candidates:\n            if added >= budget: break\n            u, v = cand['pair']\n            k_list = cand['k_list']\n            \n            # Build Multi-Node Lifting Term: Sum [ p_k * (y_uk + y_kv - 1) ]\n            # Each term (y_uk + y_kv - 1) equals 1 iff sequence is u -> k -> v, else <= 0.\n            lift_expr = 0\n            for k in k_list:\n                lift_expr += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n                \n            # Constraint: S_v >= S_u + p_u + LiftingTerm - BigM * (1 - y_uv)\n            # If u->v (y_uv=1), this enforces S_v >= S_u + p_u + Sum(p_k for all k between u and v)\n            y_uv = get_y(u, v)\n            m.density_lifting.add(\n                m.S[v] >= m.S[u] + m.p[u] + lift_expr - m.bigM * (1 - y_uv)\n            )\n            added += 1\n    \n    add_density_scored_lifting(model)\n\n    return model\n",
                        "added_cut": "def add_density_scored_lifting(m):\n    import pyomo.environ as pyo\n\n    # 1. Static Timing Analysis (Heads/Tails)\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper for precedence variable y_uv (1 if u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    candidates = []\n    \n    # 3. Candidate Generation and Scoring\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        \n        # Sort operations by earliest start (Heads) to hypothesize precedence direction\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        for i in range(n_ops):\n            u = sorted_ops[i]\n            for j in range(i + 1, n_ops):\n                v = sorted_ops[j]\n                \n                # Identify all other operations k on the same machine\n                intermediates = []\n                p_sum_k = 0\n                for k in ops:\n                    if k == u or k == v: continue\n                    intermediates.append(k)\n                    p_sum_k += m.p[k]\n                \n                if not intermediates: continue\n\n                # Hybrid Scoring: Density = Total Processing Mass / Time Spread\n                # Combines Parent 1's impact scoring with Parent 2's multi-node scope.\n                spread = heads[v] - heads[u]\n                if spread < 1.0: spread = 1.0\n                \n                # High density implies a \"tight fit\" where cuts are most effective\n                density = (m.p[u] + m.p[v] + p_sum_k) / spread\n                \n                candidates.append({\n                    'pair': (u, v),\n                    'k_list': intermediates,\n                    'score': density\n                })\n\n    # 4. Add Top Cuts (Budgeted)\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    m.density_lifting = pyo.ConstraintList()\n    \n    budget = 200\n    added = 0\n    \n    for cand in candidates:\n        if added >= budget: break\n        u, v = cand['pair']\n        k_list = cand['k_list']\n        \n        # Build Multi-Node Lifting Term: Sum [ p_k * (y_uk + y_kv - 1) ]\n        # Each term (y_uk + y_kv - 1) equals 1 iff sequence is u -> k -> v, else <= 0.\n        lift_expr = 0\n        for k in k_list:\n            lift_expr += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n            \n        # Constraint: S_v >= S_u + p_u + LiftingTerm - BigM * (1 - y_uv)\n        # If u->v (y_uv=1), this enforces S_v >= S_u + p_u + Sum(p_k for all k between u and v)\n        y_uv = get_y(u, v)\n        m.density_lifting.add(\n            m.S[v] >= m.S[u] + m.p[u] + lift_expr - m.bigM * (1 - y_uv)\n        )\n        added += 1\n\nadd_density_scored_lifting(model)",
                        "idea": "We introduce **Density-Scored Multi-Node Precedence Cuts**, a hybrid that fuses Parent 1's impact-density scoring with Parent 2's multi-node lifting structure. Instead of limiting lifting to single triplets, we identify high-contention pairs $(u, v)$ using a density metric (mass/spread) and formulate a strong start-time inequality: $S_v \\ge S_u + p_u + \\sum p_k(y_{uk} + y_{kv} - 1)$. This term aggregates the processing times of *all* intermediate operations $k$ sequenced between $u$ and $v$, creating a convex hull tightening that scales with the complexity of the critical block."
                    },
                    "fitness": 10.326282916644477,
                    "solver_reports": [
                        {
                            "total_time": 12.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 58260,
                            "explored_time": 12.54,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 13.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 75054,
                            "explored_time": 13.29,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 73370,
                            "explored_time": 12.01,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 10.47,
                            "explored_nodes": 1155,
                            "simplex_iterations": 223383,
                            "explored_time": 10.46,
                            "work_units": 10.05
                        },
                        {
                            "total_time": 12.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 78086,
                            "explored_time": 11.96,
                            "work_units": 10.0
                        },
                        {
                            "gap": 31.8699,
                            "total_time": 11.18,
                            "explored_nodes": 7982,
                            "simplex_iterations": 485596,
                            "explored_time": 11.17,
                            "work_units": 10.47
                        },
                        {
                            "total_time": 8.81,
                            "explored_nodes": 277,
                            "simplex_iterations": 113061,
                            "explored_time": 8.79,
                            "work_units": 10.07
                        },
                        {
                            "total_time": 13.61,
                            "explored_nodes": 1,
                            "simplex_iterations": 62281,
                            "explored_time": 13.56,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                        "bc6cb50d-3d85-4b20-9c7f-53aaeca904be"
                    ]
                },
                {
                    "id": "9edd243d-8a94-42ca-b2cd-501d13e23307",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_density_driven_dynamic_path_cuts(m):\n        # 1. Static Analysis (Heads/Tails) for filtering\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += pyo.value(m.p[j, k])\n        for j in m.J:\n            t = 0\n            for k in reversed(list(m.K)):\n                tails[j, k] = t\n                t += pyo.value(m.p[j, k])\n                \n        # Estimate Global LB for filtering weak cuts\n        lb_est = 0\n        for o in m.O:\n            val = heads[o] + pyo.value(m.p[o]) + tails[o]\n            if val > lb_est: lb_est = val\n    \n        # 2. Density Analysis (Parent 1 Feature)\n        # Identify bottleneck machines using workload/span density\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = pyo.value(m.mach[j, k])\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        bottlenecks = []\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            t_start = min(heads[o] for o in ops)\n            t_end = max(heads[o] + pyo.value(m.p[o]) for o in ops)\n            span = max(1e-4, t_end - t_start)\n            load = sum(pyo.value(m.p[o]) for o in ops)\n            bottlenecks.append({'mid': mid, 'score': load/span, 'ops': ops})\n        \n        # Sort machines by density score to focus on critical clusters\n        bottlenecks.sort(key=lambda x: x['score'], reverse=True)\n    \n        # 3. Generate Hybrid Cuts\n        m.density_path_cuts = pyo.ConstraintList()\n        cuts_added = 0\n        BUDGET = 200\n        \n        def get_y(j1, k1, j2, k2):\n            # Return variable representing \"j1 precedes j2\"\n            if (j1, k1) < (j2, k2): return m.y[j1, k1, j2, k2]\n            return 1 - m.y[j2, k2, j1, k1]\n    \n        for b in bottlenecks:\n            if cuts_added >= BUDGET: break\n            ops = b['ops']\n            \n            # Map job -> (current_k, next_k, next_machine_id)\n            # We only care about jobs moving to an immediate next operation\n            flow_map = {}\n            for (j, k) in ops:\n                if k < len(m.K) - 1:\n                    next_k = k + 1\n                    next_m = pyo.value(m.mach[j, next_k])\n                    flow_map[j] = (k, next_k, next_m)\n            \n            # Identify pairs in this dense block that also share the NEXT machine (Parent 2 Feature)\n            sorted_jobs = sorted(flow_map.keys())\n            for i in range(len(sorted_jobs)):\n                j1 = sorted_jobs[i]\n                for j2 in sorted_jobs[i+1:]:\n                    \n                    k1_1, k2_1, m_next1 = flow_map[j1]\n                    k1_2, k2_2, m_next2 = flow_map[j2]\n                    \n                    if m_next1 == m_next2:\n                        # Shared path: M1 -> M2\n                        # Check for \"Crossing\" penalty\n                        \n                        # y1: j1->j2 on M1, y2: j1->j2 on M2\n                        y1 = get_y(j1, k1_1, j2, k1_2)\n                        y2 = get_y(j1, k2_1, j2, k2_2)\n                        \n                        # -----------------------------------------------------\n                        # Cut A: Base Job j1\n                        # If j1->j2 on M1 (y1=1) and j2->j1 on M2 (y2=0) [Crossing]\n                        # The sequence forces j1 wait for j2 on M2.\n                        # Lift = p(j2, M1) + p(j2, M2)\n                        # -----------------------------------------------------\n                        pen_j2 = pyo.value(m.p[j2, k1_2] + m.p[j2, k2_2])\n                        \n                        # Filter based on static bound estimation\n                        est_make = heads[j1, k1_1] + pyo.value(m.p[j1, k1_1] + m.p[j1, k2_1]) + tails[j1, k2_1]\n                        if est_make + pen_j2 > 0.8 * lb_est:\n                            # Use Dynamic Start S (Parent 1) for tighter coupling than Parent 2's static base\n                            lhs = m.Cmax\n                            rhs = m.S[j1, k1_1] + m.p[j1, k1_1] + m.p[j1, k2_1] + tails[j1, k2_1] + \\\n                                  pen_j2 * (y1 - y2)\n                            m.density_path_cuts.add(lhs >= rhs)\n                            cuts_added += 1\n                        \n                        if cuts_added >= BUDGET: break\n    \n                        # -----------------------------------------------------\n                        # Cut B: Base Job j2\n                        # If j2->j1 on M1 (y1=0) and j1->j2 on M2 (y2=1) [Reverse Crossing]\n                        # Lift = p(j1, M1) + p(j1, M2)\n                        # -----------------------------------------------------\n                        pen_j1 = pyo.value(m.p[j1, k1_1] + m.p[j1, k2_1])\n                        \n                        est_make2 = heads[j2, k1_2] + pyo.value(m.p[j2, k1_2] + m.p[j2, k2_2]) + tails[j2, k2_2]\n                        if est_make2 + pen_j1 > 0.8 * lb_est:\n                            # Note: (y2 - y1) captures the (1, 0) state for this direction\n                            lhs = m.Cmax\n                            rhs = m.S[j2, k1_2] + m.p[j2, k1_2] + m.p[j2, k2_2] + tails[j2, k2_2] + \\\n                                  pen_j1 * (y2 - y1)\n                            m.density_path_cuts.add(lhs >= rhs)\n                            cuts_added += 1\n                \n                if cuts_added >= BUDGET: break\n            if cuts_added >= BUDGET: break\n    \n    add_density_driven_dynamic_path_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_density_driven_dynamic_path_cuts(m):\n    # 1. Static Analysis (Heads/Tails) for filtering\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += pyo.value(m.p[j, k])\n    for j in m.J:\n        t = 0\n        for k in reversed(list(m.K)):\n            tails[j, k] = t\n            t += pyo.value(m.p[j, k])\n            \n    # Estimate Global LB for filtering weak cuts\n    lb_est = 0\n    for o in m.O:\n        val = heads[o] + pyo.value(m.p[o]) + tails[o]\n        if val > lb_est: lb_est = val\n\n    # 2. Density Analysis (Parent 1 Feature)\n    # Identify bottleneck machines using workload/span density\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = pyo.value(m.mach[j, k])\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    bottlenecks = []\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        t_start = min(heads[o] for o in ops)\n        t_end = max(heads[o] + pyo.value(m.p[o]) for o in ops)\n        span = max(1e-4, t_end - t_start)\n        load = sum(pyo.value(m.p[o]) for o in ops)\n        bottlenecks.append({'mid': mid, 'score': load/span, 'ops': ops})\n    \n    # Sort machines by density score to focus on critical clusters\n    bottlenecks.sort(key=lambda x: x['score'], reverse=True)\n\n    # 3. Generate Hybrid Cuts\n    m.density_path_cuts = pyo.ConstraintList()\n    cuts_added = 0\n    BUDGET = 200\n    \n    def get_y(j1, k1, j2, k2):\n        # Return variable representing \"j1 precedes j2\"\n        if (j1, k1) < (j2, k2): return m.y[j1, k1, j2, k2]\n        return 1 - m.y[j2, k2, j1, k1]\n\n    for b in bottlenecks:\n        if cuts_added >= BUDGET: break\n        ops = b['ops']\n        \n        # Map job -> (current_k, next_k, next_machine_id)\n        # We only care about jobs moving to an immediate next operation\n        flow_map = {}\n        for (j, k) in ops:\n            if k < len(m.K) - 1:\n                next_k = k + 1\n                next_m = pyo.value(m.mach[j, next_k])\n                flow_map[j] = (k, next_k, next_m)\n        \n        # Identify pairs in this dense block that also share the NEXT machine (Parent 2 Feature)\n        sorted_jobs = sorted(flow_map.keys())\n        for i in range(len(sorted_jobs)):\n            j1 = sorted_jobs[i]\n            for j2 in sorted_jobs[i+1:]:\n                \n                k1_1, k2_1, m_next1 = flow_map[j1]\n                k1_2, k2_2, m_next2 = flow_map[j2]\n                \n                if m_next1 == m_next2:\n                    # Shared path: M1 -> M2\n                    # Check for \"Crossing\" penalty\n                    \n                    # y1: j1->j2 on M1, y2: j1->j2 on M2\n                    y1 = get_y(j1, k1_1, j2, k1_2)\n                    y2 = get_y(j1, k2_1, j2, k2_2)\n                    \n                    # -----------------------------------------------------\n                    # Cut A: Base Job j1\n                    # If j1->j2 on M1 (y1=1) and j2->j1 on M2 (y2=0) [Crossing]\n                    # The sequence forces j1 wait for j2 on M2.\n                    # Lift = p(j2, M1) + p(j2, M2)\n                    # -----------------------------------------------------\n                    pen_j2 = pyo.value(m.p[j2, k1_2] + m.p[j2, k2_2])\n                    \n                    # Filter based on static bound estimation\n                    est_make = heads[j1, k1_1] + pyo.value(m.p[j1, k1_1] + m.p[j1, k2_1]) + tails[j1, k2_1]\n                    if est_make + pen_j2 > 0.8 * lb_est:\n                        # Use Dynamic Start S (Parent 1) for tighter coupling than Parent 2's static base\n                        lhs = m.Cmax\n                        rhs = m.S[j1, k1_1] + m.p[j1, k1_1] + m.p[j1, k2_1] + tails[j1, k2_1] + \\\n                              pen_j2 * (y1 - y2)\n                        m.density_path_cuts.add(lhs >= rhs)\n                        cuts_added += 1\n                    \n                    if cuts_added >= BUDGET: break\n\n                    # -----------------------------------------------------\n                    # Cut B: Base Job j2\n                    # If j2->j1 on M1 (y1=0) and j1->j2 on M2 (y2=1) [Reverse Crossing]\n                    # Lift = p(j1, M1) + p(j1, M2)\n                    # -----------------------------------------------------\n                    pen_j1 = pyo.value(m.p[j1, k1_1] + m.p[j1, k2_1])\n                    \n                    est_make2 = heads[j2, k1_2] + pyo.value(m.p[j2, k1_2] + m.p[j2, k2_2]) + tails[j2, k2_2]\n                    if est_make2 + pen_j1 > 0.8 * lb_est:\n                        # Note: (y2 - y1) captures the (1, 0) state for this direction\n                        lhs = m.Cmax\n                        rhs = m.S[j2, k1_2] + m.p[j2, k1_2] + m.p[j2, k2_2] + tails[j2, k2_2] + \\\n                              pen_j1 * (y2 - y1)\n                        m.density_path_cuts.add(lhs >= rhs)\n                        cuts_added += 1\n            \n            if cuts_added >= BUDGET: break\n        if cuts_added >= BUDGET: break\n\nadd_density_driven_dynamic_path_cuts(model)",
                        "idea": "We introduce **Density-Driven Dynamic Path Lifting**, a hybrid strategy that combines Parent 1's **density-based bottleneck detection** with Parent 2's **multi-machine path consistency** logic. Instead of applying path cuts to arbitrary machine pairs (Parent 2), this method focuses on pairs of jobs within high-density blocks (Parent 1) that proceed to the same subsequent machine. It enforces a lifted lower bound on $C_{max}$ by penalizing flow crossings ($y_{M1} \\neq y_{M2}$). Crucially, it replaces Parent 2's static base bounds with **dynamic start variables** ($S_{j,k}$) from Parent 1, allowing the cut to propagate delays from earlier constraints directly into the objective function without needing a Big-M coefficient."
                    },
                    "fitness": 14.255644317148837,
                    "solver_reports": [
                        {
                            "gap": 56.7429,
                            "total_time": 13.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 66094,
                            "explored_time": 13.48,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 16.06,
                            "explored_nodes": 1,
                            "simplex_iterations": 69910,
                            "explored_time": 16.0,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.1,
                            "explored_nodes": 1,
                            "simplex_iterations": 30195,
                            "explored_time": 9.05,
                            "work_units": 10.0
                        },
                        {
                            "gap": 48.6838,
                            "total_time": 13.96,
                            "explored_nodes": 547,
                            "simplex_iterations": 89013,
                            "explored_time": 13.95,
                            "work_units": 10.02
                        },
                        {
                            "total_time": 16.87,
                            "explored_nodes": 1,
                            "simplex_iterations": 57738,
                            "explored_time": 16.81,
                            "work_units": 10.0
                        },
                        {
                            "gap": 32.8485,
                            "total_time": 12.2,
                            "explored_nodes": 5360,
                            "simplex_iterations": 277589,
                            "explored_time": 12.18,
                            "work_units": 10.05
                        },
                        {
                            "gap": 42.7393,
                            "total_time": 15.16,
                            "explored_nodes": 87,
                            "simplex_iterations": 57033,
                            "explored_time": 15.14,
                            "work_units": 10.52
                        },
                        {
                            "total_time": 17.32,
                            "explored_nodes": 1,
                            "simplex_iterations": 56981,
                            "explored_time": 17.27,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "ae40837c-8108-4aa4-b014-b93fb864c365",
                        "fbcc126d-c302-4e66-ae73-9ccd80214d44"
                    ]
                },
                {
                    "id": "d25e5e5f-1e52-47c7-bd0f-8c90c8a1509c",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_path_augmented_workload_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Compute Heads (Earliest Start) and Tails (Work Remaining)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        \n        sorted_K_rev = sorted(list(m.K), reverse=True)\n        for j in m.J:\n            t = 0\n            for k in sorted_K_rev:\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Map Operations to Machines\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Identify Critical Machines (Bottleneck Detection)\n        mach_lbs = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            min_h = min(heads[o] for o in ops)\n            min_t = min(tails[o] for o in ops)\n            total_p = sum(m.p[o] for o in ops)\n            mach_lbs.append((mid, min_h + total_p + min_t))\n        \n        if not mach_lbs: return\n        mach_lbs.sort(key=lambda x: x[1], reverse=True)\n        global_lb = mach_lbs[0][1]\n        \n        # Focus on machines with load >= 85% of global bottleneck\n        critical_mids = {mid for mid, lb in mach_lbs if lb >= 0.85 * global_lb}\n    \n        # Helper: Precedence variable access\n        def get_y_expr(o1, o2):\n            # o1, o2 are (j, k) tuples. Returns expression for \"o1 precedes o2\"\n            if o1 < o2:\n                return m.y[o1[0], o1[1], o2[0], o2[1]]\n            else:\n                return 1 - m.y[o2[0], o2[1], o1[0], o1[1]]\n    \n        m.path_augmented_cuts = pyo.ConstraintList()\n        added = 0\n        BUDGET = 200\n    \n        # 4. Generate Cuts\n        for mid in critical_mids:\n            curr_ops = mach_ops[mid]\n            if len(curr_ops) < 2: continue\n            \n            min_h_curr = min(heads[o] for o in curr_ops)\n            min_t_curr = min(tails[o] for o in curr_ops)\n    \n            for (j, k) in curr_ops:\n                if added >= BUDGET: break\n                op_curr = (j, k)\n                \n                # --- Cut A: Local Input Workload (Parent 2) ---\n                # S_curr >= MinHead(M) + Sum(p * y_prec)\n                rhs_local = min_h_curr + sum(m.p[o] * get_y_expr(o, op_curr) \n                                             for o in curr_ops if o != op_curr)\n                m.path_augmented_cuts.add(m.S[op_curr] >= rhs_local)\n                added += 1\n                if added >= BUDGET: break\n    \n                # --- Cut B: Upstream Path Propagation (Combined Idea) ---\n                # Propagates delay from the previous machine directly into S_curr\n                # S_curr >= [MinHead(M_prev) + Sum(p_prev * y_prec_prev)] + p_prev\n                if k > 0:\n                    op_prev = (j, k-1)\n                    mid_prev = m.mach[op_prev]\n                    prev_ops = mach_ops.get(mid_prev, [])\n                    \n                    if len(prev_ops) >= 2:\n                        min_h_prev = min(heads[o] for o in prev_ops)\n                        rhs_upstream = min_h_prev + m.p[op_prev] + \\\n                                       sum(m.p[o] * get_y_expr(o, op_prev) \n                                           for o in prev_ops if o != op_prev)\n                        \n                        m.path_augmented_cuts.add(m.S[op_curr] >= rhs_upstream)\n                        added += 1\n                        if added >= BUDGET: break\n    \n                # --- Cut C: Local Output Workload (Parent 2) ---\n                # Cmax >= S_curr + p_curr + Sum(p * y_succ) + MinTail(M)\n                rhs_out = m.S[op_curr] + m.p[op_curr] + \\\n                          sum(m.p[o] * get_y_expr(op_curr, o) \n                              for o in curr_ops if o != op_curr) + min_t_curr\n                \n                m.path_augmented_cuts.add(m.Cmax >= rhs_out)\n                added += 1\n    \n    add_path_augmented_workload_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_path_augmented_workload_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Compute Heads (Earliest Start) and Tails (Work Remaining)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    \n    sorted_K_rev = sorted(list(m.K), reverse=True)\n    for j in m.J:\n        t = 0\n        for k in sorted_K_rev:\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Map Operations to Machines\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Identify Critical Machines (Bottleneck Detection)\n    mach_lbs = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        min_h = min(heads[o] for o in ops)\n        min_t = min(tails[o] for o in ops)\n        total_p = sum(m.p[o] for o in ops)\n        mach_lbs.append((mid, min_h + total_p + min_t))\n    \n    if not mach_lbs: return\n    mach_lbs.sort(key=lambda x: x[1], reverse=True)\n    global_lb = mach_lbs[0][1]\n    \n    # Focus on machines with load >= 85% of global bottleneck\n    critical_mids = {mid for mid, lb in mach_lbs if lb >= 0.85 * global_lb}\n\n    # Helper: Precedence variable access\n    def get_y_expr(o1, o2):\n        # o1, o2 are (j, k) tuples. Returns expression for \"o1 precedes o2\"\n        if o1 < o2:\n            return m.y[o1[0], o1[1], o2[0], o2[1]]\n        else:\n            return 1 - m.y[o2[0], o2[1], o1[0], o1[1]]\n\n    m.path_augmented_cuts = pyo.ConstraintList()\n    added = 0\n    BUDGET = 200\n\n    # 4. Generate Cuts\n    for mid in critical_mids:\n        curr_ops = mach_ops[mid]\n        if len(curr_ops) < 2: continue\n        \n        min_h_curr = min(heads[o] for o in curr_ops)\n        min_t_curr = min(tails[o] for o in curr_ops)\n\n        for (j, k) in curr_ops:\n            if added >= BUDGET: break\n            op_curr = (j, k)\n            \n            # --- Cut A: Local Input Workload (Parent 2) ---\n            # S_curr >= MinHead(M) + Sum(p * y_prec)\n            rhs_local = min_h_curr + sum(m.p[o] * get_y_expr(o, op_curr) \n                                         for o in curr_ops if o != op_curr)\n            m.path_augmented_cuts.add(m.S[op_curr] >= rhs_local)\n            added += 1\n            if added >= BUDGET: break\n\n            # --- Cut B: Upstream Path Propagation (Combined Idea) ---\n            # Propagates delay from the previous machine directly into S_curr\n            # S_curr >= [MinHead(M_prev) + Sum(p_prev * y_prec_prev)] + p_prev\n            if k > 0:\n                op_prev = (j, k-1)\n                mid_prev = m.mach[op_prev]\n                prev_ops = mach_ops.get(mid_prev, [])\n                \n                if len(prev_ops) >= 2:\n                    min_h_prev = min(heads[o] for o in prev_ops)\n                    rhs_upstream = min_h_prev + m.p[op_prev] + \\\n                                   sum(m.p[o] * get_y_expr(o, op_prev) \n                                       for o in prev_ops if o != op_prev)\n                    \n                    m.path_augmented_cuts.add(m.S[op_curr] >= rhs_upstream)\n                    added += 1\n                    if added >= BUDGET: break\n\n            # --- Cut C: Local Output Workload (Parent 2) ---\n            # Cmax >= S_curr + p_curr + Sum(p * y_succ) + MinTail(M)\n            rhs_out = m.S[op_curr] + m.p[op_curr] + \\\n                      sum(m.p[o] * get_y_expr(op_curr, o) \n                          for o in curr_ops if o != op_curr) + min_t_curr\n            \n            m.path_augmented_cuts.add(m.Cmax >= rhs_out)\n            added += 1\n\nadd_path_augmented_workload_cuts(model)",
                        "idea": "We introduce **Path-Augmented Workload Cuts**, which unify Parent 2's pivot-based accumulation with Parent 1's path-dependency logic. For critical operations, we generate standard **local workload bounds** (forcing start times to respect machine congestion) and **upstream propagation bounds**. The upstream cuts substitute the workload-derived lower bound of the *previous* operation into the current operation's precedence relation ($S_{curr} \\ge S_{prev} + p_{prev}$). This creates a direct link between the sequencing decisions on the previous machine and the start time on the current machine, preventing the solver from satisfying local capacity constraints by 'hiding' delays in looser precedence variables."
                    },
                    "fitness": 16.94596489868757,
                    "solver_reports": [
                        {
                            "total_time": 6.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 15749,
                            "explored_time": 5.96,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.5,
                            "explored_nodes": 1,
                            "simplex_iterations": 24026,
                            "explored_time": 9.44,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.08,
                            "explored_nodes": 1,
                            "simplex_iterations": 31719,
                            "explored_time": 7.02,
                            "work_units": 10.0
                        },
                        {
                            "gap": 41.981,
                            "total_time": 10.61,
                            "explored_nodes": 31,
                            "simplex_iterations": 53954,
                            "explored_time": 10.6,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 7.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 21296,
                            "explored_time": 7.44,
                            "work_units": 10.0
                        },
                        {
                            "gap": 16.6223,
                            "total_time": 11.82,
                            "explored_nodes": 209,
                            "simplex_iterations": 59770,
                            "explored_time": 11.81,
                            "work_units": 12.78
                        },
                        {
                            "gap": 42.1204,
                            "total_time": 12.15,
                            "explored_nodes": 1,
                            "simplex_iterations": 32239,
                            "explored_time": 12.11,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 30047,
                            "explored_time": 7.95,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "fbcc126d-c302-4e66-ae73-9ccd80214d44",
                        "9a5899e1-a817-4e71-98b6-df4fe00147ca"
                    ]
                },
                {
                    "id": "bfdc758c-b673-4a74-b008-27b8abc3a65b",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_lifted_priority_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier-style)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads) to find potential blocks\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Identify sub-block with max 1-machine LB\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint (Weak Relaxation)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.lifted_priority_cuts = pyo.ConstraintList()\n        # Standard LB cut\n        m.lifted_priority_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection for Lifting\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                limit = global_max - tails[op_i]\n                end_j = min(i + WINDOW, n_sub)\n                \n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Impact Density Scoring\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Lifted Cuts\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity (Logic Lifting)\n            # Enforce consistency of the sequence\n            m.lifted_priority_cuts.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting (Tightened Local Precedence)\n            # If i -> k -> j, enforces distance S_j >= S_i + p_i + p_k\n            m.lifted_priority_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n    \n            # (C) Conditional Carlier Lifting (Global Objective Lifting)\n            # If i -> k -> j is active, Cmax must respect the specific head of i, \n            # tail of j, and the sum of processing times of the triplet.\n            # This lifts the static Carlier bound into the B&B tree conditionally.\n            term_seq = y_ik + y_kj # equals 2 if sequence i->k->j holds\n            seq_bound = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n            \n            m.lifted_priority_cuts.add(\n                m.Cmax >= seq_bound - m.bigM * (2 - term_seq)\n            )\n    \n            cuts_added += 3\n    \n    add_lifted_priority_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_lifted_priority_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier-style)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads) to find potential blocks\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Identify sub-block with max 1-machine LB\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint (Weak Relaxation)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.lifted_priority_cuts = pyo.ConstraintList()\n    # Standard LB cut\n    m.lifted_priority_cuts.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection for Lifting\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            limit = global_max - tails[op_i]\n            end_j = min(i + WINDOW, n_sub)\n            \n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Impact Density Scoring\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Lifted Cuts\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity (Logic Lifting)\n        # Enforce consistency of the sequence\n        m.lifted_priority_cuts.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting (Tightened Local Precedence)\n        # If i -> k -> j, enforces distance S_j >= S_i + p_i + p_k\n        m.lifted_priority_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n\n        # (C) Conditional Carlier Lifting (Global Objective Lifting)\n        # If i -> k -> j is active, Cmax must respect the specific head of i, \n        # tail of j, and the sum of processing times of the triplet.\n        # This lifts the static Carlier bound into the B&B tree conditionally.\n        term_seq = y_ik + y_kj # equals 2 if sequence i->k->j holds\n        seq_bound = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n        \n        m.lifted_priority_cuts.add(\n            m.Cmax >= seq_bound - m.bigM * (2 - term_seq)\n        )\n\n        cuts_added += 3\n\nadd_lifted_priority_cuts(model)",
                        "idea": "We apply **Conditional Carlier Lifting** to the Priority-Scored cuts. By lifting the static Carlier bound into the MILP variables, we generate cuts that enforce $C_{max} \\ge r_i + p_i + p_k + p_j + q_j$ specifically when the solver explores the sequence $i \\to k \\to j$. This tightens the global lower bound dynamically within specific branches of the search tree, surpassing the static global bound. This is combined with **Metric Lifting** (which tightens local start times $S_j$) and **Triangle Transitivity** to propagate the impact of critical triplets across the feasible region."
                    },
                    "fitness": 22.290768615658337,
                    "solver_reports": [
                        {
                            "gap": 15.7164,
                            "total_time": 13.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 31914,
                            "explored_time": 13.76,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 11.88,
                            "explored_nodes": 1,
                            "simplex_iterations": 32435,
                            "explored_time": 11.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 31924,
                            "explored_time": 9.67,
                            "work_units": 10.01
                        },
                        {
                            "gap": 19.5154,
                            "total_time": 13.88,
                            "explored_nodes": 3,
                            "simplex_iterations": 42325,
                            "explored_time": 13.87,
                            "work_units": 10.03
                        },
                        {
                            "total_time": 10.43,
                            "explored_nodes": 1,
                            "simplex_iterations": 31021,
                            "explored_time": 10.38,
                            "work_units": 10.0
                        },
                        {
                            "gap": 4.7436,
                            "total_time": 12.87,
                            "explored_nodes": 2578,
                            "simplex_iterations": 160449,
                            "explored_time": 12.87,
                            "work_units": 11.87
                        },
                        {
                            "gap": 25.2266,
                            "total_time": 12.9,
                            "explored_nodes": 1,
                            "simplex_iterations": 47584,
                            "explored_time": 12.88,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.24,
                            "explored_nodes": 1,
                            "simplex_iterations": 36974,
                            "explored_time": 10.18,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Lifted",
                    "parents_id": [
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "4641f8eb-56a0-46d6-b00b-87359d19a15e",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_block_accumulation_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Calculate Earliest Starts (Heads) and Tails\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Bottleneck Detection)\n        # We group operations by machine and search for subsets that maximize the relaxed Carlier bound.\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort operations by release time (Head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_block_lb = -1\n            best_block = []\n            \n            # Iterate all sub-windows to find the tightest bottleneck block\n            # LB = min(r) + sum(p) + min(q) over the block\n            for u in range(n_ops):\n                p_sum = 0\n                # Since sorted by head, min_head is heads[sorted_ops[u]]\n                r_block = heads[sorted_ops[u]]\n                current_min_tail = float('inf')\n                \n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    if tails[op_v] < current_min_tail:\n                        current_min_tail = tails[op_v]\n                    \n                    lb = r_block + p_sum + current_min_tail\n                    \n                    # Keep the block if it's the tightest found so far\n                    if lb > best_block_lb:\n                        best_block_lb = lb\n                        best_block = sorted_ops[u : v+1]\n    \n            if best_block_lb > 0 and len(best_block) > 1:\n                candidates.append({\n                    'mid': mid, \n                    'lb': best_block_lb, \n                    'ops': best_block,\n                    'min_head': min(heads[o] for o in best_block),\n                    'min_tail': min(tails[o] for o in best_block)\n                })\n    \n        if not candidates: return\n        \n        # Sort candidates by LB descending to prioritize critical paths\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max_lb = candidates[0]['lb']\n        \n        # Filter: Focus on blocks with LB >= 85% of the global max\n        critical_blocks = [c for c in candidates if c['lb'] >= 0.85 * global_max_lb]\n    \n        # 3. Add Workload Accumulation Cuts Restricted to Critical Blocks\n        m.block_accumulation = pyo.ConstraintList()\n        cuts_added = 0\n        BUDGET = 200\n        \n        def get_y(u, v):\n            # Returns binary expression for \"u precedes v\"\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for block in critical_blocks:\n            if cuts_added >= BUDGET: break\n            \n            ops = block['ops']\n            min_h = block['min_head']\n            min_t = block['min_tail']\n            \n            # Prioritize pivots with high processing times (high impact on schedule)\n            pivots = sorted(ops, key=lambda x: m.p[x], reverse=True)\n            \n            for k_op in pivots:\n                if cuts_added >= BUDGET: break\n                \n                # --- Cut A: Input Accumulation ---\n                # S_k >= min_head_block + sum_{j in block, j!=k} (p_j * y_jk)\n                # This bounds S_k by the volume of block predecessors.\n                lhs_in = m.S[k_op]\n                rhs_in = min_h + sum(m.p[j] * get_y(j, k_op) for j in ops if j != k_op)\n                m.block_accumulation.add(lhs_in >= rhs_in)\n                cuts_added += 1\n                \n                if cuts_added >= BUDGET: break\n                \n                # --- Cut B: Output Accumulation ---\n                # Cmax >= S_k + p_k + sum_{j in block, j!=k} (p_j * y_kj) + min_tail_block\n                # This links the pivot to the global makespan via block successors.\n                lhs_out = m.Cmax\n                rhs_out = m.S[k_op] + m.p[k_op] + \\\n                          sum(m.p[j] * get_y(k_op, j) for j in ops if j != k_op) + min_t\n                m.block_accumulation.add(lhs_out >= rhs_out)\n                cuts_added += 1\n    \n    add_critical_block_accumulation_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_critical_block_accumulation_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Calculate Earliest Starts (Heads) and Tails\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Bottleneck Detection)\n    # We group operations by machine and search for subsets that maximize the relaxed Carlier bound.\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort operations by release time (Head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_block_lb = -1\n        best_block = []\n        \n        # Iterate all sub-windows to find the tightest bottleneck block\n        # LB = min(r) + sum(p) + min(q) over the block\n        for u in range(n_ops):\n            p_sum = 0\n            # Since sorted by head, min_head is heads[sorted_ops[u]]\n            r_block = heads[sorted_ops[u]]\n            current_min_tail = float('inf')\n            \n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                if tails[op_v] < current_min_tail:\n                    current_min_tail = tails[op_v]\n                \n                lb = r_block + p_sum + current_min_tail\n                \n                # Keep the block if it's the tightest found so far\n                if lb > best_block_lb:\n                    best_block_lb = lb\n                    best_block = sorted_ops[u : v+1]\n\n        if best_block_lb > 0 and len(best_block) > 1:\n            candidates.append({\n                'mid': mid, \n                'lb': best_block_lb, \n                'ops': best_block,\n                'min_head': min(heads[o] for o in best_block),\n                'min_tail': min(tails[o] for o in best_block)\n            })\n\n    if not candidates: return\n    \n    # Sort candidates by LB descending to prioritize critical paths\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max_lb = candidates[0]['lb']\n    \n    # Filter: Focus on blocks with LB >= 85% of the global max\n    critical_blocks = [c for c in candidates if c['lb'] >= 0.85 * global_max_lb]\n\n    # 3. Add Workload Accumulation Cuts Restricted to Critical Blocks\n    m.block_accumulation = pyo.ConstraintList()\n    cuts_added = 0\n    BUDGET = 200\n    \n    def get_y(u, v):\n        # Returns binary expression for \"u precedes v\"\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for block in critical_blocks:\n        if cuts_added >= BUDGET: break\n        \n        ops = block['ops']\n        min_h = block['min_head']\n        min_t = block['min_tail']\n        \n        # Prioritize pivots with high processing times (high impact on schedule)\n        pivots = sorted(ops, key=lambda x: m.p[x], reverse=True)\n        \n        for k_op in pivots:\n            if cuts_added >= BUDGET: break\n            \n            # --- Cut A: Input Accumulation ---\n            # S_k >= min_head_block + sum_{j in block, j!=k} (p_j * y_jk)\n            # This bounds S_k by the volume of block predecessors.\n            lhs_in = m.S[k_op]\n            rhs_in = min_h + sum(m.p[j] * get_y(j, k_op) for j in ops if j != k_op)\n            m.block_accumulation.add(lhs_in >= rhs_in)\n            cuts_added += 1\n            \n            if cuts_added >= BUDGET: break\n            \n            # --- Cut B: Output Accumulation ---\n            # Cmax >= S_k + p_k + sum_{j in block, j!=k} (p_j * y_kj) + min_tail_block\n            # This links the pivot to the global makespan via block successors.\n            lhs_out = m.Cmax\n            rhs_out = m.S[k_op] + m.p[k_op] + \\\n                      sum(m.p[j] * get_y(k_op, j) for j in ops if j != k_op) + min_t\n            m.block_accumulation.add(lhs_out >= rhs_out)\n            cuts_added += 1\n\nadd_critical_block_accumulation_cuts(model)",
                        "idea": "We introduce **Critical Block Workload Accumulation Cuts**. This strategy improves Parent 1's pivot-based accumulation logic by restricting it to the **critical bottleneck blocks** identified via the robust window detection of Parent 2. Instead of summing workloads over the entire machine (which creates weak bounds due to loose release/tail times), we identify specific operation subsets $\\Omega$ (blocks) that maximize the bottleneck lower bound $LB = \\min_{j \\in \\Omega} r_j + \\sum_{j \\in \\Omega} p_j + \\min_{j \\in \\Omega} q_j$. For each operation $k$ in these critical blocks, we impose a Big-M-free constraint ensuring $S_k$ exceeds the block's earliest availability plus the processing volume of all block members sequenced before it. This fuses the **local tightness** of Parent 2 with the **structural aggregation** of Parent 1."
                    },
                    "fitness": 13.471668693416207,
                    "solver_reports": [
                        {
                            "total_time": 5.99,
                            "explored_nodes": 1,
                            "simplex_iterations": 26749,
                            "explored_time": 5.95,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 5.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 26958,
                            "explored_time": 5.86,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 32287,
                            "explored_time": 6.45,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.52,
                            "explored_nodes": 57,
                            "simplex_iterations": 51412,
                            "explored_time": 9.51,
                            "work_units": 10.07
                        },
                        {
                            "total_time": 6.79,
                            "explored_nodes": 1,
                            "simplex_iterations": 32499,
                            "explored_time": 6.71,
                            "work_units": 10.0
                        },
                        {
                            "gap": 23.1147,
                            "total_time": 10.03,
                            "explored_nodes": 87,
                            "simplex_iterations": 97450,
                            "explored_time": 10.02,
                            "work_units": 10.82
                        },
                        {
                            "total_time": 7.34,
                            "explored_nodes": 1,
                            "simplex_iterations": 31192,
                            "explored_time": 7.31,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 6.18,
                            "explored_nodes": 1,
                            "simplex_iterations": 28238,
                            "explored_time": 6.13,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "9a5899e1-a817-4e71-98b6-df4fe00147ca",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                }
            ],
            23.42775824076793
        ],
        [
            [
                {
                    "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
                        "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 12.38,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 12.33,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.5,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.4,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.34,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.75,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.74,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.31,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 12.21,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 13.01,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 13.01,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.01,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.96,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "46ee3ca5-e05a-4910-b129-900e3c5185b3",
                        "101328eb-f36a-4ac9-9863-144887bd3271"
                    ]
                },
                {
                    "id": "23f863a1-a5e8-4533-81dc-bb9c7b47fd7d",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_scored_carlier_metric_cuts(m):\n        import pyomo.environ as pyo\n        \n        # 1. Preprocessing: Calculate Heads (r_j) and Tails (q_j)\n        heads = {}\n        tails = {}\n        # Heads: Earliest start time from job start\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Tails: Minimum time from op completion to job end\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Machine-wise Carlier Bound)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time for 1-machine bound check\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Find tightest subset on this machine\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Bound Tightening\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.scored_carlier_cuts = pyo.ConstraintList()\n        m.scored_carlier_cuts.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Generation (Parent 2 Strategy)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Pruning (Parent 1/2 integration)\n                limit = global_max - tails[op_i]\n                end_j = min(i + WINDOW, n_sub)\n                \n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Impact Density Score (Parent 2)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({'ops': (op_i, op_k, op_j), 'score': score})\n    \n        # 5. Apply Hybrid Cuts\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity (Logic)\n            m.scored_carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting (Tighten Local Start Times)\n            # If i->k->j, force S_j >= S_i + p_i + p_k\n            m.scored_carlier_cuts.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n    \n            # (C) Conditional Carlier Lifting (Tighten Global Objective)\n            # If i->k->j, lift Cmax using the specific head/tail bounds\n            seq_bound = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n            term_seq = y_ik + y_kj # equals 2 if sequence holds\n            m.scored_carlier_cuts.add(\n                m.Cmax >= seq_bound - m.bigM * (2 - term_seq)\n            )\n            \n            cuts_added += 3\n    \n    add_scored_carlier_metric_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_scored_carlier_metric_cuts(m):\n    import pyomo.environ as pyo\n    \n    # 1. Preprocessing: Calculate Heads (r_j) and Tails (q_j)\n    heads = {}\n    tails = {}\n    # Heads: Earliest start time from job start\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Tails: Minimum time from op completion to job end\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Machine-wise Carlier Bound)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time for 1-machine bound check\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Find tightest subset on this machine\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Bound Tightening\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.scored_carlier_cuts = pyo.ConstraintList()\n    m.scored_carlier_cuts.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Generation (Parent 2 Strategy)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Pruning (Parent 1/2 integration)\n            limit = global_max - tails[op_i]\n            end_j = min(i + WINDOW, n_sub)\n            \n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Impact Density Score (Parent 2)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({'ops': (op_i, op_k, op_j), 'score': score})\n\n    # 5. Apply Hybrid Cuts\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity (Logic)\n        m.scored_carlier_cuts.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting (Tighten Local Start Times)\n        # If i->k->j, force S_j >= S_i + p_i + p_k\n        m.scored_carlier_cuts.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n\n        # (C) Conditional Carlier Lifting (Tighten Global Objective)\n        # If i->k->j, lift Cmax using the specific head/tail bounds\n        seq_bound = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n        term_seq = y_ik + y_kj # equals 2 if sequence holds\n        m.scored_carlier_cuts.add(\n            m.Cmax >= seq_bound - m.bigM * (2 - term_seq)\n        )\n        \n        cuts_added += 3\n\nadd_scored_carlier_metric_cuts(model)",
                        "idea": "We implement **Scored Carlier-Metric Lifting**, which fuses the robust **Impact Density Scoring** from Parent 2 with the aggressive **Conditional Carlier Lifting** from Parent 1. By filtering candidate triplets $(i, k, j)$ based on the ratio of processing mass to release-time spread (Impact Density), we identify the most ambiguous regions of the schedule. For these high-priority triplets, we apply a triple-layer cut: (1) **Triangle Transitivity** to enforce logical consistency, (2) **Metric Lifting** to tighten start time variables ($S_j$), and (3) **Conditional Carlier Lifting** to dynamically lower-bound the objective ($C_{max}$) if the sequence $i \to k \to j$ is active. This ensures that the global bound is strengthened exactly where the schedule is most constrained."
                    },
                    "fitness": 21.94159072477931,
                    "solver_reports": [
                        {
                            "gap": 21.7835,
                            "total_time": 12.74,
                            "explored_nodes": 1,
                            "simplex_iterations": 31484,
                            "explored_time": 12.7,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 10.42,
                            "explored_nodes": 1,
                            "simplex_iterations": 34500,
                            "explored_time": 10.37,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.65,
                            "explored_nodes": 1,
                            "simplex_iterations": 34052,
                            "explored_time": 9.59,
                            "work_units": 10.0
                        },
                        {
                            "gap": 20.7031,
                            "total_time": 12.57,
                            "explored_nodes": 87,
                            "simplex_iterations": 64549,
                            "explored_time": 12.56,
                            "work_units": 10.62
                        },
                        {
                            "total_time": 9.95,
                            "explored_nodes": 1,
                            "simplex_iterations": 30462,
                            "explored_time": 9.88,
                            "work_units": 10.0
                        },
                        {
                            "gap": 1.9789,
                            "total_time": 13.02,
                            "explored_nodes": 1250,
                            "simplex_iterations": 109135,
                            "explored_time": 13.01,
                            "work_units": 11.24
                        },
                        {
                            "gap": 21.9858,
                            "total_time": 12.55,
                            "explored_nodes": 1,
                            "simplex_iterations": 45558,
                            "explored_time": 12.53,
                            "work_units": 10.0
                        },
                        {
                            "gap": 30.9524,
                            "total_time": 9.83,
                            "explored_nodes": 1,
                            "simplex_iterations": 30010,
                            "explored_time": 9.78,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Intersection",
                    "parents_id": [
                        "bfdc758c-b673-4a74-b008-27b8abc3a65b",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "5ab8224b-c52e-4cce-a19d-1aa090d549a3",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_block_interval_cuts(m):\n        # Helper to access binary variables respecting (j1, k1) < (j2, k2) ordering\n        def get_y_uv(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n        # 1. Calculate static release times (Heads) to order operations\n        heads = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        m.block_interval_cuts = pyo.ConstraintList()\n    \n        # 3. Apply Block-Wide Interval Cut for each machine\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            \n            # Sort operations by release time to predict natural sequence\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            \n            # Select predicted First (u) and Last (v) operations\n            u = sorted_ops[0]\n            v = sorted_ops[-1]\n            \n            # Construct sum of processing times for all intermediate ops k\n            # The term (y_uk + y_kv - 1) equals 1 iff u -> k -> v, otherwise <= 0\n            inter_expr = 0\n            for k in sorted_ops[1:-1]:\n                y_uk = get_y_uv(u, k)\n                y_kv = get_y_uv(k, v)\n                inter_expr += m.p[k] * (y_uk + y_kv - 1)\n            \n            # Enforce S_v >= S_u + p_u + intermediates, active only if u -> v\n            # We use 3*bigM to safely relax the constraint when v -> u or logic fails\n            y_uv = get_y_uv(u, v)\n            m.block_interval_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + inter_expr - (3 * m.bigM) * (1 - y_uv)\n            )\n    \n    add_block_interval_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_block_interval_cuts(m):\n    # Helper to access binary variables respecting (j1, k1) < (j2, k2) ordering\n    def get_y_uv(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n    # 1. Calculate static release times (Heads) to order operations\n    heads = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    m.block_interval_cuts = pyo.ConstraintList()\n\n    # 3. Apply Block-Wide Interval Cut for each machine\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        \n        # Sort operations by release time to predict natural sequence\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        \n        # Select predicted First (u) and Last (v) operations\n        u = sorted_ops[0]\n        v = sorted_ops[-1]\n        \n        # Construct sum of processing times for all intermediate ops k\n        # The term (y_uk + y_kv - 1) equals 1 iff u -> k -> v, otherwise <= 0\n        inter_expr = 0\n        for k in sorted_ops[1:-1]:\n            y_uk = get_y_uv(u, k)\n            y_kv = get_y_uv(k, v)\n            inter_expr += m.p[k] * (y_uk + y_kv - 1)\n        \n        # Enforce S_v >= S_u + p_u + intermediates, active only if u -> v\n        # We use 3*bigM to safely relax the constraint when v -> u or logic fails\n        y_uv = get_y_uv(u, v)\n        m.block_interval_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + inter_expr - (3 * m.bigM) * (1 - y_uv)\n        )\n\nadd_block_interval_cuts(model)",
                        "idea": "We introduce **Block-Wide Interval Lifting** to generalize the local triplet logic. Instead of finding scored triplets, we consider the entire set of operations on a machine as a potential sequence block. By sorting operations based on release times (heads), we identify the likely first ($u$) and last ($v$) operations. We then construct a constraint $S_v \\ge S_u + p_u + \\sum p_k(y_{uk} + y_{kv} - 1)$ which forces the time span between $u$ and $v$ to accommodate the processing times of all intermediate operations $k$ sequenced between them. This aggregates local transitivity relations into a single, powerful linear cut that tightens the schedule along the machine's critical path."
                    },
                    "fitness": 9.639864941171329,
                    "solver_reports": [
                        {
                            "total_time": 14.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 74986,
                            "explored_time": 14.39,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 14.72,
                            "explored_nodes": 1,
                            "simplex_iterations": 55952,
                            "explored_time": 14.67,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 16.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 62619,
                            "explored_time": 16.22,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.19,
                            "explored_nodes": 2734,
                            "simplex_iterations": 340940,
                            "explored_time": 9.18,
                            "work_units": 10.07
                        },
                        {
                            "total_time": 16.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 70097,
                            "explored_time": 16.44,
                            "work_units": 10.01
                        },
                        {
                            "gap": 34.1348,
                            "total_time": 13.25,
                            "explored_nodes": 7581,
                            "simplex_iterations": 394256,
                            "explored_time": 13.23,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 7.97,
                            "explored_nodes": 1044,
                            "simplex_iterations": 144539,
                            "explored_time": 7.95,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 15.62,
                            "explored_nodes": 1,
                            "simplex_iterations": 64462,
                            "explored_time": 15.56,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "bfdc758c-b673-4a74-b008-27b8abc3a65b"
                    ]
                },
                {
                    "id": "768d55be-56bc-4138-bb99-be3a57c52c52",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_critical_block_lifting(m):\n        import pyomo.environ as pyo\n    \n        # 1. Static Analysis (Heads/Tails) for Block Detection\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n                \n        for j in m.J:\n            t = 0\n            for k in range(len(m.K)-1, -1, -1):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Strategy from Parent 2)\n        # We identify blocks of operations on a machine that maximize the Carlier Bound.\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        critical_blocks = []\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            # Sort operations by release time (head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Find the sub-window with the tightest Lower Bound (Head + Sum(P) + MinTail)\n            for i in range(n_ops):\n                p_sum = 0\n                r_val = heads[sorted_ops[i]]\n                min_tail = float('inf')\n                \n                for j in range(i, n_ops):\n                    op = sorted_ops[j]\n                    p_sum += m.p[op]\n                    if tails[op] < min_tail:\n                        min_tail = tails[op]\n                    \n                    lb = r_val + p_sum + min_tail\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[i : j+1]\n            \n            # Keep blocks large enough to support lifting\n            if len(best_sub) >= 3:\n                critical_blocks.append({\n                    'lb': best_lb,\n                    'ops': best_sub\n                })\n    \n        # Sort blocks by LB to prioritize the most critical bottlenecks\n        critical_blocks.sort(key=lambda x: x['lb'], reverse=True)\n    \n        # 3. Generate Critical Block Lifting Cuts (Hybrid Strategy)\n        # Apply Parent 1's multi-node lifting specifically within Parent 2's critical blocks.\n        m.critical_lifting = pyo.ConstraintList()\n        \n        def get_y(u, v):\n            # Helper to retrieve y_uv correctly oriented\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n        added = 0\n        budget = 200\n        \n        for block in critical_blocks:\n            if added >= budget: break\n            ops = block['ops']\n            \n            # We select pairs (u, v) that span the block to maximize intermediate lifting.\n            # u is chosen from the start of the block, v from the end.\n            starts = ops[:2]\n            ends = ops[-2:]\n            \n            for u in starts:\n                for v in ends:\n                    if u == v: continue\n                    # Ensure natural flow direction based on heads\n                    if heads[u] >= heads[v]: continue\n                    if added >= budget: break\n                    \n                    # Identify intermediates k strictly inside the block (excluding u, v)\n                    intermediates = [k for k in ops if k != u and k != v]\n                    if not intermediates: continue\n    \n                    # Calculate Lifting Term: sum( p_k * (y_uk + y_kv - 1) )\n                    # This term adds p_k to the required distance if u -> k -> v.\n                    lift_term = 0\n                    for k in intermediates:\n                        lift_term += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n                    \n                    y_uv = get_y(u, v)\n                    \n                    # Constraint: S_v >= S_u + p_u + Sum(Intermediates) - BigM*(1 - y_uv)\n                    # If u precedes v (y_uv=1), the gap S_v - S_u must accommodate p_u PLUS\n                    # any intermediates k that fall between them in the sequence.\n                    m.critical_lifting.add(\n                        m.S[v] >= m.S[u] + m.p[u] + lift_term - m.bigM * (1 - y_uv)\n                    )\n                    added += 1\n    \n    add_critical_block_lifting(model)\n\n    return model\n",
                        "added_cut": "def add_critical_block_lifting(m):\n    import pyomo.environ as pyo\n\n    # 1. Static Analysis (Heads/Tails) for Block Detection\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n            \n    for j in m.J:\n        t = 0\n        for k in range(len(m.K)-1, -1, -1):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Strategy from Parent 2)\n    # We identify blocks of operations on a machine that maximize the Carlier Bound.\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    critical_blocks = []\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        # Sort operations by release time (head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Find the sub-window with the tightest Lower Bound (Head + Sum(P) + MinTail)\n        for i in range(n_ops):\n            p_sum = 0\n            r_val = heads[sorted_ops[i]]\n            min_tail = float('inf')\n            \n            for j in range(i, n_ops):\n                op = sorted_ops[j]\n                p_sum += m.p[op]\n                if tails[op] < min_tail:\n                    min_tail = tails[op]\n                \n                lb = r_val + p_sum + min_tail\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[i : j+1]\n        \n        # Keep blocks large enough to support lifting\n        if len(best_sub) >= 3:\n            critical_blocks.append({\n                'lb': best_lb,\n                'ops': best_sub\n            })\n\n    # Sort blocks by LB to prioritize the most critical bottlenecks\n    critical_blocks.sort(key=lambda x: x['lb'], reverse=True)\n\n    # 3. Generate Critical Block Lifting Cuts (Hybrid Strategy)\n    # Apply Parent 1's multi-node lifting specifically within Parent 2's critical blocks.\n    m.critical_lifting = pyo.ConstraintList()\n    \n    def get_y(u, v):\n        # Helper to retrieve y_uv correctly oriented\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n    added = 0\n    budget = 200\n    \n    for block in critical_blocks:\n        if added >= budget: break\n        ops = block['ops']\n        \n        # We select pairs (u, v) that span the block to maximize intermediate lifting.\n        # u is chosen from the start of the block, v from the end.\n        starts = ops[:2]\n        ends = ops[-2:]\n        \n        for u in starts:\n            for v in ends:\n                if u == v: continue\n                # Ensure natural flow direction based on heads\n                if heads[u] >= heads[v]: continue\n                if added >= budget: break\n                \n                # Identify intermediates k strictly inside the block (excluding u, v)\n                intermediates = [k for k in ops if k != u and k != v]\n                if not intermediates: continue\n\n                # Calculate Lifting Term: sum( p_k * (y_uk + y_kv - 1) )\n                # This term adds p_k to the required distance if u -> k -> v.\n                lift_term = 0\n                for k in intermediates:\n                    lift_term += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n                \n                y_uv = get_y(u, v)\n                \n                # Constraint: S_v >= S_u + p_u + Sum(Intermediates) - BigM*(1 - y_uv)\n                # If u precedes v (y_uv=1), the gap S_v - S_u must accommodate p_u PLUS\n                # any intermediates k that fall between them in the sequence.\n                m.critical_lifting.add(\n                    m.S[v] >= m.S[u] + m.p[u] + lift_term - m.bigM * (1 - y_uv)\n                )\n                added += 1\n\nadd_critical_block_lifting(model)",
                        "idea": "We introduce **Critical Block Lifting Cuts**, fusing Parent 2's bottleneck detection with Parent 1's multi-node lifting logic. Instead of relying on static release/tail times (which can be loose), we use Parent 2's logic to identify high-contention 'critical blocks' where the machine is a bottleneck. Within these blocks, we apply Parent 1's lifting strategy: imposing constraints of the form $S_v \\ge S_u + p_u + \\sum p_k(y_{uk} + y_{kv} - 1)$ for boundary pairs $(u, v)$. This enforces that the time gap between operations in a critical block must account for all intermediate tasks dynamically sequenced between them, significantly tightening the relaxation in the model's most constrained subspaces."
                    },
                    "fitness": 10.264436715561187,
                    "solver_reports": [
                        {
                            "total_time": 12.97,
                            "explored_nodes": 1,
                            "simplex_iterations": 47338,
                            "explored_time": 12.92,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 15.73,
                            "explored_nodes": 1,
                            "simplex_iterations": 65068,
                            "explored_time": 15.69,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 12.32,
                            "explored_nodes": 1,
                            "simplex_iterations": 61881,
                            "explored_time": 12.27,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 8.21,
                            "explored_nodes": 764,
                            "simplex_iterations": 198532,
                            "explored_time": 8.2,
                            "work_units": 10.05
                        },
                        {
                            "total_time": 15.21,
                            "explored_nodes": 1,
                            "simplex_iterations": 59880,
                            "explored_time": 15.16,
                            "work_units": 10.01
                        },
                        {
                            "gap": 32.0677,
                            "total_time": 11.39,
                            "explored_nodes": 7262,
                            "simplex_iterations": 407714,
                            "explored_time": 11.37,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 9.09,
                            "explored_nodes": 222,
                            "simplex_iterations": 130103,
                            "explored_time": 9.07,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 13.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 70288,
                            "explored_time": 13.54,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Hybrid",
                    "parents_id": [
                        "242809ef-1b25-4c45-a4bf-814a3ea73440",
                        "4641f8eb-56a0-46d6-b00b-87359d19a15e"
                    ]
                },
                {
                    "id": "2568c50a-5aef-4143-97e5-f09f015e160d",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_impact_scored_accumulation_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Calculate Heads (Earliest Start) and Tails (Tail to Job End)\n        heads = {}\n        tails = {}\n        # Forward pass\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        # Backward pass\n        for j in m.J:\n            t = 0\n            # Safely iterate backwards over the machine sequence\n            for k in sorted(m.K, reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Identify Critical Blocks (Bottleneck Detection)\n        # Group operations by machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort operations by release time (Head)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_block = []\n            \n            # Identify the sub-window [u, v] that maximizes the Carlier Bound\n            for u in range(n_ops):\n                p_sum = 0\n                r_block = heads[sorted_ops[u]]\n                current_min_tail = float('inf')\n                \n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    if tails[op_v] < current_min_tail:\n                        current_min_tail = tails[op_v]\n                    \n                    # LB = r + P + q\n                    lb = r_block + p_sum + current_min_tail\n                    \n                    if lb > best_lb:\n                        best_lb = lb\n                        best_block = sorted_ops[u : v+1]\n    \n            if best_lb > 0 and len(best_block) > 1:\n                candidates.append({\n                    'mid': mid,\n                    'lb': best_lb, \n                    'ops': best_block,\n                    'min_head': min(heads[o] for o in best_block),\n                    'min_tail': min(tails[o] for o in best_block)\n                })\n    \n        if not candidates: return\n        # Sort blocks by LB descending to focus on the global bottleneck\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max_lb = candidates[0]['lb']\n    \n        # 3. Add Scored Accumulation Cuts\n        m.impact_accumulation = pyo.ConstraintList()\n        cuts_added = 0\n        BUDGET = 200\n        \n        def get_y(u, v):\n            # Helper to get the correct binary variable or expression for \"u precedes v\"\n            if u < v:\n                return m.y[u[0], u[1], v[0], v[1]]\n            else:\n                return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        for block in candidates:\n            if cuts_added >= BUDGET: break\n            \n            # Filter: Only target blocks close to the critical path\n            if block['lb'] < 0.85 * global_max_lb: continue\n            \n            ops = block['ops']\n            min_h = block['min_head']\n            min_t = block['min_tail']\n            \n            # Impact Scoring: Select only the top 3 most \"heavy\" operations as pivots.\n            # This incorporates Parent 2's idea of filtering by impact/density,\n            # preventing budget exhaustion on weak pivots.\n            pivots = sorted(ops, key=lambda x: m.p[x], reverse=True)[:3]\n            \n            for k_op in pivots:\n                if cuts_added >= BUDGET: break\n                \n                # (A) Input Accumulation Cut (from Parent 1)\n                # S_k >= min_head_block + sum_{j in block, j!=k} (p_j * y_jk)\n                lhs_in = m.S[k_op]\n                rhs_in = min_h + sum(m.p[j] * get_y(j, k_op) for j in ops if j != k_op)\n                m.impact_accumulation.add(lhs_in >= rhs_in)\n                cuts_added += 1\n                \n                if cuts_added >= BUDGET: break\n                \n                # (B) Output Accumulation Cut\n                # Cmax >= S_k + p_k + sum_{j in block, j!=k} (p_j * y_kj) + min_tail_block\n                lhs_out = m.Cmax\n                rhs_out = m.S[k_op] + m.p[k_op] + \\\n                          sum(m.p[j] * get_y(k_op, j) for j in ops if j != k_op) + min_t\n                m.impact_accumulation.add(lhs_out >= rhs_out)\n                cuts_added += 1\n\n    return model\n",
                        "added_cut": "def add_impact_scored_accumulation_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Calculate Heads (Earliest Start) and Tails (Tail to Job End)\n    heads = {}\n    tails = {}\n    # Forward pass\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    # Backward pass\n    for j in m.J:\n        t = 0\n        # Safely iterate backwards over the machine sequence\n        for k in sorted(m.K, reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Identify Critical Blocks (Bottleneck Detection)\n    # Group operations by machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort operations by release time (Head)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_block = []\n        \n        # Identify the sub-window [u, v] that maximizes the Carlier Bound\n        for u in range(n_ops):\n            p_sum = 0\n            r_block = heads[sorted_ops[u]]\n            current_min_tail = float('inf')\n            \n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                if tails[op_v] < current_min_tail:\n                    current_min_tail = tails[op_v]\n                \n                # LB = r + P + q\n                lb = r_block + p_sum + current_min_tail\n                \n                if lb > best_lb:\n                    best_lb = lb\n                    best_block = sorted_ops[u : v+1]\n\n        if best_lb > 0 and len(best_block) > 1:\n            candidates.append({\n                'mid': mid,\n                'lb': best_lb, \n                'ops': best_block,\n                'min_head': min(heads[o] for o in best_block),\n                'min_tail': min(tails[o] for o in best_block)\n            })\n\n    if not candidates: return\n    # Sort blocks by LB descending to focus on the global bottleneck\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max_lb = candidates[0]['lb']\n\n    # 3. Add Scored Accumulation Cuts\n    m.impact_accumulation = pyo.ConstraintList()\n    cuts_added = 0\n    BUDGET = 200\n    \n    def get_y(u, v):\n        # Helper to get the correct binary variable or expression for \"u precedes v\"\n        if u < v:\n            return m.y[u[0], u[1], v[0], v[1]]\n        else:\n            return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    for block in candidates:\n        if cuts_added >= BUDGET: break\n        \n        # Filter: Only target blocks close to the critical path\n        if block['lb'] < 0.85 * global_max_lb: continue\n        \n        ops = block['ops']\n        min_h = block['min_head']\n        min_t = block['min_tail']\n        \n        # Impact Scoring: Select only the top 3 most \"heavy\" operations as pivots.\n        # This incorporates Parent 2's idea of filtering by impact/density,\n        # preventing budget exhaustion on weak pivots.\n        pivots = sorted(ops, key=lambda x: m.p[x], reverse=True)[:3]\n        \n        for k_op in pivots:\n            if cuts_added >= BUDGET: break\n            \n            # (A) Input Accumulation Cut (from Parent 1)\n            # S_k >= min_head_block + sum_{j in block, j!=k} (p_j * y_jk)\n            lhs_in = m.S[k_op]\n            rhs_in = min_h + sum(m.p[j] * get_y(j, k_op) for j in ops if j != k_op)\n            m.impact_accumulation.add(lhs_in >= rhs_in)\n            cuts_added += 1\n            \n            if cuts_added >= BUDGET: break\n            \n            # (B) Output Accumulation Cut\n            # Cmax >= S_k + p_k + sum_{j in block, j!=k} (p_j * y_kj) + min_tail_block\n            lhs_out = m.Cmax\n            rhs_out = m.S[k_op] + m.p[k_op] + \\\n                      sum(m.p[j] * get_y(k_op, j) for j in ops if j != k_op) + min_t\n            m.impact_accumulation.add(lhs_out >= rhs_out)\n            cuts_added += 1",
                        "idea": "We introduce **Impact-Scored Accumulation Cuts**, a hybrid strategy that minimizes joint violations by combining the **structural strength** of Parent 1's accumulation cuts with the **selection efficiency** of Parent 2. We first detect critical bottleneck blocks using Carlier bounds (common to both). Then, instead of applying cuts to all operations (which dilutes Parent 1's budget) or using simple triplets (Parent 2's weaker form), we select only the top process-heavy operations within these blocks as pivots. This allows us to enforce tight **subset-sum bounds** ($S_k \\ge r_{block} + \\sum p_j y_{jk}$) specifically where processing mass is highest, effectively tightening the relaxation on the critical path."
                    },
                    "fitness": 10.0,
                    "solver_reports": [
                        {
                            "gap": 95.8767,
                            "total_time": 12.95,
                            "explored_nodes": 1,
                            "simplex_iterations": 34683,
                            "explored_time": 12.91,
                            "work_units": 10.05
                        },
                        {
                            "gap": 96.7323,
                            "total_time": 15.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 27131,
                            "explored_time": 15.81,
                            "work_units": 10.06
                        },
                        {
                            "gap": 96.7595,
                            "total_time": 15.29,
                            "explored_nodes": 1,
                            "simplex_iterations": 28980,
                            "explored_time": 15.24,
                            "work_units": 10.03
                        },
                        {
                            "gap": 92.175,
                            "total_time": 19.26,
                            "explored_nodes": 15,
                            "simplex_iterations": 30620,
                            "explored_time": 19.25,
                            "work_units": 10.02
                        },
                        {
                            "gap": 96.9489,
                            "total_time": 13.7,
                            "explored_nodes": 1,
                            "simplex_iterations": 29713,
                            "explored_time": 13.64,
                            "work_units": 10.02
                        },
                        {
                            "gap": 32.9271,
                            "total_time": 12.19,
                            "explored_nodes": 3239,
                            "simplex_iterations": 227059,
                            "explored_time": 12.18,
                            "work_units": 10.0
                        },
                        {
                            "gap": 92.0874,
                            "total_time": 18.46,
                            "explored_nodes": 1,
                            "simplex_iterations": 14843,
                            "explored_time": 18.44,
                            "work_units": 10.11
                        },
                        {
                            "gap": 96.6214,
                            "total_time": 14.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 29064,
                            "explored_time": 14.86,
                            "work_units": 10.03
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "4641f8eb-56a0-46d6-b00b-87359d19a15e",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "6e8be0de-4bc9-4007-a35a-ea9829524873",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_dense_path_carlier_cuts(m):\n        import pyomo.environ as pyo\n    \n        # 1. Timing Analysis (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Machine Grouping\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # Helper for precedence variable y_uv (1 if u -> v)\n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        candidates = []\n    \n        # 3. Density-Based Candidate Generation\n        # Uses Parent 2's scoring to find high-contention regions\n        for mid, ops in mach_ops.items():\n            if len(ops) < 3: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            for i in range(n_ops):\n                u = sorted_ops[i]\n                for j in range(i + 1, n_ops):\n                    v = sorted_ops[j]\n                    \n                    # Identify potentially active intermediates k\n                    intermediates = []\n                    p_sum_k = 0\n                    for k in ops:\n                        if k == u or k == v: continue\n                        # Heuristic filter: k must physically fit in the timeline window\n                        # to be a valid candidate for the sequence u -> k -> v\n                        if heads[k] >= heads[u] and tails[k] >= tails[v]:\n                            intermediates.append(k)\n                            p_sum_k += m.p[k]\n                    \n                    if not intermediates: continue\n    \n                    # Density Score = Total Mass / Time Spread\n                    spread = heads[v] - heads[u]\n                    if spread < 1.0: spread = 1.0\n                    density = (m.p[u] + m.p[v] + p_sum_k) / spread\n                    \n                    candidates.append({\n                        'pair': (u, v),\n                        'intermediates': intermediates,\n                        'score': density\n                    })\n    \n        # 4. Apply Combined Cuts\n        candidates.sort(key=lambda x: x['score'], reverse=True)\n        m.dense_path_cuts = pyo.ConstraintList()\n        \n        added = 0\n        BUDGET = 150\n        \n        for cand in candidates:\n            if added >= BUDGET: break\n            u, v = cand['pair']\n            inter = cand['intermediates']\n            y_uv = get_y(u, v)\n            \n            # (A) Transitivity Logic (Inherited from Parent 1)\n            # Enforce consistency: if u->k and k->v, then u->v must hold.\n            # This prevents the solver from 'cheating' the lifting by violating transitivity.\n            # We apply this only to a subset to manage constraint count.\n            for k in inter[:3]: \n                y_uk = get_y(u, k)\n                y_kv = get_y(k, v)\n                m.dense_path_cuts.add(y_uk + y_kv - y_uv <= 1)\n    \n            # (B) Build Multi-Node Lifting Term\n            # Sum [ p_k * (y_uk + y_kv - 1) ]\n            # This term activates (adds p_k) only if k is sequenced strictly between u and v.\n            lift_term = 0\n            for k in inter:\n                lift_term += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n                \n            # (C) Local Metric Lifting (Inherited from Parent 2)\n            # Tightens the start time of v relative to u based on intermediates\n            m.dense_path_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + lift_term - m.bigM * (1 - y_uv)\n            )\n            \n            # (D) Global Carlier Lifting (Inherited from Parent 1)\n            # Lifts Cmax lower bound using the aggregated path duration.\n            # If u->...->v is active, Cmax must respect the full path length + heads/tails.\n            term_global = heads[u] + m.p[u] + m.p[v] + tails[v]\n            m.dense_path_cuts.add(\n                m.Cmax >= term_global + lift_term - m.bigM * (1 - y_uv)\n            )\n            \n            added += 3\n    \n    add_dense_path_carlier_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_dense_path_carlier_cuts(m):\n    import pyomo.environ as pyo\n\n    # 1. Timing Analysis (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Machine Grouping\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # Helper for precedence variable y_uv (1 if u -> v)\n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    candidates = []\n\n    # 3. Density-Based Candidate Generation\n    # Uses Parent 2's scoring to find high-contention regions\n    for mid, ops in mach_ops.items():\n        if len(ops) < 3: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        for i in range(n_ops):\n            u = sorted_ops[i]\n            for j in range(i + 1, n_ops):\n                v = sorted_ops[j]\n                \n                # Identify potentially active intermediates k\n                intermediates = []\n                p_sum_k = 0\n                for k in ops:\n                    if k == u or k == v: continue\n                    # Heuristic filter: k must physically fit in the timeline window\n                    # to be a valid candidate for the sequence u -> k -> v\n                    if heads[k] >= heads[u] and tails[k] >= tails[v]:\n                        intermediates.append(k)\n                        p_sum_k += m.p[k]\n                \n                if not intermediates: continue\n\n                # Density Score = Total Mass / Time Spread\n                spread = heads[v] - heads[u]\n                if spread < 1.0: spread = 1.0\n                density = (m.p[u] + m.p[v] + p_sum_k) / spread\n                \n                candidates.append({\n                    'pair': (u, v),\n                    'intermediates': intermediates,\n                    'score': density\n                })\n\n    # 4. Apply Combined Cuts\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    m.dense_path_cuts = pyo.ConstraintList()\n    \n    added = 0\n    BUDGET = 150\n    \n    for cand in candidates:\n        if added >= BUDGET: break\n        u, v = cand['pair']\n        inter = cand['intermediates']\n        y_uv = get_y(u, v)\n        \n        # (A) Transitivity Logic (Inherited from Parent 1)\n        # Enforce consistency: if u->k and k->v, then u->v must hold.\n        # This prevents the solver from 'cheating' the lifting by violating transitivity.\n        # We apply this only to a subset to manage constraint count.\n        for k in inter[:3]: \n            y_uk = get_y(u, k)\n            y_kv = get_y(k, v)\n            m.dense_path_cuts.add(y_uk + y_kv - y_uv <= 1)\n\n        # (B) Build Multi-Node Lifting Term\n        # Sum [ p_k * (y_uk + y_kv - 1) ]\n        # This term activates (adds p_k) only if k is sequenced strictly between u and v.\n        lift_term = 0\n        for k in inter:\n            lift_term += m.p[k] * (get_y(u, k) + get_y(k, v) - 1)\n            \n        # (C) Local Metric Lifting (Inherited from Parent 2)\n        # Tightens the start time of v relative to u based on intermediates\n        m.dense_path_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + lift_term - m.bigM * (1 - y_uv)\n        )\n        \n        # (D) Global Carlier Lifting (Inherited from Parent 1)\n        # Lifts Cmax lower bound using the aggregated path duration.\n        # If u->...->v is active, Cmax must respect the full path length + heads/tails.\n        term_global = heads[u] + m.p[u] + m.p[v] + tails[v]\n        m.dense_path_cuts.add(\n            m.Cmax >= term_global + lift_term - m.bigM * (1 - y_uv)\n        )\n        \n        added += 3\n\nadd_dense_path_carlier_cuts(model)",
                        "idea": "We introduce **Dense-Path Carlier Cuts**, which fuse Parent 2's multi-node density scoring with Parent 1's global objective lifting and transitivity logic. By identifying high-contention pairs $(u, v)$ and their potential intermediates $K$, we formulate a composite lifting term $\\sum_{k \\in K} p_k(y_{uk} + y_{kv} - 1)$ that tightens both the local start time $S_v$ and the global makespan $C_{max}$. Crucially, we integrate explicit transitivity constraints ($y_{uk} + y_{kv} - y_{uv} \\le 1$) from Parent 1 to enforce logical consistency, ensuring the solver cannot evade the tightened bounds by violating sequence ordering."
                    },
                    "fitness": 9.60561400878452,
                    "solver_reports": [
                        {
                            "total_time": 12.17,
                            "explored_nodes": 1,
                            "simplex_iterations": 68395,
                            "explored_time": 12.13,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 13.53,
                            "explored_nodes": 1,
                            "simplex_iterations": 66285,
                            "explored_time": 13.48,
                            "work_units": 10.01
                        },
                        {
                            "total_time": 11.64,
                            "explored_nodes": 1,
                            "simplex_iterations": 48442,
                            "explored_time": 11.57,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.46,
                            "explored_nodes": 2031,
                            "simplex_iterations": 269455,
                            "explored_time": 9.44,
                            "work_units": 10.04
                        },
                        {
                            "total_time": 13.41,
                            "explored_nodes": 1,
                            "simplex_iterations": 58231,
                            "explored_time": 13.35,
                            "work_units": 10.0
                        },
                        {
                            "gap": 34.252,
                            "total_time": 11.1,
                            "explored_nodes": 9216,
                            "simplex_iterations": 412648,
                            "explored_time": 11.07,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.2,
                            "explored_nodes": 764,
                            "simplex_iterations": 159648,
                            "explored_time": 10.18,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 13.16,
                            "explored_nodes": 1,
                            "simplex_iterations": 64267,
                            "explored_time": 13.12,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "bfdc758c-b673-4a74-b008-27b8abc3a65b",
                        "242809ef-1b25-4c45-a4bf-814a3ea73440"
                    ]
                },
                {
                    "id": "a1be8606-43cc-42b7-b23c-40098d05d110",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_tightened_triplet_cuts(m):\n        # 1. Precompute Timing (Heads/Tails)\n        heads, tails = {}, {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection (Carlier-style)\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint (Static LB)\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.tightened_triplets = pyo.ConstraintList()\n        m.tightened_triplets.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection (Impact Density)\n        # Focus on blocks close to the critical path (Parent 2 logic)\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                limit = global_max - tails[op_i]\n                end_j = min(i + WINDOW, n_sub)\n                \n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Tightened Cuts\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Transitivity\n            m.tightened_triplets.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting (Var-Var tightness)\n            # Enforces S_j >= S_i + p_i + p_k if i->k->j\n            m.tightened_triplets.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n            # (C) Tightened Conditional Carlier (Global tightness)\n            # Calculate sequence-specific LB\n            seq_lb = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n            \n            # Only add cut if this sequence forces a higher bound than the static global_max\n            if seq_lb > global_max:\n                # Calculated tight Big-M\n                M_local = seq_lb - global_max\n                \n                # If i->k->j is active (sum=2), Cmax >= seq_lb\n                # If inactive (sum<=1), RHS relaxes safely to <= global_max\n                m.tightened_triplets.add(\n                    m.Cmax >= seq_lb - M_local * (2 - (y_ik + y_kj))\n                )\n                cuts_added += 1\n    \n    add_tightened_triplet_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_tightened_triplet_cuts(m):\n    # 1. Precompute Timing (Heads/Tails)\n    heads, tails = {}, {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection (Carlier-style)\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint (Static LB)\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.tightened_triplets = pyo.ConstraintList()\n    m.tightened_triplets.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection (Impact Density)\n    # Focus on blocks close to the critical path (Parent 2 logic)\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            limit = global_max - tails[op_i]\n            end_j = min(i + WINDOW, n_sub)\n            \n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Tightened Cuts\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Transitivity\n        m.tightened_triplets.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting (Var-Var tightness)\n        # Enforces S_j >= S_i + p_i + p_k if i->k->j\n        m.tightened_triplets.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\n        # (C) Tightened Conditional Carlier (Global tightness)\n        # Calculate sequence-specific LB\n        seq_lb = heads[op_i] + m.p[op_i] + m.p[op_k] + m.p[op_j] + tails[op_j]\n        \n        # Only add cut if this sequence forces a higher bound than the static global_max\n        if seq_lb > global_max:\n            # Calculated tight Big-M\n            M_local = seq_lb - global_max\n            \n            # If i->k->j is active (sum=2), Cmax >= seq_lb\n            # If inactive (sum<=1), RHS relaxes safely to <= global_max\n            m.tightened_triplets.add(\n                m.Cmax >= seq_lb - M_local * (2 - (y_ik + y_kj))\n            )\n            cuts_added += 1\n\nadd_tightened_triplet_cuts(model)",
                        "idea": "We combine the **Impact Density Scoring** from Parent 2 (identifying congested triplets) with a **Tightened Conditional Carlier Bound** derived from Parent 1. By calculating a triplet-specific penalty $M_{local} = LB_{seq} - LB_{global}$, we enforce $C_{max} \\ge LB_{seq}$ strictly when the sequence $i \\to k \\to j$ is chosen, avoiding the looseness of global Big-M constraints. This is integrated with **Metric Lifting** (local precedence tightening) and **Triangle Transitivity** to robustly prune the search space in critical blocks."
                    },
                    "fitness": 23.42775824076793,
                    "solver_reports": [
                        {
                            "total_time": 11.81,
                            "explored_nodes": 1,
                            "simplex_iterations": 27620,
                            "explored_time": 11.78,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.63,
                            "explored_nodes": 1,
                            "simplex_iterations": 37042,
                            "explored_time": 10.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 11.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 28803,
                            "explored_time": 11.79,
                            "work_units": 10.01
                        },
                        {
                            "gap": 18.4011,
                            "total_time": 13.07,
                            "explored_nodes": 1,
                            "simplex_iterations": 43262,
                            "explored_time": 13.05,
                            "work_units": 10.06
                        },
                        {
                            "total_time": 12.04,
                            "explored_nodes": 1,
                            "simplex_iterations": 30048,
                            "explored_time": 11.95,
                            "work_units": 10.0
                        },
                        {
                            "gap": 0.0,
                            "total_time": 12.6,
                            "explored_nodes": 564,
                            "simplex_iterations": 81963,
                            "explored_time": 12.6,
                            "work_units": 11.03
                        },
                        {
                            "gap": 22.6865,
                            "total_time": 12.59,
                            "explored_nodes": 1,
                            "simplex_iterations": 42173,
                            "explored_time": 12.58,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 10.51,
                            "explored_nodes": 1,
                            "simplex_iterations": 37354,
                            "explored_time": 10.46,
                            "work_units": 10.0
                        }
                    ],
                    "generator": "Min_Violation",
                    "parents_id": [
                        "bfdc758c-b673-4a74-b008-27b8abc3a65b",
                        "c863bdc4-2d6d-4d90-abfb-a8725223b5d5"
                    ]
                },
                {
                    "id": "a9d5fa37-53e0-43d3-b897-4595398fc360",
                    "chromosome": {
                        "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_sequence_dependent_cuts(m):\n        # 1. Precompute Heads (Est. Start) and Tails (Est. Remaining Work)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Group Operations by Machine\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        # 3. Helper for disjunctive variables\n        def get_y(u, v):\n            # Returns expression for y_uv (1 if u -> v)\n            if u == v: return 0\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n    \n        # 4. Identify Critical Blocks and Add Generalized Cuts\n        m.seq_cuts = pyo.ConstraintList()\n        candidates = []\n    \n        # Calculate static Carlier bounds to find critical blocks\n        for mid, ops in mach_ops.items():\n            if len(ops) < 2: continue\n            s_ops = sorted(ops, key=lambda x: heads[x])\n            n = len(s_ops)\n            best_lb = -1\n            best_pair = None\n            \n            # Find sub-block [u...v] with max LB\n            for i in range(n):\n                p_sum = 0\n                r_u = heads[s_ops[i]]\n                for k in range(i, n):\n                    p_sum += m.p[s_ops[k]]\n                    q_v = tails[s_ops[k]]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_pair = (s_ops[i], s_ops[k])\n            \n            if best_pair:\n                candidates.append({'pair': best_pair, 'lb': best_lb, 'ops': ops})\n    \n        # Sort by tightness and apply cuts to top blocks\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        \n        for cand in candidates[:6]:\n            u, v = cand['pair']\n            all_ops = cand['ops']\n            y_uv = get_y(u, v)\n    \n            # (A) Generalized Block Metric Lifting (Sum-Cut)\n            # Instead of single triplets, we sum processing times of ALL intermediate ops k\n            # Term (y_uk + y_kv - 1) is 1 iff u -> k -> v.\n            # This tightens S_v based on the set of jobs scheduled between u and v.\n            intermediate_sum = 0\n            for k_op in all_ops:\n                if k_op == u or k_op == v: continue\n                term = get_y(u, k_op) + get_y(k_op, v) - 1\n                intermediate_sum += m.p[k_op] * term\n    \n            m.seq_cuts.add(\n                m.S[v] >= m.S[u] + m.p[u] + intermediate_sum - m.bigM * (1 - y_uv)\n            )\n    \n            # (B) Tail Bound Propagation\n            # Ensure the tightened start time S_v propagates to Cmax via the tail of v\n            m.seq_cuts.add(\n                m.Cmax >= m.S[v] + m.p[v] + tails[v]\n            )\n    \n            # (C) Transitivity Anchor\n            # Enforce transitivity for the largest intermediate job to strengthen LP relaxation\n            best_k = max([k for k in all_ops if k!=u and k!=v], key=lambda x: m.p[x], default=None)\n            if best_k:\n                m.seq_cuts.add(get_y(u, best_k) + get_y(best_k, v) - y_uv <= 1)\n    \n    add_sequence_dependent_cuts(model)\n\n    return model\n",
                        "added_cut": "def add_sequence_dependent_cuts(m):\n    # 1. Precompute Heads (Est. Start) and Tails (Est. Remaining Work)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Group Operations by Machine\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    # 3. Helper for disjunctive variables\n    def get_y(u, v):\n        # Returns expression for y_uv (1 if u -> v)\n        if u == v: return 0\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n\n    # 4. Identify Critical Blocks and Add Generalized Cuts\n    m.seq_cuts = pyo.ConstraintList()\n    candidates = []\n\n    # Calculate static Carlier bounds to find critical blocks\n    for mid, ops in mach_ops.items():\n        if len(ops) < 2: continue\n        s_ops = sorted(ops, key=lambda x: heads[x])\n        n = len(s_ops)\n        best_lb = -1\n        best_pair = None\n        \n        # Find sub-block [u...v] with max LB\n        for i in range(n):\n            p_sum = 0\n            r_u = heads[s_ops[i]]\n            for k in range(i, n):\n                p_sum += m.p[s_ops[k]]\n                q_v = tails[s_ops[k]]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_pair = (s_ops[i], s_ops[k])\n        \n        if best_pair:\n            candidates.append({'pair': best_pair, 'lb': best_lb, 'ops': ops})\n\n    # Sort by tightness and apply cuts to top blocks\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    \n    for cand in candidates[:6]:\n        u, v = cand['pair']\n        all_ops = cand['ops']\n        y_uv = get_y(u, v)\n\n        # (A) Generalized Block Metric Lifting (Sum-Cut)\n        # Instead of single triplets, we sum processing times of ALL intermediate ops k\n        # Term (y_uk + y_kv - 1) is 1 iff u -> k -> v.\n        # This tightens S_v based on the set of jobs scheduled between u and v.\n        intermediate_sum = 0\n        for k_op in all_ops:\n            if k_op == u or k_op == v: continue\n            term = get_y(u, k_op) + get_y(k_op, v) - 1\n            intermediate_sum += m.p[k_op] * term\n\n        m.seq_cuts.add(\n            m.S[v] >= m.S[u] + m.p[u] + intermediate_sum - m.bigM * (1 - y_uv)\n        )\n\n        # (B) Tail Bound Propagation\n        # Ensure the tightened start time S_v propagates to Cmax via the tail of v\n        m.seq_cuts.add(\n            m.Cmax >= m.S[v] + m.p[v] + tails[v]\n        )\n\n        # (C) Transitivity Anchor\n        # Enforce transitivity for the largest intermediate job to strengthen LP relaxation\n        best_k = max([k for k in all_ops if k!=u and k!=v], key=lambda x: m.p[x], default=None)\n        if best_k:\n            m.seq_cuts.add(get_y(u, best_k) + get_y(best_k, v) - y_uv <= 1)\n\nadd_sequence_dependent_cuts(model)",
                        "idea": "We mutate the individual's 'Conditional Carlier Lifting' by generalizing it from single triplets to **Block Sequence Lifting**. Instead of adding many weak cuts for individual triplets ($i, k, j$), we identify the most critical pair $(u, v)$ (start and end) of a machine block and enforce a **Sum-based Precedence Cut**. This constraint, $S_v \\ge S_u + p_u + \\sum_{k} p_k(y_{uk} + y_{kv} - 1)$, aggregates the processing times of *all* intermediate operations $k$ that the solver schedules between $u$ and $v$. This creates a much tighter feasible region for start times than pairwise disjunctions alone. Combined with a **Tail Bound** ($C_{max} \\ge S_v + p_v + q_v$), this ensures that local sequencing decisions in critical blocks immediately impact the global lower bound."
                    },
                    "fitness": 10.213142792157408,
                    "solver_reports": [
                        {
                            "total_time": 11.85,
                            "explored_nodes": 1,
                            "simplex_iterations": 70279,
                            "explored_time": 11.8,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 13.8,
                            "explored_nodes": 1,
                            "simplex_iterations": 53731,
                            "explored_time": 13.77,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 15.91,
                            "explored_nodes": 1,
                            "simplex_iterations": 56866,
                            "explored_time": 15.83,
                            "work_units": 10.0
                        },
                        {
                            "total_time": 9.38,
                            "explored_nodes": 2312,
                            "simplex_iterations": 265678,
                            "explored_time": 9.37,
                            "work_units": 10.1
                        },
                        {
                            "total_time": 16.37,
                            "explored_nodes": 1,
                            "simplex_iterations": 56966,
                            "explored_time": 16.31,
                            "work_units": 10.0
                        },
                        {
                            "gap": 32.0208,
                            "total_time": 9.83,
                            "explored_nodes": 5928,
                            "simplex_iterations": 365690,
                            "explored_time": 9.83,
                            "work_units": 10.05
                        },
                        {
                            "total_time": 9.13,
                            "explored_nodes": 1796,
                            "simplex_iterations": 174373,
                            "explored_time": 9.12,
                            "work_units": 10.05
                        },
                        {
                            "gap": 95.2053,
                            "total_time": 17.33,
                            "explored_nodes": 1,
                            "simplex_iterations": 62292,
                            "explored_time": 17.28,
                            "work_units": 10.05
                        }
                    ],
                    "generator": "General",
                    "parents_id": [
                        "bfdc758c-b673-4a74-b008-27b8abc3a65b"
                    ]
                }
            ],
            23.42775824076793
        ]
    ],
    "best_fitness": 23.42775824076793,
    "best_indiv": {
        "id": "c863bdc4-2d6d-4d90-abfb-a8725223b5d5",
        "chromosome": {
            "full_code": "def create_model(n_jobs, n_machines, times, machines):\n    \"\"\"\n    Build a Pyomo model for the 0-based Job-Shop Scheduling Problem.\n\n    Parameters\n    n_jobs      : int                   # number of jobs (rows)\n    n_machines  : int                   # number of machines (columns)\n    times       : list[list[int]]       # p[j][k]   processing time of op k in job j\n    machines    : list[list[int]]       # m[j][k]   machine (0-based) that op k of job j uses\n\n    Returns:\n    model : pyo.ConcreteModel\n    \"\"\"\n    model = pyo.ConcreteModel()\n\n    #  Sets \n    model.J = pyo.RangeSet(0, n_jobs    - 1)              # jobs\n    model.K = pyo.RangeSet(0, n_machines - 1)             # position in the job\n    model.O = pyo.Set(initialize=[(j, k) for j in model.J for k in model.K],\n                      dimen=2)                             # all operations\n\n    #  Parameters \n    model.p = pyo.Param(model.O,\n                        initialize=lambda m, j, k: times[j][k],\n                        within=pyo.PositiveIntegers)\n\n    model.mach = pyo.Param(model.O,\n                           initialize=lambda m, j, k: machines[j][k],\n                           within=pyo.NonNegativeIntegers)\n\n    big_M = sum(sum(row) for row in times)                # simple safe big-M\n    model.bigM = pyo.Param(initialize=big_M, mutable=True)\n\n    #  Variables \n    model.S     = pyo.Var(model.O, domain=pyo.NonNegativeReals)  # start times\n    model.Cmax  = pyo.Var(domain=pyo.NonNegativeReals)\n\n    # y[(j,k,j',k')] is defined only when the two ops share a machine\n    def pair_gen():\n        for (j1, k1) in model.O:\n            for (j2, k2) in model.O:\n                if (j1, k1) < (j2, k2) and machines[j1][k1] == machines[j2][k2]:\n                    yield (j1, k1, j2, k2)\n    model.Pairs = pyo.Set(initialize=list(pair_gen()), dimen=4)\n\n    model.y = pyo.Var(model.Pairs, domain=pyo.Binary)\n\n    #  Objective \n    model.obj = pyo.Objective(expr=model.Cmax, sense=pyo.minimize)\n\n    #  Constraints \n    # (1) precedence inside each job\n    def prec_rule(m, j, k):\n        if k < n_machines - 1:\n            return m.S[j, k + 1] >= m.S[j, k] + m.p[j, k]\n        return pyo.Constraint.Skip\n    model.precedence = pyo.Constraint(model.J, model.K, rule=prec_rule)\n\n    # (2) disjunctive (machine) constraints\n    def disj1_rule(m, j1, k1, j2, k2):\n        return (m.S[j1, k1] + m.p[j1, k1]\n                <= m.S[j2, k2] + m.bigM * (1 - m.y[j1, k1, j2, k2]))\n    model.disj1 = pyo.Constraint(model.Pairs, rule=disj1_rule)\n\n    def disj2_rule(m, j1, k1, j2, k2):\n        return (m.S[j2, k2] + m.p[j2, k2]\n                <= m.S[j1, k1] + m.bigM *      m.y[j1, k1, j2, k2])\n    model.disj2 = pyo.Constraint(model.Pairs, rule=disj2_rule)\n\n    # (3) makespan definition\n    def makespan_rule(m, j):\n        return m.Cmax >= m.S[j, n_machines - 1] + m.p[j, n_machines - 1]\n    model.makespan = pyo.Constraint(model.J, rule=makespan_rule)\n\n    # Additional constraints placeholder.\n    def add_priority_carlier_cuts(m):\n        # 1. Timing Calculation (Heads/Tails)\n        heads = {}\n        tails = {}\n        for j in m.J:\n            t = 0\n            for k in m.K:\n                heads[j, k] = t\n                t += m.p[j, k]\n        for j in m.J:\n            t = 0\n            for k in sorted(list(m.K), reverse=True):\n                tails[j, k] = t\n                t += m.p[j, k]\n    \n        # 2. Critical Block Detection\n        mach_ops = {}\n        for (j, k) in m.O:\n            mid = m.mach[j, k]\n            if mid not in mach_ops: mach_ops[mid] = []\n            mach_ops[mid].append((j, k))\n    \n        candidates = []\n        for mid, ops in mach_ops.items():\n            if not ops: continue\n            # Sort by release time (heads)\n            sorted_ops = sorted(ops, key=lambda x: heads[x])\n            n_ops = len(sorted_ops)\n            \n            best_lb = -1\n            best_sub = []\n            \n            # Maximize Carlier LB: r_u + sum(p) + q_v\n            for u in range(n_ops):\n                p_sum = 0\n                r_u = heads[sorted_ops[u]]\n                for v in range(u, n_ops):\n                    op_v = sorted_ops[v]\n                    p_sum += m.p[op_v]\n                    q_v = tails[op_v]\n                    lb = r_u + p_sum + q_v\n                    if lb > best_lb:\n                        best_lb = lb\n                        best_sub = sorted_ops[u : v+1]\n            \n            if best_lb > 0:\n                candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n    \n        if not candidates: return\n    \n        # 3. Global Constraint\n        candidates.sort(key=lambda x: x['lb'], reverse=True)\n        global_max = candidates[0]['lb']\n        m.priority_carlier = pyo.ConstraintList()\n        m.priority_carlier.add(m.Cmax >= global_max)\n    \n        # 4. Scored Triplet Collection\n        # Focus on blocks close to the global critical path\n        targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n        triplets = []\n        WINDOW = 8  # Locality clamp from Parent 2\n        \n        for target in targets:\n            ops = target['ops']\n            n_sub = len(ops)\n            if n_sub < 3: continue\n            \n            for i in range(n_sub):\n                op_i = ops[i]\n                # Dynamic Horizon Limit (Parent 1)\n                # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n                limit = global_max - tails[op_i]\n                \n                # Clamp search range with Window (Parent 2)\n                end_j = min(i + WINDOW, n_sub)\n                for j in range(i + 1, end_j):\n                    op_j = ops[j]\n                    \n                    # Dynamic pruning (Parent 1)\n                    if heads[op_j] >= limit: break\n                    \n                    for k in range(i + 1, j):\n                        op_k = ops[k]\n                        \n                        # Refined pruning\n                        if heads[op_j] >= global_max - tails[op_k]: continue\n    \n                        # Score: Impact Density\n                        # Prefer high processing mass over small time spreads (high ambiguity)\n                        spread = heads[op_j] - heads[op_i]\n                        if spread < 1e-5: spread = 1e-5\n                        \n                        impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                        score = impact / spread\n                        \n                        triplets.append({\n                            'ops': (op_i, op_k, op_j), \n                            'score': score\n                        })\n    \n        # 5. Apply Cuts based on Score (Budgeted)\n        triplets.sort(key=lambda x: x['score'], reverse=True)\n        \n        def get_y(u, v):\n            if u < v: return m.y[u[0], u[1], v[0], v[1]]\n            else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n            \n        cuts_added = 0\n        CUT_BUDGET = 200\n        \n        for t in triplets:\n            if cuts_added >= CUT_BUDGET: break\n            \n            op_i, op_k, op_j = t['ops']\n            y_ij = get_y(op_i, op_j)\n            y_ik = get_y(op_i, op_k)\n            y_kj = get_y(op_k, op_j)\n            \n            # (A) Triangle Transitivity\n            m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n            \n            # (B) Metric Lifting\n            # If i->k->j, then S_j >= S_i + p_i + p_k\n            m.priority_carlier.add(\n                m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n                m.p[op_k] * (y_ik + y_kj - 1) - \n                m.bigM * (1 - y_ij)\n            )\n            cuts_added += 2\n    \n    add_priority_carlier_cuts(model)\n\n    return model\n",
            "added_cut": "def add_priority_carlier_cuts(m):\n    # 1. Timing Calculation (Heads/Tails)\n    heads = {}\n    tails = {}\n    for j in m.J:\n        t = 0\n        for k in m.K:\n            heads[j, k] = t\n            t += m.p[j, k]\n    for j in m.J:\n        t = 0\n        for k in sorted(list(m.K), reverse=True):\n            tails[j, k] = t\n            t += m.p[j, k]\n\n    # 2. Critical Block Detection\n    mach_ops = {}\n    for (j, k) in m.O:\n        mid = m.mach[j, k]\n        if mid not in mach_ops: mach_ops[mid] = []\n        mach_ops[mid].append((j, k))\n\n    candidates = []\n    for mid, ops in mach_ops.items():\n        if not ops: continue\n        # Sort by release time (heads)\n        sorted_ops = sorted(ops, key=lambda x: heads[x])\n        n_ops = len(sorted_ops)\n        \n        best_lb = -1\n        best_sub = []\n        \n        # Maximize Carlier LB: r_u + sum(p) + q_v\n        for u in range(n_ops):\n            p_sum = 0\n            r_u = heads[sorted_ops[u]]\n            for v in range(u, n_ops):\n                op_v = sorted_ops[v]\n                p_sum += m.p[op_v]\n                q_v = tails[op_v]\n                lb = r_u + p_sum + q_v\n                if lb > best_lb:\n                    best_lb = lb\n                    best_sub = sorted_ops[u : v+1]\n        \n        if best_lb > 0:\n            candidates.append({'mid': mid, 'lb': best_lb, 'ops': best_sub})\n\n    if not candidates: return\n\n    # 3. Global Constraint\n    candidates.sort(key=lambda x: x['lb'], reverse=True)\n    global_max = candidates[0]['lb']\n    m.priority_carlier = pyo.ConstraintList()\n    m.priority_carlier.add(m.Cmax >= global_max)\n\n    # 4. Scored Triplet Collection\n    # Focus on blocks close to the global critical path\n    targets = [c for c in candidates if c['lb'] >= 0.90 * global_max][:3]\n    triplets = []\n    WINDOW = 8  # Locality clamp from Parent 2\n    \n    for target in targets:\n        ops = target['ops']\n        n_sub = len(ops)\n        if n_sub < 3: continue\n        \n        for i in range(n_sub):\n            op_i = ops[i]\n            # Dynamic Horizon Limit (Parent 1)\n            # If j starts after this limit, it cannot fit in the Carlier bound if i precedes it\n            limit = global_max - tails[op_i]\n            \n            # Clamp search range with Window (Parent 2)\n            end_j = min(i + WINDOW, n_sub)\n            for j in range(i + 1, end_j):\n                op_j = ops[j]\n                \n                # Dynamic pruning (Parent 1)\n                if heads[op_j] >= limit: break\n                \n                for k in range(i + 1, j):\n                    op_k = ops[k]\n                    \n                    # Refined pruning\n                    if heads[op_j] >= global_max - tails[op_k]: continue\n\n                    # Score: Impact Density\n                    # Prefer high processing mass over small time spreads (high ambiguity)\n                    spread = heads[op_j] - heads[op_i]\n                    if spread < 1e-5: spread = 1e-5\n                    \n                    impact = m.p[op_i] + m.p[op_k] + m.p[op_j]\n                    score = impact / spread\n                    \n                    triplets.append({\n                        'ops': (op_i, op_k, op_j), \n                        'score': score\n                    })\n\n    # 5. Apply Cuts based on Score (Budgeted)\n    triplets.sort(key=lambda x: x['score'], reverse=True)\n    \n    def get_y(u, v):\n        if u < v: return m.y[u[0], u[1], v[0], v[1]]\n        else:     return 1 - m.y[v[0], v[1], u[0], u[1]]\n        \n    cuts_added = 0\n    CUT_BUDGET = 200\n    \n    for t in triplets:\n        if cuts_added >= CUT_BUDGET: break\n        \n        op_i, op_k, op_j = t['ops']\n        y_ij = get_y(op_i, op_j)\n        y_ik = get_y(op_i, op_k)\n        y_kj = get_y(op_k, op_j)\n        \n        # (A) Triangle Transitivity\n        m.priority_carlier.add(y_ik + y_kj - y_ij <= 1)\n        \n        # (B) Metric Lifting\n        # If i->k->j, then S_j >= S_i + p_i + p_k\n        m.priority_carlier.add(\n            m.S[op_j] >= m.S[op_i] + m.p[op_i] + \n            m.p[op_k] * (y_ik + y_kj - 1) - \n            m.bigM * (1 - y_ij)\n        )\n        cuts_added += 2\n\nadd_priority_carlier_cuts(model)",
            "idea": "We introduce **Priority-Scored Carlier Cuts**, which integrate the robust critical block detection of the parents with a new **impact density scoring** mechanism. Instead of simply iterating through operations and exhausting the cut budget on the earliest pairs (as in the parents), this method generates all candidate triplets $(i, k, j)$ that satisfy both the **local window constraint** (from Parent 2) and the **dynamic horizon feasibility** (from Parent 1). These candidates are then scored by the ratio of their total processing time to their release time spread and sorted. This ensures the limited budget (200 cuts) is applied specifically to the most ambiguous and congested sub-structures, maximizing the tightening effect on the relaxation."
        },
        "fitness": 23.42775824076793,
        "solver_reports": [
            {
                "total_time": 12.38,
                "explored_nodes": 1,
                "simplex_iterations": 27620,
                "explored_time": 12.33,
                "work_units": 10.0
            },
            {
                "total_time": 10.55,
                "explored_nodes": 1,
                "simplex_iterations": 37042,
                "explored_time": 10.5,
                "work_units": 10.0
            },
            {
                "total_time": 11.4,
                "explored_nodes": 1,
                "simplex_iterations": 28803,
                "explored_time": 11.34,
                "work_units": 10.01
            },
            {
                "gap": 18.4011,
                "total_time": 13.75,
                "explored_nodes": 1,
                "simplex_iterations": 43262,
                "explored_time": 13.74,
                "work_units": 10.06
            },
            {
                "total_time": 12.31,
                "explored_nodes": 1,
                "simplex_iterations": 30048,
                "explored_time": 12.21,
                "work_units": 10.0
            },
            {
                "gap": 0.0,
                "total_time": 13.01,
                "explored_nodes": 564,
                "simplex_iterations": 81963,
                "explored_time": 13.01,
                "work_units": 11.03
            },
            {
                "gap": 22.6865,
                "total_time": 12.8,
                "explored_nodes": 1,
                "simplex_iterations": 42173,
                "explored_time": 12.78,
                "work_units": 10.0
            },
            {
                "total_time": 11.01,
                "explored_nodes": 1,
                "simplex_iterations": 37354,
                "explored_time": 10.96,
                "work_units": 10.0
            }
        ],
        "generator": "Intersection",
        "parents_id": [
            "46ee3ca5-e05a-4910-b129-900e3c5185b3",
            "101328eb-f36a-4ac9-9863-144887bd3271"
        ]
    },
    "state": 19
}